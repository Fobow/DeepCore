================== Exp 0 ==================
dataset: CIFAR10, model: ResNet18, selection: GraNd, num_ex: 1, epochs: 100, fraction: 0.2, seed: 5274, lr: 0.1, save_path: ./result, resume: , device: cuda, checkpoint_name: CIFAR10_ResNet18_GraNd_exp0_epoch100_2024-03-18 14:13:27.174351_0.2_
Files already downloaded and verified
Files already downloaded and verified
called grand, with 1 ensemble and 10 epochs
=> Early Training Epoch #0
| Epoch [  0/ 10] Iter[  1/391]		Loss: 2.4754
| Epoch [  0/ 10] Iter[ 21/391]		Loss: 2.5623
| Epoch [  0/ 10] Iter[ 41/391]		Loss: 2.1857
| Epoch [  0/ 10] Iter[ 61/391]		Loss: 2.1414
| Epoch [  0/ 10] Iter[ 81/391]		Loss: 2.1049
| Epoch [  0/ 10] Iter[101/391]		Loss: 1.9151
| Epoch [  0/ 10] Iter[121/391]		Loss: 1.9443
| Epoch [  0/ 10] Iter[141/391]		Loss: 1.9803
| Epoch [  0/ 10] Iter[161/391]		Loss: 1.8582
| Epoch [  0/ 10] Iter[181/391]		Loss: 1.9268
| Epoch [  0/ 10] Iter[201/391]		Loss: 1.8239
| Epoch [  0/ 10] Iter[221/391]		Loss: 1.8472
| Epoch [  0/ 10] Iter[241/391]		Loss: 1.7337
| Epoch [  0/ 10] Iter[261/391]		Loss: 1.7562
| Epoch [  0/ 10] Iter[281/391]		Loss: 1.7319
| Epoch [  0/ 10] Iter[301/391]		Loss: 1.7758
| Epoch [  0/ 10] Iter[321/391]		Loss: 1.6817
| Epoch [  0/ 10] Iter[341/391]		Loss: 1.7549
| Epoch [  0/ 10] Iter[361/391]		Loss: 1.6213
| Epoch [  0/ 10] Iter[381/391]		Loss: 1.5306
=> Early Training Epoch #1
| Epoch [  1/ 10] Iter[  1/391]		Loss: 1.7086
| Epoch [  1/ 10] Iter[ 21/391]		Loss: 1.6716
| Epoch [  1/ 10] Iter[ 41/391]		Loss: 1.7518
| Epoch [  1/ 10] Iter[ 61/391]		Loss: 1.3158
| Epoch [  1/ 10] Iter[ 81/391]		Loss: 1.4657
| Epoch [  1/ 10] Iter[101/391]		Loss: 1.6022
| Epoch [  1/ 10] Iter[121/391]		Loss: 1.5865
| Epoch [  1/ 10] Iter[141/391]		Loss: 1.4720
| Epoch [  1/ 10] Iter[161/391]		Loss: 1.4913
| Epoch [  1/ 10] Iter[181/391]		Loss: 1.3460
| Epoch [  1/ 10] Iter[201/391]		Loss: 1.3152
| Epoch [  1/ 10] Iter[221/391]		Loss: 1.4903
| Epoch [  1/ 10] Iter[241/391]		Loss: 1.5055
| Epoch [  1/ 10] Iter[261/391]		Loss: 1.2858
| Epoch [  1/ 10] Iter[281/391]		Loss: 1.4648
| Epoch [  1/ 10] Iter[301/391]		Loss: 1.3550
| Epoch [  1/ 10] Iter[321/391]		Loss: 1.4623
| Epoch [  1/ 10] Iter[341/391]		Loss: 1.3238
| Epoch [  1/ 10] Iter[361/391]		Loss: 1.4083
| Epoch [  1/ 10] Iter[381/391]		Loss: 1.2043
=> Early Training Epoch #2
| Epoch [  2/ 10] Iter[  1/391]		Loss: 1.1702
| Epoch [  2/ 10] Iter[ 21/391]		Loss: 1.3422
| Epoch [  2/ 10] Iter[ 41/391]		Loss: 1.1789
| Epoch [  2/ 10] Iter[ 61/391]		Loss: 1.3491
| Epoch [  2/ 10] Iter[ 81/391]		Loss: 1.2160
| Epoch [  2/ 10] Iter[101/391]		Loss: 1.0937
| Epoch [  2/ 10] Iter[121/391]		Loss: 1.1663
| Epoch [  2/ 10] Iter[141/391]		Loss: 1.1662
| Epoch [  2/ 10] Iter[161/391]		Loss: 1.0693
| Epoch [  2/ 10] Iter[181/391]		Loss: 1.1859
| Epoch [  2/ 10] Iter[201/391]		Loss: 1.1501
| Epoch [  2/ 10] Iter[221/391]		Loss: 1.2239
| Epoch [  2/ 10] Iter[241/391]		Loss: 1.0970
| Epoch [  2/ 10] Iter[261/391]		Loss: 1.1365
| Epoch [  2/ 10] Iter[281/391]		Loss: 1.1714
| Epoch [  2/ 10] Iter[301/391]		Loss: 0.9798
| Epoch [  2/ 10] Iter[321/391]		Loss: 1.2453
| Epoch [  2/ 10] Iter[341/391]		Loss: 1.0077
| Epoch [  2/ 10] Iter[361/391]		Loss: 1.0963
| Epoch [  2/ 10] Iter[381/391]		Loss: 1.1100
=> Early Training Epoch #3
| Epoch [  3/ 10] Iter[  1/391]		Loss: 1.1019
| Epoch [  3/ 10] Iter[ 21/391]		Loss: 0.8623
| Epoch [  3/ 10] Iter[ 41/391]		Loss: 1.0545
| Epoch [  3/ 10] Iter[ 61/391]		Loss: 1.0604
| Epoch [  3/ 10] Iter[ 81/391]		Loss: 0.9616
| Epoch [  3/ 10] Iter[101/391]		Loss: 0.8414
| Epoch [  3/ 10] Iter[121/391]		Loss: 0.8626
| Epoch [  3/ 10] Iter[141/391]		Loss: 0.9850
| Epoch [  3/ 10] Iter[161/391]		Loss: 0.8539
| Epoch [  3/ 10] Iter[181/391]		Loss: 0.6697
| Epoch [  3/ 10] Iter[201/391]		Loss: 0.9721
| Epoch [  3/ 10] Iter[221/391]		Loss: 0.8439
| Epoch [  3/ 10] Iter[241/391]		Loss: 0.7519
| Epoch [  3/ 10] Iter[261/391]		Loss: 0.8836
| Epoch [  3/ 10] Iter[281/391]		Loss: 0.8775
| Epoch [  3/ 10] Iter[301/391]		Loss: 0.8544
| Epoch [  3/ 10] Iter[321/391]		Loss: 0.7535
| Epoch [  3/ 10] Iter[341/391]		Loss: 0.6627
| Epoch [  3/ 10] Iter[361/391]		Loss: 0.8737
| Epoch [  3/ 10] Iter[381/391]		Loss: 0.6949
=> Early Training Epoch #4
| Epoch [  4/ 10] Iter[  1/391]		Loss: 0.7235
| Epoch [  4/ 10] Iter[ 21/391]		Loss: 0.5485
| Epoch [  4/ 10] Iter[ 41/391]		Loss: 0.8375
| Epoch [  4/ 10] Iter[ 61/391]		Loss: 0.6893
| Epoch [  4/ 10] Iter[ 81/391]		Loss: 0.6319
| Epoch [  4/ 10] Iter[101/391]		Loss: 0.7762
| Epoch [  4/ 10] Iter[121/391]		Loss: 0.7814
| Epoch [  4/ 10] Iter[141/391]		Loss: 0.8576
| Epoch [  4/ 10] Iter[161/391]		Loss: 0.6799
| Epoch [  4/ 10] Iter[181/391]		Loss: 0.7861
| Epoch [  4/ 10] Iter[201/391]		Loss: 0.6875
| Epoch [  4/ 10] Iter[221/391]		Loss: 0.5764
| Epoch [  4/ 10] Iter[241/391]		Loss: 0.5601
| Epoch [  4/ 10] Iter[261/391]		Loss: 0.7139
| Epoch [  4/ 10] Iter[281/391]		Loss: 0.5801
| Epoch [  4/ 10] Iter[301/391]		Loss: 0.6155
| Epoch [  4/ 10] Iter[321/391]		Loss: 0.6599
| Epoch [  4/ 10] Iter[341/391]		Loss: 0.7261
| Epoch [  4/ 10] Iter[361/391]		Loss: 0.5962
| Epoch [  4/ 10] Iter[381/391]		Loss: 0.6039
=> Early Training Epoch #5
| Epoch [  5/ 10] Iter[  1/391]		Loss: 0.6328
| Epoch [  5/ 10] Iter[ 21/391]		Loss: 0.5524
| Epoch [  5/ 10] Iter[ 41/391]		Loss: 0.5987
| Epoch [  5/ 10] Iter[ 61/391]		Loss: 0.5185
| Epoch [  5/ 10] Iter[ 81/391]		Loss: 0.6053
| Epoch [  5/ 10] Iter[101/391]		Loss: 0.5271
| Epoch [  5/ 10] Iter[121/391]		Loss: 0.5513
| Epoch [  5/ 10] Iter[141/391]		Loss: 0.4763
| Epoch [  5/ 10] Iter[161/391]		Loss: 0.5284
| Epoch [  5/ 10] Iter[181/391]		Loss: 0.5454
| Epoch [  5/ 10] Iter[201/391]		Loss: 0.5867
| Epoch [  5/ 10] Iter[221/391]		Loss: 0.5736
| Epoch [  5/ 10] Iter[241/391]		Loss: 0.5468
| Epoch [  5/ 10] Iter[261/391]		Loss: 0.5872
| Epoch [  5/ 10] Iter[281/391]		Loss: 0.5151
| Epoch [  5/ 10] Iter[301/391]		Loss: 0.5296
| Epoch [  5/ 10] Iter[321/391]		Loss: 0.6170
| Epoch [  5/ 10] Iter[341/391]		Loss: 0.5710
| Epoch [  5/ 10] Iter[361/391]		Loss: 0.5320
| Epoch [  5/ 10] Iter[381/391]		Loss: 0.5744
=> Early Training Epoch #6
| Epoch [  6/ 10] Iter[  1/391]		Loss: 0.3350
| Epoch [  6/ 10] Iter[ 21/391]		Loss: 0.5940
| Epoch [  6/ 10] Iter[ 41/391]		Loss: 0.5377
| Epoch [  6/ 10] Iter[ 61/391]		Loss: 0.4600
| Epoch [  6/ 10] Iter[ 81/391]		Loss: 0.6170
| Epoch [  6/ 10] Iter[101/391]		Loss: 0.4963
| Epoch [  6/ 10] Iter[121/391]		Loss: 0.3861
| Epoch [  6/ 10] Iter[141/391]		Loss: 0.5454
| Epoch [  6/ 10] Iter[161/391]		Loss: 0.4934
| Epoch [  6/ 10] Iter[181/391]		Loss: 0.4591
| Epoch [  6/ 10] Iter[201/391]		Loss: 0.3979
| Epoch [  6/ 10] Iter[221/391]		Loss: 0.3811
| Epoch [  6/ 10] Iter[241/391]		Loss: 0.4887
| Epoch [  6/ 10] Iter[261/391]		Loss: 0.6334
| Epoch [  6/ 10] Iter[281/391]		Loss: 0.4591
| Epoch [  6/ 10] Iter[301/391]		Loss: 0.3555
| Epoch [  6/ 10] Iter[321/391]		Loss: 0.3690
| Epoch [  6/ 10] Iter[341/391]		Loss: 0.4652
| Epoch [  6/ 10] Iter[361/391]		Loss: 0.4427
| Epoch [  6/ 10] Iter[381/391]		Loss: 0.4914
=> Early Training Epoch #7
| Epoch [  7/ 10] Iter[  1/391]		Loss: 0.3691
| Epoch [  7/ 10] Iter[ 21/391]		Loss: 0.2670
| Epoch [  7/ 10] Iter[ 41/391]		Loss: 0.2596
| Epoch [  7/ 10] Iter[ 61/391]		Loss: 0.3205
| Epoch [  7/ 10] Iter[ 81/391]		Loss: 0.4336
| Epoch [  7/ 10] Iter[101/391]		Loss: 0.3366
| Epoch [  7/ 10] Iter[121/391]		Loss: 0.4855
| Epoch [  7/ 10] Iter[141/391]		Loss: 0.3711
| Epoch [  7/ 10] Iter[161/391]		Loss: 0.3170
| Epoch [  7/ 10] Iter[181/391]		Loss: 0.5465
| Epoch [  7/ 10] Iter[201/391]		Loss: 0.3706
| Epoch [  7/ 10] Iter[221/391]		Loss: 0.2514
| Epoch [  7/ 10] Iter[241/391]		Loss: 0.3253
| Epoch [  7/ 10] Iter[261/391]		Loss: 0.4356
| Epoch [  7/ 10] Iter[281/391]		Loss: 0.4073
| Epoch [  7/ 10] Iter[301/391]		Loss: 0.4007
| Epoch [  7/ 10] Iter[321/391]		Loss: 0.3333
| Epoch [  7/ 10] Iter[341/391]		Loss: 0.2968
| Epoch [  7/ 10] Iter[361/391]		Loss: 0.3378
| Epoch [  7/ 10] Iter[381/391]		Loss: 0.4248
=> Early Training Epoch #8
| Epoch [  8/ 10] Iter[  1/391]		Loss: 0.2338
| Epoch [  8/ 10] Iter[ 21/391]		Loss: 0.3038
| Epoch [  8/ 10] Iter[ 41/391]		Loss: 0.2007
| Epoch [  8/ 10] Iter[ 61/391]		Loss: 0.3123
| Epoch [  8/ 10] Iter[ 81/391]		Loss: 0.4255
| Epoch [  8/ 10] Iter[101/391]		Loss: 0.3546
| Epoch [  8/ 10] Iter[121/391]		Loss: 0.3006
| Epoch [  8/ 10] Iter[141/391]		Loss: 0.2866
| Epoch [  8/ 10] Iter[161/391]		Loss: 0.2756
| Epoch [  8/ 10] Iter[181/391]		Loss: 0.3754
| Epoch [  8/ 10] Iter[201/391]		Loss: 0.4207
| Epoch [  8/ 10] Iter[221/391]		Loss: 0.4568
| Epoch [  8/ 10] Iter[241/391]		Loss: 0.3445
| Epoch [  8/ 10] Iter[261/391]		Loss: 0.3911
| Epoch [  8/ 10] Iter[281/391]		Loss: 0.3006
| Epoch [  8/ 10] Iter[301/391]		Loss: 0.3729
| Epoch [  8/ 10] Iter[321/391]		Loss: 0.2899
| Epoch [  8/ 10] Iter[341/391]		Loss: 0.3320
| Epoch [  8/ 10] Iter[361/391]		Loss: 0.4734
| Epoch [  8/ 10] Iter[381/391]		Loss: 0.3842
=> Early Training Epoch #9
| Epoch [  9/ 10] Iter[  1/391]		Loss: 0.2460
| Epoch [  9/ 10] Iter[ 21/391]		Loss: 0.2559
| Epoch [  9/ 10] Iter[ 41/391]		Loss: 0.2317
| Epoch [  9/ 10] Iter[ 61/391]		Loss: 0.2996
| Epoch [  9/ 10] Iter[ 81/391]		Loss: 0.2863
| Epoch [  9/ 10] Iter[101/391]		Loss: 0.3571
| Epoch [  9/ 10] Iter[121/391]		Loss: 0.3479
| Epoch [  9/ 10] Iter[141/391]		Loss: 0.3632
| Epoch [  9/ 10] Iter[161/391]		Loss: 0.3763
| Epoch [  9/ 10] Iter[181/391]		Loss: 0.4331
| Epoch [  9/ 10] Iter[201/391]		Loss: 0.3057
| Epoch [  9/ 10] Iter[221/391]		Loss: 0.2911
| Epoch [  9/ 10] Iter[241/391]		Loss: 0.3927
| Epoch [  9/ 10] Iter[261/391]		Loss: 0.3115
| Epoch [  9/ 10] Iter[281/391]		Loss: 0.3933
| Epoch [  9/ 10] Iter[301/391]		Loss: 0.3760
| Epoch [  9/ 10] Iter[321/391]		Loss: 0.3852
| Epoch [  9/ 10] Iter[341/391]		Loss: 0.4507
| Epoch [  9/ 10] Iter[361/391]		Loss: 0.2488
| Epoch [  9/ 10] Iter[381/391]		Loss: 0.4459
=> selecting time:  121.32462549209595
=> number of seletcted samples:  10000
=> Saving checkpoint for epoch 0, with Prec@1 0.000000.
Epoch: [0][0/79]	Time 3.238 (3.238)	Loss 2.4065 (2.4065)	Prec@1 12.500 (12.500)
Epoch: [0][20/79]	Time 0.047 (0.197)	Loss 3.1290 (4.4935)	Prec@1 9.375 (9.784)
Epoch: [0][40/79]	Time 0.047 (0.123)	Loss 2.2766 (3.5049)	Prec@1 13.281 (10.842)
Epoch: [0][60/79]	Time 0.043 (0.098)	Loss 2.2890 (3.1030)	Prec@1 11.719 (12.180)
training time:  6.880519866943359
Test: [0/79]	Time 0.733 (0.733)	Loss 2.2126 (2.2126)	Prec@1 23.438 (23.438)
Test: [20/79]	Time 0.031 (0.065)	Loss 2.3046 (2.3328)	Prec@1 22.656 (18.341)
Test: [40/79]	Time 0.032 (0.049)	Loss 2.1747 (2.3287)	Prec@1 21.094 (17.797)
Test: [60/79]	Time 0.031 (0.044)	Loss 2.4227 (2.2986)	Prec@1 20.312 (18.174)
 * Prec@1 18.660
=> Saving checkpoint for epoch 0, with Prec@1 18.660000.
Epoch: [1][0/79]	Time 0.747 (0.747)	Loss 2.2007 (2.2007)	Prec@1 18.750 (18.750)
Epoch: [1][20/79]	Time 0.047 (0.079)	Loss 2.1876 (2.1719)	Prec@1 20.312 (19.903)
Epoch: [1][40/79]	Time 0.048 (0.063)	Loss 2.1740 (2.1397)	Prec@1 19.531 (20.293)
Epoch: [1][60/79]	Time 0.048 (0.058)	Loss 2.0615 (2.1090)	Prec@1 23.438 (21.363)
training time:  4.513256549835205
Test: [0/79]	Time 0.714 (0.714)	Loss 2.0325 (2.0325)	Prec@1 25.781 (25.781)
Test: [20/79]	Time 0.032 (0.065)	Loss 2.1330 (2.0667)	Prec@1 22.656 (23.475)
Test: [40/79]	Time 0.032 (0.049)	Loss 2.0998 (2.0617)	Prec@1 25.000 (23.380)
Test: [60/79]	Time 0.032 (0.043)	Loss 2.0542 (2.0473)	Prec@1 27.344 (23.463)
 * Prec@1 23.580
=> Saving checkpoint for epoch 1, with Prec@1 23.580000.
Epoch: [2][0/79]	Time 0.791 (0.791)	Loss 2.1251 (2.1251)	Prec@1 21.094 (21.094)
Epoch: [2][20/79]	Time 0.045 (0.082)	Loss 1.9367 (2.0612)	Prec@1 25.000 (23.698)
Epoch: [2][40/79]	Time 0.046 (0.065)	Loss 2.0132 (2.0143)	Prec@1 27.344 (25.191)
Epoch: [2][60/79]	Time 0.046 (0.059)	Loss 1.8627 (1.9892)	Prec@1 32.812 (26.486)
training time:  4.556615352630615
Test: [0/79]	Time 0.716 (0.716)	Loss 2.1621 (2.1621)	Prec@1 24.219 (24.219)
Test: [20/79]	Time 0.034 (0.065)	Loss 2.1414 (2.1442)	Prec@1 25.000 (23.958)
Test: [40/79]	Time 0.033 (0.049)	Loss 2.2623 (2.1315)	Prec@1 24.219 (24.733)
Test: [60/79]	Time 0.033 (0.044)	Loss 2.0951 (2.1233)	Prec@1 28.906 (24.987)
 * Prec@1 24.480
=> Saving checkpoint for epoch 2, with Prec@1 24.480000.
Epoch: [3][0/79]	Time 0.802 (0.802)	Loss 1.9722 (1.9722)	Prec@1 31.250 (31.250)
Epoch: [3][20/79]	Time 0.048 (0.083)	Loss 1.9737 (1.9577)	Prec@1 25.781 (27.604)
Epoch: [3][40/79]	Time 0.046 (0.065)	Loss 1.9134 (1.9258)	Prec@1 24.219 (28.716)
Epoch: [3][60/79]	Time 0.048 (0.059)	Loss 1.9783 (1.9120)	Prec@1 28.906 (29.214)
training time:  4.597620725631714
Test: [0/79]	Time 0.733 (0.733)	Loss 2.0162 (2.0162)	Prec@1 26.562 (26.562)
Test: [20/79]	Time 0.032 (0.071)	Loss 1.9413 (1.9674)	Prec@1 30.469 (26.860)
Test: [40/79]	Time 0.032 (0.052)	Loss 2.0212 (1.9575)	Prec@1 25.781 (27.363)
Test: [60/79]	Time 0.031 (0.045)	Loss 1.8355 (1.9582)	Prec@1 35.156 (27.536)
 * Prec@1 27.360
=> Saving checkpoint for epoch 3, with Prec@1 27.360000.
Epoch: [4][0/79]	Time 0.801 (0.801)	Loss 2.0569 (2.0569)	Prec@1 25.000 (25.000)
Epoch: [4][20/79]	Time 0.045 (0.082)	Loss 1.8075 (1.9287)	Prec@1 33.594 (28.423)
Epoch: [4][40/79]	Time 0.049 (0.065)	Loss 1.9820 (1.8837)	Prec@1 28.125 (30.488)
Epoch: [4][60/79]	Time 0.046 (0.059)	Loss 2.0179 (1.8789)	Prec@1 29.688 (30.802)
training time:  4.5863730907440186
Test: [0/79]	Time 0.785 (0.785)	Loss 1.7056 (1.7056)	Prec@1 31.250 (31.250)
Test: [20/79]	Time 0.032 (0.068)	Loss 1.7984 (1.7346)	Prec@1 35.156 (32.217)
Test: [40/79]	Time 0.032 (0.051)	Loss 1.8031 (1.7185)	Prec@1 30.469 (33.613)
Test: [60/79]	Time 0.032 (0.045)	Loss 1.5983 (1.7192)	Prec@1 42.969 (33.786)
 * Prec@1 33.560
=> Saving checkpoint for epoch 4, with Prec@1 33.560000.
Epoch: [5][0/79]	Time 0.815 (0.815)	Loss 1.7223 (1.7223)	Prec@1 34.375 (34.375)
Epoch: [5][20/79]	Time 0.046 (0.083)	Loss 1.6096 (1.7865)	Prec@1 49.219 (34.821)
Epoch: [5][40/79]	Time 0.046 (0.065)	Loss 1.8168 (1.7868)	Prec@1 35.156 (34.623)
Epoch: [5][60/79]	Time 0.047 (0.059)	Loss 1.8086 (1.7852)	Prec@1 34.375 (34.516)
training time:  4.574021339416504
Test: [0/79]	Time 0.779 (0.779)	Loss 1.6757 (1.6757)	Prec@1 36.719 (36.719)
Test: [20/79]	Time 0.030 (0.065)	Loss 1.7890 (1.6643)	Prec@1 35.156 (37.612)
Test: [40/79]	Time 0.031 (0.048)	Loss 1.6869 (1.6501)	Prec@1 34.375 (37.538)
Test: [60/79]	Time 0.031 (0.043)	Loss 1.6203 (1.6566)	Prec@1 39.844 (36.629)
 * Prec@1 36.610
=> Saving checkpoint for epoch 5, with Prec@1 36.610000.
Epoch: [6][0/79]	Time 0.806 (0.806)	Loss 1.7632 (1.7632)	Prec@1 29.688 (29.688)
Epoch: [6][20/79]	Time 0.045 (0.081)	Loss 1.7240 (1.7554)	Prec@1 39.062 (35.677)
Epoch: [6][40/79]	Time 0.046 (0.064)	Loss 1.7595 (1.7555)	Prec@1 39.844 (35.290)
Epoch: [6][60/79]	Time 0.046 (0.058)	Loss 1.6714 (1.7477)	Prec@1 37.500 (35.733)
training time:  4.50816798210144
Test: [0/79]	Time 0.770 (0.770)	Loss 1.9114 (1.9114)	Prec@1 36.719 (36.719)
Test: [20/79]	Time 0.031 (0.067)	Loss 1.9910 (1.9722)	Prec@1 22.656 (29.241)
Test: [40/79]	Time 0.032 (0.050)	Loss 2.0835 (1.9868)	Prec@1 30.469 (28.582)
Test: [60/79]	Time 0.034 (0.044)	Loss 1.9533 (1.9771)	Prec@1 27.344 (28.548)
 * Prec@1 29.180
Epoch: [7][0/79]	Time 0.809 (0.809)	Loss 1.8585 (1.8585)	Prec@1 27.344 (27.344)
Epoch: [7][20/79]	Time 0.043 (0.083)	Loss 1.6062 (1.7684)	Prec@1 46.094 (36.533)
Epoch: [7][40/79]	Time 0.050 (0.065)	Loss 1.6388 (1.7484)	Prec@1 44.531 (36.966)
Epoch: [7][60/79]	Time 0.048 (0.059)	Loss 1.6148 (1.7333)	Prec@1 39.062 (37.052)
training time:  4.544818639755249
Test: [0/79]	Time 0.767 (0.767)	Loss 1.5794 (1.5794)	Prec@1 40.625 (40.625)
Test: [20/79]	Time 0.032 (0.067)	Loss 1.7706 (1.6487)	Prec@1 35.938 (39.137)
Test: [40/79]	Time 0.031 (0.049)	Loss 1.7547 (1.6445)	Prec@1 34.375 (38.643)
Test: [60/79]	Time 0.030 (0.044)	Loss 1.4902 (1.6495)	Prec@1 45.312 (38.281)
 * Prec@1 37.970
=> Saving checkpoint for epoch 7, with Prec@1 37.970000.
Epoch: [8][0/79]	Time 0.757 (0.757)	Loss 1.5977 (1.5977)	Prec@1 46.094 (46.094)
Epoch: [8][20/79]	Time 0.044 (0.079)	Loss 1.6783 (1.6982)	Prec@1 37.500 (38.318)
Epoch: [8][40/79]	Time 0.047 (0.063)	Loss 1.8125 (1.6967)	Prec@1 36.719 (38.815)
Epoch: [8][60/79]	Time 0.047 (0.057)	Loss 1.5605 (1.6942)	Prec@1 42.188 (38.422)
training time:  4.58627724647522
Test: [0/79]	Time 0.734 (0.734)	Loss 1.7235 (1.7235)	Prec@1 34.375 (34.375)
Test: [20/79]	Time 0.031 (0.064)	Loss 1.6868 (1.6221)	Prec@1 42.188 (40.960)
Test: [40/79]	Time 0.028 (0.048)	Loss 1.7121 (1.6110)	Prec@1 33.594 (40.606)
Test: [60/79]	Time 0.031 (0.042)	Loss 1.5971 (1.6173)	Prec@1 39.844 (40.279)
 * Prec@1 40.250
=> Saving checkpoint for epoch 8, with Prec@1 40.250000.
Epoch: [9][0/79]	Time 0.771 (0.771)	Loss 1.7294 (1.7294)	Prec@1 34.375 (34.375)
Epoch: [9][20/79]	Time 0.044 (0.081)	Loss 1.5723 (1.6707)	Prec@1 40.625 (39.211)
Epoch: [9][40/79]	Time 0.045 (0.064)	Loss 1.5384 (1.6515)	Prec@1 42.969 (39.691)
Epoch: [9][60/79]	Time 0.047 (0.058)	Loss 1.6753 (1.6516)	Prec@1 34.375 (39.690)
training time:  4.521419286727905
Test: [0/79]	Time 0.776 (0.776)	Loss 1.9587 (1.9587)	Prec@1 32.031 (32.031)
Test: [20/79]	Time 0.032 (0.068)	Loss 2.0923 (1.9652)	Prec@1 27.344 (32.106)
Test: [40/79]	Time 0.032 (0.050)	Loss 2.0665 (1.9569)	Prec@1 27.344 (32.127)
Test: [60/79]	Time 0.032 (0.045)	Loss 1.7374 (1.9538)	Prec@1 32.031 (31.788)
 * Prec@1 31.870
Epoch: [10][0/79]	Time 0.808 (0.808)	Loss 1.8164 (1.8164)	Prec@1 34.375 (34.375)
Epoch: [10][20/79]	Time 0.048 (0.083)	Loss 1.8354 (1.7078)	Prec@1 35.156 (37.909)
Epoch: [10][40/79]	Time 0.047 (0.065)	Loss 1.5529 (1.6755)	Prec@1 43.750 (39.329)
Epoch: [10][60/79]	Time 0.045 (0.059)	Loss 1.7475 (1.6606)	Prec@1 30.469 (39.408)
training time:  4.577260494232178
Test: [0/79]	Time 0.782 (0.782)	Loss 1.7538 (1.7538)	Prec@1 33.594 (33.594)
Test: [20/79]	Time 0.032 (0.068)	Loss 1.6675 (1.5707)	Prec@1 36.719 (41.741)
Test: [40/79]	Time 0.032 (0.050)	Loss 1.6715 (1.5587)	Prec@1 35.156 (41.825)
Test: [60/79]	Time 0.032 (0.045)	Loss 1.5128 (1.5659)	Prec@1 42.188 (41.355)
 * Prec@1 40.980
=> Saving checkpoint for epoch 10, with Prec@1 40.980000.
Epoch: [11][0/79]	Time 0.789 (0.789)	Loss 1.7245 (1.7245)	Prec@1 42.969 (42.969)
Epoch: [11][20/79]	Time 0.049 (0.081)	Loss 1.5519 (1.6540)	Prec@1 39.844 (39.769)
Epoch: [11][40/79]	Time 0.047 (0.064)	Loss 1.5896 (1.6232)	Prec@1 39.062 (40.911)
Epoch: [11][60/79]	Time 0.046 (0.058)	Loss 1.5272 (1.6206)	Prec@1 46.875 (41.240)
training time:  4.51630425453186
Test: [0/79]	Time 0.740 (0.740)	Loss 1.6374 (1.6374)	Prec@1 43.750 (43.750)
Test: [20/79]	Time 0.032 (0.066)	Loss 1.6329 (1.5537)	Prec@1 37.500 (42.225)
Test: [40/79]	Time 0.032 (0.049)	Loss 1.5550 (1.5353)	Prec@1 41.406 (42.873)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.5569 (1.5425)	Prec@1 38.281 (42.290)
 * Prec@1 41.960
=> Saving checkpoint for epoch 11, with Prec@1 41.960000.
Epoch: [12][0/79]	Time 0.770 (0.770)	Loss 1.5489 (1.5489)	Prec@1 43.750 (43.750)
Epoch: [12][20/79]	Time 0.046 (0.081)	Loss 1.4870 (1.5465)	Prec@1 48.438 (43.527)
Epoch: [12][40/79]	Time 0.046 (0.064)	Loss 1.5741 (1.5543)	Prec@1 46.875 (43.502)
Epoch: [12][60/79]	Time 0.046 (0.063)	Loss 1.4950 (1.5579)	Prec@1 46.094 (43.494)
training time:  4.85747218132019
Test: [0/79]	Time 0.749 (0.749)	Loss 1.7265 (1.7265)	Prec@1 32.812 (32.812)
Test: [20/79]	Time 0.029 (0.064)	Loss 1.6629 (1.6014)	Prec@1 37.500 (40.439)
Test: [40/79]	Time 0.031 (0.048)	Loss 1.6951 (1.5873)	Prec@1 32.812 (40.587)
Test: [60/79]	Time 0.030 (0.043)	Loss 1.4857 (1.5893)	Prec@1 40.625 (40.318)
 * Prec@1 39.930
Epoch: [13][0/79]	Time 0.766 (0.766)	Loss 1.5579 (1.5579)	Prec@1 40.625 (40.625)
Epoch: [13][20/79]	Time 0.046 (0.081)	Loss 1.6091 (1.5962)	Prec@1 45.312 (42.039)
Epoch: [13][40/79]	Time 0.045 (0.064)	Loss 1.7409 (1.5656)	Prec@1 37.500 (43.464)
Epoch: [13][60/79]	Time 0.046 (0.058)	Loss 1.5442 (1.5534)	Prec@1 45.312 (43.545)
training time:  4.523027420043945
Test: [0/79]	Time 0.743 (0.743)	Loss 1.5913 (1.5913)	Prec@1 45.312 (45.312)
Test: [20/79]	Time 0.032 (0.065)	Loss 1.5335 (1.5062)	Prec@1 43.750 (47.173)
Test: [40/79]	Time 0.033 (0.049)	Loss 1.5523 (1.4993)	Prec@1 46.094 (46.284)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.6067 (1.5036)	Prec@1 46.875 (46.401)
 * Prec@1 46.040
=> Saving checkpoint for epoch 13, with Prec@1 46.040000.
Epoch: [14][0/79]	Time 0.780 (0.780)	Loss 1.4180 (1.4180)	Prec@1 42.188 (42.188)
Epoch: [14][20/79]	Time 0.045 (0.081)	Loss 1.4687 (1.5154)	Prec@1 48.438 (44.903)
Epoch: [14][40/79]	Time 0.046 (0.064)	Loss 1.5939 (1.5083)	Prec@1 38.281 (44.950)
Epoch: [14][60/79]	Time 0.046 (0.058)	Loss 1.5369 (1.5165)	Prec@1 41.406 (44.672)
training time:  4.500875473022461
Test: [0/79]	Time 0.729 (0.729)	Loss 1.8118 (1.8118)	Prec@1 36.719 (36.719)
Test: [20/79]	Time 0.033 (0.065)	Loss 1.8324 (1.7933)	Prec@1 38.281 (36.942)
Test: [40/79]	Time 0.031 (0.049)	Loss 1.8743 (1.7920)	Prec@1 32.031 (36.433)
Test: [60/79]	Time 0.031 (0.043)	Loss 1.5977 (1.7963)	Prec@1 44.531 (36.335)
 * Prec@1 35.930
Epoch: [15][0/79]	Time 0.787 (0.787)	Loss 1.5880 (1.5880)	Prec@1 47.656 (47.656)
Epoch: [15][20/79]	Time 0.047 (0.082)	Loss 1.3877 (1.5592)	Prec@1 48.438 (43.676)
Epoch: [15][40/79]	Time 0.047 (0.064)	Loss 1.4892 (1.5235)	Prec@1 46.094 (45.046)
Epoch: [15][60/79]	Time 0.045 (0.058)	Loss 1.3646 (1.4969)	Prec@1 47.656 (45.684)
training time:  4.544731140136719
Test: [0/79]	Time 0.740 (0.740)	Loss 1.5638 (1.5638)	Prec@1 40.625 (40.625)
Test: [20/79]	Time 0.029 (0.065)	Loss 1.7118 (1.4858)	Prec@1 35.938 (44.271)
Test: [40/79]	Time 0.030 (0.048)	Loss 1.5187 (1.4753)	Prec@1 39.062 (44.493)
Test: [60/79]	Time 0.031 (0.043)	Loss 1.3616 (1.4905)	Prec@1 49.219 (44.224)
 * Prec@1 43.780
Epoch: [16][0/79]	Time 0.777 (0.777)	Loss 1.4550 (1.4550)	Prec@1 48.438 (48.438)
Epoch: [16][20/79]	Time 0.046 (0.081)	Loss 1.5677 (1.4681)	Prec@1 42.188 (47.210)
Epoch: [16][40/79]	Time 0.046 (0.064)	Loss 1.5267 (1.4709)	Prec@1 44.531 (46.551)
Epoch: [16][60/79]	Time 0.046 (0.058)	Loss 1.5281 (1.4686)	Prec@1 49.219 (46.452)
training time:  4.523393869400024
Test: [0/79]	Time 0.862 (0.862)	Loss 1.6969 (1.6969)	Prec@1 37.500 (37.500)
Test: [20/79]	Time 0.033 (0.075)	Loss 1.6698 (1.6621)	Prec@1 39.062 (40.104)
Test: [40/79]	Time 0.032 (0.054)	Loss 1.7703 (1.6587)	Prec@1 35.938 (39.825)
Test: [60/79]	Time 0.031 (0.047)	Loss 1.6113 (1.6651)	Prec@1 43.750 (39.895)
 * Prec@1 39.650
Epoch: [17][0/79]	Time 0.786 (0.786)	Loss 1.4965 (1.4965)	Prec@1 45.312 (45.312)
Epoch: [17][20/79]	Time 0.046 (0.081)	Loss 1.4784 (1.5298)	Prec@1 46.875 (45.052)
Epoch: [17][40/79]	Time 0.047 (0.064)	Loss 1.4405 (1.5046)	Prec@1 44.531 (45.865)
Epoch: [17][60/79]	Time 0.047 (0.058)	Loss 1.4224 (1.4760)	Prec@1 46.094 (46.376)
training time:  4.514536619186401
Test: [0/79]	Time 0.738 (0.738)	Loss 1.5285 (1.5285)	Prec@1 46.094 (46.094)
Test: [20/79]	Time 0.032 (0.066)	Loss 1.5259 (1.4543)	Prec@1 46.875 (47.098)
Test: [40/79]	Time 0.032 (0.049)	Loss 1.5126 (1.4515)	Prec@1 42.188 (47.237)
Test: [60/79]	Time 0.031 (0.043)	Loss 1.4788 (1.4662)	Prec@1 42.969 (46.926)
 * Prec@1 46.460
=> Saving checkpoint for epoch 17, with Prec@1 46.460000.
Epoch: [18][0/79]	Time 0.796 (0.796)	Loss 1.5484 (1.5484)	Prec@1 39.844 (39.844)
Epoch: [18][20/79]	Time 0.048 (0.082)	Loss 1.5413 (1.4553)	Prec@1 41.406 (46.540)
Epoch: [18][40/79]	Time 0.045 (0.064)	Loss 1.3220 (1.4227)	Prec@1 53.906 (48.095)
Epoch: [18][60/79]	Time 0.046 (0.059)	Loss 1.2722 (1.4056)	Prec@1 57.031 (48.796)
training time:  4.5805299282073975
Test: [0/79]	Time 0.801 (0.801)	Loss 1.4326 (1.4326)	Prec@1 50.781 (50.781)
Test: [20/79]	Time 0.032 (0.069)	Loss 1.5805 (1.4599)	Prec@1 39.062 (46.205)
Test: [40/79]	Time 0.031 (0.051)	Loss 1.5058 (1.4615)	Prec@1 45.312 (46.170)
Test: [60/79]	Time 0.032 (0.045)	Loss 1.4786 (1.4680)	Prec@1 47.656 (46.171)
 * Prec@1 45.830
Epoch: [19][0/79]	Time 0.818 (0.818)	Loss 1.5519 (1.5519)	Prec@1 47.656 (47.656)
Epoch: [19][20/79]	Time 0.046 (0.084)	Loss 1.3392 (1.3923)	Prec@1 54.688 (50.521)
Epoch: [19][40/79]	Time 0.051 (0.065)	Loss 1.3082 (1.3664)	Prec@1 57.031 (50.457)
Epoch: [19][60/79]	Time 0.048 (0.059)	Loss 1.3312 (1.3702)	Prec@1 50.000 (50.269)
training time:  4.549354076385498
Test: [0/79]	Time 0.780 (0.780)	Loss 1.3654 (1.3654)	Prec@1 50.000 (50.000)
Test: [20/79]	Time 0.032 (0.068)	Loss 1.4260 (1.4419)	Prec@1 49.219 (46.949)
Test: [40/79]	Time 0.032 (0.050)	Loss 1.5133 (1.4511)	Prec@1 39.062 (47.046)
Test: [60/79]	Time 0.032 (0.045)	Loss 1.3376 (1.4510)	Prec@1 51.562 (46.888)
 * Prec@1 46.570
=> Saving checkpoint for epoch 19, with Prec@1 46.570000.
Epoch: [20][0/79]	Time 0.832 (0.832)	Loss 1.3961 (1.3961)	Prec@1 48.438 (48.438)
Epoch: [20][20/79]	Time 0.048 (0.085)	Loss 1.3369 (1.3808)	Prec@1 56.250 (49.219)
Epoch: [20][40/79]	Time 0.045 (0.066)	Loss 1.2190 (1.3553)	Prec@1 55.469 (49.867)
Epoch: [20][60/79]	Time 0.045 (0.059)	Loss 1.2835 (1.3323)	Prec@1 47.656 (50.871)
training time:  4.606593132019043
Test: [0/79]	Time 0.743 (0.743)	Loss 1.4885 (1.4885)	Prec@1 42.188 (42.188)
Test: [20/79]	Time 0.033 (0.065)	Loss 1.5714 (1.4709)	Prec@1 40.625 (43.118)
Test: [40/79]	Time 0.033 (0.049)	Loss 1.5033 (1.4782)	Prec@1 40.625 (43.121)
Test: [60/79]	Time 0.031 (0.043)	Loss 1.4193 (1.4871)	Prec@1 47.656 (42.661)
 * Prec@1 42.590
Epoch: [21][0/79]	Time 0.792 (0.792)	Loss 1.3834 (1.3834)	Prec@1 43.750 (43.750)
Epoch: [21][20/79]	Time 0.046 (0.081)	Loss 1.1524 (1.3131)	Prec@1 54.688 (52.455)
Epoch: [21][40/79]	Time 0.046 (0.064)	Loss 1.2969 (1.3156)	Prec@1 52.344 (51.848)
Epoch: [21][60/79]	Time 0.046 (0.058)	Loss 1.2723 (1.3103)	Prec@1 59.375 (52.254)
training time:  4.496614933013916
Test: [0/79]	Time 0.750 (0.750)	Loss 1.2728 (1.2728)	Prec@1 51.562 (51.562)
Test: [20/79]	Time 0.033 (0.066)	Loss 1.4642 (1.3395)	Prec@1 47.656 (51.004)
Test: [40/79]	Time 0.033 (0.050)	Loss 1.3367 (1.3293)	Prec@1 53.906 (51.029)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.4307 (1.3493)	Prec@1 46.875 (50.423)
 * Prec@1 50.200
=> Saving checkpoint for epoch 21, with Prec@1 50.200000.
Epoch: [22][0/79]	Time 0.935 (0.935)	Loss 1.3960 (1.3960)	Prec@1 50.000 (50.000)
Epoch: [22][20/79]	Time 0.049 (0.089)	Loss 1.3396 (1.2775)	Prec@1 51.562 (53.162)
Epoch: [22][40/79]	Time 0.045 (0.068)	Loss 1.1176 (1.2626)	Prec@1 53.906 (53.849)
Epoch: [22][60/79]	Time 0.043 (0.061)	Loss 1.2187 (1.2590)	Prec@1 56.250 (54.086)
training time:  4.699165105819702
Test: [0/79]	Time 0.747 (0.747)	Loss 1.6453 (1.6453)	Prec@1 36.719 (36.719)
Test: [20/79]	Time 0.031 (0.066)	Loss 1.5929 (1.6147)	Prec@1 42.188 (43.527)
Test: [40/79]	Time 0.032 (0.050)	Loss 1.6331 (1.6089)	Prec@1 39.844 (43.559)
Test: [60/79]	Time 0.030 (0.044)	Loss 1.4437 (1.6356)	Prec@1 40.625 (42.623)
 * Prec@1 42.240
Epoch: [23][0/79]	Time 0.826 (0.826)	Loss 1.3986 (1.3986)	Prec@1 49.219 (49.219)
Epoch: [23][20/79]	Time 0.043 (0.082)	Loss 1.2566 (1.3023)	Prec@1 59.375 (53.199)
Epoch: [23][40/79]	Time 0.045 (0.064)	Loss 1.1973 (1.2766)	Prec@1 58.594 (53.887)
Epoch: [23][60/79]	Time 0.044 (0.057)	Loss 1.3329 (1.2577)	Prec@1 53.125 (54.611)
training time:  4.483225107192993
Test: [0/79]	Time 0.807 (0.807)	Loss 1.2269 (1.2269)	Prec@1 57.031 (57.031)
Test: [20/79]	Time 0.031 (0.069)	Loss 1.2835 (1.2123)	Prec@1 46.875 (55.208)
Test: [40/79]	Time 0.032 (0.051)	Loss 1.2638 (1.2054)	Prec@1 51.562 (54.954)
Test: [60/79]	Time 0.031 (0.045)	Loss 1.2856 (1.2174)	Prec@1 53.125 (54.598)
 * Prec@1 54.310
=> Saving checkpoint for epoch 23, with Prec@1 54.310000.
Epoch: [24][0/79]	Time 0.823 (0.823)	Loss 1.2236 (1.2236)	Prec@1 56.250 (56.250)
Epoch: [24][20/79]	Time 0.047 (0.084)	Loss 1.1874 (1.1825)	Prec@1 57.031 (56.882)
Epoch: [24][40/79]	Time 0.048 (0.065)	Loss 1.2011 (1.1954)	Prec@1 60.156 (56.764)
Epoch: [24][60/79]	Time 0.046 (0.059)	Loss 1.2708 (1.2055)	Prec@1 54.688 (56.276)
training time:  4.578667879104614
Test: [0/79]	Time 0.792 (0.792)	Loss 1.3879 (1.3879)	Prec@1 52.344 (52.344)
Test: [20/79]	Time 0.032 (0.067)	Loss 1.3459 (1.3180)	Prec@1 51.562 (51.004)
Test: [40/79]	Time 0.031 (0.049)	Loss 1.3672 (1.3097)	Prec@1 50.000 (51.162)
Test: [60/79]	Time 0.031 (0.043)	Loss 1.4165 (1.3163)	Prec@1 48.438 (50.640)
 * Prec@1 50.510
Epoch: [25][0/79]	Time 0.792 (0.792)	Loss 1.2118 (1.2118)	Prec@1 53.125 (53.125)
Epoch: [25][20/79]	Time 0.044 (0.080)	Loss 1.0435 (1.1971)	Prec@1 64.844 (55.915)
Epoch: [25][40/79]	Time 0.046 (0.064)	Loss 1.1143 (1.1926)	Prec@1 62.500 (56.841)
Epoch: [25][60/79]	Time 0.048 (0.058)	Loss 1.2534 (1.1819)	Prec@1 53.906 (57.018)
training time:  4.523327350616455
Test: [0/79]	Time 0.757 (0.757)	Loss 1.3970 (1.3970)	Prec@1 53.906 (53.906)
Test: [20/79]	Time 0.032 (0.067)	Loss 1.2883 (1.2961)	Prec@1 52.344 (52.567)
Test: [40/79]	Time 0.032 (0.050)	Loss 1.3020 (1.2796)	Prec@1 51.562 (52.954)
Test: [60/79]	Time 0.032 (0.044)	Loss 1.4101 (1.2874)	Prec@1 50.000 (52.830)
 * Prec@1 52.690
Epoch: [26][0/79]	Time 0.797 (0.797)	Loss 1.2425 (1.2425)	Prec@1 57.812 (57.812)
Epoch: [26][20/79]	Time 0.046 (0.082)	Loss 1.1474 (1.1729)	Prec@1 59.375 (57.812)
Epoch: [26][40/79]	Time 0.049 (0.064)	Loss 1.1479 (1.1531)	Prec@1 58.594 (58.403)
Epoch: [26][60/79]	Time 0.047 (0.058)	Loss 1.3534 (1.1450)	Prec@1 50.781 (58.568)
training time:  4.516092300415039
Test: [0/79]	Time 0.786 (0.786)	Loss 1.0781 (1.0781)	Prec@1 62.500 (62.500)
Test: [20/79]	Time 0.032 (0.067)	Loss 1.3832 (1.1897)	Prec@1 57.031 (57.552)
Test: [40/79]	Time 0.032 (0.050)	Loss 1.3198 (1.1987)	Prec@1 50.781 (56.841)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.2532 (1.2094)	Prec@1 51.562 (56.263)
 * Prec@1 55.910
=> Saving checkpoint for epoch 26, with Prec@1 55.910000.
Epoch: [27][0/79]	Time 0.777 (0.777)	Loss 1.0490 (1.0490)	Prec@1 62.500 (62.500)
Epoch: [27][20/79]	Time 0.042 (0.080)	Loss 1.1569 (1.1105)	Prec@1 59.375 (59.784)
Epoch: [27][40/79]	Time 0.047 (0.063)	Loss 1.1401 (1.1050)	Prec@1 57.031 (59.699)
Epoch: [27][60/79]	Time 0.042 (0.057)	Loss 1.1123 (1.1060)	Prec@1 60.938 (59.721)
training time:  4.430425405502319
Test: [0/79]	Time 0.925 (0.925)	Loss 1.2728 (1.2728)	Prec@1 54.688 (54.688)
Test: [20/79]	Time 0.032 (0.074)	Loss 1.2382 (1.2121)	Prec@1 51.562 (56.138)
Test: [40/79]	Time 0.031 (0.053)	Loss 1.2139 (1.1977)	Prec@1 52.344 (55.983)
Test: [60/79]	Time 0.032 (0.046)	Loss 1.2478 (1.2124)	Prec@1 56.250 (55.597)
 * Prec@1 55.710
Epoch: [28][0/79]	Time 0.840 (0.840)	Loss 1.1388 (1.1388)	Prec@1 57.812 (57.812)
Epoch: [28][20/79]	Time 0.046 (0.084)	Loss 1.1810 (1.1684)	Prec@1 53.906 (57.701)
Epoch: [28][40/79]	Time 0.047 (0.066)	Loss 0.9077 (1.1128)	Prec@1 68.750 (59.680)
Epoch: [28][60/79]	Time 0.046 (0.059)	Loss 1.0956 (1.1123)	Prec@1 58.594 (59.721)
training time:  4.5331010818481445
Test: [0/79]	Time 0.800 (0.800)	Loss 1.1504 (1.1504)	Prec@1 63.281 (63.281)
Test: [20/79]	Time 0.029 (0.066)	Loss 1.1766 (1.2076)	Prec@1 54.688 (57.217)
Test: [40/79]	Time 0.034 (0.050)	Loss 1.2109 (1.2083)	Prec@1 56.250 (56.860)
Test: [60/79]	Time 0.030 (0.044)	Loss 1.4016 (1.2246)	Prec@1 57.031 (56.481)
 * Prec@1 56.220
=> Saving checkpoint for epoch 28, with Prec@1 56.220000.
Epoch: [29][0/79]	Time 0.831 (0.831)	Loss 0.8655 (0.8655)	Prec@1 66.406 (66.406)
Epoch: [29][20/79]	Time 0.047 (0.083)	Loss 1.0844 (1.0364)	Prec@1 61.719 (62.723)
Epoch: [29][40/79]	Time 0.045 (0.065)	Loss 0.9995 (1.0415)	Prec@1 63.281 (63.357)
Epoch: [29][60/79]	Time 0.045 (0.059)	Loss 1.0620 (1.0402)	Prec@1 64.844 (62.948)
training time:  4.58405613899231
Test: [0/79]	Time 0.790 (0.790)	Loss 1.3246 (1.3246)	Prec@1 57.031 (57.031)
Test: [20/79]	Time 0.032 (0.068)	Loss 1.2852 (1.2985)	Prec@1 61.719 (53.943)
Test: [40/79]	Time 0.032 (0.051)	Loss 1.3509 (1.2972)	Prec@1 50.000 (53.487)
Test: [60/79]	Time 0.032 (0.045)	Loss 1.5418 (1.3166)	Prec@1 43.750 (52.536)
 * Prec@1 52.920
Epoch: [30][0/79]	Time 0.786 (0.786)	Loss 0.9655 (0.9655)	Prec@1 67.188 (67.188)
Epoch: [30][20/79]	Time 0.043 (0.082)	Loss 1.0474 (1.1070)	Prec@1 60.938 (60.379)
Epoch: [30][40/79]	Time 0.044 (0.065)	Loss 0.9808 (1.0712)	Prec@1 62.500 (61.433)
Epoch: [30][60/79]	Time 0.045 (0.059)	Loss 1.0274 (1.0643)	Prec@1 64.844 (61.668)
training time:  4.5788185596466064
Test: [0/79]	Time 0.744 (0.744)	Loss 1.1791 (1.1791)	Prec@1 60.938 (60.938)
Test: [20/79]	Time 0.032 (0.066)	Loss 1.1413 (1.2045)	Prec@1 57.031 (56.399)
Test: [40/79]	Time 0.031 (0.050)	Loss 1.2446 (1.1906)	Prec@1 54.688 (56.631)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.3334 (1.2023)	Prec@1 48.438 (56.135)
 * Prec@1 56.370
=> Saving checkpoint for epoch 30, with Prec@1 56.370000.
Epoch: [31][0/79]	Time 0.830 (0.830)	Loss 0.9141 (0.9141)	Prec@1 67.188 (67.188)
Epoch: [31][20/79]	Time 0.047 (0.083)	Loss 0.8519 (1.0190)	Prec@1 70.312 (62.946)
Epoch: [31][40/79]	Time 0.046 (0.066)	Loss 1.1967 (1.0052)	Prec@1 60.938 (63.910)
Epoch: [31][60/79]	Time 0.048 (0.059)	Loss 1.0593 (1.0077)	Prec@1 56.250 (63.934)
training time:  4.584884405136108
Test: [0/79]	Time 0.779 (0.779)	Loss 1.3994 (1.3994)	Prec@1 54.688 (54.688)
Test: [20/79]	Time 0.032 (0.066)	Loss 1.2709 (1.3567)	Prec@1 60.156 (52.790)
Test: [40/79]	Time 0.028 (0.049)	Loss 1.3027 (1.3278)	Prec@1 55.469 (54.230)
Test: [60/79]	Time 0.031 (0.043)	Loss 1.1627 (1.3259)	Prec@1 61.719 (54.124)
 * Prec@1 54.300
Epoch: [32][0/79]	Time 0.835 (0.835)	Loss 0.8855 (0.8855)	Prec@1 71.875 (71.875)
Epoch: [32][20/79]	Time 0.046 (0.083)	Loss 0.9116 (1.0548)	Prec@1 66.406 (62.909)
Epoch: [32][40/79]	Time 0.046 (0.065)	Loss 1.1251 (1.0233)	Prec@1 60.938 (63.377)
Epoch: [32][60/79]	Time 0.045 (0.058)	Loss 1.0660 (1.0045)	Prec@1 65.625 (63.922)
training time:  4.5419697761535645
Test: [0/79]	Time 0.791 (0.791)	Loss 1.3260 (1.3260)	Prec@1 52.344 (52.344)
Test: [20/79]	Time 0.032 (0.068)	Loss 1.1867 (1.2657)	Prec@1 51.562 (55.320)
Test: [40/79]	Time 0.032 (0.050)	Loss 1.3371 (1.2515)	Prec@1 49.219 (54.840)
Test: [60/79]	Time 0.031 (0.045)	Loss 1.1680 (1.2472)	Prec@1 62.500 (55.085)
 * Prec@1 55.110
Epoch: [33][0/79]	Time 0.843 (0.843)	Loss 1.0967 (1.0967)	Prec@1 56.250 (56.250)
Epoch: [33][20/79]	Time 0.046 (0.090)	Loss 1.0364 (1.0191)	Prec@1 64.062 (63.318)
Epoch: [33][40/79]	Time 0.043 (0.068)	Loss 0.9282 (0.9816)	Prec@1 69.531 (64.539)
Epoch: [33][60/79]	Time 0.048 (0.060)	Loss 1.0819 (0.9692)	Prec@1 57.031 (64.946)
training time:  4.654544353485107
Test: [0/79]	Time 0.800 (0.800)	Loss 1.2038 (1.2038)	Prec@1 56.250 (56.250)
Test: [20/79]	Time 0.032 (0.068)	Loss 1.0477 (1.1544)	Prec@1 60.156 (58.631)
Test: [40/79]	Time 0.030 (0.050)	Loss 1.0821 (1.1343)	Prec@1 61.719 (58.975)
Test: [60/79]	Time 0.030 (0.045)	Loss 1.1228 (1.1288)	Prec@1 63.281 (58.965)
 * Prec@1 58.680
=> Saving checkpoint for epoch 33, with Prec@1 58.680000.
Epoch: [34][0/79]	Time 0.832 (0.832)	Loss 0.9766 (0.9766)	Prec@1 59.375 (59.375)
Epoch: [34][20/79]	Time 0.046 (0.083)	Loss 0.8261 (0.9421)	Prec@1 68.750 (66.220)
Epoch: [34][40/79]	Time 0.047 (0.064)	Loss 1.0045 (0.9356)	Prec@1 64.844 (66.635)
Epoch: [34][60/79]	Time 0.045 (0.058)	Loss 0.9225 (0.9367)	Prec@1 61.719 (66.240)
training time:  4.520074367523193
Test: [0/79]	Time 0.753 (0.753)	Loss 1.2620 (1.2620)	Prec@1 65.625 (65.625)
Test: [20/79]	Time 0.033 (0.067)	Loss 1.2364 (1.2238)	Prec@1 57.031 (58.408)
Test: [40/79]	Time 0.031 (0.050)	Loss 1.1591 (1.1985)	Prec@1 59.375 (59.032)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.2887 (1.2032)	Prec@1 55.469 (58.760)
 * Prec@1 58.670
Epoch: [35][0/79]	Time 0.779 (0.779)	Loss 0.9484 (0.9484)	Prec@1 64.844 (64.844)
Epoch: [35][20/79]	Time 0.046 (0.081)	Loss 0.8945 (0.9280)	Prec@1 67.969 (65.774)
Epoch: [35][40/79]	Time 0.045 (0.064)	Loss 0.9612 (0.9116)	Prec@1 61.719 (66.616)
Epoch: [35][60/79]	Time 0.046 (0.058)	Loss 0.9548 (0.9006)	Prec@1 64.062 (67.188)
training time:  4.522084712982178
Test: [0/79]	Time 0.755 (0.755)	Loss 1.7989 (1.7989)	Prec@1 44.531 (44.531)
Test: [20/79]	Time 0.032 (0.066)	Loss 1.5209 (1.7241)	Prec@1 49.219 (46.503)
Test: [40/79]	Time 0.031 (0.049)	Loss 1.7888 (1.7372)	Prec@1 33.594 (46.932)
Test: [60/79]	Time 0.030 (0.043)	Loss 1.9097 (1.7201)	Prec@1 44.531 (47.182)
 * Prec@1 47.070
Epoch: [36][0/79]	Time 0.792 (0.792)	Loss 1.0229 (1.0229)	Prec@1 64.844 (64.844)
Epoch: [36][20/79]	Time 0.045 (0.081)	Loss 0.9241 (0.9515)	Prec@1 67.969 (64.955)
Epoch: [36][40/79]	Time 0.046 (0.064)	Loss 0.8392 (0.9148)	Prec@1 72.656 (66.616)
Epoch: [36][60/79]	Time 0.046 (0.058)	Loss 0.9284 (0.9035)	Prec@1 64.062 (67.021)
training time:  4.49130654335022
Test: [0/79]	Time 0.785 (0.785)	Loss 1.3220 (1.3220)	Prec@1 52.344 (52.344)
Test: [20/79]	Time 0.033 (0.067)	Loss 1.3852 (1.3832)	Prec@1 50.000 (52.976)
Test: [40/79]	Time 0.033 (0.050)	Loss 1.3735 (1.3572)	Prec@1 50.781 (53.449)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.4145 (1.3702)	Prec@1 50.781 (53.087)
 * Prec@1 53.310
Epoch: [37][0/79]	Time 0.827 (0.827)	Loss 0.9739 (0.9739)	Prec@1 67.188 (67.188)
Epoch: [37][20/79]	Time 0.044 (0.082)	Loss 0.8673 (0.9159)	Prec@1 67.969 (67.076)
Epoch: [37][40/79]	Time 0.050 (0.064)	Loss 0.7848 (0.8854)	Prec@1 72.656 (68.540)
Epoch: [37][60/79]	Time 0.048 (0.058)	Loss 0.7089 (0.8571)	Prec@1 72.656 (69.506)
training time:  4.564439296722412
Test: [0/79]	Time 0.790 (0.790)	Loss 1.2519 (1.2519)	Prec@1 60.938 (60.938)
Test: [20/79]	Time 0.032 (0.068)	Loss 1.3537 (1.3162)	Prec@1 56.250 (57.887)
Test: [40/79]	Time 0.032 (0.050)	Loss 1.4828 (1.3066)	Prec@1 49.219 (57.736)
Test: [60/79]	Time 0.032 (0.044)	Loss 1.4568 (1.3011)	Prec@1 59.375 (57.505)
 * Prec@1 57.240
Epoch: [38][0/79]	Time 0.805 (0.805)	Loss 0.9136 (0.9136)	Prec@1 66.406 (66.406)
Epoch: [38][20/79]	Time 0.047 (0.083)	Loss 0.9146 (0.8524)	Prec@1 70.312 (69.494)
Epoch: [38][40/79]	Time 0.046 (0.065)	Loss 0.8585 (0.8276)	Prec@1 71.875 (70.503)
Epoch: [38][60/79]	Time 0.047 (0.059)	Loss 0.8274 (0.8236)	Prec@1 71.875 (70.735)
training time:  4.58429741859436
Test: [0/79]	Time 0.756 (0.756)	Loss 0.9904 (0.9904)	Prec@1 65.625 (65.625)
Test: [20/79]	Time 0.033 (0.073)	Loss 0.8851 (1.0251)	Prec@1 68.750 (63.467)
Test: [40/79]	Time 0.034 (0.053)	Loss 1.0578 (1.0290)	Prec@1 62.500 (63.491)
Test: [60/79]	Time 0.033 (0.046)	Loss 1.1202 (1.0291)	Prec@1 58.594 (63.064)
 * Prec@1 63.150
=> Saving checkpoint for epoch 38, with Prec@1 63.150000.
Epoch: [39][0/79]	Time 0.776 (0.776)	Loss 0.8123 (0.8123)	Prec@1 71.875 (71.875)
Epoch: [39][20/79]	Time 0.048 (0.083)	Loss 0.8377 (0.7978)	Prec@1 70.312 (71.131)
Epoch: [39][40/79]	Time 0.048 (0.066)	Loss 0.6352 (0.7755)	Prec@1 78.125 (72.199)
Epoch: [39][60/79]	Time 0.047 (0.060)	Loss 0.8251 (0.7743)	Prec@1 66.406 (72.285)
training time:  4.671973466873169
Test: [0/79]	Time 0.742 (0.742)	Loss 1.2821 (1.2821)	Prec@1 58.594 (58.594)
Test: [20/79]	Time 0.031 (0.065)	Loss 1.2518 (1.2803)	Prec@1 50.781 (56.771)
Test: [40/79]	Time 0.032 (0.049)	Loss 1.3054 (1.2668)	Prec@1 55.469 (57.317)
Test: [60/79]	Time 0.032 (0.044)	Loss 1.4177 (1.2649)	Prec@1 58.594 (57.070)
 * Prec@1 57.340
Epoch: [40][0/79]	Time 0.824 (0.824)	Loss 0.7172 (0.7172)	Prec@1 71.875 (71.875)
Epoch: [40][20/79]	Time 0.046 (0.084)	Loss 0.6715 (0.8064)	Prec@1 76.562 (71.391)
Epoch: [40][40/79]	Time 0.046 (0.065)	Loss 0.7099 (0.7902)	Prec@1 74.219 (71.799)
Epoch: [40][60/79]	Time 0.046 (0.059)	Loss 0.8436 (0.7697)	Prec@1 70.312 (72.336)
training time:  4.576042413711548
Test: [0/79]	Time 0.742 (0.742)	Loss 0.9794 (0.9794)	Prec@1 65.625 (65.625)
Test: [20/79]	Time 0.032 (0.065)	Loss 1.1261 (1.0935)	Prec@1 60.156 (61.644)
Test: [40/79]	Time 0.034 (0.049)	Loss 1.0167 (1.0866)	Prec@1 64.062 (61.814)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.1219 (1.0884)	Prec@1 61.719 (61.603)
 * Prec@1 61.540
Epoch: [41][0/79]	Time 0.788 (0.788)	Loss 0.7240 (0.7240)	Prec@1 75.000 (75.000)
Epoch: [41][20/79]	Time 0.045 (0.082)	Loss 0.6506 (0.7248)	Prec@1 78.125 (74.405)
Epoch: [41][40/79]	Time 0.046 (0.064)	Loss 0.6751 (0.7244)	Prec@1 75.000 (73.704)
Epoch: [41][60/79]	Time 0.045 (0.058)	Loss 0.8448 (0.7308)	Prec@1 70.312 (73.540)
training time:  4.533251762390137
Test: [0/79]	Time 0.754 (0.754)	Loss 1.0700 (1.0700)	Prec@1 65.625 (65.625)
Test: [20/79]	Time 0.033 (0.066)	Loss 1.2098 (1.1368)	Prec@1 60.156 (61.905)
Test: [40/79]	Time 0.032 (0.050)	Loss 1.1075 (1.1161)	Prec@1 58.594 (62.157)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.0876 (1.1130)	Prec@1 64.062 (61.693)
 * Prec@1 61.650
Epoch: [42][0/79]	Time 0.833 (0.833)	Loss 0.6460 (0.6460)	Prec@1 75.781 (75.781)
Epoch: [42][20/79]	Time 0.044 (0.084)	Loss 0.5263 (0.7125)	Prec@1 82.031 (74.814)
Epoch: [42][40/79]	Time 0.043 (0.065)	Loss 0.6811 (0.7039)	Prec@1 73.438 (74.867)
Epoch: [42][60/79]	Time 0.045 (0.059)	Loss 0.8518 (0.7044)	Prec@1 71.875 (74.731)
training time:  4.5827367305755615
Test: [0/79]	Time 0.788 (0.788)	Loss 1.6970 (1.6970)	Prec@1 40.625 (40.625)
Test: [20/79]	Time 0.033 (0.068)	Loss 1.7460 (1.6361)	Prec@1 46.094 (48.549)
Test: [40/79]	Time 0.032 (0.050)	Loss 1.8956 (1.6448)	Prec@1 47.656 (49.085)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.5870 (1.6472)	Prec@1 53.125 (49.244)
 * Prec@1 49.490
Epoch: [43][0/79]	Time 0.781 (0.781)	Loss 0.8069 (0.8069)	Prec@1 71.875 (71.875)
Epoch: [43][20/79]	Time 0.047 (0.082)	Loss 0.5897 (0.7082)	Prec@1 78.906 (74.293)
Epoch: [43][40/79]	Time 0.044 (0.064)	Loss 0.7617 (0.7050)	Prec@1 73.438 (74.867)
Epoch: [43][60/79]	Time 0.047 (0.058)	Loss 0.6023 (0.6846)	Prec@1 79.688 (75.589)
training time:  4.548311948776245
Test: [0/79]	Time 0.745 (0.745)	Loss 1.1264 (1.1264)	Prec@1 60.938 (60.938)
Test: [20/79]	Time 0.032 (0.065)	Loss 1.2341 (1.2856)	Prec@1 57.031 (56.324)
Test: [40/79]	Time 0.032 (0.049)	Loss 1.2080 (1.2715)	Prec@1 62.500 (57.050)
Test: [60/79]	Time 0.032 (0.043)	Loss 1.4037 (1.2880)	Prec@1 57.812 (56.429)
 * Prec@1 56.560
Epoch: [44][0/79]	Time 0.799 (0.799)	Loss 0.6031 (0.6031)	Prec@1 75.781 (75.781)
Epoch: [44][20/79]	Time 0.046 (0.089)	Loss 0.7126 (0.6633)	Prec@1 74.219 (76.488)
Epoch: [44][40/79]	Time 0.046 (0.068)	Loss 0.5899 (0.6523)	Prec@1 79.688 (76.582)
Epoch: [44][60/79]	Time 0.046 (0.061)	Loss 0.5250 (0.6565)	Prec@1 83.594 (76.396)
training time:  4.68021821975708
Test: [0/79]	Time 0.738 (0.738)	Loss 1.0814 (1.0814)	Prec@1 67.188 (67.188)
Test: [20/79]	Time 0.032 (0.065)	Loss 1.1963 (1.2289)	Prec@1 60.938 (60.714)
Test: [40/79]	Time 0.032 (0.049)	Loss 1.2351 (1.2519)	Prec@1 57.031 (60.023)
Test: [60/79]	Time 0.031 (0.043)	Loss 1.3504 (1.2595)	Prec@1 57.812 (59.593)
 * Prec@1 59.610
Epoch: [45][0/79]	Time 0.777 (0.777)	Loss 0.7441 (0.7441)	Prec@1 70.312 (70.312)
Epoch: [45][20/79]	Time 0.045 (0.081)	Loss 0.6839 (0.7130)	Prec@1 77.344 (75.335)
Epoch: [45][40/79]	Time 0.045 (0.064)	Loss 0.5968 (0.6720)	Prec@1 78.125 (76.315)
Epoch: [45][60/79]	Time 0.045 (0.058)	Loss 0.5296 (0.6556)	Prec@1 79.688 (76.972)
training time:  4.527397632598877
Test: [0/79]	Time 0.745 (0.745)	Loss 0.9231 (0.9231)	Prec@1 65.625 (65.625)
Test: [20/79]	Time 0.032 (0.064)	Loss 1.0395 (1.0173)	Prec@1 64.062 (65.179)
Test: [40/79]	Time 0.032 (0.048)	Loss 1.0389 (0.9898)	Prec@1 65.625 (66.387)
Test: [60/79]	Time 0.031 (0.043)	Loss 1.0975 (0.9899)	Prec@1 64.844 (66.240)
 * Prec@1 66.000
=> Saving checkpoint for epoch 45, with Prec@1 66.000000.
Epoch: [46][0/79]	Time 0.790 (0.790)	Loss 0.6151 (0.6151)	Prec@1 79.688 (79.688)
Epoch: [46][20/79]	Time 0.045 (0.081)	Loss 0.5862 (0.6122)	Prec@1 77.344 (77.269)
Epoch: [46][40/79]	Time 0.045 (0.064)	Loss 0.7337 (0.5929)	Prec@1 78.125 (78.296)
Epoch: [46][60/79]	Time 0.044 (0.058)	Loss 0.5856 (0.5915)	Prec@1 75.781 (78.701)
training time:  4.502490282058716
Test: [0/79]	Time 0.764 (0.764)	Loss 1.3789 (1.3789)	Prec@1 60.938 (60.938)
Test: [20/79]	Time 0.031 (0.066)	Loss 1.2497 (1.2472)	Prec@1 63.281 (60.938)
Test: [40/79]	Time 0.032 (0.049)	Loss 1.1710 (1.2196)	Prec@1 62.500 (61.700)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.1779 (1.2265)	Prec@1 67.188 (61.629)
 * Prec@1 61.510
Epoch: [47][0/79]	Time 0.790 (0.790)	Loss 0.5940 (0.5940)	Prec@1 78.125 (78.125)
Epoch: [47][20/79]	Time 0.044 (0.082)	Loss 0.6311 (0.6290)	Prec@1 74.219 (77.121)
Epoch: [47][40/79]	Time 0.044 (0.065)	Loss 0.5843 (0.5965)	Prec@1 82.031 (78.563)
Epoch: [47][60/79]	Time 0.047 (0.059)	Loss 0.5470 (0.5933)	Prec@1 82.031 (78.919)
training time:  4.557597398757935
Test: [0/79]	Time 0.799 (0.799)	Loss 1.5923 (1.5923)	Prec@1 57.031 (57.031)
Test: [20/79]	Time 0.032 (0.068)	Loss 1.5159 (1.5677)	Prec@1 56.250 (54.911)
Test: [40/79]	Time 0.032 (0.051)	Loss 1.8019 (1.5537)	Prec@1 52.344 (55.221)
Test: [60/79]	Time 0.031 (0.045)	Loss 1.5503 (1.5527)	Prec@1 56.250 (55.085)
 * Prec@1 55.440
Epoch: [48][0/79]	Time 0.818 (0.818)	Loss 0.6581 (0.6581)	Prec@1 77.344 (77.344)
Epoch: [48][20/79]	Time 0.045 (0.083)	Loss 0.5383 (0.6582)	Prec@1 82.812 (76.749)
Epoch: [48][40/79]	Time 0.045 (0.065)	Loss 0.5707 (0.6210)	Prec@1 79.688 (78.049)
Epoch: [48][60/79]	Time 0.046 (0.059)	Loss 0.6760 (0.5938)	Prec@1 75.000 (78.970)
training time:  4.581467390060425
Test: [0/79]	Time 0.781 (0.781)	Loss 1.0282 (1.0282)	Prec@1 66.406 (66.406)
Test: [20/79]	Time 0.031 (0.067)	Loss 1.0921 (1.1059)	Prec@1 64.062 (64.211)
Test: [40/79]	Time 0.032 (0.049)	Loss 1.2179 (1.0815)	Prec@1 58.594 (64.482)
Test: [60/79]	Time 0.032 (0.044)	Loss 1.1255 (1.0883)	Prec@1 67.188 (64.319)
 * Prec@1 64.350
Epoch: [49][0/79]	Time 0.822 (0.822)	Loss 0.5672 (0.5672)	Prec@1 78.906 (78.906)
Epoch: [49][20/79]	Time 0.046 (0.083)	Loss 0.4616 (0.5331)	Prec@1 86.719 (80.915)
Epoch: [49][40/79]	Time 0.048 (0.065)	Loss 0.4848 (0.5268)	Prec@1 82.812 (81.174)
Epoch: [49][60/79]	Time 0.043 (0.059)	Loss 0.6609 (0.5308)	Prec@1 77.344 (81.160)
training time:  4.55364465713501
Test: [0/79]	Time 0.780 (0.780)	Loss 1.4364 (1.4364)	Prec@1 59.375 (59.375)
Test: [20/79]	Time 0.032 (0.075)	Loss 1.2160 (1.4091)	Prec@1 58.594 (59.189)
Test: [40/79]	Time 0.032 (0.054)	Loss 1.5599 (1.3874)	Prec@1 57.031 (59.604)
Test: [60/79]	Time 0.032 (0.047)	Loss 1.4737 (1.4039)	Prec@1 59.375 (59.209)
 * Prec@1 58.970
Epoch: [50][0/79]	Time 0.831 (0.831)	Loss 0.7025 (0.7025)	Prec@1 78.125 (78.125)
Epoch: [50][20/79]	Time 0.046 (0.084)	Loss 0.6062 (0.5606)	Prec@1 82.031 (79.390)
Epoch: [50][40/79]	Time 0.046 (0.065)	Loss 0.4984 (0.5507)	Prec@1 82.031 (79.916)
Epoch: [50][60/79]	Time 0.049 (0.059)	Loss 0.5912 (0.5480)	Prec@1 81.250 (80.059)
training time:  4.57522988319397
Test: [0/79]	Time 0.796 (0.796)	Loss 1.1664 (1.1664)	Prec@1 67.188 (67.188)
Test: [20/79]	Time 0.031 (0.068)	Loss 1.1879 (1.2469)	Prec@1 60.938 (61.682)
Test: [40/79]	Time 0.032 (0.050)	Loss 1.2033 (1.2321)	Prec@1 61.719 (62.062)
Test: [60/79]	Time 0.033 (0.044)	Loss 1.0392 (1.2269)	Prec@1 69.531 (62.321)
 * Prec@1 62.430
Epoch: [51][0/79]	Time 0.825 (0.825)	Loss 0.4684 (0.4684)	Prec@1 80.469 (80.469)
Epoch: [51][20/79]	Time 0.047 (0.083)	Loss 0.4187 (0.5027)	Prec@1 84.375 (81.473)
Epoch: [51][40/79]	Time 0.046 (0.065)	Loss 0.4482 (0.4943)	Prec@1 83.594 (82.165)
Epoch: [51][60/79]	Time 0.048 (0.059)	Loss 0.3832 (0.4895)	Prec@1 87.500 (82.454)
training time:  4.566198110580444
Test: [0/79]	Time 0.804 (0.804)	Loss 1.6453 (1.6453)	Prec@1 47.656 (47.656)
Test: [20/79]	Time 0.032 (0.069)	Loss 1.3849 (1.7447)	Prec@1 55.469 (52.158)
Test: [40/79]	Time 0.032 (0.051)	Loss 1.7659 (1.7109)	Prec@1 55.469 (53.735)
Test: [60/79]	Time 0.032 (0.045)	Loss 1.7253 (1.7313)	Prec@1 54.688 (53.612)
 * Prec@1 53.880
Epoch: [52][0/79]	Time 0.839 (0.839)	Loss 0.7266 (0.7266)	Prec@1 74.219 (74.219)
Epoch: [52][20/79]	Time 0.043 (0.083)	Loss 0.4795 (0.6875)	Prec@1 82.812 (75.223)
Epoch: [52][40/79]	Time 0.044 (0.065)	Loss 0.4565 (0.6140)	Prec@1 85.938 (77.725)
Epoch: [52][60/79]	Time 0.044 (0.058)	Loss 0.4708 (0.5721)	Prec@1 85.156 (79.380)
training time:  4.491258144378662
Test: [0/79]	Time 0.782 (0.782)	Loss 1.1338 (1.1338)	Prec@1 62.500 (62.500)
Test: [20/79]	Time 0.032 (0.068)	Loss 1.2330 (1.2300)	Prec@1 58.594 (62.909)
Test: [40/79]	Time 0.032 (0.050)	Loss 1.2909 (1.2446)	Prec@1 60.938 (62.329)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.4720 (1.2609)	Prec@1 61.719 (61.578)
 * Prec@1 61.450
Epoch: [53][0/79]	Time 0.792 (0.792)	Loss 0.5171 (0.5171)	Prec@1 79.688 (79.688)
Epoch: [53][20/79]	Time 0.049 (0.082)	Loss 0.4465 (0.5140)	Prec@1 84.375 (81.808)
Epoch: [53][40/79]	Time 0.046 (0.065)	Loss 0.5487 (0.4803)	Prec@1 75.781 (82.908)
Epoch: [53][60/79]	Time 0.046 (0.059)	Loss 0.4509 (0.4610)	Prec@1 79.688 (83.568)
training time:  4.565109968185425
Test: [0/79]	Time 0.760 (0.760)	Loss 1.0093 (1.0093)	Prec@1 68.750 (68.750)
Test: [20/79]	Time 0.031 (0.065)	Loss 0.9463 (1.0781)	Prec@1 71.875 (66.481)
Test: [40/79]	Time 0.029 (0.049)	Loss 1.1277 (1.0799)	Prec@1 60.938 (66.101)
Test: [60/79]	Time 0.030 (0.043)	Loss 1.2416 (1.0992)	Prec@1 65.625 (65.394)
 * Prec@1 65.420
Epoch: [54][0/79]	Time 0.799 (0.799)	Loss 0.3451 (0.3451)	Prec@1 90.625 (90.625)
Epoch: [54][20/79]	Time 0.046 (0.083)	Loss 0.4287 (0.3952)	Prec@1 88.281 (86.533)
Epoch: [54][40/79]	Time 0.046 (0.065)	Loss 0.3133 (0.3855)	Prec@1 88.281 (86.833)
Epoch: [54][60/79]	Time 0.046 (0.059)	Loss 0.3555 (0.3849)	Prec@1 88.281 (86.475)
training time:  4.562646389007568
Test: [0/79]	Time 0.746 (0.746)	Loss 1.3684 (1.3684)	Prec@1 66.406 (66.406)
Test: [20/79]	Time 0.032 (0.066)	Loss 1.6440 (1.5313)	Prec@1 57.031 (60.454)
Test: [40/79]	Time 0.032 (0.049)	Loss 1.3897 (1.4946)	Prec@1 64.844 (60.823)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.8326 (1.4816)	Prec@1 59.375 (60.566)
 * Prec@1 60.260
Epoch: [55][0/79]	Time 0.793 (0.793)	Loss 0.5230 (0.5230)	Prec@1 81.250 (81.250)
Epoch: [55][20/79]	Time 0.050 (0.088)	Loss 0.6996 (0.4906)	Prec@1 73.438 (82.961)
Epoch: [55][40/79]	Time 0.048 (0.068)	Loss 0.4744 (0.4731)	Prec@1 84.375 (83.460)
Epoch: [55][60/79]	Time 0.044 (0.061)	Loss 0.3285 (0.4521)	Prec@1 88.281 (84.080)
training time:  4.688531160354614
Test: [0/79]	Time 0.785 (0.785)	Loss 1.2990 (1.2990)	Prec@1 60.156 (60.156)
Test: [20/79]	Time 0.030 (0.067)	Loss 1.2060 (1.2227)	Prec@1 63.281 (65.179)
Test: [40/79]	Time 0.032 (0.049)	Loss 1.3318 (1.2167)	Prec@1 65.625 (65.187)
Test: [60/79]	Time 0.031 (0.043)	Loss 1.3433 (1.2186)	Prec@1 68.750 (64.831)
 * Prec@1 64.890
Epoch: [56][0/79]	Time 0.845 (0.845)	Loss 0.3187 (0.3187)	Prec@1 90.625 (90.625)
Epoch: [56][20/79]	Time 0.045 (0.085)	Loss 0.4495 (0.4142)	Prec@1 85.938 (86.012)
Epoch: [56][40/79]	Time 0.046 (0.066)	Loss 0.4947 (0.3933)	Prec@1 83.594 (86.585)
Epoch: [56][60/79]	Time 0.045 (0.060)	Loss 0.4289 (0.3891)	Prec@1 82.812 (86.591)
training time:  4.6161158084869385
Test: [0/79]	Time 0.780 (0.780)	Loss 0.9839 (0.9839)	Prec@1 67.969 (67.969)
Test: [20/79]	Time 0.033 (0.066)	Loss 1.1925 (1.1894)	Prec@1 63.281 (65.365)
Test: [40/79]	Time 0.033 (0.050)	Loss 1.1394 (1.1886)	Prec@1 68.750 (65.034)
Test: [60/79]	Time 0.030 (0.044)	Loss 1.3544 (1.2029)	Prec@1 61.719 (64.575)
 * Prec@1 64.440
Epoch: [57][0/79]	Time 0.830 (0.830)	Loss 0.3575 (0.3575)	Prec@1 90.625 (90.625)
Epoch: [57][20/79]	Time 0.046 (0.083)	Loss 0.2833 (0.3739)	Prec@1 88.281 (85.900)
Epoch: [57][40/79]	Time 0.042 (0.064)	Loss 0.4444 (0.3545)	Prec@1 84.375 (87.005)
Epoch: [57][60/79]	Time 0.046 (0.058)	Loss 0.3706 (0.3429)	Prec@1 89.062 (87.679)
training time:  4.495916366577148
Test: [0/79]	Time 0.786 (0.786)	Loss 1.1540 (1.1540)	Prec@1 65.625 (65.625)
Test: [20/79]	Time 0.032 (0.068)	Loss 1.1630 (1.2712)	Prec@1 67.969 (64.583)
Test: [40/79]	Time 0.031 (0.050)	Loss 1.1877 (1.2554)	Prec@1 64.062 (65.015)
Test: [60/79]	Time 0.032 (0.044)	Loss 1.4973 (1.2597)	Prec@1 60.938 (65.061)
 * Prec@1 65.160
Epoch: [58][0/79]	Time 0.819 (0.819)	Loss 0.3451 (0.3451)	Prec@1 89.062 (89.062)
Epoch: [58][20/79]	Time 0.049 (0.083)	Loss 0.2682 (0.3941)	Prec@1 90.625 (85.826)
Epoch: [58][40/79]	Time 0.044 (0.065)	Loss 0.3969 (0.3844)	Prec@1 84.375 (86.490)
Epoch: [58][60/79]	Time 0.048 (0.059)	Loss 0.3037 (0.3723)	Prec@1 90.625 (86.949)
training time:  4.556585788726807
Test: [0/79]	Time 0.782 (0.782)	Loss 1.4129 (1.4129)	Prec@1 59.375 (59.375)
Test: [20/79]	Time 0.033 (0.067)	Loss 1.4753 (1.5871)	Prec@1 56.250 (56.882)
Test: [40/79]	Time 0.032 (0.050)	Loss 1.7860 (1.5603)	Prec@1 53.125 (57.717)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.8756 (1.5882)	Prec@1 52.344 (57.172)
 * Prec@1 56.810
Epoch: [59][0/79]	Time 0.820 (0.820)	Loss 0.2255 (0.2255)	Prec@1 92.969 (92.969)
Epoch: [59][20/79]	Time 0.047 (0.084)	Loss 0.4957 (0.4325)	Prec@1 83.594 (84.561)
Epoch: [59][40/79]	Time 0.045 (0.065)	Loss 0.3037 (0.4094)	Prec@1 90.625 (85.442)
Epoch: [59][60/79]	Time 0.045 (0.059)	Loss 0.2149 (0.3732)	Prec@1 93.750 (86.924)
training time:  4.580964088439941
Test: [0/79]	Time 0.793 (0.793)	Loss 1.0987 (1.0987)	Prec@1 70.312 (70.312)
Test: [20/79]	Time 0.031 (0.068)	Loss 1.3387 (1.2015)	Prec@1 62.500 (65.327)
Test: [40/79]	Time 0.031 (0.051)	Loss 1.4689 (1.1991)	Prec@1 56.250 (65.816)
Test: [60/79]	Time 0.031 (0.045)	Loss 1.3597 (1.1902)	Prec@1 64.062 (65.817)
 * Prec@1 65.730
Epoch: [60][0/79]	Time 0.833 (0.833)	Loss 0.2335 (0.2335)	Prec@1 92.188 (92.188)
Epoch: [60][20/79]	Time 0.047 (0.083)	Loss 0.3528 (0.3235)	Prec@1 85.156 (88.430)
Epoch: [60][40/79]	Time 0.045 (0.065)	Loss 0.2631 (0.3016)	Prec@1 91.406 (89.367)
Epoch: [60][60/79]	Time 0.045 (0.059)	Loss 0.2336 (0.2949)	Prec@1 92.188 (89.767)
training time:  4.563870429992676
Test: [0/79]	Time 0.790 (0.790)	Loss 1.1124 (1.1124)	Prec@1 73.438 (73.438)
Test: [20/79]	Time 0.029 (0.073)	Loss 1.0011 (1.1513)	Prec@1 70.312 (67.932)
Test: [40/79]	Time 0.032 (0.052)	Loss 1.1381 (1.1280)	Prec@1 68.750 (68.483)
Test: [60/79]	Time 0.032 (0.046)	Loss 1.2642 (1.1326)	Prec@1 64.844 (68.494)
 * Prec@1 68.540
=> Saving checkpoint for epoch 60, with Prec@1 68.540000.
Epoch: [61][0/79]	Time 0.838 (0.838)	Loss 0.1608 (0.1608)	Prec@1 95.312 (95.312)
Epoch: [61][20/79]	Time 0.046 (0.084)	Loss 0.2669 (0.2333)	Prec@1 91.406 (92.113)
Epoch: [61][40/79]	Time 0.042 (0.065)	Loss 0.2154 (0.2193)	Prec@1 92.969 (92.397)
Epoch: [61][60/79]	Time 0.042 (0.058)	Loss 0.2800 (0.2225)	Prec@1 85.938 (92.303)
training time:  4.4796178340911865
Test: [0/79]	Time 0.799 (0.799)	Loss 1.2070 (1.2070)	Prec@1 68.750 (68.750)
Test: [20/79]	Time 0.032 (0.068)	Loss 1.0779 (1.1800)	Prec@1 65.625 (68.006)
Test: [40/79]	Time 0.033 (0.051)	Loss 1.2798 (1.1673)	Prec@1 67.188 (68.007)
Test: [60/79]	Time 0.031 (0.045)	Loss 1.1830 (1.1543)	Prec@1 69.531 (67.392)
 * Prec@1 67.520
Epoch: [62][0/79]	Time 0.816 (0.816)	Loss 0.2733 (0.2733)	Prec@1 88.281 (88.281)
Epoch: [62][20/79]	Time 0.046 (0.083)	Loss 0.2515 (0.2727)	Prec@1 92.969 (90.290)
Epoch: [62][40/79]	Time 0.046 (0.065)	Loss 0.1509 (0.2457)	Prec@1 95.312 (91.120)
Epoch: [62][60/79]	Time 0.046 (0.059)	Loss 0.2675 (0.2310)	Prec@1 90.625 (91.803)
training time:  4.554324150085449
Test: [0/79]	Time 0.761 (0.761)	Loss 1.2092 (1.2092)	Prec@1 64.062 (64.062)
Test: [20/79]	Time 0.032 (0.065)	Loss 1.2740 (1.2565)	Prec@1 68.750 (64.955)
Test: [40/79]	Time 0.032 (0.048)	Loss 1.3564 (1.2416)	Prec@1 67.188 (65.739)
Test: [60/79]	Time 0.031 (0.043)	Loss 1.4160 (1.2475)	Prec@1 64.062 (65.932)
 * Prec@1 65.990
Epoch: [63][0/79]	Time 0.783 (0.783)	Loss 0.2137 (0.2137)	Prec@1 93.750 (93.750)
Epoch: [63][20/79]	Time 0.046 (0.082)	Loss 0.1889 (0.2934)	Prec@1 95.312 (89.286)
Epoch: [63][40/79]	Time 0.047 (0.065)	Loss 0.2209 (0.2763)	Prec@1 94.531 (90.396)
Epoch: [63][60/79]	Time 0.045 (0.059)	Loss 0.2819 (0.2677)	Prec@1 90.625 (90.599)
training time:  4.561027765274048
Test: [0/79]	Time 0.754 (0.754)	Loss 1.2181 (1.2181)	Prec@1 70.312 (70.312)
Test: [20/79]	Time 0.032 (0.065)	Loss 1.0726 (1.1484)	Prec@1 71.875 (68.601)
Test: [40/79]	Time 0.032 (0.049)	Loss 1.3069 (1.1547)	Prec@1 64.844 (68.540)
Test: [60/79]	Time 0.031 (0.043)	Loss 1.3666 (1.1517)	Prec@1 65.625 (68.122)
 * Prec@1 68.030
Epoch: [64][0/79]	Time 0.793 (0.793)	Loss 0.2098 (0.2098)	Prec@1 90.625 (90.625)
Epoch: [64][20/79]	Time 0.047 (0.082)	Loss 0.2497 (0.2855)	Prec@1 91.406 (89.844)
Epoch: [64][40/79]	Time 0.046 (0.064)	Loss 0.2154 (0.2612)	Prec@1 94.531 (90.758)
Epoch: [64][60/79]	Time 0.045 (0.058)	Loss 0.2118 (0.2459)	Prec@1 91.406 (91.368)
training time:  4.5183610916137695
Test: [0/79]	Time 0.755 (0.755)	Loss 1.1554 (1.1554)	Prec@1 63.281 (63.281)
Test: [20/79]	Time 0.031 (0.066)	Loss 1.2858 (1.2627)	Prec@1 61.719 (65.290)
Test: [40/79]	Time 0.032 (0.050)	Loss 1.4549 (1.2709)	Prec@1 62.500 (65.339)
Test: [60/79]	Time 0.032 (0.044)	Loss 1.4571 (1.2662)	Prec@1 64.062 (65.113)
 * Prec@1 65.190
Epoch: [65][0/79]	Time 0.783 (0.783)	Loss 0.2489 (0.2489)	Prec@1 92.188 (92.188)
Epoch: [65][20/79]	Time 0.046 (0.082)	Loss 0.2462 (0.2440)	Prec@1 89.062 (91.257)
Epoch: [65][40/79]	Time 0.046 (0.064)	Loss 0.1536 (0.2143)	Prec@1 96.094 (92.359)
Epoch: [65][60/79]	Time 0.046 (0.058)	Loss 0.2445 (0.2097)	Prec@1 92.188 (92.610)
training time:  4.534507989883423
Test: [0/79]	Time 0.755 (0.755)	Loss 1.3705 (1.3705)	Prec@1 64.062 (64.062)
Test: [20/79]	Time 0.029 (0.064)	Loss 1.0252 (1.1571)	Prec@1 72.656 (68.676)
Test: [40/79]	Time 0.032 (0.047)	Loss 1.0569 (1.1324)	Prec@1 68.750 (69.207)
Test: [60/79]	Time 0.031 (0.042)	Loss 1.3564 (1.1259)	Prec@1 64.062 (69.121)
 * Prec@1 68.970
=> Saving checkpoint for epoch 65, with Prec@1 68.970000.
Epoch: [66][0/79]	Time 0.790 (0.790)	Loss 0.1782 (0.1782)	Prec@1 92.969 (92.969)
Epoch: [66][20/79]	Time 0.046 (0.088)	Loss 0.2188 (0.2680)	Prec@1 90.625 (90.885)
Epoch: [66][40/79]	Time 0.044 (0.068)	Loss 0.2038 (0.2344)	Prec@1 92.969 (91.959)
Epoch: [66][60/79]	Time 0.044 (0.061)	Loss 0.1793 (0.2183)	Prec@1 94.531 (92.431)
training time:  4.706005811691284
Test: [0/79]	Time 0.786 (0.786)	Loss 1.3799 (1.3799)	Prec@1 69.531 (69.531)
Test: [20/79]	Time 0.029 (0.066)	Loss 1.3665 (1.2831)	Prec@1 66.406 (67.039)
Test: [40/79]	Time 0.032 (0.048)	Loss 1.3189 (1.2871)	Prec@1 65.625 (66.978)
Test: [60/79]	Time 0.029 (0.043)	Loss 1.4284 (1.2945)	Prec@1 68.750 (66.752)
 * Prec@1 66.850
Epoch: [67][0/79]	Time 0.785 (0.785)	Loss 0.2051 (0.2051)	Prec@1 93.750 (93.750)
Epoch: [67][20/79]	Time 0.046 (0.082)	Loss 0.1593 (0.1784)	Prec@1 95.312 (93.601)
Epoch: [67][40/79]	Time 0.045 (0.065)	Loss 0.1840 (0.1650)	Prec@1 92.188 (94.264)
Epoch: [67][60/79]	Time 0.045 (0.059)	Loss 0.1549 (0.1595)	Prec@1 92.188 (94.352)
training time:  4.565747976303101
Test: [0/79]	Time 0.747 (0.747)	Loss 1.3797 (1.3797)	Prec@1 70.312 (70.312)
Test: [20/79]	Time 0.032 (0.066)	Loss 1.4538 (1.3504)	Prec@1 64.062 (66.555)
Test: [40/79]	Time 0.032 (0.049)	Loss 1.2557 (1.3323)	Prec@1 69.531 (66.597)
Test: [60/79]	Time 0.032 (0.044)	Loss 1.5002 (1.3326)	Prec@1 68.750 (66.790)
 * Prec@1 66.790
Epoch: [68][0/79]	Time 0.792 (0.792)	Loss 0.0787 (0.0787)	Prec@1 99.219 (99.219)
Epoch: [68][20/79]	Time 0.046 (0.080)	Loss 0.1326 (0.1592)	Prec@1 94.531 (94.866)
Epoch: [68][40/79]	Time 0.046 (0.063)	Loss 0.1535 (0.1526)	Prec@1 92.188 (95.027)
Epoch: [68][60/79]	Time 0.045 (0.057)	Loss 0.0817 (0.1427)	Prec@1 97.656 (95.377)
training time:  4.469945430755615
Test: [0/79]	Time 0.751 (0.751)	Loss 0.9863 (0.9863)	Prec@1 71.094 (71.094)
Test: [20/79]	Time 0.033 (0.066)	Loss 1.1528 (1.1748)	Prec@1 70.312 (69.792)
Test: [40/79]	Time 0.032 (0.050)	Loss 1.0329 (1.1291)	Prec@1 69.531 (70.408)
Test: [60/79]	Time 0.030 (0.044)	Loss 1.3340 (1.1312)	Prec@1 63.281 (70.517)
 * Prec@1 70.370
=> Saving checkpoint for epoch 68, with Prec@1 70.370000.
Epoch: [69][0/79]	Time 0.793 (0.793)	Loss 0.1249 (0.1249)	Prec@1 95.312 (95.312)
Epoch: [69][20/79]	Time 0.048 (0.081)	Loss 0.2261 (0.1565)	Prec@1 92.969 (94.457)
Epoch: [69][40/79]	Time 0.047 (0.064)	Loss 0.1221 (0.1463)	Prec@1 96.094 (95.008)
Epoch: [69][60/79]	Time 0.045 (0.058)	Loss 0.1288 (0.1355)	Prec@1 95.312 (95.556)
training time:  4.5359108448028564
Test: [0/79]	Time 0.745 (0.745)	Loss 1.2944 (1.2944)	Prec@1 67.969 (67.969)
Test: [20/79]	Time 0.031 (0.066)	Loss 1.5588 (1.4200)	Prec@1 57.812 (65.439)
Test: [40/79]	Time 0.032 (0.049)	Loss 1.3740 (1.3776)	Prec@1 67.969 (65.911)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.6603 (1.3771)	Prec@1 63.281 (65.945)
 * Prec@1 66.110
Epoch: [70][0/79]	Time 0.842 (0.842)	Loss 0.1122 (0.1122)	Prec@1 96.094 (96.094)
Epoch: [70][20/79]	Time 0.047 (0.083)	Loss 0.1521 (0.1428)	Prec@1 95.312 (95.015)
Epoch: [70][40/79]	Time 0.048 (0.065)	Loss 0.0960 (0.1289)	Prec@1 96.094 (95.541)
Epoch: [70][60/79]	Time 0.047 (0.059)	Loss 0.1148 (0.1245)	Prec@1 98.438 (95.927)
training time:  4.584365367889404
Test: [0/79]	Time 0.789 (0.789)	Loss 1.1041 (1.1041)	Prec@1 75.000 (75.000)
Test: [20/79]	Time 0.030 (0.066)	Loss 1.4609 (1.3000)	Prec@1 63.281 (68.713)
Test: [40/79]	Time 0.029 (0.049)	Loss 1.3120 (1.2683)	Prec@1 72.656 (69.017)
Test: [60/79]	Time 0.031 (0.043)	Loss 1.5471 (1.2574)	Prec@1 68.750 (69.032)
 * Prec@1 69.100
Epoch: [71][0/79]	Time 0.833 (0.833)	Loss 0.2268 (0.2268)	Prec@1 91.406 (91.406)
Epoch: [71][20/79]	Time 0.047 (0.084)	Loss 0.2578 (0.2323)	Prec@1 92.188 (92.522)
Epoch: [71][40/79]	Time 0.047 (0.066)	Loss 0.1055 (0.1887)	Prec@1 95.312 (94.112)
Epoch: [71][60/79]	Time 0.046 (0.059)	Loss 0.1273 (0.1628)	Prec@1 95.312 (94.851)
training time:  4.5974061489105225
Test: [0/79]	Time 0.778 (0.778)	Loss 1.3195 (1.3195)	Prec@1 71.094 (71.094)
Test: [20/79]	Time 0.029 (0.073)	Loss 1.2005 (1.1975)	Prec@1 67.969 (70.126)
Test: [40/79]	Time 0.030 (0.052)	Loss 1.4208 (1.1819)	Prec@1 65.625 (70.065)
Test: [60/79]	Time 0.032 (0.046)	Loss 1.3805 (1.1716)	Prec@1 65.625 (69.595)
 * Prec@1 69.730
Epoch: [72][0/79]	Time 0.829 (0.829)	Loss 0.1303 (0.1303)	Prec@1 96.094 (96.094)
Epoch: [72][20/79]	Time 0.046 (0.083)	Loss 0.1912 (0.2190)	Prec@1 93.750 (92.671)
Epoch: [72][40/79]	Time 0.047 (0.064)	Loss 0.1309 (0.1802)	Prec@1 95.312 (94.036)
Epoch: [72][60/79]	Time 0.044 (0.058)	Loss 0.1103 (0.1586)	Prec@1 97.656 (94.839)
training time:  4.489526033401489
Test: [0/79]	Time 0.794 (0.794)	Loss 1.1164 (1.1164)	Prec@1 71.094 (71.094)
Test: [20/79]	Time 0.032 (0.068)	Loss 0.9898 (1.1300)	Prec@1 74.219 (70.908)
Test: [40/79]	Time 0.032 (0.050)	Loss 1.0432 (1.1255)	Prec@1 71.094 (71.075)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.4752 (1.1135)	Prec@1 64.844 (71.004)
 * Prec@1 71.170
=> Saving checkpoint for epoch 72, with Prec@1 71.170000.
Epoch: [73][0/79]	Time 0.834 (0.834)	Loss 0.0916 (0.0916)	Prec@1 96.875 (96.875)
Epoch: [73][20/79]	Time 0.046 (0.084)	Loss 0.1616 (0.1451)	Prec@1 96.094 (94.978)
Epoch: [73][40/79]	Time 0.046 (0.066)	Loss 0.1291 (0.1278)	Prec@1 94.531 (95.465)
Epoch: [73][60/79]	Time 0.046 (0.059)	Loss 0.1706 (0.1181)	Prec@1 96.094 (95.991)
training time:  4.580599308013916
Test: [0/79]	Time 0.744 (0.744)	Loss 1.1847 (1.1847)	Prec@1 71.094 (71.094)
Test: [20/79]	Time 0.032 (0.065)	Loss 1.1290 (1.1578)	Prec@1 69.531 (70.833)
Test: [40/79]	Time 0.032 (0.048)	Loss 1.0489 (1.1232)	Prec@1 70.312 (71.208)
Test: [60/79]	Time 0.031 (0.043)	Loss 1.3608 (1.1133)	Prec@1 66.406 (71.183)
 * Prec@1 71.480
=> Saving checkpoint for epoch 73, with Prec@1 71.480000.
Epoch: [74][0/79]	Time 0.786 (0.786)	Loss 0.0610 (0.0610)	Prec@1 98.438 (98.438)
Epoch: [74][20/79]	Time 0.050 (0.082)	Loss 0.0620 (0.0715)	Prec@1 99.219 (98.214)
Epoch: [74][40/79]	Time 0.046 (0.065)	Loss 0.0623 (0.0719)	Prec@1 99.219 (98.114)
Epoch: [74][60/79]	Time 0.046 (0.059)	Loss 0.0541 (0.0703)	Prec@1 98.438 (98.156)
training time:  4.574281215667725
Test: [0/79]	Time 0.767 (0.767)	Loss 1.1211 (1.1211)	Prec@1 75.781 (75.781)
Test: [20/79]	Time 0.032 (0.067)	Loss 1.0497 (1.1215)	Prec@1 71.875 (72.098)
Test: [40/79]	Time 0.032 (0.050)	Loss 1.2181 (1.1051)	Prec@1 67.969 (71.932)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.4893 (1.0968)	Prec@1 69.531 (71.824)
 * Prec@1 71.850
=> Saving checkpoint for epoch 74, with Prec@1 71.850000.
Epoch: [75][0/79]	Time 0.781 (0.781)	Loss 0.0382 (0.0382)	Prec@1 99.219 (99.219)
Epoch: [75][20/79]	Time 0.043 (0.079)	Loss 0.0966 (0.0819)	Prec@1 98.438 (97.359)
Epoch: [75][40/79]	Time 0.042 (0.063)	Loss 0.0856 (0.0748)	Prec@1 96.094 (97.580)
Epoch: [75][60/79]	Time 0.045 (0.057)	Loss 0.0473 (0.0699)	Prec@1 99.219 (97.810)
training time:  4.489309787750244
Test: [0/79]	Time 0.806 (0.806)	Loss 1.0510 (1.0510)	Prec@1 75.781 (75.781)
Test: [20/79]	Time 0.029 (0.068)	Loss 1.2087 (1.1646)	Prec@1 69.531 (71.577)
Test: [40/79]	Time 0.031 (0.050)	Loss 1.2496 (1.1521)	Prec@1 68.750 (71.761)
Test: [60/79]	Time 0.031 (0.045)	Loss 1.4689 (1.1541)	Prec@1 65.625 (71.721)
 * Prec@1 71.680
Epoch: [76][0/79]	Time 0.827 (0.827)	Loss 0.0457 (0.0457)	Prec@1 99.219 (99.219)
Epoch: [76][20/79]	Time 0.044 (0.083)	Loss 0.0748 (0.0833)	Prec@1 97.656 (97.321)
Epoch: [76][40/79]	Time 0.045 (0.065)	Loss 0.0551 (0.0739)	Prec@1 97.656 (97.542)
Epoch: [76][60/79]	Time 0.045 (0.058)	Loss 0.0844 (0.0699)	Prec@1 97.656 (97.772)
training time:  4.542821168899536
Test: [0/79]	Time 0.793 (0.793)	Loss 1.1299 (1.1299)	Prec@1 71.875 (71.875)
Test: [20/79]	Time 0.032 (0.068)	Loss 1.1470 (1.1593)	Prec@1 72.656 (71.987)
Test: [40/79]	Time 0.032 (0.051)	Loss 1.2032 (1.1362)	Prec@1 70.312 (71.684)
Test: [60/79]	Time 0.032 (0.045)	Loss 1.3709 (1.1286)	Prec@1 67.188 (71.734)
 * Prec@1 72.090
=> Saving checkpoint for epoch 76, with Prec@1 72.090000.
Epoch: [77][0/79]	Time 0.818 (0.818)	Loss 0.0327 (0.0327)	Prec@1 99.219 (99.219)
Epoch: [77][20/79]	Time 0.046 (0.088)	Loss 0.0518 (0.0751)	Prec@1 98.438 (97.879)
Epoch: [77][40/79]	Time 0.049 (0.068)	Loss 0.0723 (0.0665)	Prec@1 97.656 (98.075)
Epoch: [77][60/79]	Time 0.047 (0.061)	Loss 0.0435 (0.0585)	Prec@1 99.219 (98.412)
training time:  4.750858306884766
Test: [0/79]	Time 0.790 (0.790)	Loss 1.2083 (1.2083)	Prec@1 72.656 (72.656)
Test: [20/79]	Time 0.032 (0.068)	Loss 1.0456 (1.2056)	Prec@1 74.219 (71.317)
Test: [40/79]	Time 0.034 (0.051)	Loss 1.2423 (1.1932)	Prec@1 67.188 (71.189)
Test: [60/79]	Time 0.033 (0.045)	Loss 1.6848 (1.1906)	Prec@1 61.719 (70.940)
 * Prec@1 71.470
Epoch: [78][0/79]	Time 0.828 (0.828)	Loss 0.0202 (0.0202)	Prec@1 99.219 (99.219)
Epoch: [78][20/79]	Time 0.047 (0.083)	Loss 0.0844 (0.0744)	Prec@1 96.094 (97.507)
Epoch: [78][40/79]	Time 0.046 (0.065)	Loss 0.0863 (0.0660)	Prec@1 96.094 (97.904)
Epoch: [78][60/79]	Time 0.046 (0.059)	Loss 0.0290 (0.0625)	Prec@1 99.219 (98.053)
training time:  4.5480146408081055
Test: [0/79]	Time 0.759 (0.759)	Loss 1.1410 (1.1410)	Prec@1 74.219 (74.219)
Test: [20/79]	Time 0.032 (0.066)	Loss 1.2335 (1.2540)	Prec@1 70.312 (70.201)
Test: [40/79]	Time 0.032 (0.049)	Loss 1.2310 (1.2284)	Prec@1 65.625 (70.732)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.6453 (1.2243)	Prec@1 63.281 (70.389)
 * Prec@1 70.290
Epoch: [79][0/79]	Time 0.785 (0.785)	Loss 0.0375 (0.0375)	Prec@1 98.438 (98.438)
Epoch: [79][20/79]	Time 0.044 (0.081)	Loss 0.0767 (0.0584)	Prec@1 96.094 (98.140)
Epoch: [79][40/79]	Time 0.046 (0.064)	Loss 0.0385 (0.0528)	Prec@1 100.000 (98.342)
Epoch: [79][60/79]	Time 0.046 (0.058)	Loss 0.0426 (0.0493)	Prec@1 98.438 (98.527)
training time:  4.522785663604736
Test: [0/79]	Time 0.745 (0.745)	Loss 1.1192 (1.1192)	Prec@1 76.562 (76.562)
Test: [20/79]	Time 0.032 (0.066)	Loss 0.9222 (1.1294)	Prec@1 75.781 (73.289)
Test: [40/79]	Time 0.032 (0.049)	Loss 1.0850 (1.1163)	Prec@1 73.438 (73.152)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.6017 (1.1214)	Prec@1 65.625 (72.554)
 * Prec@1 72.780
=> Saving checkpoint for epoch 79, with Prec@1 72.780000.
Epoch: [80][0/79]	Time 0.781 (0.781)	Loss 0.0241 (0.0241)	Prec@1 99.219 (99.219)
Epoch: [80][20/79]	Time 0.048 (0.083)	Loss 0.0264 (0.0404)	Prec@1 100.000 (98.847)
Epoch: [80][40/79]	Time 0.049 (0.066)	Loss 0.0743 (0.0420)	Prec@1 96.875 (98.723)
Epoch: [80][60/79]	Time 0.048 (0.060)	Loss 0.0310 (0.0391)	Prec@1 99.219 (98.873)
training time:  4.684177875518799
Test: [0/79]	Time 0.755 (0.755)	Loss 1.1219 (1.1219)	Prec@1 73.438 (73.438)
Test: [20/79]	Time 0.031 (0.066)	Loss 1.0865 (1.1850)	Prec@1 73.438 (71.949)
Test: [40/79]	Time 0.029 (0.049)	Loss 1.1244 (1.1503)	Prec@1 69.531 (72.008)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.5524 (1.1520)	Prec@1 68.750 (71.785)
 * Prec@1 71.920
Epoch: [81][0/79]	Time 0.779 (0.779)	Loss 0.0384 (0.0384)	Prec@1 98.438 (98.438)
Epoch: [81][20/79]	Time 0.046 (0.081)	Loss 0.0405 (0.0323)	Prec@1 98.438 (99.330)
Epoch: [81][40/79]	Time 0.047 (0.064)	Loss 0.0358 (0.0343)	Prec@1 99.219 (99.104)
Epoch: [81][60/79]	Time 0.047 (0.058)	Loss 0.0190 (0.0340)	Prec@1 100.000 (99.116)
training time:  4.509248733520508
Test: [0/79]	Time 0.744 (0.744)	Loss 1.0609 (1.0609)	Prec@1 75.000 (75.000)
Test: [20/79]	Time 0.032 (0.065)	Loss 1.0520 (1.1336)	Prec@1 72.656 (72.507)
Test: [40/79]	Time 0.032 (0.049)	Loss 1.0801 (1.1078)	Prec@1 69.531 (72.675)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.4822 (1.1137)	Prec@1 65.625 (72.400)
 * Prec@1 72.640
Epoch: [82][0/79]	Time 0.790 (0.790)	Loss 0.0416 (0.0416)	Prec@1 97.656 (97.656)
Epoch: [82][20/79]	Time 0.043 (0.081)	Loss 0.0254 (0.0429)	Prec@1 99.219 (98.512)
Epoch: [82][40/79]	Time 0.048 (0.063)	Loss 0.0210 (0.0415)	Prec@1 99.219 (98.723)
Epoch: [82][60/79]	Time 0.046 (0.057)	Loss 0.0448 (0.0397)	Prec@1 98.438 (98.860)
training time:  4.475758790969849
Test: [0/79]	Time 0.745 (0.745)	Loss 1.1388 (1.1388)	Prec@1 77.344 (77.344)
Test: [20/79]	Time 0.032 (0.072)	Loss 0.9808 (1.1606)	Prec@1 73.438 (72.135)
Test: [40/79]	Time 0.032 (0.053)	Loss 1.1833 (1.1390)	Prec@1 65.625 (72.046)
Test: [60/79]	Time 0.033 (0.046)	Loss 1.5303 (1.1456)	Prec@1 66.406 (71.798)
 * Prec@1 72.290
Epoch: [83][0/79]	Time 0.804 (0.804)	Loss 0.0407 (0.0407)	Prec@1 99.219 (99.219)
Epoch: [83][20/79]	Time 0.046 (0.083)	Loss 0.0351 (0.0370)	Prec@1 99.219 (99.070)
Epoch: [83][40/79]	Time 0.045 (0.065)	Loss 0.0202 (0.0317)	Prec@1 100.000 (99.219)
Epoch: [83][60/79]	Time 0.047 (0.059)	Loss 0.0357 (0.0294)	Prec@1 99.219 (99.321)
training time:  4.582833528518677
Test: [0/79]	Time 0.744 (0.744)	Loss 1.1234 (1.1234)	Prec@1 73.438 (73.438)
Test: [20/79]	Time 0.032 (0.065)	Loss 1.1669 (1.1689)	Prec@1 70.312 (72.247)
Test: [40/79]	Time 0.032 (0.049)	Loss 1.2091 (1.1377)	Prec@1 67.188 (72.370)
Test: [60/79]	Time 0.030 (0.043)	Loss 1.4316 (1.1391)	Prec@1 67.188 (72.195)
 * Prec@1 72.400
Epoch: [84][0/79]	Time 0.793 (0.793)	Loss 0.0122 (0.0122)	Prec@1 100.000 (100.000)
Epoch: [84][20/79]	Time 0.047 (0.082)	Loss 0.0610 (0.0402)	Prec@1 97.656 (98.810)
Epoch: [84][40/79]	Time 0.048 (0.065)	Loss 0.0285 (0.0375)	Prec@1 100.000 (98.971)
Epoch: [84][60/79]	Time 0.045 (0.059)	Loss 0.0547 (0.0348)	Prec@1 97.656 (99.142)
training time:  4.536233901977539
Test: [0/79]	Time 0.736 (0.736)	Loss 1.1734 (1.1734)	Prec@1 74.219 (74.219)
Test: [20/79]	Time 0.032 (0.065)	Loss 1.2039 (1.1674)	Prec@1 71.094 (72.061)
Test: [40/79]	Time 0.032 (0.049)	Loss 1.2067 (1.1449)	Prec@1 70.312 (72.104)
Test: [60/79]	Time 0.032 (0.044)	Loss 1.4354 (1.1464)	Prec@1 66.406 (72.131)
 * Prec@1 72.340
Epoch: [85][0/79]	Time 0.798 (0.798)	Loss 0.0266 (0.0266)	Prec@1 99.219 (99.219)
Epoch: [85][20/79]	Time 0.046 (0.082)	Loss 0.0146 (0.0299)	Prec@1 100.000 (99.144)
Epoch: [85][40/79]	Time 0.046 (0.065)	Loss 0.0143 (0.0284)	Prec@1 100.000 (99.238)
Epoch: [85][60/79]	Time 0.046 (0.059)	Loss 0.0207 (0.0273)	Prec@1 100.000 (99.334)
training time:  4.576692581176758
Test: [0/79]	Time 0.762 (0.762)	Loss 1.1810 (1.1810)	Prec@1 73.438 (73.438)
Test: [20/79]	Time 0.029 (0.065)	Loss 1.1220 (1.1465)	Prec@1 72.656 (72.954)
Test: [40/79]	Time 0.031 (0.049)	Loss 1.1692 (1.1150)	Prec@1 68.750 (72.828)
Test: [60/79]	Time 0.032 (0.044)	Loss 1.3767 (1.1211)	Prec@1 70.312 (72.669)
 * Prec@1 72.810
=> Saving checkpoint for epoch 85, with Prec@1 72.810000.
Epoch: [86][0/79]	Time 0.787 (0.787)	Loss 0.0152 (0.0152)	Prec@1 100.000 (100.000)
Epoch: [86][20/79]	Time 0.043 (0.080)	Loss 0.0139 (0.0174)	Prec@1 100.000 (99.665)
Epoch: [86][40/79]	Time 0.043 (0.062)	Loss 0.0119 (0.0193)	Prec@1 100.000 (99.638)
Epoch: [86][60/79]	Time 0.045 (0.057)	Loss 0.0650 (0.0200)	Prec@1 99.219 (99.654)
training time:  4.446826457977295
Test: [0/79]	Time 0.746 (0.746)	Loss 1.1499 (1.1499)	Prec@1 74.219 (74.219)
Test: [20/79]	Time 0.032 (0.066)	Loss 1.0354 (1.1117)	Prec@1 75.781 (73.512)
Test: [40/79]	Time 0.032 (0.049)	Loss 1.1116 (1.0848)	Prec@1 67.969 (73.457)
Test: [60/79]	Time 0.030 (0.043)	Loss 1.3220 (1.0907)	Prec@1 70.312 (73.207)
 * Prec@1 73.540
=> Saving checkpoint for epoch 86, with Prec@1 73.540000.
Epoch: [87][0/79]	Time 0.781 (0.781)	Loss 0.0084 (0.0084)	Prec@1 100.000 (100.000)
Epoch: [87][20/79]	Time 0.043 (0.080)	Loss 0.0089 (0.0131)	Prec@1 100.000 (99.888)
Epoch: [87][40/79]	Time 0.049 (0.063)	Loss 0.0313 (0.0142)	Prec@1 99.219 (99.829)
Epoch: [87][60/79]	Time 0.046 (0.057)	Loss 0.0220 (0.0149)	Prec@1 100.000 (99.782)
training time:  4.470257043838501
Test: [0/79]	Time 0.747 (0.747)	Loss 1.2209 (1.2209)	Prec@1 71.875 (71.875)
Test: [20/79]	Time 0.032 (0.066)	Loss 1.0879 (1.1379)	Prec@1 73.438 (72.991)
Test: [40/79]	Time 0.033 (0.050)	Loss 1.2198 (1.1193)	Prec@1 67.969 (72.713)
Test: [60/79]	Time 0.032 (0.044)	Loss 1.4193 (1.1192)	Prec@1 67.969 (72.605)
 * Prec@1 72.690
Epoch: [88][0/79]	Time 0.800 (0.800)	Loss 0.0086 (0.0086)	Prec@1 100.000 (100.000)
Epoch: [88][20/79]	Time 0.048 (0.088)	Loss 0.0291 (0.0182)	Prec@1 98.438 (99.442)
Epoch: [88][40/79]	Time 0.048 (0.068)	Loss 0.0116 (0.0178)	Prec@1 100.000 (99.581)
Epoch: [88][60/79]	Time 0.046 (0.062)	Loss 0.0137 (0.0172)	Prec@1 100.000 (99.629)
training time:  4.7308619022369385
Test: [0/79]	Time 0.746 (0.746)	Loss 1.0813 (1.0813)	Prec@1 73.438 (73.438)
Test: [20/79]	Time 0.033 (0.067)	Loss 1.0365 (1.0953)	Prec@1 77.344 (73.177)
Test: [40/79]	Time 0.032 (0.050)	Loss 1.1255 (1.0764)	Prec@1 68.750 (73.114)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.4256 (1.0859)	Prec@1 67.969 (73.143)
 * Prec@1 73.340
Epoch: [89][0/79]	Time 0.796 (0.796)	Loss 0.0148 (0.0148)	Prec@1 100.000 (100.000)
Epoch: [89][20/79]	Time 0.047 (0.082)	Loss 0.0130 (0.0164)	Prec@1 100.000 (99.777)
Epoch: [89][40/79]	Time 0.046 (0.064)	Loss 0.0103 (0.0169)	Prec@1 100.000 (99.676)
Epoch: [89][60/79]	Time 0.046 (0.058)	Loss 0.0103 (0.0167)	Prec@1 100.000 (99.667)
training time:  4.5375401973724365
Test: [0/79]	Time 0.791 (0.791)	Loss 1.1612 (1.1612)	Prec@1 72.656 (72.656)
Test: [20/79]	Time 0.032 (0.068)	Loss 1.1141 (1.1196)	Prec@1 75.000 (73.624)
Test: [40/79]	Time 0.032 (0.050)	Loss 1.1827 (1.1006)	Prec@1 69.531 (73.685)
Test: [60/79]	Time 0.031 (0.045)	Loss 1.3990 (1.1079)	Prec@1 66.406 (73.361)
 * Prec@1 73.350
Epoch: [90][0/79]	Time 0.825 (0.825)	Loss 0.0173 (0.0173)	Prec@1 99.219 (99.219)
Epoch: [90][20/79]	Time 0.045 (0.084)	Loss 0.0213 (0.0155)	Prec@1 99.219 (99.814)
Epoch: [90][40/79]	Time 0.045 (0.065)	Loss 0.0068 (0.0154)	Prec@1 100.000 (99.790)
Epoch: [90][60/79]	Time 0.045 (0.059)	Loss 0.0129 (0.0146)	Prec@1 100.000 (99.795)
training time:  4.572594165802002
Test: [0/79]	Time 0.748 (0.748)	Loss 1.1832 (1.1832)	Prec@1 75.000 (75.000)
Test: [20/79]	Time 0.031 (0.064)	Loss 1.0930 (1.1157)	Prec@1 74.219 (73.400)
Test: [40/79]	Time 0.030 (0.048)	Loss 1.1113 (1.1032)	Prec@1 69.531 (73.457)
Test: [60/79]	Time 0.032 (0.043)	Loss 1.3390 (1.1091)	Prec@1 70.312 (73.297)
 * Prec@1 73.360
Epoch: [91][0/79]	Time 0.834 (0.834)	Loss 0.0307 (0.0307)	Prec@1 99.219 (99.219)
Epoch: [91][20/79]	Time 0.046 (0.083)	Loss 0.0152 (0.0153)	Prec@1 100.000 (99.777)
Epoch: [91][40/79]	Time 0.046 (0.065)	Loss 0.0212 (0.0144)	Prec@1 99.219 (99.809)
Epoch: [91][60/79]	Time 0.046 (0.059)	Loss 0.0082 (0.0149)	Prec@1 100.000 (99.705)
training time:  4.561001777648926
Test: [0/79]	Time 0.793 (0.793)	Loss 1.1788 (1.1788)	Prec@1 73.438 (73.438)
Test: [20/79]	Time 0.032 (0.068)	Loss 1.0875 (1.1092)	Prec@1 76.562 (73.698)
Test: [40/79]	Time 0.032 (0.050)	Loss 1.1115 (1.0886)	Prec@1 67.188 (73.552)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.4513 (1.0953)	Prec@1 68.750 (73.438)
 * Prec@1 73.670
=> Saving checkpoint for epoch 91, with Prec@1 73.670000.
Epoch: [92][0/79]	Time 0.789 (0.789)	Loss 0.0109 (0.0109)	Prec@1 100.000 (100.000)
Epoch: [92][20/79]	Time 0.047 (0.082)	Loss 0.0099 (0.0145)	Prec@1 100.000 (99.740)
Epoch: [92][40/79]	Time 0.048 (0.065)	Loss 0.0074 (0.0144)	Prec@1 100.000 (99.790)
Epoch: [92][60/79]	Time 0.046 (0.059)	Loss 0.0134 (0.0142)	Prec@1 100.000 (99.782)
training time:  4.590251207351685
Test: [0/79]	Time 0.786 (0.786)	Loss 1.1462 (1.1462)	Prec@1 75.000 (75.000)
Test: [20/79]	Time 0.029 (0.066)	Loss 1.0616 (1.0802)	Prec@1 75.000 (73.921)
Test: [40/79]	Time 0.030 (0.049)	Loss 1.0952 (1.0627)	Prec@1 69.531 (73.952)
Test: [60/79]	Time 0.030 (0.043)	Loss 1.3588 (1.0714)	Prec@1 68.750 (73.770)
 * Prec@1 73.840
=> Saving checkpoint for epoch 92, with Prec@1 73.840000.
Epoch: [93][0/79]	Time 0.823 (0.823)	Loss 0.0070 (0.0070)	Prec@1 100.000 (100.000)
Epoch: [93][20/79]	Time 0.046 (0.082)	Loss 0.0140 (0.0165)	Prec@1 100.000 (99.740)
Epoch: [93][40/79]	Time 0.046 (0.065)	Loss 0.0159 (0.0164)	Prec@1 100.000 (99.752)
Epoch: [93][60/79]	Time 0.046 (0.059)	Loss 0.0104 (0.0148)	Prec@1 100.000 (99.821)
training time:  4.53809928894043
Test: [0/79]	Time 0.790 (0.790)	Loss 1.1753 (1.1753)	Prec@1 75.000 (75.000)
Test: [20/79]	Time 0.029 (0.073)	Loss 1.0926 (1.1189)	Prec@1 74.219 (73.065)
Test: [40/79]	Time 0.032 (0.052)	Loss 1.1785 (1.1069)	Prec@1 70.312 (73.285)
Test: [60/79]	Time 0.031 (0.046)	Loss 1.4438 (1.1079)	Prec@1 68.750 (73.066)
 * Prec@1 73.050
Epoch: [94][0/79]	Time 0.833 (0.833)	Loss 0.0094 (0.0094)	Prec@1 100.000 (100.000)
Epoch: [94][20/79]	Time 0.045 (0.083)	Loss 0.0127 (0.0124)	Prec@1 100.000 (99.814)
Epoch: [94][40/79]	Time 0.043 (0.064)	Loss 0.0140 (0.0133)	Prec@1 100.000 (99.790)
Epoch: [94][60/79]	Time 0.046 (0.058)	Loss 0.0349 (0.0139)	Prec@1 98.438 (99.769)
training time:  4.540657043457031
Test: [0/79]	Time 0.812 (0.812)	Loss 1.1589 (1.1589)	Prec@1 74.219 (74.219)
Test: [20/79]	Time 0.032 (0.068)	Loss 1.0545 (1.1005)	Prec@1 75.000 (72.991)
Test: [40/79]	Time 0.031 (0.051)	Loss 1.1509 (1.0879)	Prec@1 69.531 (73.285)
Test: [60/79]	Time 0.030 (0.044)	Loss 1.3548 (1.0926)	Prec@1 69.531 (73.258)
 * Prec@1 73.410
Epoch: [95][0/79]	Time 0.798 (0.798)	Loss 0.0049 (0.0049)	Prec@1 100.000 (100.000)
Epoch: [95][20/79]	Time 0.042 (0.080)	Loss 0.0077 (0.0120)	Prec@1 100.000 (99.851)
Epoch: [95][40/79]	Time 0.046 (0.063)	Loss 0.0181 (0.0147)	Prec@1 100.000 (99.771)
Epoch: [95][60/79]	Time 0.045 (0.057)	Loss 0.0045 (0.0141)	Prec@1 100.000 (99.782)
training time:  4.457405090332031
Test: [0/79]	Time 0.784 (0.784)	Loss 1.2261 (1.2261)	Prec@1 73.438 (73.438)
Test: [20/79]	Time 0.029 (0.065)	Loss 1.1060 (1.1301)	Prec@1 76.562 (73.065)
Test: [40/79]	Time 0.029 (0.048)	Loss 1.1841 (1.1203)	Prec@1 67.969 (73.075)
Test: [60/79]	Time 0.032 (0.043)	Loss 1.3842 (1.1258)	Prec@1 67.969 (73.053)
 * Prec@1 73.180
Epoch: [96][0/79]	Time 0.830 (0.830)	Loss 0.0323 (0.0323)	Prec@1 99.219 (99.219)
Epoch: [96][20/79]	Time 0.046 (0.082)	Loss 0.0106 (0.0128)	Prec@1 100.000 (99.777)
Epoch: [96][40/79]	Time 0.043 (0.063)	Loss 0.0126 (0.0130)	Prec@1 100.000 (99.790)
Epoch: [96][60/79]	Time 0.043 (0.057)	Loss 0.0179 (0.0143)	Prec@1 99.219 (99.744)
training time:  4.4587318897247314
Test: [0/79]	Time 0.793 (0.793)	Loss 1.1909 (1.1909)	Prec@1 73.438 (73.438)
Test: [20/79]	Time 0.031 (0.067)	Loss 1.1079 (1.1358)	Prec@1 74.219 (72.619)
Test: [40/79]	Time 0.032 (0.050)	Loss 1.1813 (1.1237)	Prec@1 68.750 (72.809)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.4205 (1.1291)	Prec@1 69.531 (72.912)
 * Prec@1 73.090
Epoch: [97][0/79]	Time 0.836 (0.836)	Loss 0.0070 (0.0070)	Prec@1 100.000 (100.000)
Epoch: [97][20/79]	Time 0.047 (0.084)	Loss 0.0069 (0.0145)	Prec@1 100.000 (99.702)
Epoch: [97][40/79]	Time 0.046 (0.066)	Loss 0.0087 (0.0127)	Prec@1 100.000 (99.829)
Epoch: [97][60/79]	Time 0.046 (0.059)	Loss 0.0039 (0.0126)	Prec@1 100.000 (99.834)
training time:  4.588710308074951
Test: [0/79]	Time 0.750 (0.750)	Loss 1.1659 (1.1659)	Prec@1 74.219 (74.219)
Test: [20/79]	Time 0.032 (0.065)	Loss 1.1112 (1.1160)	Prec@1 75.781 (72.805)
Test: [40/79]	Time 0.032 (0.049)	Loss 1.2048 (1.1031)	Prec@1 68.750 (72.942)
Test: [60/79]	Time 0.029 (0.043)	Loss 1.3779 (1.1065)	Prec@1 67.969 (72.900)
 * Prec@1 72.930
Epoch: [98][0/79]	Time 0.791 (0.791)	Loss 0.0144 (0.0144)	Prec@1 100.000 (100.000)
Epoch: [98][20/79]	Time 0.045 (0.082)	Loss 0.0073 (0.0123)	Prec@1 100.000 (99.851)
Epoch: [98][40/79]	Time 0.047 (0.064)	Loss 0.0071 (0.0121)	Prec@1 100.000 (99.848)
Epoch: [98][60/79]	Time 0.046 (0.058)	Loss 0.0118 (0.0126)	Prec@1 100.000 (99.834)
training time:  4.5365893840789795
Test: [0/79]	Time 0.753 (0.753)	Loss 1.2619 (1.2619)	Prec@1 74.219 (74.219)
Test: [20/79]	Time 0.031 (0.066)	Loss 1.1164 (1.1545)	Prec@1 75.000 (72.619)
Test: [40/79]	Time 0.032 (0.050)	Loss 1.2291 (1.1376)	Prec@1 67.969 (72.732)
Test: [60/79]	Time 0.032 (0.044)	Loss 1.4759 (1.1382)	Prec@1 66.406 (72.976)
 * Prec@1 73.080
Epoch: [99][0/79]	Time 0.800 (0.800)	Loss 0.0084 (0.0084)	Prec@1 100.000 (100.000)
Epoch: [99][20/79]	Time 0.047 (0.081)	Loss 0.0131 (0.0107)	Prec@1 100.000 (99.814)
Epoch: [99][40/79]	Time 0.044 (0.064)	Loss 0.0230 (0.0113)	Prec@1 100.000 (99.809)
Epoch: [99][60/79]	Time 0.047 (0.058)	Loss 0.0118 (0.0125)	Prec@1 100.000 (99.757)
training time:  4.498110771179199
Test: [0/79]	Time 0.737 (0.737)	Loss 1.1711 (1.1711)	Prec@1 74.219 (74.219)
Test: [20/79]	Time 0.028 (0.065)	Loss 1.0863 (1.1016)	Prec@1 77.344 (73.475)
Test: [40/79]	Time 0.032 (0.048)	Loss 1.1432 (1.0867)	Prec@1 69.531 (73.514)
Test: [60/79]	Time 0.031 (0.043)	Loss 1.3877 (1.0933)	Prec@1 68.750 (73.502)
 * Prec@1 73.490
training time:  804.9195580482483
| Best accuracy:  73.84