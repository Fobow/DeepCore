================== Exp 0 ==================
dataset: CIFAR10, model: ResNet18, selection: Uniform, num_ex: 1, epochs: 100, fraction: 0.1, seed: 91866, lr: 0.1, save_path: ./result, resume: , device: cuda, checkpoint_name: CIFAR10_ResNet18_Uniform_exp0_epoch100_2024-03-18 13:09:59.043388_0.1_
Files already downloaded and verified
Files already downloaded and verified
=>number of samples:  5000
=> Saving checkpoint for epoch 0, with Prec@1 0.000000.
Epoch: [0][0/40]	Time 4.700 (4.700)	Loss 2.3715 (2.3715)	Prec@1 10.938 (10.938)
Epoch: [0][20/40]	Time 0.046 (0.268)	Loss 2.5941 (4.4021)	Prec@1 8.594 (10.231)
training time:  6.601369142532349
Test: [0/79]	Time 0.709 (0.709)	Loss 3.0875 (3.0875)	Prec@1 10.156 (10.156)
Test: [20/79]	Time 0.029 (0.062)	Loss 2.5929 (2.7931)	Prec@1 11.719 (13.728)
Test: [40/79]	Time 0.029 (0.047)	Loss 3.0983 (2.8416)	Prec@1 10.938 (13.510)
Test: [60/79]	Time 0.032 (0.042)	Loss 2.7880 (2.8468)	Prec@1 7.812 (13.665)
 * Prec@1 13.540
=> Saving checkpoint for epoch 0, with Prec@1 13.540000.
Epoch: [1][0/40]	Time 0.696 (0.696)	Loss 2.2831 (2.2831)	Prec@1 9.375 (9.375)
Epoch: [1][20/40]	Time 0.047 (0.077)	Loss 2.2660 (2.3157)	Prec@1 14.844 (13.170)
training time:  2.639202117919922
Test: [0/79]	Time 0.674 (0.674)	Loss 2.1696 (2.1696)	Prec@1 13.281 (13.281)
Test: [20/79]	Time 0.032 (0.063)	Loss 2.1942 (2.1881)	Prec@1 21.094 (19.457)
Test: [40/79]	Time 0.032 (0.048)	Loss 2.1868 (2.1842)	Prec@1 22.656 (20.179)
Test: [60/79]	Time 0.031 (0.043)	Loss 2.0800 (2.1832)	Prec@1 28.125 (20.274)
 * Prec@1 19.910
=> Saving checkpoint for epoch 1, with Prec@1 19.910000.
Epoch: [2][0/40]	Time 0.713 (0.713)	Loss 2.1601 (2.1601)	Prec@1 17.969 (17.969)
Epoch: [2][20/40]	Time 0.043 (0.076)	Loss 2.0599 (2.1025)	Prec@1 19.531 (20.610)
training time:  2.6175742149353027
Test: [0/79]	Time 0.681 (0.681)	Loss 2.0376 (2.0376)	Prec@1 22.656 (22.656)
Test: [20/79]	Time 0.032 (0.063)	Loss 2.1002 (2.0411)	Prec@1 20.312 (22.991)
Test: [40/79]	Time 0.033 (0.048)	Loss 2.1147 (2.0333)	Prec@1 20.312 (22.828)
Test: [60/79]	Time 0.031 (0.043)	Loss 2.0099 (2.0349)	Prec@1 25.781 (22.836)
 * Prec@1 22.810
=> Saving checkpoint for epoch 2, with Prec@1 22.810000.
Epoch: [3][0/40]	Time 0.724 (0.724)	Loss 1.9947 (1.9947)	Prec@1 23.438 (23.438)
Epoch: [3][20/40]	Time 0.046 (0.079)	Loss 2.0128 (2.0096)	Prec@1 21.094 (23.735)
training time:  2.6874144077301025
Test: [0/79]	Time 0.687 (0.687)	Loss 2.0590 (2.0590)	Prec@1 17.188 (17.188)
Test: [20/79]	Time 0.029 (0.063)	Loss 2.0537 (2.0300)	Prec@1 25.000 (21.875)
Test: [40/79]	Time 0.032 (0.047)	Loss 2.0675 (2.0174)	Prec@1 22.656 (23.056)
Test: [60/79]	Time 0.032 (0.042)	Loss 2.0191 (2.0241)	Prec@1 19.531 (23.079)
 * Prec@1 22.850
=> Saving checkpoint for epoch 3, with Prec@1 22.850000.
Epoch: [4][0/40]	Time 0.753 (0.753)	Loss 2.0088 (2.0088)	Prec@1 24.219 (24.219)
Epoch: [4][20/40]	Time 0.045 (0.079)	Loss 1.8895 (1.9780)	Prec@1 28.125 (24.405)
training time:  2.6713385581970215
Test: [0/79]	Time 0.722 (0.722)	Loss 2.0178 (2.0178)	Prec@1 23.438 (23.438)
Test: [20/79]	Time 0.032 (0.064)	Loss 2.0907 (1.9697)	Prec@1 22.656 (26.190)
Test: [40/79]	Time 0.032 (0.049)	Loss 2.0647 (1.9529)	Prec@1 21.094 (26.524)
Test: [60/79]	Time 0.032 (0.043)	Loss 1.8824 (1.9562)	Prec@1 28.125 (26.473)
 * Prec@1 26.430
=> Saving checkpoint for epoch 4, with Prec@1 26.430000.
Epoch: [5][0/40]	Time 0.715 (0.715)	Loss 1.9532 (1.9532)	Prec@1 24.219 (24.219)
Epoch: [5][20/40]	Time 0.044 (0.078)	Loss 1.7764 (1.8699)	Prec@1 36.719 (28.832)
training time:  2.620529890060425
Test: [0/79]	Time 0.696 (0.696)	Loss 1.8226 (1.8226)	Prec@1 28.125 (28.125)
Test: [20/79]	Time 0.033 (0.064)	Loss 1.9206 (1.8385)	Prec@1 32.812 (30.841)
Test: [40/79]	Time 0.033 (0.049)	Loss 1.8404 (1.8170)	Prec@1 27.344 (31.441)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.7011 (1.8189)	Prec@1 37.500 (31.224)
 * Prec@1 31.110
=> Saving checkpoint for epoch 5, with Prec@1 31.110000.
Epoch: [6][0/40]	Time 0.716 (0.716)	Loss 1.8972 (1.8972)	Prec@1 29.688 (29.688)
Epoch: [6][20/40]	Time 0.047 (0.078)	Loss 1.7811 (1.8047)	Prec@1 29.688 (31.362)
training time:  2.6396515369415283
Test: [0/79]	Time 0.741 (0.741)	Loss 1.8722 (1.8722)	Prec@1 26.562 (26.562)
Test: [20/79]	Time 0.032 (0.066)	Loss 1.8242 (1.8066)	Prec@1 28.125 (31.213)
Test: [40/79]	Time 0.032 (0.049)	Loss 1.8279 (1.7875)	Prec@1 26.562 (31.879)
Test: [60/79]	Time 0.032 (0.044)	Loss 1.7214 (1.7920)	Prec@1 33.594 (31.724)
 * Prec@1 31.770
=> Saving checkpoint for epoch 6, with Prec@1 31.770000.
Epoch: [7][0/40]	Time 0.729 (0.729)	Loss 1.9646 (1.9646)	Prec@1 22.656 (22.656)
Epoch: [7][20/40]	Time 0.047 (0.079)	Loss 1.7578 (1.7751)	Prec@1 32.031 (32.738)
training time:  2.6888113021850586
Test: [0/79]	Time 0.697 (0.697)	Loss 1.7175 (1.7175)	Prec@1 39.062 (39.062)
Test: [20/79]	Time 0.030 (0.062)	Loss 1.9641 (1.8114)	Prec@1 26.562 (32.924)
Test: [40/79]	Time 0.032 (0.047)	Loss 1.8816 (1.8026)	Prec@1 30.469 (32.946)
Test: [60/79]	Time 0.031 (0.042)	Loss 1.7994 (1.8123)	Prec@1 28.906 (32.006)
 * Prec@1 31.970
=> Saving checkpoint for epoch 7, with Prec@1 31.970000.
Epoch: [8][0/40]	Time 0.721 (0.721)	Loss 1.9100 (1.9100)	Prec@1 26.562 (26.562)
Epoch: [8][20/40]	Time 0.047 (0.078)	Loss 1.7105 (1.7748)	Prec@1 31.250 (32.887)
training time:  2.6496763229370117
Test: [0/79]	Time 0.707 (0.707)	Loss 2.2545 (2.2545)	Prec@1 30.469 (30.469)
Test: [20/79]	Time 0.031 (0.064)	Loss 2.1730 (2.1527)	Prec@1 24.219 (28.683)
Test: [40/79]	Time 0.031 (0.048)	Loss 2.2102 (2.1257)	Prec@1 24.219 (28.754)
Test: [60/79]	Time 0.032 (0.043)	Loss 2.1263 (2.1524)	Prec@1 26.562 (28.202)
 * Prec@1 28.030
Epoch: [9][0/40]	Time 0.751 (0.751)	Loss 1.9601 (1.9601)	Prec@1 31.250 (31.250)
Epoch: [9][20/40]	Time 0.045 (0.080)	Loss 1.6551 (1.7213)	Prec@1 39.062 (35.789)
training time:  2.723240613937378
Test: [0/79]	Time 0.682 (0.682)	Loss 1.8290 (1.8290)	Prec@1 33.594 (33.594)
Test: [20/79]	Time 0.032 (0.061)	Loss 2.1864 (1.8950)	Prec@1 24.219 (28.720)
Test: [40/79]	Time 0.031 (0.046)	Loss 1.9976 (1.8748)	Prec@1 29.688 (30.488)
Test: [60/79]	Time 0.032 (0.041)	Loss 1.6755 (1.8779)	Prec@1 38.281 (30.251)
 * Prec@1 30.480
Epoch: [10][0/40]	Time 0.730 (0.730)	Loss 1.7224 (1.7224)	Prec@1 34.375 (34.375)
Epoch: [10][20/40]	Time 0.042 (0.077)	Loss 1.5670 (1.6654)	Prec@1 43.750 (37.202)
training time:  2.624582052230835
Test: [0/79]	Time 0.697 (0.697)	Loss 1.5818 (1.5818)	Prec@1 42.188 (42.188)
Test: [20/79]	Time 0.032 (0.064)	Loss 1.8106 (1.6976)	Prec@1 34.375 (39.807)
Test: [40/79]	Time 0.032 (0.048)	Loss 1.7769 (1.6929)	Prec@1 32.812 (39.196)
Test: [60/79]	Time 0.031 (0.043)	Loss 1.5806 (1.6933)	Prec@1 44.531 (38.653)
 * Prec@1 38.560
=> Saving checkpoint for epoch 10, with Prec@1 38.560000.
Epoch: [11][0/40]	Time 0.740 (0.740)	Loss 1.5635 (1.5635)	Prec@1 39.062 (39.062)
Epoch: [11][20/40]	Time 0.045 (0.085)	Loss 1.6192 (1.6430)	Prec@1 35.938 (39.137)
training time:  2.800522565841675
Test: [0/79]	Time 0.681 (0.681)	Loss 1.8024 (1.8024)	Prec@1 30.469 (30.469)
Test: [20/79]	Time 0.029 (0.061)	Loss 1.9021 (1.8193)	Prec@1 28.906 (34.784)
Test: [40/79]	Time 0.032 (0.045)	Loss 1.8048 (1.8146)	Prec@1 28.125 (34.794)
Test: [60/79]	Time 0.033 (0.041)	Loss 1.6298 (1.8089)	Prec@1 42.188 (34.452)
 * Prec@1 34.440
Epoch: [12][0/40]	Time 0.728 (0.728)	Loss 1.6037 (1.6037)	Prec@1 42.969 (42.969)
Epoch: [12][20/40]	Time 0.044 (0.079)	Loss 1.5647 (1.6089)	Prec@1 41.406 (40.104)
training time:  2.6948657035827637
Test: [0/79]	Time 0.707 (0.707)	Loss 1.5145 (1.5145)	Prec@1 45.312 (45.312)
Test: [20/79]	Time 0.029 (0.063)	Loss 1.7016 (1.5933)	Prec@1 38.281 (41.369)
Test: [40/79]	Time 0.029 (0.048)	Loss 1.6493 (1.5822)	Prec@1 35.156 (41.292)
Test: [60/79]	Time 0.032 (0.043)	Loss 1.3910 (1.5796)	Prec@1 45.312 (41.406)
 * Prec@1 41.230
=> Saving checkpoint for epoch 12, with Prec@1 41.230000.
Epoch: [13][0/40]	Time 0.723 (0.723)	Loss 1.4887 (1.4887)	Prec@1 41.406 (41.406)
Epoch: [13][20/40]	Time 0.047 (0.078)	Loss 1.4349 (1.5033)	Prec@1 40.625 (42.150)
training time:  2.642302989959717
Test: [0/79]	Time 0.708 (0.708)	Loss 1.5437 (1.5437)	Prec@1 46.094 (46.094)
Test: [20/79]	Time 0.031 (0.064)	Loss 1.6642 (1.6157)	Prec@1 43.750 (39.435)
Test: [40/79]	Time 0.032 (0.049)	Loss 1.6076 (1.6108)	Prec@1 36.719 (39.958)
Test: [60/79]	Time 0.032 (0.043)	Loss 1.5699 (1.6133)	Prec@1 42.969 (40.036)
 * Prec@1 39.450
Epoch: [14][0/40]	Time 0.725 (0.725)	Loss 1.6503 (1.6503)	Prec@1 37.500 (37.500)
Epoch: [14][20/40]	Time 0.045 (0.078)	Loss 1.3805 (1.4960)	Prec@1 44.531 (44.048)
training time:  2.688868284225464
Test: [0/79]	Time 0.690 (0.690)	Loss 1.6318 (1.6318)	Prec@1 41.406 (41.406)
Test: [20/79]	Time 0.029 (0.062)	Loss 1.6809 (1.5533)	Prec@1 35.156 (39.769)
Test: [40/79]	Time 0.032 (0.047)	Loss 1.5773 (1.5428)	Prec@1 39.844 (40.187)
Test: [60/79]	Time 0.031 (0.042)	Loss 1.5096 (1.5560)	Prec@1 38.281 (39.062)
 * Prec@1 39.110
Epoch: [15][0/40]	Time 0.732 (0.732)	Loss 1.5173 (1.5173)	Prec@1 40.625 (40.625)
Epoch: [15][20/40]	Time 0.048 (0.078)	Loss 1.4008 (1.4487)	Prec@1 49.219 (44.903)
training time:  2.6713309288024902
Test: [0/79]	Time 0.704 (0.704)	Loss 1.4812 (1.4812)	Prec@1 48.438 (48.438)
Test: [20/79]	Time 0.032 (0.063)	Loss 1.5499 (1.4871)	Prec@1 44.531 (48.177)
Test: [40/79]	Time 0.032 (0.048)	Loss 1.4624 (1.4886)	Prec@1 50.781 (47.752)
Test: [60/79]	Time 0.032 (0.043)	Loss 1.4672 (1.4982)	Prec@1 46.875 (46.632)
 * Prec@1 46.250
=> Saving checkpoint for epoch 15, with Prec@1 46.250000.
Epoch: [16][0/40]	Time 0.731 (0.731)	Loss 1.3088 (1.3088)	Prec@1 54.688 (54.688)
Epoch: [16][20/40]	Time 0.046 (0.079)	Loss 1.3476 (1.3873)	Prec@1 50.781 (48.400)
training time:  2.674997329711914
Test: [0/79]	Time 0.691 (0.691)	Loss 1.5220 (1.5220)	Prec@1 47.656 (47.656)
Test: [20/79]	Time 0.034 (0.063)	Loss 1.7125 (1.6822)	Prec@1 38.281 (39.993)
Test: [40/79]	Time 0.032 (0.048)	Loss 1.6017 (1.6833)	Prec@1 40.625 (39.158)
Test: [60/79]	Time 0.030 (0.043)	Loss 1.6015 (1.6934)	Prec@1 39.062 (38.268)
 * Prec@1 38.390
Epoch: [17][0/40]	Time 0.745 (0.745)	Loss 1.4000 (1.4000)	Prec@1 48.438 (48.438)
Epoch: [17][20/40]	Time 0.045 (0.080)	Loss 1.3356 (1.4506)	Prec@1 50.781 (45.499)
training time:  2.8143022060394287
Test: [0/79]	Time 0.694 (0.694)	Loss 1.4209 (1.4209)	Prec@1 49.219 (49.219)
Test: [20/79]	Time 0.032 (0.063)	Loss 1.6284 (1.5490)	Prec@1 39.844 (45.126)
Test: [40/79]	Time 0.031 (0.048)	Loss 1.6618 (1.5610)	Prec@1 45.312 (44.646)
Test: [60/79]	Time 0.031 (0.043)	Loss 1.4581 (1.5753)	Prec@1 48.438 (44.096)
 * Prec@1 43.850
Epoch: [18][0/40]	Time 0.769 (0.769)	Loss 1.3006 (1.3006)	Prec@1 47.656 (47.656)
Epoch: [18][20/40]	Time 0.046 (0.080)	Loss 1.4012 (1.3578)	Prec@1 47.656 (50.335)
Traceback (most recent call last):
  File "/home/yancheng/code/DeepCore/main.py", line 341, in <module>
    main()
  File "/home/yancheng/code/DeepCore/main.py", line 282, in main
    train(train_loader, network, criterion, optimizer, scheduler, epoch, args, rec, if_weighted=if_weighted)
  File "/home/yancheng/code/DeepCore/utils.py", line 45, in train
    output = network(input)
  File "/home/yancheng/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/yancheng/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/yancheng/.local/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 185, in forward
    outputs = self.parallel_apply(replicas, inputs, module_kwargs)
  File "/home/yancheng/.local/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 200, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/yancheng/.local/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py", line 102, in parallel_apply
    thread.join()
  File "/usr/lib/python3.10/threading.py", line 1096, in join
    self._wait_for_tstate_lock()
  File "/usr/lib/python3.10/threading.py", line 1116, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yancheng/code/DeepCore/main.py", line 341, in <module>
    main()
  File "/home/yancheng/code/DeepCore/main.py", line 282, in main
    train(train_loader, network, criterion, optimizer, scheduler, epoch, args, rec, if_weighted=if_weighted)
  File "/home/yancheng/code/DeepCore/utils.py", line 45, in train
    output = network(input)
  File "/home/yancheng/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/yancheng/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/yancheng/.local/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 185, in forward
    outputs = self.parallel_apply(replicas, inputs, module_kwargs)
  File "/home/yancheng/.local/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 200, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/yancheng/.local/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py", line 102, in parallel_apply
    thread.join()
  File "/usr/lib/python3.10/threading.py", line 1096, in join
    self._wait_for_tstate_lock()
  File "/usr/lib/python3.10/threading.py", line 1116, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt