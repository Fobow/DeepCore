================== Exp 0 ==================
dataset: CIFAR10, model: ResNet18, selection: Full, num_ex: 1, epochs: 100, fraction: 0.2, seed: 4595, lr: 0.1, save_path: ./result, resume: , device: cuda, checkpoint_name: CIFAR10_ResNet18_Full_exp0_epoch100_2024-03-18 14:31:46.379097_0.2_
Files already downloaded and verified
Files already downloaded and verified
=> selecting time:  6.103515625e-05
=> number of seletcted samples:  50000
=> Saving checkpoint for epoch 0, with Prec@1 0.000000.
Epoch: [0][0/391]	Time 4.746 (4.746)	Loss 2.4151 (2.4151)	Prec@1 10.156 (10.156)
Epoch: [0][20/391]	Time 0.046 (0.270)	Loss 2.8432 (4.7015)	Prec@1 16.406 (11.086)
Epoch: [0][40/391]	Time 0.045 (0.161)	Loss 2.2964 (3.5819)	Prec@1 16.406 (12.405)
Epoch: [0][60/391]	Time 0.047 (0.123)	Loss 2.0666 (3.1222)	Prec@1 17.969 (14.037)
Epoch: [0][80/391]	Time 0.044 (0.104)	Loss 2.1046 (2.8777)	Prec@1 18.750 (15.162)
Epoch: [0][100/391]	Time 0.046 (0.092)	Loss 2.1145 (2.7197)	Prec@1 17.969 (16.174)
Epoch: [0][120/391]	Time 0.047 (0.085)	Loss 2.1564 (2.6085)	Prec@1 23.438 (17.168)
Epoch: [0][140/391]	Time 0.046 (0.079)	Loss 2.1853 (2.5221)	Prec@1 21.094 (18.257)
Epoch: [0][160/391]	Time 0.045 (0.075)	Loss 1.9927 (2.4526)	Prec@1 21.094 (19.318)
Epoch: [0][180/391]	Time 0.047 (0.072)	Loss 1.9826 (2.3940)	Prec@1 28.125 (20.343)
Epoch: [0][200/391]	Time 0.047 (0.069)	Loss 1.8969 (2.3449)	Prec@1 28.125 (21.265)
Epoch: [0][220/391]	Time 0.049 (0.067)	Loss 1.8245 (2.3004)	Prec@1 29.688 (22.140)
Epoch: [0][240/391]	Time 0.049 (0.066)	Loss 1.8803 (2.2645)	Prec@1 31.250 (22.916)
Epoch: [0][260/391]	Time 0.049 (0.064)	Loss 1.9299 (2.2300)	Prec@1 28.125 (23.653)
Epoch: [0][280/391]	Time 0.047 (0.063)	Loss 1.9574 (2.2007)	Prec@1 30.469 (24.338)
Epoch: [0][300/391]	Time 0.047 (0.062)	Loss 1.6943 (2.1703)	Prec@1 39.062 (25.075)
Epoch: [0][320/391]	Time 0.049 (0.061)	Loss 1.7889 (2.1442)	Prec@1 36.719 (25.723)
Epoch: [0][340/391]	Time 0.047 (0.060)	Loss 1.7904 (2.1196)	Prec@1 29.688 (26.345)
Epoch: [0][360/391]	Time 0.046 (0.059)	Loss 1.7379 (2.0966)	Prec@1 28.906 (26.911)
Epoch: [0][380/391]	Time 0.045 (0.059)	Loss 1.7420 (2.0754)	Prec@1 34.375 (27.473)
training time:  22.88569736480713
Test: [0/79]	Time 0.753 (0.753)	Loss 1.5279 (1.5279)	Prec@1 42.969 (42.969)
Test: [20/79]	Time 0.031 (0.066)	Loss 1.6272 (1.5592)	Prec@1 44.531 (42.708)
Test: [40/79]	Time 0.029 (0.049)	Loss 1.5871 (1.5414)	Prec@1 42.188 (43.312)
Test: [60/79]	Time 0.031 (0.043)	Loss 1.4795 (1.5493)	Prec@1 49.219 (42.533)
 * Prec@1 42.520
=> Saving checkpoint for epoch 0, with Prec@1 42.520000.
Epoch: [1][0/391]	Time 0.787 (0.787)	Loss 1.6521 (1.6521)	Prec@1 37.500 (37.500)
Epoch: [1][20/391]	Time 0.045 (0.080)	Loss 1.4688 (1.6317)	Prec@1 42.969 (40.402)
Epoch: [1][40/391]	Time 0.045 (0.064)	Loss 1.6256 (1.6500)	Prec@1 38.281 (39.501)
Epoch: [1][60/391]	Time 0.045 (0.058)	Loss 1.7128 (1.6392)	Prec@1 35.156 (39.716)
Epoch: [1][80/391]	Time 0.045 (0.055)	Loss 1.4695 (1.6315)	Prec@1 51.562 (39.988)
Epoch: [1][100/391]	Time 0.045 (0.053)	Loss 1.8427 (1.6158)	Prec@1 36.719 (40.362)
Epoch: [1][120/391]	Time 0.045 (0.052)	Loss 1.5507 (1.6069)	Prec@1 46.875 (40.896)
Epoch: [1][140/391]	Time 0.047 (0.051)	Loss 1.6444 (1.5950)	Prec@1 35.938 (41.240)
Epoch: [1][160/391]	Time 0.047 (0.051)	Loss 1.5176 (1.5867)	Prec@1 53.125 (41.537)
Epoch: [1][180/391]	Time 0.047 (0.050)	Loss 1.3969 (1.5752)	Prec@1 52.344 (41.967)
Epoch: [1][200/391]	Time 0.047 (0.050)	Loss 1.3535 (1.5636)	Prec@1 50.000 (42.304)
Epoch: [1][220/391]	Time 0.046 (0.050)	Loss 1.5439 (1.5564)	Prec@1 42.969 (42.686)
Epoch: [1][240/391]	Time 0.046 (0.049)	Loss 1.4832 (1.5478)	Prec@1 53.125 (43.095)
Epoch: [1][260/391]	Time 0.047 (0.049)	Loss 1.5972 (1.5423)	Prec@1 42.188 (43.289)
Epoch: [1][280/391]	Time 0.047 (0.049)	Loss 1.4854 (1.5340)	Prec@1 46.094 (43.592)
Epoch: [1][300/391]	Time 0.047 (0.049)	Loss 1.3091 (1.5233)	Prec@1 55.469 (44.072)
Epoch: [1][320/391]	Time 0.047 (0.049)	Loss 1.2866 (1.5150)	Prec@1 54.688 (44.490)
Epoch: [1][340/391]	Time 0.047 (0.048)	Loss 1.4145 (1.5072)	Prec@1 41.406 (44.765)
Epoch: [1][360/391]	Time 0.045 (0.048)	Loss 1.2481 (1.4982)	Prec@1 53.906 (45.113)
Epoch: [1][380/391]	Time 0.045 (0.048)	Loss 1.3786 (1.4897)	Prec@1 50.000 (45.509)
training time:  19.000532388687134
Test: [0/79]	Time 0.747 (0.747)	Loss 1.2064 (1.2064)	Prec@1 61.719 (61.719)
Test: [20/79]	Time 0.030 (0.064)	Loss 1.3185 (1.2885)	Prec@1 46.875 (53.162)
Test: [40/79]	Time 0.028 (0.047)	Loss 1.2762 (1.2774)	Prec@1 54.688 (53.335)
Test: [60/79]	Time 0.032 (0.042)	Loss 1.2028 (1.2817)	Prec@1 54.688 (53.176)
 * Prec@1 53.160
=> Saving checkpoint for epoch 1, with Prec@1 53.160000.
Epoch: [2][0/391]	Time 0.788 (0.788)	Loss 1.4071 (1.4071)	Prec@1 50.000 (50.000)
Epoch: [2][20/391]	Time 0.045 (0.082)	Loss 1.4656 (1.3581)	Prec@1 47.656 (51.190)
Epoch: [2][40/391]	Time 0.046 (0.065)	Loss 1.2167 (1.3259)	Prec@1 53.125 (52.172)
Epoch: [2][60/391]	Time 0.046 (0.059)	Loss 1.2480 (1.3112)	Prec@1 54.688 (52.856)
Epoch: [2][80/391]	Time 0.045 (0.056)	Loss 1.3449 (1.2956)	Prec@1 52.344 (53.578)
Epoch: [2][100/391]	Time 0.046 (0.054)	Loss 1.2356 (1.2882)	Prec@1 56.250 (53.736)
Epoch: [2][120/391]	Time 0.045 (0.053)	Loss 1.0970 (1.2768)	Prec@1 60.938 (54.016)
Epoch: [2][140/391]	Time 0.045 (0.052)	Loss 1.2122 (1.2661)	Prec@1 56.250 (54.460)
Epoch: [2][160/391]	Time 0.047 (0.051)	Loss 1.3560 (1.2612)	Prec@1 56.250 (54.571)
Epoch: [2][180/391]	Time 0.046 (0.050)	Loss 1.3465 (1.2559)	Prec@1 52.344 (54.808)
Epoch: [2][200/391]	Time 0.046 (0.050)	Loss 1.0844 (1.2497)	Prec@1 59.375 (54.991)
Epoch: [2][220/391]	Time 0.047 (0.051)	Loss 1.2236 (1.2410)	Prec@1 51.562 (55.200)
Epoch: [2][240/391]	Time 0.050 (0.051)	Loss 1.0998 (1.2315)	Prec@1 60.938 (55.543)
Epoch: [2][260/391]	Time 0.046 (0.050)	Loss 1.1428 (1.2249)	Prec@1 59.375 (55.765)
Epoch: [2][280/391]	Time 0.046 (0.050)	Loss 0.9613 (1.2155)	Prec@1 65.625 (56.100)
Epoch: [2][300/391]	Time 0.046 (0.050)	Loss 1.0764 (1.2091)	Prec@1 63.281 (56.351)
Epoch: [2][320/391]	Time 0.045 (0.050)	Loss 1.2238 (1.2040)	Prec@1 58.594 (56.569)
Epoch: [2][340/391]	Time 0.046 (0.049)	Loss 0.9800 (1.1991)	Prec@1 63.281 (56.779)
Epoch: [2][360/391]	Time 0.046 (0.049)	Loss 1.0571 (1.1950)	Prec@1 64.844 (56.962)
Epoch: [2][380/391]	Time 0.045 (0.049)	Loss 1.2990 (1.1890)	Prec@1 53.906 (57.208)
training time:  19.32489252090454
Test: [0/79]	Time 0.740 (0.740)	Loss 1.0027 (1.0027)	Prec@1 65.625 (65.625)
Test: [20/79]	Time 0.028 (0.063)	Loss 1.0598 (1.0682)	Prec@1 59.375 (61.347)
Test: [40/79]	Time 0.032 (0.047)	Loss 1.2107 (1.0619)	Prec@1 53.906 (61.909)
Test: [60/79]	Time 0.030 (0.042)	Loss 1.0041 (1.0639)	Prec@1 65.625 (62.001)
 * Prec@1 62.020
=> Saving checkpoint for epoch 2, with Prec@1 62.020000.
Epoch: [3][0/391]	Time 0.765 (0.765)	Loss 1.0926 (1.0926)	Prec@1 60.938 (60.938)
Epoch: [3][20/391]	Time 0.047 (0.081)	Loss 1.0831 (1.1025)	Prec@1 61.719 (61.496)
Epoch: [3][40/391]	Time 0.046 (0.064)	Loss 1.1991 (1.0830)	Prec@1 57.031 (61.966)
Epoch: [3][60/391]	Time 0.046 (0.058)	Loss 0.8914 (1.0755)	Prec@1 67.969 (62.039)
Epoch: [3][80/391]	Time 0.047 (0.055)	Loss 1.1939 (1.0689)	Prec@1 57.031 (62.153)
Epoch: [3][100/391]	Time 0.049 (0.054)	Loss 0.8765 (1.0560)	Prec@1 66.406 (62.647)
Epoch: [3][120/391]	Time 0.048 (0.052)	Loss 0.9564 (1.0561)	Prec@1 65.625 (62.532)
Epoch: [3][140/391]	Time 0.047 (0.051)	Loss 1.0192 (1.0519)	Prec@1 64.844 (62.766)
Epoch: [3][160/391]	Time 0.047 (0.051)	Loss 1.0518 (1.0443)	Prec@1 63.281 (62.990)
Epoch: [3][180/391]	Time 0.047 (0.050)	Loss 1.0562 (1.0385)	Prec@1 61.719 (63.160)
Epoch: [3][200/391]	Time 0.047 (0.050)	Loss 1.0702 (1.0385)	Prec@1 64.062 (63.238)
Epoch: [3][220/391]	Time 0.046 (0.050)	Loss 0.9888 (1.0329)	Prec@1 65.625 (63.355)
Epoch: [3][240/391]	Time 0.047 (0.049)	Loss 1.1896 (1.0308)	Prec@1 57.812 (63.417)
Epoch: [3][260/391]	Time 0.047 (0.049)	Loss 0.9311 (1.0291)	Prec@1 68.750 (63.440)
Epoch: [3][280/391]	Time 0.047 (0.049)	Loss 0.9775 (1.0253)	Prec@1 65.625 (63.618)
Epoch: [3][300/391]	Time 0.046 (0.049)	Loss 0.9067 (1.0193)	Prec@1 67.969 (63.837)
Epoch: [3][320/391]	Time 0.047 (0.049)	Loss 0.7746 (1.0143)	Prec@1 69.531 (64.009)
Epoch: [3][340/391]	Time 0.049 (0.048)	Loss 0.9003 (1.0087)	Prec@1 64.844 (64.170)
Epoch: [3][360/391]	Time 0.047 (0.048)	Loss 0.9932 (1.0051)	Prec@1 67.969 (64.270)
Epoch: [3][380/391]	Time 0.045 (0.048)	Loss 0.8171 (0.9998)	Prec@1 71.875 (64.544)
training time:  18.922497749328613
Test: [0/79]	Time 0.774 (0.774)	Loss 0.9533 (0.9533)	Prec@1 66.406 (66.406)
Test: [20/79]	Time 0.033 (0.067)	Loss 0.9897 (0.9849)	Prec@1 62.500 (66.071)
Test: [40/79]	Time 0.031 (0.050)	Loss 1.1595 (0.9816)	Prec@1 59.375 (66.235)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.0680 (0.9785)	Prec@1 63.281 (66.278)
 * Prec@1 66.130
=> Saving checkpoint for epoch 3, with Prec@1 66.130000.
Epoch: [4][0/391]	Time 0.806 (0.806)	Loss 0.9734 (0.9734)	Prec@1 67.188 (67.188)
Epoch: [4][20/391]	Time 0.045 (0.082)	Loss 0.8330 (0.8955)	Prec@1 69.531 (68.490)
Epoch: [4][40/391]	Time 0.048 (0.065)	Loss 0.9606 (0.9080)	Prec@1 67.188 (67.683)
Epoch: [4][60/391]	Time 0.050 (0.060)	Loss 0.8694 (0.8968)	Prec@1 70.312 (68.186)
Epoch: [4][80/391]	Time 0.049 (0.057)	Loss 1.0006 (0.8994)	Prec@1 64.844 (67.998)
Epoch: [4][100/391]	Time 0.042 (0.055)	Loss 1.0721 (0.8963)	Prec@1 62.500 (68.170)
Epoch: [4][120/391]	Time 0.047 (0.053)	Loss 0.9890 (0.8857)	Prec@1 65.625 (68.634)
Epoch: [4][140/391]	Time 0.046 (0.053)	Loss 0.9408 (0.8842)	Prec@1 70.312 (68.678)
Epoch: [4][160/391]	Time 0.044 (0.052)	Loss 0.8938 (0.8836)	Prec@1 69.531 (68.721)
Epoch: [4][180/391]	Time 0.047 (0.051)	Loss 0.9336 (0.8870)	Prec@1 64.844 (68.629)
Epoch: [4][200/391]	Time 0.046 (0.051)	Loss 0.9327 (0.8844)	Prec@1 67.969 (68.847)
Epoch: [4][220/391]	Time 0.047 (0.051)	Loss 0.8991 (0.8840)	Prec@1 69.531 (68.962)
Epoch: [4][240/391]	Time 0.045 (0.050)	Loss 0.8555 (0.8802)	Prec@1 69.531 (69.022)
Epoch: [4][260/391]	Time 0.049 (0.050)	Loss 0.9129 (0.8814)	Prec@1 66.406 (69.025)
Epoch: [4][280/391]	Time 0.046 (0.050)	Loss 1.0014 (0.8807)	Prec@1 64.062 (69.050)
Epoch: [4][300/391]	Time 0.046 (0.049)	Loss 0.8829 (0.8759)	Prec@1 69.531 (69.217)
Epoch: [4][320/391]	Time 0.046 (0.049)	Loss 0.7745 (0.8728)	Prec@1 71.875 (69.293)
Epoch: [4][340/391]	Time 0.047 (0.049)	Loss 0.9386 (0.8711)	Prec@1 69.531 (69.353)
Epoch: [4][360/391]	Time 0.047 (0.049)	Loss 0.7918 (0.8717)	Prec@1 69.531 (69.341)
Epoch: [4][380/391]	Time 0.046 (0.049)	Loss 1.0611 (0.8694)	Prec@1 68.750 (69.406)
training time:  19.20392632484436
Test: [0/79]	Time 0.730 (0.730)	Loss 0.9192 (0.9192)	Prec@1 68.750 (68.750)
Test: [20/79]	Time 0.033 (0.063)	Loss 0.9016 (0.8747)	Prec@1 67.969 (69.234)
Test: [40/79]	Time 0.031 (0.047)	Loss 0.8684 (0.8663)	Prec@1 70.312 (69.741)
Test: [60/79]	Time 0.031 (0.042)	Loss 0.7364 (0.8709)	Prec@1 71.875 (69.339)
 * Prec@1 69.340
=> Saving checkpoint for epoch 4, with Prec@1 69.340000.
Epoch: [5][0/391]	Time 0.776 (0.776)	Loss 0.8554 (0.8554)	Prec@1 66.406 (66.406)
Epoch: [5][20/391]	Time 0.045 (0.080)	Loss 0.9152 (0.8179)	Prec@1 64.062 (70.461)
Epoch: [5][40/391]	Time 0.044 (0.064)	Loss 0.7598 (0.8025)	Prec@1 74.219 (71.646)
Epoch: [5][60/391]	Time 0.047 (0.058)	Loss 0.8981 (0.8001)	Prec@1 70.312 (71.798)
Epoch: [5][80/391]	Time 0.046 (0.055)	Loss 0.9207 (0.7992)	Prec@1 69.531 (71.779)
Epoch: [5][100/391]	Time 0.046 (0.053)	Loss 0.8283 (0.8051)	Prec@1 73.438 (71.705)
Epoch: [5][120/391]	Time 0.045 (0.052)	Loss 0.7451 (0.8024)	Prec@1 73.438 (71.972)
Epoch: [5][140/391]	Time 0.047 (0.051)	Loss 0.7875 (0.7996)	Prec@1 75.781 (72.097)
Epoch: [5][160/391]	Time 0.046 (0.051)	Loss 0.8488 (0.8006)	Prec@1 69.531 (72.190)
Epoch: [5][180/391]	Time 0.046 (0.050)	Loss 0.9153 (0.7973)	Prec@1 71.875 (72.255)
Epoch: [5][200/391]	Time 0.046 (0.050)	Loss 0.8432 (0.7935)	Prec@1 69.531 (72.326)
Epoch: [5][220/391]	Time 0.046 (0.049)	Loss 0.6820 (0.7921)	Prec@1 77.344 (72.342)
Epoch: [5][240/391]	Time 0.046 (0.049)	Loss 0.7587 (0.7866)	Prec@1 73.438 (72.475)
Epoch: [5][260/391]	Time 0.046 (0.049)	Loss 0.7273 (0.7850)	Prec@1 74.219 (72.551)
Epoch: [5][280/391]	Time 0.046 (0.049)	Loss 0.7237 (0.7819)	Prec@1 75.781 (72.626)
Epoch: [5][300/391]	Time 0.046 (0.049)	Loss 0.6856 (0.7792)	Prec@1 78.125 (72.706)
Epoch: [5][320/391]	Time 0.046 (0.048)	Loss 0.6511 (0.7793)	Prec@1 72.656 (72.707)
Epoch: [5][340/391]	Time 0.045 (0.048)	Loss 0.5763 (0.7788)	Prec@1 83.594 (72.730)
Epoch: [5][360/391]	Time 0.046 (0.048)	Loss 0.6673 (0.7761)	Prec@1 75.781 (72.870)
Epoch: [5][380/391]	Time 0.046 (0.048)	Loss 0.5454 (0.7719)	Prec@1 76.562 (73.048)
training time:  18.91815447807312
Test: [0/79]	Time 0.768 (0.768)	Loss 0.8029 (0.8029)	Prec@1 75.781 (75.781)
Test: [20/79]	Time 0.032 (0.065)	Loss 0.8429 (0.8617)	Prec@1 71.875 (70.685)
Test: [40/79]	Time 0.028 (0.049)	Loss 0.8926 (0.8377)	Prec@1 71.094 (71.608)
Test: [60/79]	Time 0.031 (0.043)	Loss 0.8596 (0.8486)	Prec@1 71.875 (71.734)
 * Prec@1 71.410
=> Saving checkpoint for epoch 5, with Prec@1 71.410000.
Epoch: [6][0/391]	Time 0.811 (0.811)	Loss 0.6776 (0.6776)	Prec@1 77.344 (77.344)
Epoch: [6][20/391]	Time 0.046 (0.083)	Loss 0.7344 (0.7078)	Prec@1 71.094 (74.665)
Epoch: [6][40/391]	Time 0.047 (0.065)	Loss 0.6334 (0.7036)	Prec@1 78.906 (75.210)
Epoch: [6][60/391]	Time 0.046 (0.059)	Loss 0.6592 (0.7005)	Prec@1 75.781 (75.141)
Epoch: [6][80/391]	Time 0.046 (0.056)	Loss 0.6743 (0.6950)	Prec@1 77.344 (75.309)
Epoch: [6][100/391]	Time 0.047 (0.054)	Loss 0.7780 (0.6921)	Prec@1 71.094 (75.526)
Epoch: [6][120/391]	Time 0.046 (0.053)	Loss 0.7255 (0.6894)	Prec@1 75.781 (75.581)
Epoch: [6][140/391]	Time 0.043 (0.053)	Loss 0.6471 (0.6912)	Prec@1 80.469 (75.571)
Epoch: [6][160/391]	Time 0.047 (0.052)	Loss 0.7817 (0.6904)	Prec@1 71.094 (75.728)
Epoch: [6][180/391]	Time 0.043 (0.051)	Loss 0.7405 (0.6856)	Prec@1 69.531 (75.893)
Epoch: [6][200/391]	Time 0.047 (0.051)	Loss 0.7538 (0.6863)	Prec@1 75.781 (75.890)
Epoch: [6][220/391]	Time 0.047 (0.050)	Loss 0.6774 (0.6885)	Prec@1 80.469 (75.848)
Epoch: [6][240/391]	Time 0.046 (0.050)	Loss 0.8421 (0.6901)	Prec@1 68.750 (75.823)
Epoch: [6][260/391]	Time 0.047 (0.050)	Loss 0.7910 (0.6899)	Prec@1 74.219 (75.913)
Epoch: [6][280/391]	Time 0.046 (0.049)	Loss 0.6336 (0.6891)	Prec@1 74.219 (75.887)
Epoch: [6][300/391]	Time 0.046 (0.049)	Loss 0.5523 (0.6868)	Prec@1 77.344 (76.017)
Epoch: [6][320/391]	Time 0.046 (0.049)	Loss 0.5899 (0.6839)	Prec@1 82.031 (76.144)
Epoch: [6][340/391]	Time 0.045 (0.049)	Loss 0.4829 (0.6836)	Prec@1 82.031 (76.210)
Epoch: [6][360/391]	Time 0.046 (0.049)	Loss 0.6321 (0.6813)	Prec@1 74.219 (76.277)
Epoch: [6][380/391]	Time 0.045 (0.049)	Loss 0.5546 (0.6805)	Prec@1 85.938 (76.357)
training time:  19.131508827209473
Test: [0/79]	Time 0.768 (0.768)	Loss 0.7569 (0.7569)	Prec@1 73.438 (73.438)
Test: [20/79]	Time 0.031 (0.066)	Loss 0.6878 (0.7569)	Prec@1 79.688 (73.996)
Test: [40/79]	Time 0.031 (0.049)	Loss 0.7757 (0.7435)	Prec@1 70.312 (75.305)
Test: [60/79]	Time 0.032 (0.044)	Loss 0.6501 (0.7460)	Prec@1 77.344 (75.090)
 * Prec@1 74.640
=> Saving checkpoint for epoch 6, with Prec@1 74.640000.
Epoch: [7][0/391]	Time 0.813 (0.813)	Loss 0.6203 (0.6203)	Prec@1 76.562 (76.562)
Epoch: [7][20/391]	Time 0.045 (0.082)	Loss 0.5759 (0.6129)	Prec@1 79.688 (80.097)
Epoch: [7][40/391]	Time 0.046 (0.065)	Loss 0.6691 (0.6272)	Prec@1 78.125 (78.906)
Epoch: [7][60/391]	Time 0.046 (0.059)	Loss 0.5855 (0.6207)	Prec@1 78.906 (79.188)
Epoch: [7][80/391]	Time 0.047 (0.056)	Loss 0.6559 (0.6263)	Prec@1 78.906 (78.858)
Epoch: [7][100/391]	Time 0.048 (0.054)	Loss 0.6581 (0.6264)	Prec@1 82.031 (78.759)
Epoch: [7][120/391]	Time 0.048 (0.052)	Loss 0.6373 (0.6205)	Prec@1 78.906 (78.971)
Epoch: [7][140/391]	Time 0.043 (0.051)	Loss 0.6782 (0.6225)	Prec@1 76.562 (78.734)
Epoch: [7][160/391]	Time 0.048 (0.050)	Loss 0.6277 (0.6262)	Prec@1 75.781 (78.470)
Epoch: [7][180/391]	Time 0.044 (0.050)	Loss 0.5068 (0.6238)	Prec@1 82.812 (78.518)
Epoch: [7][200/391]	Time 0.046 (0.049)	Loss 0.5884 (0.6215)	Prec@1 76.562 (78.588)
Epoch: [7][220/391]	Time 0.047 (0.049)	Loss 0.6611 (0.6208)	Prec@1 74.219 (78.546)
Epoch: [7][240/391]	Time 0.047 (0.049)	Loss 0.6023 (0.6196)	Prec@1 78.906 (78.614)
Epoch: [7][260/391]	Time 0.046 (0.049)	Loss 0.4536 (0.6188)	Prec@1 84.375 (78.664)
Epoch: [7][280/391]	Time 0.048 (0.049)	Loss 0.6739 (0.6196)	Prec@1 78.125 (78.609)
Epoch: [7][300/391]	Time 0.047 (0.048)	Loss 0.6419 (0.6205)	Prec@1 80.469 (78.540)
Epoch: [7][320/391]	Time 0.047 (0.048)	Loss 0.5903 (0.6203)	Prec@1 81.250 (78.517)
Epoch: [7][340/391]	Time 0.043 (0.048)	Loss 0.6059 (0.6189)	Prec@1 81.250 (78.569)
Epoch: [7][360/391]	Time 0.046 (0.048)	Loss 0.6486 (0.6171)	Prec@1 82.812 (78.660)
Epoch: [7][380/391]	Time 0.043 (0.048)	Loss 0.5732 (0.6152)	Prec@1 77.344 (78.722)
training time:  18.741053104400635
Test: [0/79]	Time 0.781 (0.781)	Loss 0.5166 (0.5166)	Prec@1 82.031 (82.031)
Test: [20/79]	Time 0.032 (0.068)	Loss 0.5229 (0.5928)	Prec@1 79.688 (79.874)
Test: [40/79]	Time 0.029 (0.050)	Loss 0.5965 (0.5816)	Prec@1 78.906 (80.297)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.6078 (0.5878)	Prec@1 77.344 (80.008)
 * Prec@1 79.860
=> Saving checkpoint for epoch 7, with Prec@1 79.860000.
Epoch: [8][0/391]	Time 0.777 (0.777)	Loss 0.6468 (0.6468)	Prec@1 81.250 (81.250)
Epoch: [8][20/391]	Time 0.046 (0.079)	Loss 0.6374 (0.6021)	Prec@1 78.125 (79.315)
Epoch: [8][40/391]	Time 0.047 (0.063)	Loss 0.4789 (0.5833)	Prec@1 84.375 (80.088)
Epoch: [8][60/391]	Time 0.047 (0.057)	Loss 0.4759 (0.5892)	Prec@1 84.375 (79.790)
Epoch: [8][80/391]	Time 0.046 (0.054)	Loss 0.6425 (0.5889)	Prec@1 78.125 (79.861)
Epoch: [8][100/391]	Time 0.047 (0.052)	Loss 0.4056 (0.5824)	Prec@1 85.156 (80.074)
Epoch: [8][120/391]	Time 0.048 (0.051)	Loss 0.5239 (0.5809)	Prec@1 78.906 (80.107)
Epoch: [8][140/391]	Time 0.046 (0.052)	Loss 0.6086 (0.5795)	Prec@1 79.688 (80.053)
Epoch: [8][160/391]	Time 0.046 (0.051)	Loss 0.6041 (0.5785)	Prec@1 78.125 (80.085)
Epoch: [8][180/391]	Time 0.047 (0.051)	Loss 0.6201 (0.5815)	Prec@1 78.125 (79.908)
Epoch: [8][200/391]	Time 0.047 (0.050)	Loss 0.5336 (0.5800)	Prec@1 80.469 (79.998)
Epoch: [8][220/391]	Time 0.045 (0.050)	Loss 0.6060 (0.5820)	Prec@1 81.250 (79.882)
Epoch: [8][240/391]	Time 0.048 (0.050)	Loss 0.5909 (0.5795)	Prec@1 79.688 (79.937)
Epoch: [8][260/391]	Time 0.047 (0.049)	Loss 0.5168 (0.5766)	Prec@1 84.375 (80.056)
Epoch: [8][280/391]	Time 0.047 (0.049)	Loss 0.5603 (0.5739)	Prec@1 82.031 (80.182)
Epoch: [8][300/391]	Time 0.046 (0.049)	Loss 0.3509 (0.5704)	Prec@1 89.062 (80.344)
Epoch: [8][320/391]	Time 0.045 (0.049)	Loss 0.6676 (0.5710)	Prec@1 80.469 (80.340)
Epoch: [8][340/391]	Time 0.046 (0.049)	Loss 0.6547 (0.5695)	Prec@1 75.781 (80.384)
Epoch: [8][360/391]	Time 0.045 (0.048)	Loss 0.5425 (0.5690)	Prec@1 73.438 (80.387)
Epoch: [8][380/391]	Time 0.045 (0.048)	Loss 0.4366 (0.5682)	Prec@1 81.250 (80.383)
training time:  19.01093864440918
Test: [0/79]	Time 0.738 (0.738)	Loss 0.4724 (0.4724)	Prec@1 85.156 (85.156)
Test: [20/79]	Time 0.032 (0.064)	Loss 0.4705 (0.6181)	Prec@1 84.375 (79.204)
Test: [40/79]	Time 0.031 (0.049)	Loss 0.6380 (0.6084)	Prec@1 77.344 (79.497)
Test: [60/79]	Time 0.031 (0.043)	Loss 0.7473 (0.6075)	Prec@1 73.438 (79.470)
 * Prec@1 79.370
Epoch: [9][0/391]	Time 0.778 (0.778)	Loss 0.6013 (0.6013)	Prec@1 75.781 (75.781)
Epoch: [9][20/391]	Time 0.048 (0.081)	Loss 0.4403 (0.5300)	Prec@1 86.719 (81.659)
Epoch: [9][40/391]	Time 0.046 (0.064)	Loss 0.5521 (0.5479)	Prec@1 82.812 (81.021)
Epoch: [9][60/391]	Time 0.047 (0.058)	Loss 0.6755 (0.5485)	Prec@1 75.000 (80.789)
Epoch: [9][80/391]	Time 0.046 (0.055)	Loss 0.6233 (0.5465)	Prec@1 79.688 (81.028)
Epoch: [9][100/391]	Time 0.045 (0.053)	Loss 0.6359 (0.5462)	Prec@1 77.344 (81.088)
Epoch: [9][120/391]	Time 0.047 (0.052)	Loss 0.6669 (0.5473)	Prec@1 78.125 (81.082)
Epoch: [9][140/391]	Time 0.045 (0.051)	Loss 0.5437 (0.5456)	Prec@1 83.594 (81.106)
Epoch: [9][160/391]	Time 0.046 (0.051)	Loss 0.6889 (0.5424)	Prec@1 76.562 (81.192)
Epoch: [9][180/391]	Time 0.045 (0.050)	Loss 0.5497 (0.5400)	Prec@1 78.906 (81.371)
Epoch: [9][200/391]	Time 0.043 (0.050)	Loss 0.5956 (0.5423)	Prec@1 79.688 (81.297)
Epoch: [9][220/391]	Time 0.047 (0.050)	Loss 0.5758 (0.5457)	Prec@1 81.250 (81.215)
Epoch: [9][240/391]	Time 0.050 (0.049)	Loss 0.6735 (0.5460)	Prec@1 79.688 (81.260)
Epoch: [9][260/391]	Time 0.048 (0.049)	Loss 0.4639 (0.5445)	Prec@1 82.812 (81.331)
Epoch: [9][280/391]	Time 0.046 (0.049)	Loss 0.5629 (0.5452)	Prec@1 79.688 (81.306)
Epoch: [9][300/391]	Time 0.042 (0.049)	Loss 0.5210 (0.5441)	Prec@1 83.594 (81.364)
Epoch: [9][320/391]	Time 0.048 (0.048)	Loss 0.4192 (0.5439)	Prec@1 83.594 (81.342)
Epoch: [9][340/391]	Time 0.045 (0.048)	Loss 0.5769 (0.5436)	Prec@1 78.906 (81.358)
Epoch: [9][360/391]	Time 0.047 (0.048)	Loss 0.4213 (0.5407)	Prec@1 84.375 (81.443)
Epoch: [9][380/391]	Time 0.044 (0.048)	Loss 0.5996 (0.5400)	Prec@1 81.250 (81.461)
training time:  18.95261263847351
Test: [0/79]	Time 0.734 (0.734)	Loss 0.4704 (0.4704)	Prec@1 84.375 (84.375)
Test: [20/79]	Time 0.029 (0.064)	Loss 0.5826 (0.5759)	Prec@1 81.250 (80.580)
Test: [40/79]	Time 0.029 (0.048)	Loss 0.6570 (0.5708)	Prec@1 75.781 (80.888)
Test: [60/79]	Time 0.030 (0.042)	Loss 0.6152 (0.5678)	Prec@1 82.031 (80.994)
 * Prec@1 81.010
=> Saving checkpoint for epoch 9, with Prec@1 81.010000.
Epoch: [10][0/391]	Time 0.767 (0.767)	Loss 0.4219 (0.4219)	Prec@1 88.281 (88.281)
Epoch: [10][20/391]	Time 0.048 (0.080)	Loss 0.5328 (0.4761)	Prec@1 84.375 (83.929)
Epoch: [10][40/391]	Time 0.046 (0.064)	Loss 0.5059 (0.4976)	Prec@1 85.938 (83.270)
Epoch: [10][60/391]	Time 0.045 (0.058)	Loss 0.5356 (0.4939)	Prec@1 81.250 (83.325)
Epoch: [10][80/391]	Time 0.046 (0.055)	Loss 0.4140 (0.4903)	Prec@1 85.156 (83.430)
Epoch: [10][100/391]	Time 0.045 (0.054)	Loss 0.5019 (0.4964)	Prec@1 85.156 (83.253)
Epoch: [10][120/391]	Time 0.045 (0.054)	Loss 0.5014 (0.5052)	Prec@1 85.156 (82.896)
Epoch: [10][140/391]	Time 0.046 (0.053)	Loss 0.5707 (0.5079)	Prec@1 79.688 (82.774)
Epoch: [10][160/391]	Time 0.045 (0.052)	Loss 0.5377 (0.5127)	Prec@1 83.594 (82.628)
Epoch: [10][180/391]	Time 0.047 (0.051)	Loss 0.4819 (0.5120)	Prec@1 84.375 (82.679)
Epoch: [10][200/391]	Time 0.046 (0.051)	Loss 0.4958 (0.5117)	Prec@1 84.375 (82.572)
Epoch: [10][220/391]	Time 0.048 (0.050)	Loss 0.4984 (0.5121)	Prec@1 81.250 (82.494)
Epoch: [10][240/391]	Time 0.046 (0.050)	Loss 0.6041 (0.5134)	Prec@1 75.000 (82.472)
Epoch: [10][260/391]	Time 0.047 (0.050)	Loss 0.4273 (0.5134)	Prec@1 87.500 (82.498)
Epoch: [10][280/391]	Time 0.048 (0.050)	Loss 0.4434 (0.5115)	Prec@1 84.375 (82.509)
Epoch: [10][300/391]	Time 0.047 (0.049)	Loss 0.4799 (0.5096)	Prec@1 85.938 (82.563)
Epoch: [10][320/391]	Time 0.046 (0.049)	Loss 0.4539 (0.5109)	Prec@1 85.938 (82.513)
Epoch: [10][340/391]	Time 0.047 (0.049)	Loss 0.4954 (0.5124)	Prec@1 82.031 (82.428)
Epoch: [10][360/391]	Time 0.046 (0.049)	Loss 0.4952 (0.5124)	Prec@1 85.156 (82.427)
Epoch: [10][380/391]	Time 0.044 (0.049)	Loss 0.5280 (0.5123)	Prec@1 78.906 (82.406)
training time:  19.177045822143555
Test: [0/79]	Time 0.735 (0.735)	Loss 0.5690 (0.5690)	Prec@1 82.031 (82.031)
Test: [20/79]	Time 0.029 (0.065)	Loss 0.5295 (0.6155)	Prec@1 81.250 (78.832)
Test: [40/79]	Time 0.033 (0.049)	Loss 0.6365 (0.6129)	Prec@1 73.438 (79.078)
Test: [60/79]	Time 0.032 (0.044)	Loss 0.6824 (0.6173)	Prec@1 79.688 (79.098)
 * Prec@1 79.410
Epoch: [11][0/391]	Time 0.827 (0.827)	Loss 0.4765 (0.4765)	Prec@1 84.375 (84.375)
Epoch: [11][20/391]	Time 0.050 (0.084)	Loss 0.4442 (0.4610)	Prec@1 84.375 (84.635)
Epoch: [11][40/391]	Time 0.047 (0.065)	Loss 0.5537 (0.4643)	Prec@1 83.594 (84.165)
Epoch: [11][60/391]	Time 0.046 (0.059)	Loss 0.5334 (0.4758)	Prec@1 82.031 (83.709)
Epoch: [11][80/391]	Time 0.046 (0.056)	Loss 0.4430 (0.4830)	Prec@1 81.250 (83.565)
Epoch: [11][100/391]	Time 0.045 (0.054)	Loss 0.4142 (0.4787)	Prec@1 86.719 (83.779)
Epoch: [11][120/391]	Time 0.049 (0.053)	Loss 0.7821 (0.4854)	Prec@1 75.000 (83.490)
Epoch: [11][140/391]	Time 0.045 (0.052)	Loss 0.5439 (0.4893)	Prec@1 85.938 (83.439)
Epoch: [11][160/391]	Time 0.045 (0.051)	Loss 0.4322 (0.4892)	Prec@1 86.719 (83.390)
Epoch: [11][180/391]	Time 0.045 (0.050)	Loss 0.4677 (0.4881)	Prec@1 83.594 (83.387)
Epoch: [11][200/391]	Time 0.046 (0.050)	Loss 0.5232 (0.4881)	Prec@1 80.469 (83.353)
Epoch: [11][220/391]	Time 0.045 (0.050)	Loss 0.4845 (0.4898)	Prec@1 79.688 (83.244)
Epoch: [11][240/391]	Time 0.045 (0.049)	Loss 0.5289 (0.4899)	Prec@1 81.250 (83.273)
Epoch: [11][260/391]	Time 0.047 (0.049)	Loss 0.4440 (0.4914)	Prec@1 89.062 (83.196)
Epoch: [11][280/391]	Time 0.047 (0.049)	Loss 0.3783 (0.4929)	Prec@1 85.938 (83.154)
Epoch: [11][300/391]	Time 0.045 (0.049)	Loss 0.4573 (0.4920)	Prec@1 87.500 (83.220)
Epoch: [11][320/391]	Time 0.043 (0.048)	Loss 0.6029 (0.4937)	Prec@1 78.906 (83.214)
Epoch: [11][340/391]	Time 0.045 (0.048)	Loss 0.5175 (0.4936)	Prec@1 77.344 (83.216)
Epoch: [11][360/391]	Time 0.047 (0.048)	Loss 0.4652 (0.4931)	Prec@1 82.812 (83.224)
Epoch: [11][380/391]	Time 0.047 (0.048)	Loss 0.4697 (0.4927)	Prec@1 85.156 (83.202)
training time:  18.95331072807312
Test: [0/79]	Time 0.790 (0.790)	Loss 0.4888 (0.4888)	Prec@1 85.938 (85.938)
Test: [20/79]	Time 0.028 (0.068)	Loss 0.5809 (0.5787)	Prec@1 80.469 (80.320)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.5693 (0.5688)	Prec@1 77.344 (80.697)
Test: [60/79]	Time 0.033 (0.044)	Loss 0.5900 (0.5646)	Prec@1 79.688 (81.019)
 * Prec@1 80.760
Epoch: [12][0/391]	Time 0.820 (0.820)	Loss 0.4551 (0.4551)	Prec@1 82.812 (82.812)
Epoch: [12][20/391]	Time 0.043 (0.082)	Loss 0.5446 (0.4513)	Prec@1 78.906 (83.891)
Epoch: [12][40/391]	Time 0.044 (0.064)	Loss 0.4373 (0.4540)	Prec@1 86.719 (84.013)
Epoch: [12][60/391]	Time 0.044 (0.058)	Loss 0.4774 (0.4604)	Prec@1 80.469 (84.042)
Epoch: [12][80/391]	Time 0.047 (0.055)	Loss 0.6023 (0.4660)	Prec@1 77.344 (83.864)
Epoch: [12][100/391]	Time 0.047 (0.053)	Loss 0.5173 (0.4630)	Prec@1 81.250 (83.934)
Epoch: [12][120/391]	Time 0.047 (0.053)	Loss 0.4859 (0.4657)	Prec@1 83.594 (83.858)
Epoch: [12][140/391]	Time 0.046 (0.052)	Loss 0.5157 (0.4709)	Prec@1 81.250 (83.649)
Epoch: [12][160/391]	Time 0.047 (0.051)	Loss 0.3819 (0.4727)	Prec@1 82.812 (83.531)
Epoch: [12][180/391]	Time 0.046 (0.051)	Loss 0.3605 (0.4728)	Prec@1 87.500 (83.585)
Epoch: [12][200/391]	Time 0.047 (0.050)	Loss 0.5597 (0.4715)	Prec@1 83.594 (83.675)
Epoch: [12][220/391]	Time 0.047 (0.050)	Loss 0.3893 (0.4710)	Prec@1 88.281 (83.725)
Epoch: [12][240/391]	Time 0.048 (0.050)	Loss 0.5432 (0.4714)	Prec@1 81.250 (83.694)
Epoch: [12][260/391]	Time 0.046 (0.049)	Loss 0.4270 (0.4730)	Prec@1 86.719 (83.660)
Epoch: [12][280/391]	Time 0.047 (0.049)	Loss 0.5312 (0.4736)	Prec@1 82.031 (83.591)
Epoch: [12][300/391]	Time 0.046 (0.049)	Loss 0.3594 (0.4748)	Prec@1 89.844 (83.594)
Epoch: [12][320/391]	Time 0.045 (0.049)	Loss 0.5034 (0.4757)	Prec@1 82.031 (83.565)
Epoch: [12][340/391]	Time 0.046 (0.049)	Loss 0.3361 (0.4735)	Prec@1 87.500 (83.649)
Epoch: [12][360/391]	Time 0.047 (0.049)	Loss 0.4014 (0.4726)	Prec@1 88.281 (83.702)
Epoch: [12][380/391]	Time 0.045 (0.048)	Loss 0.4438 (0.4747)	Prec@1 84.375 (83.635)
training time:  19.06505036354065
Test: [0/79]	Time 0.777 (0.777)	Loss 0.4423 (0.4423)	Prec@1 85.938 (85.938)
Test: [20/79]	Time 0.033 (0.067)	Loss 0.4714 (0.5415)	Prec@1 82.031 (81.176)
Test: [40/79]	Time 0.033 (0.050)	Loss 0.5686 (0.5371)	Prec@1 81.250 (81.288)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.5327 (0.5368)	Prec@1 83.594 (81.455)
 * Prec@1 81.200
=> Saving checkpoint for epoch 12, with Prec@1 81.200000.
Epoch: [13][0/391]	Time 0.772 (0.772)	Loss 0.4382 (0.4382)	Prec@1 87.500 (87.500)
Epoch: [13][20/391]	Time 0.047 (0.081)	Loss 0.3567 (0.4191)	Prec@1 87.500 (86.272)
Epoch: [13][40/391]	Time 0.046 (0.064)	Loss 0.3574 (0.4389)	Prec@1 89.062 (85.042)
Epoch: [13][60/391]	Time 0.046 (0.058)	Loss 0.5086 (0.4391)	Prec@1 82.812 (84.900)
Epoch: [13][80/391]	Time 0.047 (0.056)	Loss 0.4426 (0.4391)	Prec@1 85.938 (84.770)
Epoch: [13][100/391]	Time 0.047 (0.054)	Loss 0.4970 (0.4412)	Prec@1 82.812 (84.623)
Epoch: [13][120/391]	Time 0.049 (0.053)	Loss 0.4150 (0.4447)	Prec@1 86.719 (84.743)
Epoch: [13][140/391]	Time 0.045 (0.052)	Loss 0.4006 (0.4461)	Prec@1 86.719 (84.624)
Epoch: [13][160/391]	Time 0.045 (0.051)	Loss 0.5062 (0.4484)	Prec@1 78.906 (84.564)
Epoch: [13][180/391]	Time 0.045 (0.050)	Loss 0.3912 (0.4532)	Prec@1 89.844 (84.422)
Epoch: [13][200/391]	Time 0.046 (0.050)	Loss 0.5923 (0.4538)	Prec@1 82.812 (84.398)
Epoch: [13][220/391]	Time 0.046 (0.050)	Loss 0.3864 (0.4536)	Prec@1 88.281 (84.368)
Epoch: [13][240/391]	Time 0.047 (0.050)	Loss 0.4468 (0.4565)	Prec@1 84.375 (84.242)
Epoch: [13][260/391]	Time 0.046 (0.049)	Loss 0.4232 (0.4557)	Prec@1 85.938 (84.201)
Epoch: [13][280/391]	Time 0.046 (0.049)	Loss 0.4150 (0.4535)	Prec@1 89.062 (84.280)
Epoch: [13][300/391]	Time 0.046 (0.049)	Loss 0.3927 (0.4537)	Prec@1 88.281 (84.297)
Epoch: [13][320/391]	Time 0.045 (0.049)	Loss 0.5517 (0.4543)	Prec@1 83.594 (84.287)
Epoch: [13][340/391]	Time 0.046 (0.049)	Loss 0.4017 (0.4552)	Prec@1 85.938 (84.263)
Epoch: [13][360/391]	Time 0.046 (0.049)	Loss 0.3988 (0.4547)	Prec@1 84.375 (84.256)
Epoch: [13][380/391]	Time 0.045 (0.048)	Loss 0.4278 (0.4550)	Prec@1 82.031 (84.236)
training time:  19.060192108154297
Test: [0/79]	Time 0.731 (0.731)	Loss 0.4995 (0.4995)	Prec@1 82.031 (82.031)
Test: [20/79]	Time 0.031 (0.065)	Loss 0.6455 (0.5762)	Prec@1 81.250 (80.915)
Test: [40/79]	Time 0.032 (0.049)	Loss 0.7222 (0.5632)	Prec@1 76.562 (81.441)
Test: [60/79]	Time 0.032 (0.043)	Loss 0.4049 (0.5539)	Prec@1 85.938 (81.788)
 * Prec@1 81.890
=> Saving checkpoint for epoch 13, with Prec@1 81.890000.
Epoch: [14][0/391]	Time 0.816 (0.816)	Loss 0.3665 (0.3665)	Prec@1 85.938 (85.938)
Epoch: [14][20/391]	Time 0.047 (0.083)	Loss 0.5355 (0.4301)	Prec@1 82.812 (85.045)
Epoch: [14][40/391]	Time 0.046 (0.065)	Loss 0.4395 (0.4558)	Prec@1 85.938 (84.604)
Epoch: [14][60/391]	Time 0.049 (0.059)	Loss 0.5698 (0.4499)	Prec@1 78.125 (84.849)
Epoch: [14][80/391]	Time 0.047 (0.056)	Loss 0.4681 (0.4559)	Prec@1 82.031 (84.443)
Epoch: [14][100/391]	Time 0.047 (0.054)	Loss 0.3982 (0.4480)	Prec@1 87.500 (84.754)
Epoch: [14][120/391]	Time 0.048 (0.054)	Loss 0.3857 (0.4440)	Prec@1 85.156 (84.859)
Epoch: [14][140/391]	Time 0.048 (0.053)	Loss 0.4885 (0.4432)	Prec@1 84.375 (84.818)
Epoch: [14][160/391]	Time 0.046 (0.052)	Loss 0.4497 (0.4413)	Prec@1 81.250 (84.821)
Epoch: [14][180/391]	Time 0.048 (0.051)	Loss 0.4484 (0.4443)	Prec@1 83.594 (84.699)
Epoch: [14][200/391]	Time 0.047 (0.051)	Loss 0.4535 (0.4457)	Prec@1 80.469 (84.694)
Epoch: [14][220/391]	Time 0.047 (0.051)	Loss 0.3417 (0.4465)	Prec@1 89.844 (84.658)
Epoch: [14][240/391]	Time 0.045 (0.050)	Loss 0.4324 (0.4431)	Prec@1 82.812 (84.826)
Epoch: [14][260/391]	Time 0.048 (0.050)	Loss 0.3892 (0.4448)	Prec@1 86.719 (84.770)
Epoch: [14][280/391]	Time 0.047 (0.050)	Loss 0.3180 (0.4457)	Prec@1 91.406 (84.773)
Epoch: [14][300/391]	Time 0.048 (0.050)	Loss 0.4956 (0.4457)	Prec@1 81.250 (84.759)
Epoch: [14][320/391]	Time 0.048 (0.049)	Loss 0.4837 (0.4441)	Prec@1 84.375 (84.784)
Epoch: [14][340/391]	Time 0.046 (0.049)	Loss 0.4966 (0.4453)	Prec@1 83.594 (84.719)
Epoch: [14][360/391]	Time 0.046 (0.049)	Loss 0.4391 (0.4462)	Prec@1 83.594 (84.674)
Epoch: [14][380/391]	Time 0.048 (0.049)	Loss 0.4633 (0.4447)	Prec@1 84.375 (84.724)
training time:  19.240227222442627
Test: [0/79]	Time 0.787 (0.787)	Loss 0.5072 (0.5072)	Prec@1 82.031 (82.031)
Test: [20/79]	Time 0.028 (0.066)	Loss 0.5625 (0.5573)	Prec@1 79.688 (81.436)
Test: [40/79]	Time 0.031 (0.049)	Loss 0.6839 (0.5472)	Prec@1 75.000 (81.650)
Test: [60/79]	Time 0.031 (0.043)	Loss 0.5884 (0.5466)	Prec@1 83.594 (81.519)
 * Prec@1 81.720
Epoch: [15][0/391]	Time 0.812 (0.812)	Loss 0.4199 (0.4199)	Prec@1 89.062 (89.062)
Epoch: [15][20/391]	Time 0.045 (0.082)	Loss 0.3193 (0.4167)	Prec@1 88.281 (86.086)
Epoch: [15][40/391]	Time 0.042 (0.063)	Loss 0.3680 (0.4161)	Prec@1 86.719 (85.785)
Epoch: [15][60/391]	Time 0.042 (0.057)	Loss 0.4832 (0.4131)	Prec@1 84.375 (85.873)
Epoch: [15][80/391]	Time 0.046 (0.053)	Loss 0.4309 (0.4178)	Prec@1 85.156 (85.619)
Epoch: [15][100/391]	Time 0.042 (0.051)	Loss 0.4567 (0.4254)	Prec@1 83.594 (85.466)
Epoch: [15][120/391]	Time 0.042 (0.050)	Loss 0.4187 (0.4278)	Prec@1 83.594 (85.369)
Epoch: [15][140/391]	Time 0.042 (0.049)	Loss 0.5073 (0.4287)	Prec@1 82.812 (85.328)
Epoch: [15][160/391]	Time 0.041 (0.049)	Loss 0.5468 (0.4311)	Prec@1 80.469 (85.224)
Epoch: [15][180/391]	Time 0.042 (0.048)	Loss 0.4524 (0.4296)	Prec@1 85.938 (85.277)
Epoch: [15][200/391]	Time 0.041 (0.048)	Loss 0.3386 (0.4279)	Prec@1 88.281 (85.331)
Epoch: [15][220/391]	Time 0.041 (0.047)	Loss 0.4130 (0.4325)	Prec@1 84.375 (85.188)
Epoch: [15][240/391]	Time 0.044 (0.047)	Loss 0.5896 (0.4353)	Prec@1 84.375 (85.182)
Epoch: [15][260/391]	Time 0.042 (0.047)	Loss 0.4297 (0.4353)	Prec@1 81.250 (85.201)
Epoch: [15][280/391]	Time 0.043 (0.046)	Loss 0.3642 (0.4355)	Prec@1 85.156 (85.198)
Epoch: [15][300/391]	Time 0.041 (0.046)	Loss 0.4212 (0.4360)	Prec@1 84.375 (85.133)
Epoch: [15][320/391]	Time 0.044 (0.046)	Loss 0.4606 (0.4344)	Prec@1 85.156 (85.188)
Epoch: [15][340/391]	Time 0.041 (0.046)	Loss 0.4455 (0.4345)	Prec@1 83.594 (85.147)
Epoch: [15][360/391]	Time 0.041 (0.046)	Loss 0.5863 (0.4361)	Prec@1 79.688 (85.109)
Epoch: [15][380/391]	Time 0.045 (0.046)	Loss 0.4123 (0.4336)	Prec@1 82.812 (85.150)
training time:  18.01177406311035
Test: [0/79]	Time 0.776 (0.776)	Loss 0.4379 (0.4379)	Prec@1 85.156 (85.156)
Test: [20/79]	Time 0.034 (0.067)	Loss 0.5046 (0.5107)	Prec@1 78.906 (82.478)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.4929 (0.4944)	Prec@1 79.688 (82.965)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.4670 (0.4873)	Prec@1 83.594 (83.184)
 * Prec@1 83.100
=> Saving checkpoint for epoch 15, with Prec@1 83.100000.
Epoch: [16][0/391]	Time 0.828 (0.828)	Loss 0.4655 (0.4655)	Prec@1 84.375 (84.375)
Epoch: [16][20/391]	Time 0.044 (0.083)	Loss 0.2967 (0.4066)	Prec@1 91.406 (86.124)
Epoch: [16][40/391]	Time 0.047 (0.065)	Loss 0.3273 (0.4014)	Prec@1 85.938 (86.090)
Epoch: [16][60/391]	Time 0.045 (0.059)	Loss 0.4409 (0.4014)	Prec@1 83.594 (86.181)
Epoch: [16][80/391]	Time 0.044 (0.056)	Loss 0.4692 (0.4167)	Prec@1 85.156 (85.677)
Epoch: [16][100/391]	Time 0.045 (0.054)	Loss 0.4212 (0.4207)	Prec@1 88.281 (85.512)
Epoch: [16][120/391]	Time 0.042 (0.054)	Loss 0.4460 (0.4231)	Prec@1 85.156 (85.318)
Epoch: [16][140/391]	Time 0.045 (0.052)	Loss 0.3970 (0.4243)	Prec@1 87.500 (85.289)
Epoch: [16][160/391]	Time 0.045 (0.051)	Loss 0.4843 (0.4276)	Prec@1 82.031 (85.224)
Epoch: [16][180/391]	Time 0.045 (0.051)	Loss 0.4550 (0.4273)	Prec@1 82.812 (85.273)
Epoch: [16][200/391]	Time 0.045 (0.050)	Loss 0.3861 (0.4249)	Prec@1 84.375 (85.370)
Epoch: [16][220/391]	Time 0.046 (0.050)	Loss 0.4925 (0.4253)	Prec@1 82.812 (85.379)
Epoch: [16][240/391]	Time 0.044 (0.049)	Loss 0.4365 (0.4271)	Prec@1 85.156 (85.335)
Epoch: [16][260/391]	Time 0.045 (0.049)	Loss 0.4678 (0.4256)	Prec@1 85.938 (85.399)
Epoch: [16][280/391]	Time 0.046 (0.049)	Loss 0.4178 (0.4237)	Prec@1 82.812 (85.431)
Epoch: [16][300/391]	Time 0.044 (0.049)	Loss 0.3777 (0.4224)	Prec@1 85.156 (85.460)
Epoch: [16][320/391]	Time 0.045 (0.049)	Loss 0.3356 (0.4221)	Prec@1 89.062 (85.475)
Epoch: [16][340/391]	Time 0.044 (0.048)	Loss 0.3682 (0.4233)	Prec@1 85.938 (85.456)
Epoch: [16][360/391]	Time 0.045 (0.048)	Loss 0.3857 (0.4240)	Prec@1 86.719 (85.451)
Epoch: [16][380/391]	Time 0.045 (0.048)	Loss 0.5219 (0.4233)	Prec@1 80.469 (85.454)
training time:  18.94989037513733
Test: [0/79]	Time 0.770 (0.770)	Loss 0.6184 (0.6184)	Prec@1 77.344 (77.344)
Test: [20/79]	Time 0.032 (0.066)	Loss 0.5733 (0.6348)	Prec@1 77.344 (78.534)
Test: [40/79]	Time 0.029 (0.049)	Loss 0.7744 (0.6304)	Prec@1 75.781 (78.735)
Test: [60/79]	Time 0.032 (0.044)	Loss 0.5576 (0.6168)	Prec@1 80.469 (79.162)
 * Prec@1 79.310
Epoch: [17][0/391]	Time 0.817 (0.817)	Loss 0.4984 (0.4984)	Prec@1 86.719 (86.719)
Epoch: [17][20/391]	Time 0.047 (0.083)	Loss 0.3577 (0.3809)	Prec@1 86.719 (87.054)
Epoch: [17][40/391]	Time 0.046 (0.065)	Loss 0.4307 (0.3922)	Prec@1 85.156 (86.700)
Epoch: [17][60/391]	Time 0.047 (0.059)	Loss 0.3577 (0.4004)	Prec@1 85.156 (86.642)
Epoch: [17][80/391]	Time 0.047 (0.056)	Loss 0.4495 (0.4016)	Prec@1 83.594 (86.545)
Epoch: [17][100/391]	Time 0.046 (0.054)	Loss 0.4145 (0.4014)	Prec@1 85.156 (86.518)
Epoch: [17][120/391]	Time 0.048 (0.053)	Loss 0.4905 (0.4056)	Prec@1 83.594 (86.312)
Epoch: [17][140/391]	Time 0.043 (0.052)	Loss 0.3091 (0.4028)	Prec@1 87.500 (86.320)
Epoch: [17][160/391]	Time 0.041 (0.051)	Loss 0.4871 (0.4038)	Prec@1 85.156 (86.297)
Epoch: [17][180/391]	Time 0.043 (0.050)	Loss 0.3893 (0.4080)	Prec@1 86.719 (86.114)
Epoch: [17][200/391]	Time 0.043 (0.049)	Loss 0.4063 (0.4079)	Prec@1 85.938 (86.101)
Epoch: [17][220/391]	Time 0.043 (0.049)	Loss 0.5206 (0.4083)	Prec@1 82.812 (86.075)
Epoch: [17][240/391]	Time 0.042 (0.049)	Loss 0.6385 (0.4102)	Prec@1 80.469 (86.032)
Epoch: [17][260/391]	Time 0.042 (0.048)	Loss 0.2736 (0.4122)	Prec@1 89.062 (85.952)
Epoch: [17][280/391]	Time 0.046 (0.048)	Loss 0.3595 (0.4123)	Prec@1 86.719 (85.938)
Epoch: [17][300/391]	Time 0.045 (0.048)	Loss 0.4967 (0.4139)	Prec@1 86.719 (85.896)
Epoch: [17][320/391]	Time 0.046 (0.048)	Loss 0.4320 (0.4148)	Prec@1 87.500 (85.860)
Epoch: [17][340/391]	Time 0.046 (0.048)	Loss 0.3378 (0.4144)	Prec@1 89.062 (85.855)
Epoch: [17][360/391]	Time 0.043 (0.048)	Loss 0.4054 (0.4150)	Prec@1 80.469 (85.816)
Epoch: [17][380/391]	Time 0.045 (0.047)	Loss 0.4458 (0.4167)	Prec@1 81.250 (85.739)
training time:  18.712688446044922
Test: [0/79]	Time 0.783 (0.783)	Loss 0.5285 (0.5285)	Prec@1 82.031 (82.031)
Test: [20/79]	Time 0.032 (0.068)	Loss 0.5027 (0.5651)	Prec@1 78.906 (81.027)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.6762 (0.5429)	Prec@1 78.125 (81.364)
Test: [60/79]	Time 0.030 (0.044)	Loss 0.5805 (0.5406)	Prec@1 78.125 (81.237)
 * Prec@1 81.440
Epoch: [18][0/391]	Time 0.823 (0.823)	Loss 0.3757 (0.3757)	Prec@1 85.156 (85.156)
Epoch: [18][20/391]	Time 0.049 (0.083)	Loss 0.2725 (0.3700)	Prec@1 91.406 (87.723)
Epoch: [18][40/391]	Time 0.049 (0.065)	Loss 0.3308 (0.3826)	Prec@1 88.281 (87.214)
Epoch: [18][60/391]	Time 0.046 (0.059)	Loss 0.4716 (0.3802)	Prec@1 82.812 (87.269)
Epoch: [18][80/391]	Time 0.048 (0.056)	Loss 0.3112 (0.3789)	Prec@1 89.062 (87.278)
Epoch: [18][100/391]	Time 0.046 (0.054)	Loss 0.3717 (0.3873)	Prec@1 89.844 (87.059)
Epoch: [18][120/391]	Time 0.048 (0.054)	Loss 0.3007 (0.3902)	Prec@1 90.625 (86.912)
Epoch: [18][140/391]	Time 0.045 (0.053)	Loss 0.4951 (0.3937)	Prec@1 81.250 (86.730)
Epoch: [18][160/391]	Time 0.048 (0.052)	Loss 0.3991 (0.3927)	Prec@1 87.500 (86.694)
Epoch: [18][180/391]	Time 0.046 (0.051)	Loss 0.6790 (0.3969)	Prec@1 75.000 (86.559)
Epoch: [18][200/391]	Time 0.047 (0.051)	Loss 0.4218 (0.3987)	Prec@1 88.281 (86.462)
Epoch: [18][220/391]	Time 0.046 (0.051)	Loss 0.2823 (0.3999)	Prec@1 89.844 (86.401)
Epoch: [18][240/391]	Time 0.045 (0.050)	Loss 0.5540 (0.3996)	Prec@1 80.469 (86.421)
Epoch: [18][260/391]	Time 0.048 (0.050)	Loss 0.3416 (0.3986)	Prec@1 86.719 (86.467)
Epoch: [18][280/391]	Time 0.049 (0.050)	Loss 0.3580 (0.4002)	Prec@1 87.500 (86.405)
Epoch: [18][300/391]	Time 0.048 (0.050)	Loss 0.2979 (0.4029)	Prec@1 92.188 (86.293)
Epoch: [18][320/391]	Time 0.049 (0.049)	Loss 0.4951 (0.4028)	Prec@1 86.719 (86.271)
Epoch: [18][340/391]	Time 0.049 (0.049)	Loss 0.3116 (0.4032)	Prec@1 87.500 (86.263)
Epoch: [18][360/391]	Time 0.049 (0.049)	Loss 0.3977 (0.4031)	Prec@1 89.844 (86.299)
Epoch: [18][380/391]	Time 0.045 (0.049)	Loss 0.3559 (0.4034)	Prec@1 89.062 (86.307)
training time:  19.32691788673401
Test: [0/79]	Time 0.782 (0.782)	Loss 0.3872 (0.3872)	Prec@1 86.719 (86.719)
Test: [20/79]	Time 0.032 (0.067)	Loss 0.3838 (0.4761)	Prec@1 87.500 (83.780)
Test: [40/79]	Time 0.033 (0.050)	Loss 0.5359 (0.4670)	Prec@1 82.812 (84.032)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.4293 (0.4614)	Prec@1 84.375 (84.285)
 * Prec@1 84.070
=> Saving checkpoint for epoch 18, with Prec@1 84.070000.
Epoch: [19][0/391]	Time 0.769 (0.769)	Loss 0.3010 (0.3010)	Prec@1 90.625 (90.625)
Epoch: [19][20/391]	Time 0.046 (0.081)	Loss 0.4493 (0.3875)	Prec@1 83.594 (87.128)
Epoch: [19][40/391]	Time 0.047 (0.064)	Loss 0.4649 (0.3790)	Prec@1 85.156 (87.081)
Epoch: [19][60/391]	Time 0.046 (0.058)	Loss 0.3708 (0.3849)	Prec@1 89.062 (87.065)
Epoch: [19][80/391]	Time 0.045 (0.055)	Loss 0.2896 (0.3859)	Prec@1 87.500 (87.018)
Epoch: [19][100/391]	Time 0.046 (0.053)	Loss 0.2997 (0.3917)	Prec@1 89.844 (86.757)
Epoch: [19][120/391]	Time 0.045 (0.052)	Loss 0.3776 (0.3925)	Prec@1 87.500 (86.686)
Epoch: [19][140/391]	Time 0.046 (0.051)	Loss 0.3973 (0.3939)	Prec@1 83.594 (86.663)
Epoch: [19][160/391]	Time 0.046 (0.051)	Loss 0.4646 (0.3930)	Prec@1 85.156 (86.699)
Epoch: [19][180/391]	Time 0.046 (0.050)	Loss 0.4444 (0.3943)	Prec@1 84.375 (86.594)
Epoch: [19][200/391]	Time 0.047 (0.050)	Loss 0.4434 (0.3979)	Prec@1 87.500 (86.489)
Epoch: [19][220/391]	Time 0.047 (0.049)	Loss 0.3558 (0.3984)	Prec@1 90.625 (86.429)
Epoch: [19][240/391]	Time 0.046 (0.049)	Loss 0.4117 (0.4001)	Prec@1 85.938 (86.395)
Epoch: [19][260/391]	Time 0.043 (0.049)	Loss 0.4945 (0.3988)	Prec@1 84.375 (86.413)
Epoch: [19][280/391]	Time 0.043 (0.049)	Loss 0.4601 (0.4001)	Prec@1 87.500 (86.357)
Epoch: [19][300/391]	Time 0.044 (0.048)	Loss 0.4682 (0.4003)	Prec@1 82.031 (86.348)
Epoch: [19][320/391]	Time 0.044 (0.048)	Loss 0.2907 (0.4002)	Prec@1 91.406 (86.363)
Epoch: [19][340/391]	Time 0.049 (0.048)	Loss 0.4736 (0.4004)	Prec@1 84.375 (86.320)
Epoch: [19][360/391]	Time 0.046 (0.048)	Loss 0.3467 (0.4018)	Prec@1 89.844 (86.295)
Epoch: [19][380/391]	Time 0.045 (0.048)	Loss 0.5173 (0.4022)	Prec@1 79.688 (86.253)
training time:  18.769911289215088
Test: [0/79]	Time 0.746 (0.746)	Loss 0.5238 (0.5238)	Prec@1 82.031 (82.031)
Test: [20/79]	Time 0.032 (0.066)	Loss 0.6451 (0.5647)	Prec@1 78.906 (80.022)
Test: [40/79]	Time 0.030 (0.049)	Loss 0.7641 (0.5691)	Prec@1 75.000 (80.030)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.4750 (0.5656)	Prec@1 82.812 (80.085)
 * Prec@1 80.120
Epoch: [20][0/391]	Time 0.776 (0.776)	Loss 0.3452 (0.3452)	Prec@1 85.156 (85.156)
Epoch: [20][20/391]	Time 0.043 (0.080)	Loss 0.2861 (0.3393)	Prec@1 92.188 (89.025)
Epoch: [20][40/391]	Time 0.045 (0.063)	Loss 0.3446 (0.3542)	Prec@1 87.500 (88.281)
Epoch: [20][60/391]	Time 0.046 (0.058)	Loss 0.5416 (0.3543)	Prec@1 82.812 (88.025)
Epoch: [20][80/391]	Time 0.047 (0.055)	Loss 0.4512 (0.3645)	Prec@1 84.375 (87.654)
Epoch: [20][100/391]	Time 0.046 (0.053)	Loss 0.4595 (0.3731)	Prec@1 85.938 (87.454)
Epoch: [20][120/391]	Time 0.043 (0.053)	Loss 0.4131 (0.3764)	Prec@1 82.031 (87.287)
Epoch: [20][140/391]	Time 0.046 (0.052)	Loss 0.2668 (0.3768)	Prec@1 90.625 (87.289)
Epoch: [20][160/391]	Time 0.046 (0.052)	Loss 0.3081 (0.3731)	Prec@1 89.062 (87.451)
Epoch: [20][180/391]	Time 0.044 (0.051)	Loss 0.2921 (0.3748)	Prec@1 91.406 (87.332)
Epoch: [20][200/391]	Time 0.046 (0.051)	Loss 0.3611 (0.3808)	Prec@1 90.625 (87.185)
Epoch: [20][220/391]	Time 0.047 (0.050)	Loss 0.4598 (0.3820)	Prec@1 79.688 (87.122)
Epoch: [20][240/391]	Time 0.046 (0.050)	Loss 0.4605 (0.3832)	Prec@1 85.156 (87.059)
Epoch: [20][260/391]	Time 0.048 (0.050)	Loss 0.4882 (0.3854)	Prec@1 82.812 (86.943)
Epoch: [20][280/391]	Time 0.045 (0.049)	Loss 0.4646 (0.3849)	Prec@1 85.156 (86.958)
Epoch: [20][300/391]	Time 0.048 (0.049)	Loss 0.3219 (0.3853)	Prec@1 90.625 (86.952)
Epoch: [20][320/391]	Time 0.047 (0.049)	Loss 0.4194 (0.3879)	Prec@1 85.938 (86.894)
Epoch: [20][340/391]	Time 0.047 (0.049)	Loss 0.4421 (0.3879)	Prec@1 85.156 (86.900)
Epoch: [20][360/391]	Time 0.046 (0.049)	Loss 0.3973 (0.3885)	Prec@1 86.719 (86.883)
Epoch: [20][380/391]	Time 0.045 (0.049)	Loss 0.4243 (0.3904)	Prec@1 85.156 (86.832)
training time:  19.139723539352417
Test: [0/79]	Time 0.775 (0.775)	Loss 0.5324 (0.5324)	Prec@1 80.469 (80.469)
Test: [20/79]	Time 0.032 (0.067)	Loss 0.4093 (0.5487)	Prec@1 86.719 (81.696)
Test: [40/79]	Time 0.033 (0.050)	Loss 0.6420 (0.5341)	Prec@1 78.125 (82.317)
Test: [60/79]	Time 0.032 (0.044)	Loss 0.5618 (0.5310)	Prec@1 82.812 (82.351)
 * Prec@1 81.980
Epoch: [21][0/391]	Time 0.792 (0.792)	Loss 0.3878 (0.3878)	Prec@1 86.719 (86.719)
Epoch: [21][20/391]	Time 0.045 (0.082)	Loss 0.4892 (0.3712)	Prec@1 83.594 (87.016)
Epoch: [21][40/391]	Time 0.046 (0.065)	Loss 0.3280 (0.3555)	Prec@1 92.188 (87.691)
Epoch: [21][60/391]	Time 0.046 (0.059)	Loss 0.2715 (0.3563)	Prec@1 90.625 (87.679)
Epoch: [21][80/391]	Time 0.048 (0.056)	Loss 0.5034 (0.3614)	Prec@1 82.031 (87.568)
Epoch: [21][100/391]	Time 0.046 (0.054)	Loss 0.5053 (0.3635)	Prec@1 80.469 (87.492)
Epoch: [21][120/391]	Time 0.046 (0.053)	Loss 0.3951 (0.3718)	Prec@1 85.156 (87.287)
Epoch: [21][140/391]	Time 0.043 (0.052)	Loss 0.3702 (0.3691)	Prec@1 90.625 (87.389)
Epoch: [21][160/391]	Time 0.046 (0.051)	Loss 0.3760 (0.3683)	Prec@1 85.938 (87.359)
Epoch: [21][180/391]	Time 0.045 (0.051)	Loss 0.3934 (0.3700)	Prec@1 87.500 (87.349)
Epoch: [21][200/391]	Time 0.045 (0.050)	Loss 0.2353 (0.3696)	Prec@1 90.625 (87.294)
Epoch: [21][220/391]	Time 0.045 (0.050)	Loss 0.3304 (0.3736)	Prec@1 89.062 (87.146)
Epoch: [21][240/391]	Time 0.046 (0.049)	Loss 0.4886 (0.3743)	Prec@1 85.938 (87.121)
Epoch: [21][260/391]	Time 0.046 (0.049)	Loss 0.3795 (0.3763)	Prec@1 86.719 (87.078)
Epoch: [21][280/391]	Time 0.045 (0.049)	Loss 0.4238 (0.3789)	Prec@1 85.156 (87.005)
Epoch: [21][300/391]	Time 0.046 (0.049)	Loss 0.4479 (0.3780)	Prec@1 86.719 (87.046)
Epoch: [21][320/391]	Time 0.048 (0.048)	Loss 0.4213 (0.3800)	Prec@1 87.500 (86.994)
Epoch: [21][340/391]	Time 0.046 (0.048)	Loss 0.4415 (0.3808)	Prec@1 87.500 (86.962)
Epoch: [21][360/391]	Time 0.047 (0.048)	Loss 0.2804 (0.3820)	Prec@1 89.062 (86.894)
Epoch: [21][380/391]	Time 0.045 (0.048)	Loss 0.3021 (0.3836)	Prec@1 89.844 (86.873)
training time:  18.93458867073059
Test: [0/79]	Time 0.776 (0.776)	Loss 0.3907 (0.3907)	Prec@1 87.500 (87.500)
Test: [20/79]	Time 0.031 (0.067)	Loss 0.3705 (0.4406)	Prec@1 89.062 (85.640)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.4939 (0.4298)	Prec@1 84.375 (85.423)
Test: [60/79]	Time 0.032 (0.044)	Loss 0.5076 (0.4343)	Prec@1 84.375 (85.054)
 * Prec@1 85.250
=> Saving checkpoint for epoch 21, with Prec@1 85.250000.
Epoch: [22][0/391]	Time 0.821 (0.821)	Loss 0.2541 (0.2541)	Prec@1 90.625 (90.625)
Epoch: [22][20/391]	Time 0.046 (0.083)	Loss 0.4555 (0.3743)	Prec@1 87.500 (87.500)
Epoch: [22][40/391]	Time 0.048 (0.065)	Loss 0.4460 (0.3638)	Prec@1 83.594 (87.671)
Epoch: [22][60/391]	Time 0.044 (0.059)	Loss 0.4527 (0.3647)	Prec@1 85.938 (87.538)
Epoch: [22][80/391]	Time 0.045 (0.056)	Loss 0.2772 (0.3653)	Prec@1 94.531 (87.625)
Epoch: [22][100/391]	Time 0.046 (0.054)	Loss 0.3844 (0.3751)	Prec@1 86.719 (87.229)
Epoch: [22][120/391]	Time 0.043 (0.054)	Loss 0.4099 (0.3762)	Prec@1 88.281 (87.126)
Epoch: [22][140/391]	Time 0.047 (0.053)	Loss 0.4096 (0.3745)	Prec@1 84.375 (87.096)
Epoch: [22][160/391]	Time 0.045 (0.052)	Loss 0.3374 (0.3721)	Prec@1 90.625 (87.199)
Epoch: [22][180/391]	Time 0.046 (0.051)	Loss 0.4046 (0.3750)	Prec@1 88.281 (87.060)
Epoch: [22][200/391]	Time 0.048 (0.051)	Loss 0.2884 (0.3742)	Prec@1 90.625 (87.119)
Epoch: [22][220/391]	Time 0.048 (0.050)	Loss 0.2918 (0.3731)	Prec@1 91.406 (87.150)
Epoch: [22][240/391]	Time 0.048 (0.050)	Loss 0.2896 (0.3705)	Prec@1 92.188 (87.276)
Epoch: [22][260/391]	Time 0.048 (0.050)	Loss 0.2590 (0.3700)	Prec@1 89.062 (87.290)
Epoch: [22][280/391]	Time 0.046 (0.050)	Loss 0.4856 (0.3707)	Prec@1 83.594 (87.253)
Epoch: [22][300/391]	Time 0.049 (0.050)	Loss 0.4641 (0.3710)	Prec@1 85.156 (87.235)
Epoch: [22][320/391]	Time 0.043 (0.049)	Loss 0.3940 (0.3729)	Prec@1 86.719 (87.152)
Epoch: [22][340/391]	Time 0.043 (0.049)	Loss 0.4821 (0.3746)	Prec@1 85.156 (87.088)
Epoch: [22][360/391]	Time 0.046 (0.049)	Loss 0.4763 (0.3750)	Prec@1 84.375 (87.100)
Epoch: [22][380/391]	Time 0.045 (0.049)	Loss 0.4390 (0.3760)	Prec@1 85.156 (87.082)
training time:  19.19706916809082
Test: [0/79]	Time 0.784 (0.784)	Loss 0.5231 (0.5231)	Prec@1 85.156 (85.156)
Test: [20/79]	Time 0.032 (0.068)	Loss 0.5220 (0.5193)	Prec@1 80.469 (82.812)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.5946 (0.5046)	Prec@1 78.906 (82.946)
Test: [60/79]	Time 0.030 (0.044)	Loss 0.3792 (0.4977)	Prec@1 85.156 (83.299)
 * Prec@1 83.450
Epoch: [23][0/391]	Time 0.787 (0.787)	Loss 0.4751 (0.4751)	Prec@1 82.812 (82.812)
Epoch: [23][20/391]	Time 0.046 (0.082)	Loss 0.2305 (0.3498)	Prec@1 91.406 (87.984)
Epoch: [23][40/391]	Time 0.046 (0.065)	Loss 0.2548 (0.3395)	Prec@1 94.531 (88.586)
Epoch: [23][60/391]	Time 0.045 (0.059)	Loss 0.3399 (0.3395)	Prec@1 89.844 (88.704)
Epoch: [23][80/391]	Time 0.046 (0.056)	Loss 0.4144 (0.3396)	Prec@1 86.719 (88.628)
Epoch: [23][100/391]	Time 0.046 (0.054)	Loss 0.2696 (0.3435)	Prec@1 90.625 (88.444)
Epoch: [23][120/391]	Time 0.045 (0.053)	Loss 0.4451 (0.3422)	Prec@1 87.500 (88.430)
Epoch: [23][140/391]	Time 0.045 (0.052)	Loss 0.5502 (0.3482)	Prec@1 81.250 (88.231)
Epoch: [23][160/391]	Time 0.046 (0.051)	Loss 0.2991 (0.3528)	Prec@1 88.281 (87.942)
Epoch: [23][180/391]	Time 0.045 (0.050)	Loss 0.3355 (0.3575)	Prec@1 88.281 (87.854)
Epoch: [23][200/391]	Time 0.046 (0.050)	Loss 0.4753 (0.3610)	Prec@1 83.594 (87.710)
Epoch: [23][220/391]	Time 0.046 (0.050)	Loss 0.4129 (0.3608)	Prec@1 86.719 (87.698)
Epoch: [23][240/391]	Time 0.050 (0.049)	Loss 0.4514 (0.3627)	Prec@1 83.594 (87.562)
Epoch: [23][260/391]	Time 0.047 (0.049)	Loss 0.4011 (0.3648)	Prec@1 88.281 (87.521)
Epoch: [23][280/391]	Time 0.047 (0.049)	Loss 0.4723 (0.3661)	Prec@1 85.938 (87.467)
Epoch: [23][300/391]	Time 0.048 (0.049)	Loss 0.3139 (0.3639)	Prec@1 90.625 (87.526)
Epoch: [23][320/391]	Time 0.046 (0.049)	Loss 0.2955 (0.3628)	Prec@1 88.281 (87.554)
Epoch: [23][340/391]	Time 0.047 (0.049)	Loss 0.3769 (0.3642)	Prec@1 85.156 (87.482)
Epoch: [23][360/391]	Time 0.046 (0.048)	Loss 0.3860 (0.3660)	Prec@1 87.500 (87.420)
Epoch: [23][380/391]	Time 0.046 (0.048)	Loss 0.3547 (0.3682)	Prec@1 88.281 (87.375)
training time:  19.006209135055542
Test: [0/79]	Time 0.745 (0.745)	Loss 0.5010 (0.5010)	Prec@1 82.812 (82.812)
Test: [20/79]	Time 0.032 (0.065)	Loss 0.5108 (0.5225)	Prec@1 78.906 (82.329)
Test: [40/79]	Time 0.032 (0.049)	Loss 0.5669 (0.5143)	Prec@1 78.906 (82.565)
Test: [60/79]	Time 0.031 (0.043)	Loss 0.3636 (0.5044)	Prec@1 85.938 (82.979)
 * Prec@1 82.850
Epoch: [24][0/391]	Time 0.784 (0.784)	Loss 0.3345 (0.3345)	Prec@1 85.938 (85.938)
Epoch: [24][20/391]	Time 0.045 (0.081)	Loss 0.4013 (0.3361)	Prec@1 85.156 (87.500)
Epoch: [24][40/391]	Time 0.046 (0.064)	Loss 0.3724 (0.3459)	Prec@1 87.500 (87.748)
Epoch: [24][60/391]	Time 0.045 (0.058)	Loss 0.3368 (0.3467)	Prec@1 89.844 (87.884)
Epoch: [24][80/391]	Time 0.048 (0.055)	Loss 0.4482 (0.3481)	Prec@1 87.500 (87.992)
Epoch: [24][100/391]	Time 0.046 (0.053)	Loss 0.3725 (0.3519)	Prec@1 84.375 (87.848)
Epoch: [24][120/391]	Time 0.045 (0.052)	Loss 0.2856 (0.3524)	Prec@1 92.188 (87.855)
Epoch: [24][140/391]	Time 0.047 (0.052)	Loss 0.3546 (0.3556)	Prec@1 87.500 (87.716)
Epoch: [24][160/391]	Time 0.045 (0.052)	Loss 0.3973 (0.3536)	Prec@1 83.594 (87.772)
Epoch: [24][180/391]	Time 0.049 (0.051)	Loss 0.4704 (0.3551)	Prec@1 85.938 (87.750)
Epoch: [24][200/391]	Time 0.046 (0.050)	Loss 0.4708 (0.3556)	Prec@1 85.156 (87.722)
Epoch: [24][220/391]	Time 0.046 (0.050)	Loss 0.2551 (0.3609)	Prec@1 93.750 (87.560)
Epoch: [24][240/391]	Time 0.044 (0.050)	Loss 0.5010 (0.3647)	Prec@1 85.938 (87.481)
Epoch: [24][260/391]	Time 0.046 (0.049)	Loss 0.3745 (0.3647)	Prec@1 87.500 (87.479)
Epoch: [24][280/391]	Time 0.046 (0.049)	Loss 0.3694 (0.3644)	Prec@1 87.500 (87.500)
Epoch: [24][300/391]	Time 0.046 (0.049)	Loss 0.4251 (0.3644)	Prec@1 85.156 (87.513)
Epoch: [24][320/391]	Time 0.047 (0.049)	Loss 0.3006 (0.3637)	Prec@1 90.625 (87.510)
Epoch: [24][340/391]	Time 0.046 (0.048)	Loss 0.3751 (0.3636)	Prec@1 88.281 (87.562)
Epoch: [24][360/391]	Time 0.046 (0.048)	Loss 0.3092 (0.3646)	Prec@1 89.844 (87.535)
Epoch: [24][380/391]	Time 0.046 (0.048)	Loss 0.3272 (0.3646)	Prec@1 85.938 (87.533)
training time:  19.004323482513428
Test: [0/79]	Time 0.739 (0.739)	Loss 0.3358 (0.3358)	Prec@1 87.500 (87.500)
Test: [20/79]	Time 0.029 (0.064)	Loss 0.4555 (0.4867)	Prec@1 85.156 (83.631)
Test: [40/79]	Time 0.028 (0.048)	Loss 0.3464 (0.4628)	Prec@1 89.062 (84.546)
Test: [60/79]	Time 0.031 (0.043)	Loss 0.4232 (0.4557)	Prec@1 87.500 (84.810)
 * Prec@1 84.410
Epoch: [25][0/391]	Time 0.784 (0.784)	Loss 0.3398 (0.3398)	Prec@1 89.844 (89.844)
Epoch: [25][20/391]	Time 0.047 (0.082)	Loss 0.3329 (0.3629)	Prec@1 89.062 (87.612)
Epoch: [25][40/391]	Time 0.047 (0.065)	Loss 0.3918 (0.3439)	Prec@1 86.719 (88.148)
Epoch: [25][60/391]	Time 0.049 (0.059)	Loss 0.3509 (0.3330)	Prec@1 87.500 (88.448)
Epoch: [25][80/391]	Time 0.046 (0.056)	Loss 0.2905 (0.3387)	Prec@1 89.062 (88.069)
Epoch: [25][100/391]	Time 0.048 (0.054)	Loss 0.2885 (0.3369)	Prec@1 90.625 (88.343)
Epoch: [25][120/391]	Time 0.046 (0.052)	Loss 0.4183 (0.3415)	Prec@1 83.594 (88.165)
Epoch: [25][140/391]	Time 0.046 (0.051)	Loss 0.3437 (0.3409)	Prec@1 89.844 (88.287)
Epoch: [25][160/391]	Time 0.047 (0.051)	Loss 0.3680 (0.3448)	Prec@1 87.500 (88.136)
Epoch: [25][180/391]	Time 0.049 (0.050)	Loss 0.4989 (0.3492)	Prec@1 81.250 (87.927)
Epoch: [25][200/391]	Time 0.050 (0.050)	Loss 0.3444 (0.3508)	Prec@1 86.719 (87.885)
Epoch: [25][220/391]	Time 0.050 (0.049)	Loss 0.3581 (0.3542)	Prec@1 87.500 (87.783)
Epoch: [25][240/391]	Time 0.046 (0.049)	Loss 0.3226 (0.3534)	Prec@1 89.844 (87.834)
Epoch: [25][260/391]	Time 0.047 (0.049)	Loss 0.3447 (0.3539)	Prec@1 87.500 (87.832)
Epoch: [25][280/391]	Time 0.047 (0.049)	Loss 0.4341 (0.3547)	Prec@1 83.594 (87.820)
Epoch: [25][300/391]	Time 0.047 (0.049)	Loss 0.3452 (0.3545)	Prec@1 88.281 (87.832)
Epoch: [25][320/391]	Time 0.046 (0.049)	Loss 0.3496 (0.3569)	Prec@1 89.062 (87.756)
Epoch: [25][340/391]	Time 0.046 (0.048)	Loss 0.3318 (0.3565)	Prec@1 87.500 (87.766)
Epoch: [25][360/391]	Time 0.047 (0.048)	Loss 0.3465 (0.3552)	Prec@1 88.281 (87.816)
Epoch: [25][380/391]	Time 0.045 (0.048)	Loss 0.2696 (0.3540)	Prec@1 89.844 (87.853)
training time:  18.89232349395752
Test: [0/79]	Time 0.792 (0.792)	Loss 0.5157 (0.5157)	Prec@1 85.938 (85.938)
Test: [20/79]	Time 0.032 (0.068)	Loss 0.5357 (0.6086)	Prec@1 80.469 (81.399)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.6748 (0.5732)	Prec@1 78.906 (82.241)
Test: [60/79]	Time 0.032 (0.045)	Loss 0.5029 (0.5644)	Prec@1 85.156 (82.518)
 * Prec@1 82.550
Epoch: [26][0/391]	Time 0.819 (0.819)	Loss 0.3090 (0.3090)	Prec@1 89.844 (89.844)
Epoch: [26][20/391]	Time 0.042 (0.082)	Loss 0.3747 (0.3413)	Prec@1 83.594 (87.984)
Epoch: [26][40/391]	Time 0.047 (0.064)	Loss 0.2687 (0.3293)	Prec@1 92.188 (88.796)
Epoch: [26][60/391]	Time 0.047 (0.058)	Loss 0.3034 (0.3351)	Prec@1 90.625 (88.550)
Epoch: [26][80/391]	Time 0.046 (0.055)	Loss 0.3894 (0.3417)	Prec@1 84.375 (88.358)
Epoch: [26][100/391]	Time 0.050 (0.054)	Loss 0.2316 (0.3443)	Prec@1 92.188 (88.281)
Epoch: [26][120/391]	Time 0.048 (0.053)	Loss 0.2035 (0.3397)	Prec@1 89.844 (88.378)
Epoch: [26][140/391]	Time 0.048 (0.052)	Loss 0.3724 (0.3385)	Prec@1 87.500 (88.459)
Epoch: [26][160/391]	Time 0.049 (0.052)	Loss 0.2724 (0.3402)	Prec@1 90.625 (88.437)
Epoch: [26][180/391]	Time 0.049 (0.052)	Loss 0.3702 (0.3439)	Prec@1 87.500 (88.359)
Epoch: [26][200/391]	Time 0.046 (0.052)	Loss 0.3522 (0.3442)	Prec@1 87.500 (88.324)
Epoch: [26][220/391]	Time 0.047 (0.051)	Loss 0.3183 (0.3456)	Prec@1 89.844 (88.257)
Epoch: [26][240/391]	Time 0.047 (0.051)	Loss 0.3261 (0.3507)	Prec@1 86.719 (88.064)
Epoch: [26][260/391]	Time 0.045 (0.050)	Loss 0.3930 (0.3516)	Prec@1 85.938 (88.042)
Epoch: [26][280/391]	Time 0.046 (0.050)	Loss 0.3641 (0.3499)	Prec@1 86.719 (88.059)
Epoch: [26][300/391]	Time 0.044 (0.050)	Loss 0.2656 (0.3492)	Prec@1 90.625 (88.061)
Epoch: [26][320/391]	Time 0.046 (0.049)	Loss 0.2966 (0.3501)	Prec@1 89.844 (88.021)
Epoch: [26][340/391]	Time 0.043 (0.049)	Loss 0.3393 (0.3498)	Prec@1 86.719 (88.002)
Epoch: [26][360/391]	Time 0.045 (0.049)	Loss 0.3263 (0.3516)	Prec@1 89.844 (87.952)
Epoch: [26][380/391]	Time 0.041 (0.049)	Loss 0.3597 (0.3514)	Prec@1 86.719 (87.984)
training time:  19.12567400932312
Test: [0/79]	Time 0.735 (0.735)	Loss 0.3696 (0.3696)	Prec@1 85.156 (85.156)
Test: [20/79]	Time 0.031 (0.064)	Loss 0.4480 (0.5472)	Prec@1 84.375 (81.622)
Test: [40/79]	Time 0.031 (0.049)	Loss 0.6116 (0.5368)	Prec@1 75.781 (81.688)
Test: [60/79]	Time 0.031 (0.043)	Loss 0.5148 (0.5290)	Prec@1 81.250 (81.967)
 * Prec@1 82.190
Epoch: [27][0/391]	Time 0.777 (0.777)	Loss 0.2462 (0.2462)	Prec@1 92.188 (92.188)
Epoch: [27][20/391]	Time 0.043 (0.080)	Loss 0.5735 (0.3449)	Prec@1 82.812 (88.393)
Epoch: [27][40/391]	Time 0.047 (0.063)	Loss 0.3145 (0.3328)	Prec@1 87.500 (88.415)
Epoch: [27][60/391]	Time 0.042 (0.057)	Loss 0.2791 (0.3414)	Prec@1 93.750 (88.166)
Epoch: [27][80/391]	Time 0.043 (0.054)	Loss 0.3624 (0.3365)	Prec@1 88.281 (88.358)
Epoch: [27][100/391]	Time 0.047 (0.052)	Loss 0.4256 (0.3412)	Prec@1 83.594 (88.188)
Epoch: [27][120/391]	Time 0.043 (0.051)	Loss 0.2718 (0.3387)	Prec@1 91.406 (88.236)
Epoch: [27][140/391]	Time 0.042 (0.050)	Loss 0.3344 (0.3401)	Prec@1 88.281 (88.270)
Epoch: [27][160/391]	Time 0.042 (0.049)	Loss 0.2925 (0.3382)	Prec@1 88.281 (88.344)
Epoch: [27][180/391]	Time 0.046 (0.049)	Loss 0.3358 (0.3387)	Prec@1 87.500 (88.415)
Epoch: [27][200/391]	Time 0.048 (0.049)	Loss 0.4039 (0.3397)	Prec@1 87.500 (88.402)
Epoch: [27][220/391]	Time 0.048 (0.048)	Loss 0.2724 (0.3423)	Prec@1 92.969 (88.320)
Epoch: [27][240/391]	Time 0.047 (0.048)	Loss 0.3609 (0.3448)	Prec@1 87.500 (88.272)
Epoch: [27][260/391]	Time 0.047 (0.048)	Loss 0.4308 (0.3452)	Prec@1 84.375 (88.284)
Epoch: [27][280/391]	Time 0.047 (0.048)	Loss 0.5529 (0.3452)	Prec@1 81.250 (88.267)
Epoch: [27][300/391]	Time 0.046 (0.048)	Loss 0.5107 (0.3473)	Prec@1 82.812 (88.209)
Epoch: [27][320/391]	Time 0.046 (0.048)	Loss 0.4119 (0.3465)	Prec@1 86.719 (88.216)
Epoch: [27][340/391]	Time 0.045 (0.048)	Loss 0.4536 (0.3459)	Prec@1 87.500 (88.233)
Epoch: [27][360/391]	Time 0.042 (0.048)	Loss 0.3569 (0.3480)	Prec@1 89.062 (88.171)
Epoch: [27][380/391]	Time 0.047 (0.048)	Loss 0.2400 (0.3478)	Prec@1 92.188 (88.181)
training time:  18.727023124694824
Test: [0/79]	Time 0.784 (0.784)	Loss 0.4447 (0.4447)	Prec@1 82.812 (82.812)
Test: [20/79]	Time 0.032 (0.068)	Loss 0.5071 (0.4390)	Prec@1 83.594 (85.305)
Test: [40/79]	Time 0.031 (0.050)	Loss 0.6141 (0.4439)	Prec@1 79.688 (85.194)
Test: [60/79]	Time 0.031 (0.045)	Loss 0.3673 (0.4380)	Prec@1 85.938 (85.630)
 * Prec@1 85.540
=> Saving checkpoint for epoch 27, with Prec@1 85.540000.
Epoch: [28][0/391]	Time 0.824 (0.824)	Loss 0.2541 (0.2541)	Prec@1 92.188 (92.188)
Epoch: [28][20/391]	Time 0.047 (0.083)	Loss 0.2629 (0.3110)	Prec@1 88.281 (89.062)
Epoch: [28][40/391]	Time 0.047 (0.065)	Loss 0.3582 (0.3227)	Prec@1 88.281 (88.929)
Epoch: [28][60/391]	Time 0.046 (0.059)	Loss 0.2976 (0.3252)	Prec@1 89.844 (88.768)
Epoch: [28][80/391]	Time 0.043 (0.056)	Loss 0.2574 (0.3319)	Prec@1 89.844 (88.445)
Epoch: [28][100/391]	Time 0.047 (0.054)	Loss 0.3137 (0.3318)	Prec@1 92.188 (88.598)
Epoch: [28][120/391]	Time 0.043 (0.053)	Loss 0.3827 (0.3368)	Prec@1 85.938 (88.320)
Epoch: [28][140/391]	Time 0.047 (0.052)	Loss 0.1916 (0.3374)	Prec@1 92.969 (88.303)
Epoch: [28][160/391]	Time 0.044 (0.051)	Loss 0.3521 (0.3356)	Prec@1 86.719 (88.393)
Epoch: [28][180/391]	Time 0.046 (0.051)	Loss 0.4342 (0.3346)	Prec@1 82.031 (88.441)
Epoch: [28][200/391]	Time 0.048 (0.051)	Loss 0.2959 (0.3353)	Prec@1 89.062 (88.507)
Epoch: [28][220/391]	Time 0.049 (0.051)	Loss 0.3098 (0.3384)	Prec@1 89.844 (88.363)
Epoch: [28][240/391]	Time 0.046 (0.050)	Loss 0.3632 (0.3389)	Prec@1 88.281 (88.320)
Epoch: [28][260/391]	Time 0.046 (0.050)	Loss 0.4078 (0.3407)	Prec@1 85.156 (88.350)
Epoch: [28][280/391]	Time 0.050 (0.050)	Loss 0.3774 (0.3416)	Prec@1 85.156 (88.295)
Epoch: [28][300/391]	Time 0.046 (0.049)	Loss 0.2528 (0.3393)	Prec@1 93.750 (88.372)
Epoch: [28][320/391]	Time 0.046 (0.049)	Loss 0.4651 (0.3389)	Prec@1 82.031 (88.359)
Epoch: [28][340/391]	Time 0.047 (0.049)	Loss 0.2553 (0.3387)	Prec@1 92.188 (88.357)
Epoch: [28][360/391]	Time 0.046 (0.049)	Loss 0.3852 (0.3380)	Prec@1 87.500 (88.383)
Epoch: [28][380/391]	Time 0.047 (0.049)	Loss 0.3320 (0.3405)	Prec@1 89.844 (88.306)
training time:  19.207780361175537
Test: [0/79]	Time 0.732 (0.732)	Loss 0.4126 (0.4126)	Prec@1 87.500 (87.500)
Test: [20/79]	Time 0.032 (0.065)	Loss 0.3936 (0.4898)	Prec@1 85.156 (83.668)
Test: [40/79]	Time 0.030 (0.049)	Loss 0.5764 (0.4878)	Prec@1 76.562 (83.537)
Test: [60/79]	Time 0.032 (0.044)	Loss 0.4827 (0.4831)	Prec@1 85.156 (83.760)
 * Prec@1 83.740
Epoch: [29][0/391]	Time 0.846 (0.846)	Loss 0.2049 (0.2049)	Prec@1 93.750 (93.750)
Epoch: [29][20/391]	Time 0.046 (0.085)	Loss 0.3706 (0.3020)	Prec@1 85.156 (89.286)
Epoch: [29][40/391]	Time 0.045 (0.066)	Loss 0.4391 (0.3121)	Prec@1 86.719 (89.291)
Epoch: [29][60/391]	Time 0.046 (0.060)	Loss 0.4038 (0.3144)	Prec@1 85.938 (89.101)
Epoch: [29][80/391]	Time 0.046 (0.056)	Loss 0.3813 (0.3126)	Prec@1 85.156 (89.120)
Epoch: [29][100/391]	Time 0.046 (0.054)	Loss 0.2392 (0.3174)	Prec@1 92.188 (88.931)
Epoch: [29][120/391]	Time 0.045 (0.053)	Loss 0.4024 (0.3212)	Prec@1 86.719 (88.837)
Epoch: [29][140/391]	Time 0.046 (0.052)	Loss 0.2939 (0.3201)	Prec@1 89.844 (88.813)
Epoch: [29][160/391]	Time 0.047 (0.051)	Loss 0.3858 (0.3245)	Prec@1 89.062 (88.752)
Epoch: [29][180/391]	Time 0.046 (0.051)	Loss 0.3500 (0.3261)	Prec@1 89.062 (88.722)
Epoch: [29][200/391]	Time 0.046 (0.050)	Loss 0.2520 (0.3315)	Prec@1 90.625 (88.557)
Epoch: [29][220/391]	Time 0.048 (0.050)	Loss 0.3162 (0.3320)	Prec@1 88.281 (88.529)
Epoch: [29][240/391]	Time 0.047 (0.049)	Loss 0.2437 (0.3342)	Prec@1 91.406 (88.531)
Epoch: [29][260/391]	Time 0.047 (0.049)	Loss 0.2021 (0.3337)	Prec@1 94.531 (88.569)
Epoch: [29][280/391]	Time 0.048 (0.049)	Loss 0.3418 (0.3354)	Prec@1 86.719 (88.551)
Epoch: [29][300/391]	Time 0.048 (0.049)	Loss 0.4350 (0.3385)	Prec@1 86.719 (88.486)
Epoch: [29][320/391]	Time 0.046 (0.049)	Loss 0.3121 (0.3391)	Prec@1 91.406 (88.493)
Epoch: [29][340/391]	Time 0.048 (0.049)	Loss 0.2818 (0.3377)	Prec@1 87.500 (88.487)
Epoch: [29][360/391]	Time 0.045 (0.049)	Loss 0.3409 (0.3377)	Prec@1 91.406 (88.526)
Epoch: [29][380/391]	Time 0.045 (0.048)	Loss 0.4299 (0.3373)	Prec@1 86.719 (88.513)
training time:  19.031130075454712
Test: [0/79]	Time 0.775 (0.775)	Loss 0.3780 (0.3780)	Prec@1 89.062 (89.062)
Test: [20/79]	Time 0.029 (0.067)	Loss 0.4256 (0.4252)	Prec@1 84.375 (85.119)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.4463 (0.4119)	Prec@1 85.156 (85.671)
Test: [60/79]	Time 0.032 (0.044)	Loss 0.3123 (0.4030)	Prec@1 88.281 (85.822)
 * Prec@1 85.800
=> Saving checkpoint for epoch 29, with Prec@1 85.800000.
Epoch: [30][0/391]	Time 0.787 (0.787)	Loss 0.3231 (0.3231)	Prec@1 89.062 (89.062)
Epoch: [30][20/391]	Time 0.048 (0.082)	Loss 0.3130 (0.2912)	Prec@1 89.844 (89.732)
Epoch: [30][40/391]	Time 0.047 (0.065)	Loss 0.2414 (0.2892)	Prec@1 92.188 (89.977)
Epoch: [30][60/391]	Time 0.045 (0.059)	Loss 0.2513 (0.3035)	Prec@1 90.625 (89.703)
Epoch: [30][80/391]	Time 0.046 (0.056)	Loss 0.4049 (0.3166)	Prec@1 85.938 (89.284)
Epoch: [30][100/391]	Time 0.046 (0.054)	Loss 0.4980 (0.3195)	Prec@1 81.250 (89.086)
Epoch: [30][120/391]	Time 0.046 (0.053)	Loss 0.3657 (0.3235)	Prec@1 90.625 (88.966)
Epoch: [30][140/391]	Time 0.047 (0.052)	Loss 0.2612 (0.3206)	Prec@1 89.844 (89.090)
Epoch: [30][160/391]	Time 0.046 (0.051)	Loss 0.3851 (0.3179)	Prec@1 87.500 (89.227)
Epoch: [30][180/391]	Time 0.049 (0.051)	Loss 0.3706 (0.3165)	Prec@1 87.500 (89.321)
Epoch: [30][200/391]	Time 0.048 (0.051)	Loss 0.2700 (0.3177)	Prec@1 92.969 (89.311)
Epoch: [30][220/391]	Time 0.047 (0.050)	Loss 0.2289 (0.3174)	Prec@1 93.750 (89.381)
Epoch: [30][240/391]	Time 0.047 (0.050)	Loss 0.2037 (0.3170)	Prec@1 92.969 (89.348)
Epoch: [30][260/391]	Time 0.046 (0.050)	Loss 0.2297 (0.3166)	Prec@1 93.750 (89.317)
Epoch: [30][280/391]	Time 0.047 (0.050)	Loss 0.1880 (0.3157)	Prec@1 92.188 (89.321)
Epoch: [30][300/391]	Time 0.047 (0.049)	Loss 0.2955 (0.3171)	Prec@1 89.844 (89.231)
Epoch: [30][320/391]	Time 0.046 (0.049)	Loss 0.2414 (0.3192)	Prec@1 91.406 (89.153)
Epoch: [30][340/391]	Time 0.046 (0.049)	Loss 0.3391 (0.3219)	Prec@1 90.625 (89.060)
Epoch: [30][360/391]	Time 0.047 (0.049)	Loss 0.3448 (0.3228)	Prec@1 87.500 (89.034)
Epoch: [30][380/391]	Time 0.043 (0.049)	Loss 0.3851 (0.3232)	Prec@1 85.938 (89.030)
training time:  19.165321350097656
Test: [0/79]	Time 0.738 (0.738)	Loss 0.5001 (0.5001)	Prec@1 83.594 (83.594)
Test: [20/79]	Time 0.033 (0.065)	Loss 0.6518 (0.5868)	Prec@1 79.688 (79.911)
Test: [40/79]	Time 0.033 (0.049)	Loss 0.7372 (0.5653)	Prec@1 75.781 (80.526)
Test: [60/79]	Time 0.031 (0.043)	Loss 0.4674 (0.5520)	Prec@1 82.031 (81.045)
 * Prec@1 81.020
Epoch: [31][0/391]	Time 0.784 (0.784)	Loss 0.2233 (0.2233)	Prec@1 89.844 (89.844)
Epoch: [31][20/391]	Time 0.046 (0.081)	Loss 0.4121 (0.3099)	Prec@1 83.594 (88.988)
Epoch: [31][40/391]	Time 0.045 (0.064)	Loss 0.3010 (0.3199)	Prec@1 90.625 (88.929)
Epoch: [31][60/391]	Time 0.044 (0.058)	Loss 0.2864 (0.3175)	Prec@1 89.062 (88.998)
Epoch: [31][80/391]	Time 0.043 (0.054)	Loss 0.3064 (0.3138)	Prec@1 92.188 (89.120)
Epoch: [31][100/391]	Time 0.042 (0.052)	Loss 0.2532 (0.3126)	Prec@1 89.844 (89.124)
Epoch: [31][120/391]	Time 0.042 (0.051)	Loss 0.4071 (0.3109)	Prec@1 83.594 (89.179)
Epoch: [31][140/391]	Time 0.041 (0.050)	Loss 0.3724 (0.3166)	Prec@1 87.500 (89.024)
Epoch: [31][160/391]	Time 0.041 (0.049)	Loss 0.3508 (0.3190)	Prec@1 88.281 (88.985)
Epoch: [31][180/391]	Time 0.044 (0.049)	Loss 0.2241 (0.3195)	Prec@1 91.406 (88.950)
Epoch: [31][200/391]	Time 0.046 (0.048)	Loss 0.4741 (0.3218)	Prec@1 86.719 (88.911)
Epoch: [31][220/391]	Time 0.046 (0.048)	Loss 0.3132 (0.3258)	Prec@1 87.500 (88.748)
Epoch: [31][240/391]	Time 0.046 (0.048)	Loss 0.2509 (0.3280)	Prec@1 91.406 (88.696)
Epoch: [31][260/391]	Time 0.045 (0.048)	Loss 0.2294 (0.3281)	Prec@1 92.188 (88.742)
Epoch: [31][280/391]	Time 0.047 (0.048)	Loss 0.3690 (0.3278)	Prec@1 86.719 (88.723)
Epoch: [31][300/391]	Time 0.045 (0.048)	Loss 0.3252 (0.3256)	Prec@1 87.500 (88.850)
Epoch: [31][320/391]	Time 0.045 (0.048)	Loss 0.3420 (0.3257)	Prec@1 86.719 (88.853)
Epoch: [31][340/391]	Time 0.045 (0.047)	Loss 0.3728 (0.3258)	Prec@1 89.844 (88.877)
Epoch: [31][360/391]	Time 0.044 (0.047)	Loss 0.3263 (0.3248)	Prec@1 89.062 (88.889)
Epoch: [31][380/391]	Time 0.045 (0.047)	Loss 0.4949 (0.3263)	Prec@1 82.031 (88.855)
training time:  18.611857891082764
Test: [0/79]	Time 0.743 (0.743)	Loss 0.4005 (0.4005)	Prec@1 87.500 (87.500)
Test: [20/79]	Time 0.032 (0.065)	Loss 0.3609 (0.4694)	Prec@1 92.188 (85.975)
Test: [40/79]	Time 0.032 (0.049)	Loss 0.5251 (0.4625)	Prec@1 79.688 (85.309)
Test: [60/79]	Time 0.032 (0.044)	Loss 0.3645 (0.4534)	Prec@1 85.156 (85.566)
 * Prec@1 85.480
Epoch: [32][0/391]	Time 0.779 (0.779)	Loss 0.3110 (0.3110)	Prec@1 88.281 (88.281)
Epoch: [32][20/391]	Time 0.045 (0.081)	Loss 0.3240 (0.2989)	Prec@1 89.062 (90.141)
Epoch: [32][40/391]	Time 0.046 (0.064)	Loss 0.2061 (0.3017)	Prec@1 92.969 (89.768)
Epoch: [32][60/391]	Time 0.046 (0.058)	Loss 0.3154 (0.2970)	Prec@1 86.719 (89.844)
Epoch: [32][80/391]	Time 0.046 (0.055)	Loss 0.3221 (0.2981)	Prec@1 90.625 (89.931)
Epoch: [32][100/391]	Time 0.046 (0.053)	Loss 0.2856 (0.3026)	Prec@1 89.844 (89.805)
Epoch: [32][120/391]	Time 0.046 (0.052)	Loss 0.3432 (0.3042)	Prec@1 85.938 (89.734)
Epoch: [32][140/391]	Time 0.045 (0.051)	Loss 0.3657 (0.3091)	Prec@1 89.062 (89.539)
Epoch: [32][160/391]	Time 0.046 (0.051)	Loss 0.3369 (0.3114)	Prec@1 89.844 (89.538)
Epoch: [32][180/391]	Time 0.047 (0.051)	Loss 0.3585 (0.3106)	Prec@1 90.625 (89.598)
Epoch: [32][200/391]	Time 0.046 (0.050)	Loss 0.3045 (0.3116)	Prec@1 90.625 (89.541)
Epoch: [32][220/391]	Time 0.047 (0.050)	Loss 0.4082 (0.3115)	Prec@1 85.156 (89.561)
Epoch: [32][240/391]	Time 0.046 (0.050)	Loss 0.2329 (0.3097)	Prec@1 92.969 (89.620)
Epoch: [32][260/391]	Time 0.046 (0.050)	Loss 0.3095 (0.3112)	Prec@1 89.062 (89.517)
Epoch: [32][280/391]	Time 0.046 (0.049)	Loss 0.2294 (0.3114)	Prec@1 89.844 (89.496)
Epoch: [32][300/391]	Time 0.047 (0.049)	Loss 0.2021 (0.3109)	Prec@1 92.969 (89.499)
Epoch: [32][320/391]	Time 0.046 (0.049)	Loss 0.3473 (0.3115)	Prec@1 90.625 (89.457)
Epoch: [32][340/391]	Time 0.046 (0.049)	Loss 0.2931 (0.3121)	Prec@1 90.625 (89.406)
Epoch: [32][360/391]	Time 0.046 (0.049)	Loss 0.3027 (0.3141)	Prec@1 90.625 (89.342)
Epoch: [32][380/391]	Time 0.045 (0.049)	Loss 0.3447 (0.3147)	Prec@1 88.281 (89.317)
training time:  19.131421327590942
Test: [0/79]	Time 0.751 (0.751)	Loss 0.3290 (0.3290)	Prec@1 88.281 (88.281)
Test: [20/79]	Time 0.030 (0.064)	Loss 0.3699 (0.4377)	Prec@1 86.719 (85.268)
Test: [40/79]	Time 0.031 (0.048)	Loss 0.4807 (0.4339)	Prec@1 87.500 (85.709)
Test: [60/79]	Time 0.030 (0.042)	Loss 0.3845 (0.4300)	Prec@1 88.281 (85.720)
 * Prec@1 85.890
=> Saving checkpoint for epoch 32, with Prec@1 85.890000.
Epoch: [33][0/391]	Time 0.776 (0.776)	Loss 0.2611 (0.2611)	Prec@1 90.625 (90.625)
Epoch: [33][20/391]	Time 0.047 (0.081)	Loss 0.3118 (0.3168)	Prec@1 89.062 (89.062)
Epoch: [33][40/391]	Time 0.046 (0.064)	Loss 0.1319 (0.2958)	Prec@1 96.875 (89.729)
Epoch: [33][60/391]	Time 0.048 (0.058)	Loss 0.3632 (0.2977)	Prec@1 88.281 (89.793)
Epoch: [33][80/391]	Time 0.047 (0.055)	Loss 0.1964 (0.3032)	Prec@1 93.750 (89.583)
Epoch: [33][100/391]	Time 0.045 (0.054)	Loss 0.4901 (0.3060)	Prec@1 82.031 (89.496)
Epoch: [33][120/391]	Time 0.046 (0.053)	Loss 0.2652 (0.3046)	Prec@1 92.188 (89.624)
Epoch: [33][140/391]	Time 0.044 (0.052)	Loss 0.4033 (0.3076)	Prec@1 86.719 (89.522)
Epoch: [33][160/391]	Time 0.043 (0.051)	Loss 0.2150 (0.3052)	Prec@1 91.406 (89.523)
Epoch: [33][180/391]	Time 0.042 (0.050)	Loss 0.2683 (0.3026)	Prec@1 90.625 (89.628)
Epoch: [33][200/391]	Time 0.046 (0.050)	Loss 0.6063 (0.3027)	Prec@1 78.125 (89.634)
Epoch: [33][220/391]	Time 0.043 (0.049)	Loss 0.2625 (0.3056)	Prec@1 90.625 (89.572)
Epoch: [33][240/391]	Time 0.042 (0.049)	Loss 0.2390 (0.3066)	Prec@1 91.406 (89.523)
Epoch: [33][260/391]	Time 0.047 (0.049)	Loss 0.5370 (0.3087)	Prec@1 85.156 (89.455)
Epoch: [33][280/391]	Time 0.048 (0.049)	Loss 0.2060 (0.3095)	Prec@1 90.625 (89.393)
Epoch: [33][300/391]	Time 0.046 (0.049)	Loss 0.3246 (0.3090)	Prec@1 89.062 (89.405)
Epoch: [33][320/391]	Time 0.048 (0.048)	Loss 0.4065 (0.3094)	Prec@1 86.719 (89.384)
Epoch: [33][340/391]	Time 0.049 (0.048)	Loss 0.3372 (0.3092)	Prec@1 90.625 (89.370)
Epoch: [33][360/391]	Time 0.047 (0.048)	Loss 0.3336 (0.3089)	Prec@1 89.062 (89.376)
Epoch: [33][380/391]	Time 0.046 (0.048)	Loss 0.2352 (0.3096)	Prec@1 91.406 (89.370)
training time:  18.94495391845703
Test: [0/79]	Time 0.788 (0.788)	Loss 0.3416 (0.3416)	Prec@1 87.500 (87.500)
Test: [20/79]	Time 0.029 (0.066)	Loss 0.5338 (0.5076)	Prec@1 84.375 (84.338)
Test: [40/79]	Time 0.032 (0.049)	Loss 0.4604 (0.4905)	Prec@1 82.031 (84.261)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.3881 (0.4851)	Prec@1 85.938 (84.413)
 * Prec@1 84.620
Epoch: [34][0/391]	Time 0.832 (0.832)	Loss 0.2606 (0.2606)	Prec@1 91.406 (91.406)
Epoch: [34][20/391]	Time 0.046 (0.082)	Loss 0.2885 (0.2928)	Prec@1 91.406 (89.732)
Epoch: [34][40/391]	Time 0.046 (0.065)	Loss 0.3231 (0.2959)	Prec@1 89.844 (89.653)
Epoch: [34][60/391]	Time 0.045 (0.059)	Loss 0.3659 (0.2950)	Prec@1 85.938 (89.728)
Epoch: [34][80/391]	Time 0.046 (0.056)	Loss 0.3344 (0.3058)	Prec@1 87.500 (89.371)
Epoch: [34][100/391]	Time 0.045 (0.054)	Loss 0.3233 (0.3098)	Prec@1 89.062 (89.333)
Epoch: [34][120/391]	Time 0.045 (0.052)	Loss 0.2282 (0.3051)	Prec@1 90.625 (89.514)
Epoch: [34][140/391]	Time 0.045 (0.052)	Loss 0.2083 (0.3069)	Prec@1 92.188 (89.550)
Epoch: [34][160/391]	Time 0.045 (0.051)	Loss 0.3116 (0.3046)	Prec@1 90.625 (89.630)
Epoch: [34][180/391]	Time 0.046 (0.050)	Loss 0.2610 (0.3049)	Prec@1 92.969 (89.619)
Epoch: [34][200/391]	Time 0.047 (0.051)	Loss 0.2795 (0.3064)	Prec@1 89.844 (89.533)
Epoch: [34][220/391]	Time 0.051 (0.050)	Loss 0.2887 (0.3043)	Prec@1 92.188 (89.614)
Epoch: [34][240/391]	Time 0.047 (0.050)	Loss 0.2778 (0.3044)	Prec@1 90.625 (89.640)
Epoch: [34][260/391]	Time 0.046 (0.050)	Loss 0.2588 (0.3046)	Prec@1 92.969 (89.655)
Epoch: [34][280/391]	Time 0.046 (0.049)	Loss 0.3545 (0.3050)	Prec@1 89.062 (89.632)
Epoch: [34][300/391]	Time 0.047 (0.049)	Loss 0.2957 (0.3064)	Prec@1 89.062 (89.595)
Epoch: [34][320/391]	Time 0.047 (0.049)	Loss 0.3603 (0.3083)	Prec@1 88.281 (89.535)
Epoch: [34][340/391]	Time 0.046 (0.049)	Loss 0.2098 (0.3071)	Prec@1 90.625 (89.550)
Epoch: [34][360/391]	Time 0.045 (0.049)	Loss 0.2373 (0.3070)	Prec@1 90.625 (89.539)
Epoch: [34][380/391]	Time 0.046 (0.049)	Loss 0.5151 (0.3078)	Prec@1 85.156 (89.530)
training time:  19.13329792022705
Test: [0/79]	Time 0.788 (0.788)	Loss 0.4132 (0.4132)	Prec@1 85.938 (85.938)
Test: [20/79]	Time 0.033 (0.067)	Loss 0.5163 (0.4320)	Prec@1 82.031 (85.305)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.4178 (0.4212)	Prec@1 83.594 (85.614)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.3194 (0.4181)	Prec@1 89.844 (85.835)
 * Prec@1 85.730
Epoch: [35][0/391]	Time 0.830 (0.830)	Loss 0.2894 (0.2894)	Prec@1 90.625 (90.625)
Epoch: [35][20/391]	Time 0.042 (0.082)	Loss 0.3838 (0.2885)	Prec@1 89.844 (90.699)
Epoch: [35][40/391]	Time 0.045 (0.064)	Loss 0.3619 (0.2880)	Prec@1 90.625 (90.568)
Epoch: [35][60/391]	Time 0.046 (0.058)	Loss 0.2722 (0.2833)	Prec@1 89.062 (90.612)
Epoch: [35][80/391]	Time 0.047 (0.055)	Loss 0.2899 (0.2798)	Prec@1 89.844 (90.673)
Epoch: [35][100/391]	Time 0.048 (0.054)	Loss 0.3002 (0.2817)	Prec@1 88.281 (90.602)
Epoch: [35][120/391]	Time 0.047 (0.052)	Loss 0.3356 (0.2811)	Prec@1 89.062 (90.664)
Epoch: [35][140/391]	Time 0.042 (0.051)	Loss 0.4037 (0.2820)	Prec@1 86.719 (90.631)
Epoch: [35][160/391]	Time 0.046 (0.051)	Loss 0.2521 (0.2856)	Prec@1 91.406 (90.499)
Epoch: [35][180/391]	Time 0.046 (0.050)	Loss 0.4209 (0.2915)	Prec@1 85.156 (90.284)
Epoch: [35][200/391]	Time 0.046 (0.050)	Loss 0.2630 (0.2947)	Prec@1 89.844 (90.186)
Epoch: [35][220/391]	Time 0.046 (0.049)	Loss 0.4080 (0.2966)	Prec@1 87.500 (90.123)
Epoch: [35][240/391]	Time 0.047 (0.049)	Loss 0.2532 (0.2960)	Prec@1 91.406 (90.126)
Epoch: [35][260/391]	Time 0.047 (0.049)	Loss 0.4514 (0.2965)	Prec@1 85.156 (90.083)
Epoch: [35][280/391]	Time 0.044 (0.049)	Loss 0.3189 (0.2963)	Prec@1 90.625 (90.100)
Epoch: [35][300/391]	Time 0.050 (0.048)	Loss 0.4109 (0.2978)	Prec@1 87.500 (90.057)
Epoch: [35][320/391]	Time 0.047 (0.048)	Loss 0.4511 (0.2983)	Prec@1 86.719 (90.038)
Epoch: [35][340/391]	Time 0.047 (0.048)	Loss 0.3586 (0.2982)	Prec@1 89.844 (90.055)
Epoch: [35][360/391]	Time 0.047 (0.048)	Loss 0.2497 (0.2990)	Prec@1 90.625 (90.000)
Epoch: [35][380/391]	Time 0.046 (0.048)	Loss 0.2958 (0.2989)	Prec@1 88.281 (90.006)
training time:  18.8931245803833
Test: [0/79]	Time 0.784 (0.784)	Loss 0.4323 (0.4323)	Prec@1 86.719 (86.719)
Test: [20/79]	Time 0.032 (0.068)	Loss 0.2915 (0.4416)	Prec@1 89.062 (85.379)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.4362 (0.4238)	Prec@1 85.938 (86.223)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.3077 (0.4105)	Prec@1 91.406 (86.539)
 * Prec@1 86.370
=> Saving checkpoint for epoch 35, with Prec@1 86.370000.
Epoch: [36][0/391]	Time 0.817 (0.817)	Loss 0.2633 (0.2633)	Prec@1 90.625 (90.625)
Epoch: [36][20/391]	Time 0.044 (0.082)	Loss 0.2795 (0.2803)	Prec@1 89.062 (90.439)
Epoch: [36][40/391]	Time 0.043 (0.064)	Loss 0.5025 (0.2868)	Prec@1 84.375 (89.863)
Epoch: [36][60/391]	Time 0.044 (0.058)	Loss 0.3401 (0.2779)	Prec@1 89.844 (90.305)
Epoch: [36][80/391]	Time 0.047 (0.055)	Loss 0.3548 (0.2871)	Prec@1 86.719 (90.037)
Epoch: [36][100/391]	Time 0.051 (0.053)	Loss 0.2878 (0.2874)	Prec@1 90.625 (89.998)
Epoch: [36][120/391]	Time 0.045 (0.052)	Loss 0.2042 (0.2848)	Prec@1 95.312 (90.031)
Epoch: [36][140/391]	Time 0.045 (0.051)	Loss 0.1970 (0.2835)	Prec@1 91.406 (90.110)
Epoch: [36][160/391]	Time 0.046 (0.051)	Loss 0.3404 (0.2838)	Prec@1 91.406 (90.261)
Epoch: [36][180/391]	Time 0.047 (0.050)	Loss 0.2928 (0.2888)	Prec@1 88.281 (90.047)
Epoch: [36][200/391]	Time 0.047 (0.051)	Loss 0.2164 (0.2924)	Prec@1 91.406 (89.910)
Epoch: [36][220/391]	Time 0.048 (0.050)	Loss 0.2996 (0.2942)	Prec@1 91.406 (89.798)
Epoch: [36][240/391]	Time 0.046 (0.050)	Loss 0.3055 (0.2968)	Prec@1 87.500 (89.724)
Epoch: [36][260/391]	Time 0.047 (0.050)	Loss 0.3284 (0.2959)	Prec@1 89.844 (89.724)
Epoch: [36][280/391]	Time 0.046 (0.049)	Loss 0.2207 (0.2963)	Prec@1 91.406 (89.688)
Epoch: [36][300/391]	Time 0.046 (0.049)	Loss 0.3399 (0.2958)	Prec@1 87.500 (89.709)
Epoch: [36][320/391]	Time 0.045 (0.049)	Loss 0.2140 (0.2951)	Prec@1 90.625 (89.717)
Epoch: [36][340/391]	Time 0.046 (0.049)	Loss 0.2283 (0.2959)	Prec@1 92.188 (89.727)
Epoch: [36][360/391]	Time 0.045 (0.048)	Loss 0.3782 (0.2964)	Prec@1 84.375 (89.703)
Epoch: [36][380/391]	Time 0.046 (0.048)	Loss 0.3104 (0.2978)	Prec@1 89.844 (89.663)
training time:  19.01075267791748
Test: [0/79]	Time 0.777 (0.777)	Loss 0.3777 (0.3777)	Prec@1 86.719 (86.719)
Test: [20/79]	Time 0.033 (0.066)	Loss 0.3401 (0.4023)	Prec@1 88.281 (86.086)
Test: [40/79]	Time 0.031 (0.049)	Loss 0.4531 (0.4013)	Prec@1 87.500 (86.433)
Test: [60/79]	Time 0.032 (0.043)	Loss 0.3778 (0.3960)	Prec@1 87.500 (86.757)
 * Prec@1 86.750
=> Saving checkpoint for epoch 36, with Prec@1 86.750000.
Epoch: [37][0/391]	Time 0.775 (0.775)	Loss 0.2644 (0.2644)	Prec@1 89.844 (89.844)
Epoch: [37][20/391]	Time 0.048 (0.083)	Loss 0.2115 (0.2735)	Prec@1 92.969 (90.960)
Epoch: [37][40/391]	Time 0.049 (0.066)	Loss 0.3653 (0.2778)	Prec@1 85.156 (90.511)
Epoch: [37][60/391]	Time 0.044 (0.060)	Loss 0.2213 (0.2825)	Prec@1 92.188 (90.523)
Epoch: [37][80/391]	Time 0.046 (0.056)	Loss 0.2362 (0.2870)	Prec@1 89.062 (90.230)
Epoch: [37][100/391]	Time 0.042 (0.054)	Loss 0.2526 (0.2817)	Prec@1 92.969 (90.277)
Epoch: [37][120/391]	Time 0.046 (0.053)	Loss 0.2391 (0.2823)	Prec@1 92.969 (90.289)
Epoch: [37][140/391]	Time 0.046 (0.052)	Loss 0.4065 (0.2853)	Prec@1 84.375 (90.137)
Epoch: [37][160/391]	Time 0.047 (0.051)	Loss 0.3076 (0.2873)	Prec@1 92.969 (90.130)
Epoch: [37][180/391]	Time 0.047 (0.050)	Loss 0.1900 (0.2871)	Prec@1 92.969 (90.142)
Epoch: [37][200/391]	Time 0.048 (0.050)	Loss 0.2073 (0.2850)	Prec@1 94.531 (90.201)
Epoch: [37][220/391]	Time 0.046 (0.050)	Loss 0.1854 (0.2861)	Prec@1 93.750 (90.151)
Epoch: [37][240/391]	Time 0.048 (0.049)	Loss 0.3312 (0.2872)	Prec@1 88.281 (90.136)
Epoch: [37][260/391]	Time 0.046 (0.049)	Loss 0.2294 (0.2888)	Prec@1 93.750 (90.062)
Epoch: [37][280/391]	Time 0.048 (0.049)	Loss 0.2810 (0.2882)	Prec@1 89.062 (90.044)
Epoch: [37][300/391]	Time 0.046 (0.049)	Loss 0.3084 (0.2892)	Prec@1 89.844 (89.992)
Epoch: [37][320/391]	Time 0.046 (0.049)	Loss 0.2202 (0.2906)	Prec@1 92.969 (89.953)
Epoch: [37][340/391]	Time 0.046 (0.048)	Loss 0.3818 (0.2911)	Prec@1 87.500 (89.949)
Epoch: [37][360/391]	Time 0.045 (0.048)	Loss 0.3693 (0.2915)	Prec@1 89.062 (89.969)
Epoch: [37][380/391]	Time 0.047 (0.048)	Loss 0.2966 (0.2915)	Prec@1 89.844 (90.006)
training time:  18.9999577999115
Test: [0/79]	Time 0.794 (0.794)	Loss 0.3913 (0.3913)	Prec@1 87.500 (87.500)
Test: [20/79]	Time 0.032 (0.068)	Loss 0.4563 (0.4831)	Prec@1 84.375 (84.338)
Test: [40/79]	Time 0.031 (0.050)	Loss 0.4742 (0.4845)	Prec@1 82.031 (84.356)
Test: [60/79]	Time 0.030 (0.044)	Loss 0.4642 (0.4755)	Prec@1 83.594 (84.477)
 * Prec@1 84.400
Epoch: [38][0/391]	Time 0.824 (0.824)	Loss 0.2418 (0.2418)	Prec@1 92.969 (92.969)
Epoch: [38][20/391]	Time 0.045 (0.083)	Loss 0.2365 (0.2692)	Prec@1 92.969 (90.997)
Epoch: [38][40/391]	Time 0.046 (0.065)	Loss 0.3045 (0.2693)	Prec@1 92.188 (90.682)
Epoch: [38][60/391]	Time 0.047 (0.059)	Loss 0.2474 (0.2756)	Prec@1 92.188 (90.625)
Epoch: [38][80/391]	Time 0.046 (0.055)	Loss 0.2570 (0.2755)	Prec@1 92.188 (90.712)
Epoch: [38][100/391]	Time 0.046 (0.054)	Loss 0.2515 (0.2760)	Prec@1 89.062 (90.586)
Epoch: [38][120/391]	Time 0.046 (0.052)	Loss 0.2426 (0.2750)	Prec@1 91.406 (90.541)
Epoch: [38][140/391]	Time 0.046 (0.052)	Loss 0.3842 (0.2749)	Prec@1 88.281 (90.570)
Epoch: [38][160/391]	Time 0.049 (0.051)	Loss 0.3026 (0.2788)	Prec@1 89.844 (90.470)
Epoch: [38][180/391]	Time 0.047 (0.051)	Loss 0.2267 (0.2825)	Prec@1 93.750 (90.323)
Epoch: [38][200/391]	Time 0.049 (0.051)	Loss 0.2692 (0.2820)	Prec@1 90.625 (90.368)
Epoch: [38][220/391]	Time 0.048 (0.051)	Loss 0.2962 (0.2833)	Prec@1 89.844 (90.300)
Epoch: [38][240/391]	Time 0.047 (0.050)	Loss 0.3571 (0.2815)	Prec@1 89.844 (90.366)
Epoch: [38][260/391]	Time 0.047 (0.050)	Loss 0.2422 (0.2828)	Prec@1 89.062 (90.299)
Epoch: [38][280/391]	Time 0.048 (0.050)	Loss 0.3512 (0.2841)	Prec@1 88.281 (90.250)
Epoch: [38][300/391]	Time 0.046 (0.049)	Loss 0.3377 (0.2856)	Prec@1 89.844 (90.197)
Epoch: [38][320/391]	Time 0.047 (0.049)	Loss 0.3247 (0.2870)	Prec@1 88.281 (90.167)
Epoch: [38][340/391]	Time 0.048 (0.049)	Loss 0.2974 (0.2866)	Prec@1 90.625 (90.181)
Epoch: [38][360/391]	Time 0.046 (0.049)	Loss 0.3079 (0.2870)	Prec@1 91.406 (90.164)
Epoch: [38][380/391]	Time 0.045 (0.049)	Loss 0.2477 (0.2876)	Prec@1 92.188 (90.147)
training time:  19.244384765625
Test: [0/79]	Time 0.774 (0.774)	Loss 0.3308 (0.3308)	Prec@1 89.062 (89.062)
Test: [20/79]	Time 0.032 (0.067)	Loss 0.5262 (0.4027)	Prec@1 83.594 (86.644)
Test: [40/79]	Time 0.031 (0.050)	Loss 0.4906 (0.4043)	Prec@1 83.594 (86.509)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.3544 (0.4027)	Prec@1 86.719 (86.642)
 * Prec@1 86.610
Epoch: [39][0/391]	Time 0.790 (0.790)	Loss 0.2724 (0.2724)	Prec@1 89.062 (89.062)
Epoch: [39][20/391]	Time 0.045 (0.080)	Loss 0.2478 (0.2746)	Prec@1 90.625 (90.290)
Epoch: [39][40/391]	Time 0.046 (0.063)	Loss 0.2484 (0.2632)	Prec@1 92.188 (90.911)
Epoch: [39][60/391]	Time 0.046 (0.057)	Loss 0.2210 (0.2613)	Prec@1 92.969 (91.035)
Epoch: [39][80/391]	Time 0.047 (0.054)	Loss 0.3484 (0.2677)	Prec@1 92.188 (90.856)
Epoch: [39][100/391]	Time 0.046 (0.053)	Loss 0.2884 (0.2687)	Prec@1 87.500 (90.834)
Epoch: [39][120/391]	Time 0.047 (0.052)	Loss 0.2022 (0.2718)	Prec@1 90.625 (90.702)
Epoch: [39][140/391]	Time 0.046 (0.051)	Loss 0.2095 (0.2675)	Prec@1 91.406 (90.847)
Epoch: [39][160/391]	Time 0.048 (0.050)	Loss 0.2940 (0.2689)	Prec@1 85.938 (90.756)
Epoch: [39][180/391]	Time 0.046 (0.050)	Loss 0.2176 (0.2703)	Prec@1 92.969 (90.754)
Epoch: [39][200/391]	Time 0.045 (0.050)	Loss 0.3554 (0.2720)	Prec@1 87.500 (90.703)
Epoch: [39][220/391]	Time 0.046 (0.049)	Loss 0.3206 (0.2722)	Prec@1 85.938 (90.667)
Epoch: [39][240/391]	Time 0.047 (0.049)	Loss 0.1791 (0.2724)	Prec@1 94.531 (90.696)
Epoch: [39][260/391]	Time 0.048 (0.049)	Loss 0.2739 (0.2709)	Prec@1 92.188 (90.700)
Epoch: [39][280/391]	Time 0.047 (0.049)	Loss 0.2068 (0.2723)	Prec@1 93.750 (90.628)
Epoch: [39][300/391]	Time 0.050 (0.049)	Loss 0.3238 (0.2727)	Prec@1 89.062 (90.622)
Epoch: [39][320/391]	Time 0.046 (0.048)	Loss 0.3333 (0.2742)	Prec@1 88.281 (90.562)
Epoch: [39][340/391]	Time 0.047 (0.048)	Loss 0.3468 (0.2756)	Prec@1 88.281 (90.524)
Epoch: [39][360/391]	Time 0.045 (0.048)	Loss 0.2888 (0.2768)	Prec@1 89.844 (90.499)
Epoch: [39][380/391]	Time 0.046 (0.048)	Loss 0.3413 (0.2774)	Prec@1 89.062 (90.477)
training time:  18.923628091812134
Test: [0/79]	Time 0.740 (0.740)	Loss 0.4078 (0.4078)	Prec@1 87.500 (87.500)
Test: [20/79]	Time 0.031 (0.066)	Loss 0.4273 (0.4235)	Prec@1 84.375 (86.086)
Test: [40/79]	Time 0.032 (0.049)	Loss 0.3751 (0.4161)	Prec@1 86.719 (86.185)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.4287 (0.4039)	Prec@1 84.375 (86.463)
 * Prec@1 86.540
Epoch: [40][0/391]	Time 0.815 (0.815)	Loss 0.2726 (0.2726)	Prec@1 91.406 (91.406)
Epoch: [40][20/391]	Time 0.045 (0.082)	Loss 0.3113 (0.2627)	Prec@1 90.625 (91.220)
Epoch: [40][40/391]	Time 0.047 (0.065)	Loss 0.2516 (0.2589)	Prec@1 90.625 (91.235)
Epoch: [40][60/391]	Time 0.045 (0.059)	Loss 0.1626 (0.2457)	Prec@1 94.531 (91.662)
Epoch: [40][80/391]	Time 0.044 (0.055)	Loss 0.3101 (0.2492)	Prec@1 89.062 (91.580)
Epoch: [40][100/391]	Time 0.046 (0.054)	Loss 0.1979 (0.2568)	Prec@1 93.750 (91.228)
Epoch: [40][120/391]	Time 0.047 (0.052)	Loss 0.1576 (0.2538)	Prec@1 92.969 (91.348)
Epoch: [40][140/391]	Time 0.045 (0.052)	Loss 0.2946 (0.2535)	Prec@1 90.625 (91.251)
Epoch: [40][160/391]	Time 0.047 (0.051)	Loss 0.2082 (0.2558)	Prec@1 92.188 (91.144)
Epoch: [40][180/391]	Time 0.044 (0.051)	Loss 0.2169 (0.2604)	Prec@1 92.188 (91.005)
Epoch: [40][200/391]	Time 0.046 (0.051)	Loss 0.3238 (0.2628)	Prec@1 90.625 (90.990)
Epoch: [40][220/391]	Time 0.046 (0.050)	Loss 0.3339 (0.2663)	Prec@1 89.062 (90.834)
Epoch: [40][240/391]	Time 0.046 (0.050)	Loss 0.2316 (0.2680)	Prec@1 92.969 (90.784)
Epoch: [40][260/391]	Time 0.046 (0.050)	Loss 0.2978 (0.2705)	Prec@1 89.062 (90.709)
Epoch: [40][280/391]	Time 0.046 (0.049)	Loss 0.3380 (0.2704)	Prec@1 87.500 (90.708)
Epoch: [40][300/391]	Time 0.046 (0.049)	Loss 0.2876 (0.2703)	Prec@1 90.625 (90.690)
Epoch: [40][320/391]	Time 0.045 (0.049)	Loss 0.2782 (0.2716)	Prec@1 89.844 (90.664)
Epoch: [40][340/391]	Time 0.046 (0.049)	Loss 0.2041 (0.2723)	Prec@1 95.312 (90.675)
Epoch: [40][360/391]	Time 0.041 (0.049)	Loss 0.3437 (0.2727)	Prec@1 89.062 (90.625)
Epoch: [40][380/391]	Time 0.045 (0.049)	Loss 0.1591 (0.2732)	Prec@1 92.188 (90.617)
training time:  19.126837730407715
Test: [0/79]	Time 0.795 (0.795)	Loss 0.3932 (0.3932)	Prec@1 88.281 (88.281)
Test: [20/79]	Time 0.032 (0.068)	Loss 0.4121 (0.4159)	Prec@1 88.281 (86.607)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.3644 (0.4092)	Prec@1 87.500 (86.757)
Test: [60/79]	Time 0.032 (0.044)	Loss 0.3375 (0.3934)	Prec@1 88.281 (87.180)
 * Prec@1 86.980
=> Saving checkpoint for epoch 40, with Prec@1 86.980000.
Epoch: [41][0/391]	Time 0.817 (0.817)	Loss 0.2527 (0.2527)	Prec@1 92.188 (92.188)
Epoch: [41][20/391]	Time 0.042 (0.082)	Loss 0.2095 (0.2568)	Prec@1 92.969 (91.518)
Epoch: [41][40/391]	Time 0.046 (0.064)	Loss 0.2332 (0.2543)	Prec@1 91.406 (91.235)
Epoch: [41][60/391]	Time 0.048 (0.058)	Loss 0.2510 (0.2525)	Prec@1 93.750 (91.124)
Epoch: [41][80/391]	Time 0.048 (0.056)	Loss 0.3297 (0.2571)	Prec@1 89.062 (91.001)
Epoch: [41][100/391]	Time 0.044 (0.054)	Loss 0.2457 (0.2584)	Prec@1 89.844 (91.120)
Epoch: [41][120/391]	Time 0.046 (0.053)	Loss 0.3563 (0.2647)	Prec@1 85.156 (90.857)
Epoch: [41][140/391]	Time 0.048 (0.052)	Loss 0.1956 (0.2675)	Prec@1 91.406 (90.736)
Epoch: [41][160/391]	Time 0.042 (0.051)	Loss 0.2242 (0.2688)	Prec@1 94.531 (90.707)
Epoch: [41][180/391]	Time 0.043 (0.050)	Loss 0.4493 (0.2714)	Prec@1 85.938 (90.612)
Epoch: [41][200/391]	Time 0.046 (0.049)	Loss 0.2549 (0.2727)	Prec@1 92.969 (90.594)
Epoch: [41][220/391]	Time 0.048 (0.049)	Loss 0.2106 (0.2735)	Prec@1 90.625 (90.583)
Epoch: [41][240/391]	Time 0.047 (0.048)	Loss 0.2657 (0.2732)	Prec@1 91.406 (90.615)
Epoch: [41][260/391]	Time 0.047 (0.048)	Loss 0.2707 (0.2710)	Prec@1 88.281 (90.700)
Epoch: [41][280/391]	Time 0.046 (0.048)	Loss 0.4628 (0.2717)	Prec@1 86.719 (90.686)
Epoch: [41][300/391]	Time 0.046 (0.048)	Loss 0.2104 (0.2725)	Prec@1 93.750 (90.638)
Epoch: [41][320/391]	Time 0.047 (0.047)	Loss 0.3659 (0.2747)	Prec@1 87.500 (90.557)
Epoch: [41][340/391]	Time 0.047 (0.047)	Loss 0.2262 (0.2751)	Prec@1 92.188 (90.543)
Epoch: [41][360/391]	Time 0.044 (0.047)	Loss 0.2323 (0.2750)	Prec@1 92.969 (90.560)
Epoch: [41][380/391]	Time 0.046 (0.047)	Loss 0.2432 (0.2743)	Prec@1 91.406 (90.592)
training time:  18.510420560836792
Test: [0/79]	Time 0.792 (0.792)	Loss 0.3919 (0.3919)	Prec@1 87.500 (87.500)
Test: [20/79]	Time 0.030 (0.067)	Loss 0.5025 (0.4554)	Prec@1 83.594 (84.412)
Test: [40/79]	Time 0.033 (0.050)	Loss 0.5042 (0.4549)	Prec@1 86.719 (84.889)
Test: [60/79]	Time 0.030 (0.044)	Loss 0.3440 (0.4566)	Prec@1 89.844 (84.990)
 * Prec@1 85.090
Epoch: [42][0/391]	Time 0.828 (0.828)	Loss 0.2732 (0.2732)	Prec@1 89.844 (89.844)
Epoch: [42][20/391]	Time 0.048 (0.084)	Loss 0.2031 (0.2573)	Prec@1 92.188 (91.146)
Epoch: [42][40/391]	Time 0.048 (0.066)	Loss 0.2538 (0.2541)	Prec@1 92.188 (91.559)
Epoch: [42][60/391]	Time 0.048 (0.059)	Loss 0.1649 (0.2461)	Prec@1 93.750 (91.803)
Epoch: [42][80/391]	Time 0.048 (0.056)	Loss 0.1655 (0.2405)	Prec@1 95.312 (91.908)
Epoch: [42][100/391]	Time 0.048 (0.054)	Loss 0.2084 (0.2430)	Prec@1 92.969 (91.832)
Epoch: [42][120/391]	Time 0.049 (0.053)	Loss 0.2586 (0.2459)	Prec@1 92.188 (91.755)
Epoch: [42][140/391]	Time 0.046 (0.052)	Loss 0.3814 (0.2479)	Prec@1 89.062 (91.633)
Epoch: [42][160/391]	Time 0.048 (0.052)	Loss 0.3647 (0.2498)	Prec@1 89.062 (91.586)
Epoch: [42][180/391]	Time 0.047 (0.052)	Loss 0.2806 (0.2512)	Prec@1 91.406 (91.557)
Epoch: [42][200/391]	Time 0.046 (0.051)	Loss 0.2247 (0.2530)	Prec@1 93.750 (91.511)
Epoch: [42][220/391]	Time 0.042 (0.051)	Loss 0.2491 (0.2547)	Prec@1 92.969 (91.431)
Epoch: [42][240/391]	Time 0.043 (0.050)	Loss 0.2782 (0.2544)	Prec@1 89.844 (91.403)
Epoch: [42][260/391]	Time 0.046 (0.050)	Loss 0.3077 (0.2552)	Prec@1 90.625 (91.394)
Epoch: [42][280/391]	Time 0.046 (0.050)	Loss 0.3692 (0.2555)	Prec@1 89.062 (91.401)
Epoch: [42][300/391]	Time 0.045 (0.050)	Loss 0.2180 (0.2561)	Prec@1 92.188 (91.360)
Epoch: [42][320/391]	Time 0.046 (0.049)	Loss 0.3367 (0.2559)	Prec@1 88.281 (91.377)
Epoch: [42][340/391]	Time 0.046 (0.049)	Loss 0.3069 (0.2574)	Prec@1 88.281 (91.342)
Epoch: [42][360/391]	Time 0.047 (0.049)	Loss 0.2165 (0.2584)	Prec@1 94.531 (91.274)
Epoch: [42][380/391]	Time 0.045 (0.049)	Loss 0.3315 (0.2597)	Prec@1 86.719 (91.222)
training time:  19.24090075492859
Test: [0/79]	Time 0.785 (0.785)	Loss 0.5517 (0.5517)	Prec@1 82.031 (82.031)
Test: [20/79]	Time 0.031 (0.067)	Loss 0.4101 (0.5095)	Prec@1 88.281 (84.152)
Test: [40/79]	Time 0.031 (0.050)	Loss 0.5506 (0.4990)	Prec@1 82.031 (83.861)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.3291 (0.4802)	Prec@1 85.938 (84.465)
 * Prec@1 84.320
Epoch: [43][0/391]	Time 0.793 (0.793)	Loss 0.1951 (0.1951)	Prec@1 94.531 (94.531)
Epoch: [43][20/391]	Time 0.047 (0.081)	Loss 0.3160 (0.2572)	Prec@1 90.625 (92.001)
Epoch: [43][40/391]	Time 0.047 (0.063)	Loss 0.3132 (0.2509)	Prec@1 88.281 (91.902)
Epoch: [43][60/391]	Time 0.046 (0.057)	Loss 0.1320 (0.2437)	Prec@1 96.094 (91.995)
Epoch: [43][80/391]	Time 0.047 (0.055)	Loss 0.2582 (0.2456)	Prec@1 89.844 (91.753)
Epoch: [43][100/391]	Time 0.045 (0.053)	Loss 0.3416 (0.2467)	Prec@1 91.406 (91.754)
Epoch: [43][120/391]	Time 0.046 (0.052)	Loss 0.2019 (0.2485)	Prec@1 91.406 (91.716)
Epoch: [43][140/391]	Time 0.043 (0.051)	Loss 0.2555 (0.2486)	Prec@1 91.406 (91.705)
Epoch: [43][160/391]	Time 0.047 (0.050)	Loss 0.2770 (0.2478)	Prec@1 91.406 (91.765)
Epoch: [43][180/391]	Time 0.044 (0.050)	Loss 0.1931 (0.2494)	Prec@1 91.406 (91.704)
Epoch: [43][200/391]	Time 0.048 (0.050)	Loss 0.3091 (0.2482)	Prec@1 88.281 (91.706)
Epoch: [43][220/391]	Time 0.044 (0.049)	Loss 0.3152 (0.2475)	Prec@1 90.625 (91.731)
Epoch: [43][240/391]	Time 0.044 (0.049)	Loss 0.2321 (0.2504)	Prec@1 92.188 (91.610)
Epoch: [43][260/391]	Time 0.046 (0.049)	Loss 0.2802 (0.2524)	Prec@1 88.281 (91.529)
Epoch: [43][280/391]	Time 0.045 (0.049)	Loss 0.2477 (0.2538)	Prec@1 91.406 (91.459)
Epoch: [43][300/391]	Time 0.044 (0.049)	Loss 0.3497 (0.2544)	Prec@1 84.375 (91.474)
Epoch: [43][320/391]	Time 0.045 (0.048)	Loss 0.3028 (0.2534)	Prec@1 90.625 (91.499)
Epoch: [43][340/391]	Time 0.043 (0.048)	Loss 0.1511 (0.2528)	Prec@1 95.312 (91.507)
Epoch: [43][360/391]	Time 0.042 (0.048)	Loss 0.2849 (0.2536)	Prec@1 86.719 (91.454)
Epoch: [43][380/391]	Time 0.045 (0.048)	Loss 0.3413 (0.2544)	Prec@1 90.625 (91.435)
training time:  18.86923623085022
Test: [0/79]	Time 0.786 (0.786)	Loss 0.3695 (0.3695)	Prec@1 89.062 (89.062)
Test: [20/79]	Time 0.032 (0.068)	Loss 0.3452 (0.3979)	Prec@1 89.062 (86.570)
Test: [40/79]	Time 0.032 (0.051)	Loss 0.4668 (0.3803)	Prec@1 79.688 (86.662)
Test: [60/79]	Time 0.031 (0.045)	Loss 0.3246 (0.3765)	Prec@1 88.281 (86.860)
 * Prec@1 86.970
Epoch: [44][0/391]	Time 0.775 (0.775)	Loss 0.2951 (0.2951)	Prec@1 90.625 (90.625)
Epoch: [44][20/391]	Time 0.045 (0.081)	Loss 0.2223 (0.2264)	Prec@1 93.750 (92.374)
Epoch: [44][40/391]	Time 0.047 (0.064)	Loss 0.2590 (0.2346)	Prec@1 88.281 (91.787)
Epoch: [44][60/391]	Time 0.044 (0.058)	Loss 0.1580 (0.2275)	Prec@1 95.312 (92.252)
Epoch: [44][80/391]	Time 0.049 (0.055)	Loss 0.1221 (0.2316)	Prec@1 96.094 (92.101)
Epoch: [44][100/391]	Time 0.048 (0.053)	Loss 0.1541 (0.2360)	Prec@1 96.875 (91.932)
Epoch: [44][120/391]	Time 0.049 (0.052)	Loss 0.2824 (0.2384)	Prec@1 89.844 (91.813)
Epoch: [44][140/391]	Time 0.046 (0.051)	Loss 0.2202 (0.2383)	Prec@1 91.406 (91.789)
Epoch: [44][160/391]	Time 0.048 (0.051)	Loss 0.1864 (0.2403)	Prec@1 92.969 (91.697)
Epoch: [44][180/391]	Time 0.047 (0.051)	Loss 0.2915 (0.2408)	Prec@1 91.406 (91.657)
Epoch: [44][200/391]	Time 0.047 (0.051)	Loss 0.2661 (0.2394)	Prec@1 90.625 (91.748)
Epoch: [44][220/391]	Time 0.047 (0.050)	Loss 0.3066 (0.2403)	Prec@1 91.406 (91.700)
Epoch: [44][240/391]	Time 0.046 (0.050)	Loss 0.2102 (0.2413)	Prec@1 92.188 (91.669)
Epoch: [44][260/391]	Time 0.048 (0.050)	Loss 0.3032 (0.2427)	Prec@1 91.406 (91.640)
Epoch: [44][280/391]	Time 0.047 (0.049)	Loss 0.1986 (0.2455)	Prec@1 92.969 (91.581)
Epoch: [44][300/391]	Time 0.044 (0.049)	Loss 0.2165 (0.2471)	Prec@1 94.531 (91.559)
Epoch: [44][320/391]	Time 0.045 (0.049)	Loss 0.1584 (0.2473)	Prec@1 93.750 (91.567)
Epoch: [44][340/391]	Time 0.048 (0.049)	Loss 0.3195 (0.2471)	Prec@1 87.500 (91.562)
Epoch: [44][360/391]	Time 0.045 (0.049)	Loss 0.3381 (0.2479)	Prec@1 87.500 (91.521)
Epoch: [44][380/391]	Time 0.047 (0.049)	Loss 0.2821 (0.2487)	Prec@1 90.625 (91.472)
training time:  19.191611289978027
Test: [0/79]	Time 0.741 (0.741)	Loss 0.2858 (0.2858)	Prec@1 88.281 (88.281)
Test: [20/79]	Time 0.032 (0.065)	Loss 0.2752 (0.3573)	Prec@1 92.188 (88.132)
Test: [40/79]	Time 0.033 (0.049)	Loss 0.4128 (0.3632)	Prec@1 85.938 (88.014)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.4311 (0.3631)	Prec@1 89.062 (87.923)
 * Prec@1 88.040
=> Saving checkpoint for epoch 44, with Prec@1 88.040000.
Epoch: [45][0/391]	Time 0.777 (0.777)	Loss 0.2466 (0.2466)	Prec@1 93.750 (93.750)
Epoch: [45][20/391]	Time 0.047 (0.081)	Loss 0.4106 (0.2518)	Prec@1 85.156 (91.481)
Epoch: [45][40/391]	Time 0.046 (0.064)	Loss 0.2804 (0.2405)	Prec@1 90.625 (92.073)
Epoch: [45][60/391]	Time 0.046 (0.058)	Loss 0.1566 (0.2325)	Prec@1 96.094 (92.328)
Epoch: [45][80/391]	Time 0.047 (0.056)	Loss 0.2526 (0.2365)	Prec@1 92.188 (92.207)
Epoch: [45][100/391]	Time 0.046 (0.054)	Loss 0.3273 (0.2412)	Prec@1 89.062 (92.095)
Epoch: [45][120/391]	Time 0.046 (0.052)	Loss 0.2280 (0.2428)	Prec@1 90.625 (91.936)
Epoch: [45][140/391]	Time 0.048 (0.052)	Loss 0.2261 (0.2430)	Prec@1 91.406 (91.872)
Epoch: [45][160/391]	Time 0.047 (0.051)	Loss 0.2605 (0.2438)	Prec@1 90.625 (91.804)
Epoch: [45][180/391]	Time 0.043 (0.050)	Loss 0.2721 (0.2433)	Prec@1 90.625 (91.821)
Epoch: [45][200/391]	Time 0.042 (0.050)	Loss 0.1077 (0.2440)	Prec@1 96.875 (91.783)
Epoch: [45][220/391]	Time 0.046 (0.049)	Loss 0.3253 (0.2429)	Prec@1 88.281 (91.799)
Epoch: [45][240/391]	Time 0.046 (0.049)	Loss 0.2420 (0.2421)	Prec@1 91.406 (91.798)
Epoch: [45][260/391]	Time 0.044 (0.049)	Loss 0.2852 (0.2427)	Prec@1 91.406 (91.783)
Epoch: [45][280/391]	Time 0.044 (0.048)	Loss 0.2571 (0.2448)	Prec@1 89.844 (91.681)
Epoch: [45][300/391]	Time 0.046 (0.048)	Loss 0.2279 (0.2481)	Prec@1 88.281 (91.531)
Epoch: [45][320/391]	Time 0.048 (0.048)	Loss 0.1648 (0.2494)	Prec@1 94.531 (91.472)
Epoch: [45][340/391]	Time 0.047 (0.048)	Loss 0.1476 (0.2503)	Prec@1 94.531 (91.425)
Epoch: [45][360/391]	Time 0.046 (0.048)	Loss 0.3023 (0.2522)	Prec@1 89.844 (91.346)
Epoch: [45][380/391]	Time 0.045 (0.048)	Loss 0.3269 (0.2514)	Prec@1 90.625 (91.382)
training time:  18.79877519607544
Test: [0/79]	Time 0.738 (0.738)	Loss 0.2981 (0.2981)	Prec@1 91.406 (91.406)
Test: [20/79]	Time 0.031 (0.065)	Loss 0.2958 (0.3527)	Prec@1 89.062 (87.946)
Test: [40/79]	Time 0.032 (0.049)	Loss 0.4705 (0.3459)	Prec@1 85.156 (88.186)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.2395 (0.3345)	Prec@1 90.625 (88.614)
 * Prec@1 88.710
=> Saving checkpoint for epoch 45, with Prec@1 88.710000.
Epoch: [46][0/391]	Time 0.815 (0.815)	Loss 0.1476 (0.1476)	Prec@1 95.312 (95.312)
Epoch: [46][20/391]	Time 0.048 (0.083)	Loss 0.1714 (0.1972)	Prec@1 94.531 (93.452)
Epoch: [46][40/391]	Time 0.047 (0.065)	Loss 0.2424 (0.2100)	Prec@1 89.062 (92.950)
Epoch: [46][60/391]	Time 0.047 (0.059)	Loss 0.2216 (0.2159)	Prec@1 92.188 (92.687)
Epoch: [46][80/391]	Time 0.048 (0.056)	Loss 0.2330 (0.2241)	Prec@1 92.969 (92.419)
Epoch: [46][100/391]	Time 0.047 (0.054)	Loss 0.1348 (0.2217)	Prec@1 96.094 (92.621)
Epoch: [46][120/391]	Time 0.047 (0.053)	Loss 0.2150 (0.2256)	Prec@1 93.750 (92.472)
Epoch: [46][140/391]	Time 0.048 (0.052)	Loss 0.2273 (0.2264)	Prec@1 91.406 (92.426)
Epoch: [46][160/391]	Time 0.046 (0.051)	Loss 0.2333 (0.2282)	Prec@1 92.969 (92.304)
Epoch: [46][180/391]	Time 0.047 (0.051)	Loss 0.2216 (0.2323)	Prec@1 92.969 (92.127)
Epoch: [46][200/391]	Time 0.047 (0.051)	Loss 0.2493 (0.2352)	Prec@1 91.406 (92.040)
Epoch: [46][220/391]	Time 0.046 (0.051)	Loss 0.3425 (0.2374)	Prec@1 86.719 (91.951)
Epoch: [46][240/391]	Time 0.047 (0.050)	Loss 0.2661 (0.2391)	Prec@1 89.062 (91.893)
Epoch: [46][260/391]	Time 0.048 (0.050)	Loss 0.1837 (0.2402)	Prec@1 92.188 (91.828)
Epoch: [46][280/391]	Time 0.046 (0.050)	Loss 0.2749 (0.2423)	Prec@1 91.406 (91.745)
Epoch: [46][300/391]	Time 0.048 (0.049)	Loss 0.2933 (0.2431)	Prec@1 90.625 (91.692)
Epoch: [46][320/391]	Time 0.045 (0.049)	Loss 0.3468 (0.2436)	Prec@1 88.281 (91.686)
Epoch: [46][340/391]	Time 0.047 (0.049)	Loss 0.3226 (0.2428)	Prec@1 89.062 (91.711)
Epoch: [46][360/391]	Time 0.045 (0.049)	Loss 0.2129 (0.2418)	Prec@1 91.406 (91.761)
Epoch: [46][380/391]	Time 0.045 (0.049)	Loss 0.1862 (0.2420)	Prec@1 92.969 (91.724)
training time:  19.175053358078003
Test: [0/79]	Time 0.733 (0.733)	Loss 0.3170 (0.3170)	Prec@1 89.844 (89.844)
Test: [20/79]	Time 0.032 (0.065)	Loss 0.3671 (0.3424)	Prec@1 89.062 (88.318)
Test: [40/79]	Time 0.031 (0.049)	Loss 0.4031 (0.3379)	Prec@1 85.938 (88.624)
Test: [60/79]	Time 0.029 (0.043)	Loss 0.4733 (0.3441)	Prec@1 85.156 (88.550)
 * Prec@1 88.670
Epoch: [47][0/391]	Time 0.834 (0.834)	Loss 0.2016 (0.2016)	Prec@1 90.625 (90.625)
Epoch: [47][20/391]	Time 0.047 (0.084)	Loss 0.2427 (0.2276)	Prec@1 93.750 (92.188)
Epoch: [47][40/391]	Time 0.046 (0.066)	Loss 0.2677 (0.2256)	Prec@1 89.062 (92.111)
Epoch: [47][60/391]	Time 0.045 (0.059)	Loss 0.2800 (0.2332)	Prec@1 89.844 (91.995)
Epoch: [47][80/391]	Time 0.047 (0.056)	Loss 0.2423 (0.2291)	Prec@1 92.188 (92.120)
Epoch: [47][100/391]	Time 0.047 (0.054)	Loss 0.2610 (0.2278)	Prec@1 90.625 (92.102)
Epoch: [47][120/391]	Time 0.046 (0.053)	Loss 0.2838 (0.2292)	Prec@1 92.969 (92.000)
Epoch: [47][140/391]	Time 0.048 (0.052)	Loss 0.1578 (0.2293)	Prec@1 94.531 (92.021)
Epoch: [47][160/391]	Time 0.046 (0.051)	Loss 0.2356 (0.2268)	Prec@1 93.750 (92.163)
Epoch: [47][180/391]	Time 0.045 (0.051)	Loss 0.2126 (0.2252)	Prec@1 91.406 (92.144)
Epoch: [47][200/391]	Time 0.046 (0.050)	Loss 0.1794 (0.2277)	Prec@1 92.969 (92.063)
Epoch: [47][220/391]	Time 0.045 (0.050)	Loss 0.3096 (0.2278)	Prec@1 89.844 (92.085)
Epoch: [47][240/391]	Time 0.046 (0.050)	Loss 0.2618 (0.2308)	Prec@1 89.844 (91.928)
Epoch: [47][260/391]	Time 0.046 (0.049)	Loss 0.3878 (0.2321)	Prec@1 86.719 (91.906)
Epoch: [47][280/391]	Time 0.045 (0.049)	Loss 0.2575 (0.2334)	Prec@1 92.188 (91.921)
Epoch: [47][300/391]	Time 0.047 (0.049)	Loss 0.2379 (0.2374)	Prec@1 91.406 (91.811)
Epoch: [47][320/391]	Time 0.047 (0.049)	Loss 0.2161 (0.2381)	Prec@1 94.531 (91.801)
Epoch: [47][340/391]	Time 0.045 (0.049)	Loss 0.2756 (0.2375)	Prec@1 89.844 (91.821)
Epoch: [47][360/391]	Time 0.047 (0.049)	Loss 0.2919 (0.2375)	Prec@1 89.844 (91.830)
Epoch: [47][380/391]	Time 0.045 (0.048)	Loss 0.2313 (0.2377)	Prec@1 92.969 (91.845)
training time:  19.073540925979614
Test: [0/79]	Time 0.785 (0.785)	Loss 0.2871 (0.2871)	Prec@1 92.188 (92.188)
Test: [20/79]	Time 0.032 (0.068)	Loss 0.3352 (0.3460)	Prec@1 84.375 (87.612)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.3721 (0.3415)	Prec@1 85.938 (87.938)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.2958 (0.3422)	Prec@1 87.500 (88.012)
 * Prec@1 88.170
Epoch: [48][0/391]	Time 0.821 (0.821)	Loss 0.2936 (0.2936)	Prec@1 90.625 (90.625)
Epoch: [48][20/391]	Time 0.046 (0.082)	Loss 0.2190 (0.2428)	Prec@1 92.969 (91.629)
Epoch: [48][40/391]	Time 0.045 (0.064)	Loss 0.1748 (0.2193)	Prec@1 94.531 (92.721)
Epoch: [48][60/391]	Time 0.046 (0.058)	Loss 0.2085 (0.2197)	Prec@1 92.969 (92.713)
Epoch: [48][80/391]	Time 0.046 (0.055)	Loss 0.3455 (0.2276)	Prec@1 88.281 (92.323)
Epoch: [48][100/391]	Time 0.047 (0.054)	Loss 0.2055 (0.2264)	Prec@1 90.625 (92.327)
Epoch: [48][120/391]	Time 0.046 (0.052)	Loss 0.1664 (0.2281)	Prec@1 92.188 (92.271)
Epoch: [48][140/391]	Time 0.047 (0.052)	Loss 0.2063 (0.2278)	Prec@1 95.312 (92.354)
Epoch: [48][160/391]	Time 0.047 (0.051)	Loss 0.2478 (0.2278)	Prec@1 89.844 (92.319)
Epoch: [48][180/391]	Time 0.047 (0.051)	Loss 0.1719 (0.2284)	Prec@1 94.531 (92.257)
Epoch: [48][200/391]	Time 0.047 (0.051)	Loss 0.3429 (0.2301)	Prec@1 89.844 (92.191)
Epoch: [48][220/391]	Time 0.046 (0.050)	Loss 0.3124 (0.2305)	Prec@1 90.625 (92.159)
Epoch: [48][240/391]	Time 0.046 (0.050)	Loss 0.1715 (0.2291)	Prec@1 95.312 (92.200)
Epoch: [48][260/391]	Time 0.045 (0.050)	Loss 0.3829 (0.2294)	Prec@1 85.156 (92.205)
Epoch: [48][280/391]	Time 0.046 (0.050)	Loss 0.2338 (0.2299)	Prec@1 91.406 (92.218)
Epoch: [48][300/391]	Time 0.046 (0.049)	Loss 0.3055 (0.2302)	Prec@1 89.062 (92.182)
Epoch: [48][320/391]	Time 0.045 (0.049)	Loss 0.2472 (0.2306)	Prec@1 92.969 (92.146)
Epoch: [48][340/391]	Time 0.045 (0.049)	Loss 0.2238 (0.2304)	Prec@1 92.969 (92.160)
Epoch: [48][360/391]	Time 0.045 (0.049)	Loss 0.2078 (0.2305)	Prec@1 89.844 (92.155)
Epoch: [48][380/391]	Time 0.046 (0.049)	Loss 0.2427 (0.2305)	Prec@1 89.062 (92.146)
training time:  19.19927453994751
Test: [0/79]	Time 0.778 (0.778)	Loss 0.3562 (0.3562)	Prec@1 89.062 (89.062)
Test: [20/79]	Time 0.028 (0.066)	Loss 0.4640 (0.4477)	Prec@1 88.281 (85.789)
Test: [40/79]	Time 0.031 (0.049)	Loss 0.7272 (0.4369)	Prec@1 79.688 (86.033)
Test: [60/79]	Time 0.031 (0.043)	Loss 0.4049 (0.4320)	Prec@1 85.156 (86.002)
 * Prec@1 86.060
Epoch: [49][0/391]	Time 0.824 (0.824)	Loss 0.2507 (0.2507)	Prec@1 89.844 (89.844)
Epoch: [49][20/391]	Time 0.046 (0.083)	Loss 0.3182 (0.1979)	Prec@1 89.844 (92.932)
Epoch: [49][40/391]	Time 0.041 (0.065)	Loss 0.1485 (0.2024)	Prec@1 96.094 (93.026)
Epoch: [49][60/391]	Time 0.043 (0.058)	Loss 0.2160 (0.2055)	Prec@1 92.188 (92.943)
Epoch: [49][80/391]	Time 0.047 (0.055)	Loss 0.2076 (0.2027)	Prec@1 92.969 (93.027)
Epoch: [49][100/391]	Time 0.046 (0.053)	Loss 0.2606 (0.2052)	Prec@1 89.844 (92.884)
Epoch: [49][120/391]	Time 0.046 (0.052)	Loss 0.1422 (0.2077)	Prec@1 95.312 (92.833)
Epoch: [49][140/391]	Time 0.046 (0.051)	Loss 0.2698 (0.2108)	Prec@1 91.406 (92.730)
Epoch: [49][160/391]	Time 0.047 (0.050)	Loss 0.2251 (0.2141)	Prec@1 93.750 (92.653)
Epoch: [49][180/391]	Time 0.045 (0.050)	Loss 0.2195 (0.2188)	Prec@1 92.969 (92.580)
Epoch: [49][200/391]	Time 0.044 (0.050)	Loss 0.2984 (0.2175)	Prec@1 89.062 (92.615)
Epoch: [49][220/391]	Time 0.045 (0.049)	Loss 0.1831 (0.2190)	Prec@1 96.094 (92.573)
Epoch: [49][240/391]	Time 0.042 (0.049)	Loss 0.2126 (0.2213)	Prec@1 96.875 (92.521)
Epoch: [49][260/391]	Time 0.046 (0.049)	Loss 0.3028 (0.2239)	Prec@1 92.188 (92.442)
Epoch: [49][280/391]	Time 0.046 (0.048)	Loss 0.3168 (0.2270)	Prec@1 89.844 (92.329)
Epoch: [49][300/391]	Time 0.046 (0.048)	Loss 0.2228 (0.2272)	Prec@1 92.188 (92.338)
Epoch: [49][320/391]	Time 0.045 (0.048)	Loss 0.2862 (0.2271)	Prec@1 90.625 (92.321)
Epoch: [49][340/391]	Time 0.046 (0.048)	Loss 0.1656 (0.2278)	Prec@1 95.312 (92.281)
Epoch: [49][360/391]	Time 0.047 (0.048)	Loss 0.3071 (0.2267)	Prec@1 89.844 (92.330)
Epoch: [49][380/391]	Time 0.046 (0.048)	Loss 0.1564 (0.2273)	Prec@1 94.531 (92.298)
training time:  18.85330367088318
Test: [0/79]	Time 0.782 (0.782)	Loss 0.4615 (0.4615)	Prec@1 85.938 (85.938)
Test: [20/79]	Time 0.032 (0.068)	Loss 0.3802 (0.3644)	Prec@1 85.938 (88.132)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.4289 (0.3579)	Prec@1 87.500 (88.186)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.3434 (0.3497)	Prec@1 89.062 (88.473)
 * Prec@1 88.440
Epoch: [50][0/391]	Time 0.823 (0.823)	Loss 0.2225 (0.2225)	Prec@1 90.625 (90.625)
Epoch: [50][20/391]	Time 0.048 (0.084)	Loss 0.2489 (0.2099)	Prec@1 90.625 (92.597)
Epoch: [50][40/391]	Time 0.047 (0.066)	Loss 0.2609 (0.2102)	Prec@1 89.062 (92.378)
Epoch: [50][60/391]	Time 0.046 (0.060)	Loss 0.1760 (0.2039)	Prec@1 97.656 (92.841)
Epoch: [50][80/391]	Time 0.048 (0.056)	Loss 0.2006 (0.2072)	Prec@1 93.750 (92.718)
Epoch: [50][100/391]	Time 0.047 (0.054)	Loss 0.1669 (0.2109)	Prec@1 95.312 (92.613)
Epoch: [50][120/391]	Time 0.042 (0.053)	Loss 0.2563 (0.2095)	Prec@1 92.969 (92.691)
Epoch: [50][140/391]	Time 0.047 (0.052)	Loss 0.2415 (0.2070)	Prec@1 92.188 (92.852)
Epoch: [50][160/391]	Time 0.046 (0.051)	Loss 0.2062 (0.2067)	Prec@1 92.969 (92.828)
Epoch: [50][180/391]	Time 0.049 (0.051)	Loss 0.1972 (0.2087)	Prec@1 92.969 (92.757)
Epoch: [50][200/391]	Time 0.043 (0.051)	Loss 0.2295 (0.2097)	Prec@1 92.188 (92.724)
Epoch: [50][220/391]	Time 0.042 (0.050)	Loss 0.1470 (0.2113)	Prec@1 93.750 (92.633)
Epoch: [50][240/391]	Time 0.044 (0.050)	Loss 0.2942 (0.2123)	Prec@1 92.188 (92.632)
Epoch: [50][260/391]	Time 0.046 (0.049)	Loss 0.2196 (0.2143)	Prec@1 92.188 (92.556)
Epoch: [50][280/391]	Time 0.047 (0.049)	Loss 0.1722 (0.2152)	Prec@1 94.531 (92.518)
Epoch: [50][300/391]	Time 0.043 (0.049)	Loss 0.2911 (0.2162)	Prec@1 91.406 (92.499)
Epoch: [50][320/391]	Time 0.043 (0.049)	Loss 0.2157 (0.2162)	Prec@1 91.406 (92.494)
Epoch: [50][340/391]	Time 0.043 (0.048)	Loss 0.1886 (0.2155)	Prec@1 92.188 (92.508)
Epoch: [50][360/391]	Time 0.043 (0.048)	Loss 0.2136 (0.2151)	Prec@1 91.406 (92.536)
Epoch: [50][380/391]	Time 0.045 (0.048)	Loss 0.3352 (0.2160)	Prec@1 88.281 (92.518)
training time:  18.934378147125244
Test: [0/79]	Time 0.748 (0.748)	Loss 0.3559 (0.3559)	Prec@1 89.062 (89.062)
Test: [20/79]	Time 0.029 (0.065)	Loss 0.4193 (0.3599)	Prec@1 87.500 (88.132)
Test: [40/79]	Time 0.029 (0.049)	Loss 0.3071 (0.3380)	Prec@1 90.625 (88.700)
Test: [60/79]	Time 0.031 (0.043)	Loss 0.2527 (0.3297)	Prec@1 92.188 (88.934)
 * Prec@1 89.010
=> Saving checkpoint for epoch 50, with Prec@1 89.010000.
Epoch: [51][0/391]	Time 0.785 (0.785)	Loss 0.1949 (0.1949)	Prec@1 95.312 (95.312)
Epoch: [51][20/391]	Time 0.046 (0.081)	Loss 0.1833 (0.1812)	Prec@1 94.531 (94.085)
Epoch: [51][40/391]	Time 0.045 (0.064)	Loss 0.2093 (0.1961)	Prec@1 91.406 (93.464)
Epoch: [51][60/391]	Time 0.047 (0.059)	Loss 0.0867 (0.2023)	Prec@1 98.438 (93.417)
Epoch: [51][80/391]	Time 0.045 (0.056)	Loss 0.1411 (0.2003)	Prec@1 96.094 (93.403)
Epoch: [51][100/391]	Time 0.047 (0.054)	Loss 0.2313 (0.2010)	Prec@1 92.188 (93.371)
Epoch: [51][120/391]	Time 0.048 (0.053)	Loss 0.2380 (0.2007)	Prec@1 92.969 (93.388)
Epoch: [51][140/391]	Time 0.045 (0.052)	Loss 0.1853 (0.2028)	Prec@1 94.531 (93.285)
Epoch: [51][160/391]	Time 0.045 (0.051)	Loss 0.3921 (0.2034)	Prec@1 88.281 (93.279)
Epoch: [51][180/391]	Time 0.045 (0.051)	Loss 0.1698 (0.2021)	Prec@1 95.312 (93.280)
Epoch: [51][200/391]	Time 0.048 (0.050)	Loss 0.2375 (0.2040)	Prec@1 91.406 (93.210)
Epoch: [51][220/391]	Time 0.045 (0.050)	Loss 0.1741 (0.2044)	Prec@1 92.969 (93.181)
Epoch: [51][240/391]	Time 0.045 (0.049)	Loss 0.3298 (0.2053)	Prec@1 90.625 (93.186)
Epoch: [51][260/391]	Time 0.045 (0.049)	Loss 0.2584 (0.2075)	Prec@1 92.188 (93.118)
Epoch: [51][280/391]	Time 0.045 (0.049)	Loss 0.2539 (0.2087)	Prec@1 90.625 (93.094)
Epoch: [51][300/391]	Time 0.046 (0.049)	Loss 0.2756 (0.2085)	Prec@1 90.625 (93.096)
Epoch: [51][320/391]	Time 0.046 (0.049)	Loss 0.2680 (0.2087)	Prec@1 88.281 (93.069)
Epoch: [51][340/391]	Time 0.041 (0.048)	Loss 0.1173 (0.2083)	Prec@1 95.312 (93.065)
Epoch: [51][360/391]	Time 0.042 (0.048)	Loss 0.1703 (0.2101)	Prec@1 94.531 (92.988)
Epoch: [51][380/391]	Time 0.045 (0.048)	Loss 0.2448 (0.2116)	Prec@1 89.062 (92.934)
training time:  18.87523865699768
Test: [0/79]	Time 0.738 (0.738)	Loss 0.2493 (0.2493)	Prec@1 94.531 (94.531)
Test: [20/79]	Time 0.031 (0.065)	Loss 0.2646 (0.3234)	Prec@1 92.188 (89.732)
Test: [40/79]	Time 0.032 (0.049)	Loss 0.3551 (0.3243)	Prec@1 88.281 (89.558)
Test: [60/79]	Time 0.031 (0.043)	Loss 0.2897 (0.3168)	Prec@1 89.844 (89.703)
 * Prec@1 89.310
=> Saving checkpoint for epoch 51, with Prec@1 89.310000.
Epoch: [52][0/391]	Time 0.783 (0.783)	Loss 0.2220 (0.2220)	Prec@1 91.406 (91.406)
Epoch: [52][20/391]	Time 0.047 (0.081)	Loss 0.0858 (0.2001)	Prec@1 97.656 (93.043)
Epoch: [52][40/391]	Time 0.049 (0.063)	Loss 0.2077 (0.2095)	Prec@1 92.188 (92.873)
Epoch: [52][60/391]	Time 0.048 (0.058)	Loss 0.1078 (0.1999)	Prec@1 96.094 (93.097)
Epoch: [52][80/391]	Time 0.047 (0.055)	Loss 0.1226 (0.1968)	Prec@1 97.656 (93.239)
Epoch: [52][100/391]	Time 0.047 (0.053)	Loss 0.2385 (0.1983)	Prec@1 91.406 (93.239)
Epoch: [52][120/391]	Time 0.049 (0.052)	Loss 0.1825 (0.1956)	Prec@1 92.969 (93.285)
Epoch: [52][140/391]	Time 0.046 (0.051)	Loss 0.1630 (0.1937)	Prec@1 94.531 (93.423)
Epoch: [52][160/391]	Time 0.048 (0.051)	Loss 0.1852 (0.1937)	Prec@1 93.750 (93.396)
Epoch: [52][180/391]	Time 0.046 (0.051)	Loss 0.1257 (0.1912)	Prec@1 95.312 (93.513)
Epoch: [52][200/391]	Time 0.044 (0.051)	Loss 0.1643 (0.1933)	Prec@1 93.750 (93.470)
Epoch: [52][220/391]	Time 0.046 (0.050)	Loss 0.2232 (0.1952)	Prec@1 92.969 (93.425)
Epoch: [52][240/391]	Time 0.046 (0.050)	Loss 0.1443 (0.1977)	Prec@1 95.312 (93.348)
Epoch: [52][260/391]	Time 0.047 (0.050)	Loss 0.1413 (0.1966)	Prec@1 94.531 (93.403)
Epoch: [52][280/391]	Time 0.047 (0.049)	Loss 0.1931 (0.1982)	Prec@1 92.188 (93.333)
Epoch: [52][300/391]	Time 0.046 (0.049)	Loss 0.2290 (0.2001)	Prec@1 89.062 (93.231)
Epoch: [52][320/391]	Time 0.045 (0.049)	Loss 0.2530 (0.2003)	Prec@1 90.625 (93.215)
Epoch: [52][340/391]	Time 0.045 (0.049)	Loss 0.2415 (0.2009)	Prec@1 93.750 (93.198)
Epoch: [52][360/391]	Time 0.048 (0.049)	Loss 0.2565 (0.2018)	Prec@1 92.188 (93.151)
Epoch: [52][380/391]	Time 0.045 (0.049)	Loss 0.1584 (0.2026)	Prec@1 96.094 (93.141)
training time:  19.14714765548706
Test: [0/79]	Time 0.771 (0.771)	Loss 0.3396 (0.3396)	Prec@1 89.844 (89.844)
Test: [20/79]	Time 0.032 (0.067)	Loss 0.3762 (0.3186)	Prec@1 89.844 (89.546)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.3978 (0.3130)	Prec@1 88.281 (89.653)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.2700 (0.3172)	Prec@1 92.188 (89.664)
 * Prec@1 89.650
=> Saving checkpoint for epoch 52, with Prec@1 89.650000.
Epoch: [53][0/391]	Time 0.822 (0.822)	Loss 0.4082 (0.4082)	Prec@1 89.062 (89.062)
Epoch: [53][20/391]	Time 0.045 (0.082)	Loss 0.1939 (0.1979)	Prec@1 93.750 (93.452)
Epoch: [53][40/391]	Time 0.046 (0.064)	Loss 0.2702 (0.2005)	Prec@1 89.844 (93.083)
Epoch: [53][60/391]	Time 0.044 (0.058)	Loss 0.2379 (0.1944)	Prec@1 89.844 (93.353)
Epoch: [53][80/391]	Time 0.046 (0.055)	Loss 0.1649 (0.1966)	Prec@1 95.312 (93.316)
Epoch: [53][100/391]	Time 0.045 (0.053)	Loss 0.1975 (0.1945)	Prec@1 90.625 (93.340)
Epoch: [53][120/391]	Time 0.047 (0.052)	Loss 0.2315 (0.1929)	Prec@1 92.188 (93.414)
Epoch: [53][140/391]	Time 0.044 (0.051)	Loss 0.2732 (0.1968)	Prec@1 90.625 (93.296)
Epoch: [53][160/391]	Time 0.043 (0.050)	Loss 0.1075 (0.1966)	Prec@1 96.875 (93.323)
Epoch: [53][180/391]	Time 0.045 (0.050)	Loss 0.1265 (0.1953)	Prec@1 95.312 (93.383)
Epoch: [53][200/391]	Time 0.042 (0.049)	Loss 0.1783 (0.1974)	Prec@1 92.969 (93.307)
Epoch: [53][220/391]	Time 0.042 (0.049)	Loss 0.1641 (0.1998)	Prec@1 93.750 (93.177)
Epoch: [53][240/391]	Time 0.043 (0.049)	Loss 0.1614 (0.2005)	Prec@1 94.531 (93.154)
Epoch: [53][260/391]	Time 0.045 (0.048)	Loss 0.2487 (0.2011)	Prec@1 90.625 (93.136)
Epoch: [53][280/391]	Time 0.042 (0.048)	Loss 0.2093 (0.2026)	Prec@1 95.312 (93.033)
Epoch: [53][300/391]	Time 0.042 (0.048)	Loss 0.2398 (0.2021)	Prec@1 92.188 (93.065)
Epoch: [53][320/391]	Time 0.042 (0.048)	Loss 0.1916 (0.2021)	Prec@1 92.969 (93.056)
Epoch: [53][340/391]	Time 0.042 (0.048)	Loss 0.1917 (0.2024)	Prec@1 92.969 (93.051)
Epoch: [53][360/391]	Time 0.043 (0.048)	Loss 0.2699 (0.2027)	Prec@1 92.188 (93.036)
Epoch: [53][380/391]	Time 0.045 (0.047)	Loss 0.2187 (0.2029)	Prec@1 92.969 (93.034)
training time:  18.675784826278687
Test: [0/79]	Time 0.785 (0.785)	Loss 0.3497 (0.3497)	Prec@1 90.625 (90.625)
Test: [20/79]	Time 0.033 (0.066)	Loss 0.3350 (0.3150)	Prec@1 89.062 (89.732)
Test: [40/79]	Time 0.032 (0.049)	Loss 0.4659 (0.3187)	Prec@1 85.156 (89.615)
Test: [60/79]	Time 0.031 (0.043)	Loss 0.2909 (0.3165)	Prec@1 89.844 (89.600)
 * Prec@1 89.590
Epoch: [54][0/391]	Time 0.827 (0.827)	Loss 0.2024 (0.2024)	Prec@1 92.969 (92.969)
Epoch: [54][20/391]	Time 0.046 (0.082)	Loss 0.1562 (0.1971)	Prec@1 93.750 (93.118)
Epoch: [54][40/391]	Time 0.043 (0.064)	Loss 0.1137 (0.1809)	Prec@1 97.656 (93.788)
Epoch: [54][60/391]	Time 0.045 (0.057)	Loss 0.2574 (0.1871)	Prec@1 92.969 (93.699)
Epoch: [54][80/391]	Time 0.043 (0.054)	Loss 0.1482 (0.1842)	Prec@1 95.312 (93.721)
Epoch: [54][100/391]	Time 0.045 (0.051)	Loss 0.1606 (0.1825)	Prec@1 92.969 (93.796)
Epoch: [54][120/391]	Time 0.042 (0.050)	Loss 0.1818 (0.1844)	Prec@1 94.531 (93.718)
Epoch: [54][140/391]	Time 0.047 (0.050)	Loss 0.2196 (0.1865)	Prec@1 92.188 (93.700)
Epoch: [54][160/391]	Time 0.043 (0.049)	Loss 0.3059 (0.1893)	Prec@1 91.406 (93.604)
Epoch: [54][180/391]	Time 0.044 (0.049)	Loss 0.1882 (0.1892)	Prec@1 92.969 (93.612)
Epoch: [54][200/391]	Time 0.046 (0.049)	Loss 0.1147 (0.1882)	Prec@1 96.094 (93.703)
Epoch: [54][220/391]	Time 0.050 (0.048)	Loss 0.1600 (0.1883)	Prec@1 96.094 (93.704)
Epoch: [54][240/391]	Time 0.046 (0.048)	Loss 0.1732 (0.1878)	Prec@1 93.750 (93.695)
Epoch: [54][260/391]	Time 0.047 (0.048)	Loss 0.1516 (0.1883)	Prec@1 96.094 (93.726)
Epoch: [54][280/391]	Time 0.047 (0.048)	Loss 0.2005 (0.1892)	Prec@1 92.188 (93.711)
Epoch: [54][300/391]	Time 0.046 (0.048)	Loss 0.1512 (0.1903)	Prec@1 93.750 (93.644)
Epoch: [54][320/391]	Time 0.049 (0.048)	Loss 0.2865 (0.1925)	Prec@1 92.969 (93.611)
Epoch: [54][340/391]	Time 0.049 (0.048)	Loss 0.1867 (0.1923)	Prec@1 91.406 (93.599)
Epoch: [54][360/391]	Time 0.048 (0.048)	Loss 0.2428 (0.1926)	Prec@1 91.406 (93.564)
Epoch: [54][380/391]	Time 0.045 (0.048)	Loss 0.2313 (0.1936)	Prec@1 92.188 (93.522)
training time:  18.739267587661743
Test: [0/79]	Time 0.787 (0.787)	Loss 0.4126 (0.4126)	Prec@1 85.938 (85.938)
Test: [20/79]	Time 0.029 (0.067)	Loss 0.3573 (0.3973)	Prec@1 89.844 (87.388)
Test: [40/79]	Time 0.033 (0.050)	Loss 0.4780 (0.3920)	Prec@1 83.594 (87.500)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.3352 (0.3831)	Prec@1 89.062 (87.948)
 * Prec@1 87.960
Epoch: [55][0/391]	Time 0.827 (0.827)	Loss 0.1749 (0.1749)	Prec@1 92.969 (92.969)
Epoch: [55][20/391]	Time 0.045 (0.084)	Loss 0.1697 (0.1676)	Prec@1 92.969 (94.196)
Epoch: [55][40/391]	Time 0.046 (0.065)	Loss 0.1663 (0.1714)	Prec@1 95.312 (94.055)
Epoch: [55][60/391]	Time 0.047 (0.059)	Loss 0.1559 (0.1653)	Prec@1 96.094 (94.109)
Epoch: [55][80/391]	Time 0.046 (0.056)	Loss 0.1428 (0.1691)	Prec@1 95.312 (94.097)
Epoch: [55][100/391]	Time 0.046 (0.054)	Loss 0.2368 (0.1736)	Prec@1 89.062 (93.982)
Epoch: [55][120/391]	Time 0.046 (0.053)	Loss 0.2626 (0.1768)	Prec@1 92.969 (93.840)
Epoch: [55][140/391]	Time 0.045 (0.052)	Loss 0.1877 (0.1756)	Prec@1 94.531 (93.889)
Epoch: [55][160/391]	Time 0.045 (0.051)	Loss 0.1952 (0.1775)	Prec@1 94.531 (93.857)
Epoch: [55][180/391]	Time 0.044 (0.051)	Loss 0.1401 (0.1780)	Prec@1 96.094 (93.836)
Epoch: [55][200/391]	Time 0.045 (0.050)	Loss 0.1834 (0.1786)	Prec@1 92.969 (93.812)
Epoch: [55][220/391]	Time 0.046 (0.050)	Loss 0.1771 (0.1793)	Prec@1 92.969 (93.792)
Epoch: [55][240/391]	Time 0.046 (0.049)	Loss 0.1433 (0.1811)	Prec@1 95.312 (93.714)
Epoch: [55][260/391]	Time 0.046 (0.049)	Loss 0.1296 (0.1840)	Prec@1 94.531 (93.636)
Epoch: [55][280/391]	Time 0.046 (0.049)	Loss 0.2340 (0.1849)	Prec@1 92.188 (93.605)
Epoch: [55][300/391]	Time 0.045 (0.049)	Loss 0.0842 (0.1864)	Prec@1 98.438 (93.571)
Epoch: [55][320/391]	Time 0.046 (0.049)	Loss 0.2086 (0.1868)	Prec@1 92.188 (93.526)
Epoch: [55][340/391]	Time 0.044 (0.049)	Loss 0.2137 (0.1888)	Prec@1 92.969 (93.441)
Epoch: [55][360/391]	Time 0.045 (0.048)	Loss 0.1901 (0.1906)	Prec@1 93.750 (93.371)
Epoch: [55][380/391]	Time 0.045 (0.048)	Loss 0.2018 (0.1905)	Prec@1 91.406 (93.375)
training time:  19.04512119293213
Test: [0/79]	Time 0.751 (0.751)	Loss 0.2590 (0.2590)	Prec@1 93.750 (93.750)
Test: [20/79]	Time 0.032 (0.066)	Loss 0.3366 (0.3112)	Prec@1 89.062 (89.769)
Test: [40/79]	Time 0.031 (0.049)	Loss 0.3772 (0.3089)	Prec@1 87.500 (89.672)
Test: [60/79]	Time 0.029 (0.044)	Loss 0.2869 (0.2997)	Prec@1 92.188 (89.831)
 * Prec@1 89.950
=> Saving checkpoint for epoch 55, with Prec@1 89.950000.
Epoch: [56][0/391]	Time 0.783 (0.783)	Loss 0.2521 (0.2521)	Prec@1 90.625 (90.625)
Epoch: [56][20/391]	Time 0.042 (0.080)	Loss 0.2879 (0.1833)	Prec@1 89.844 (93.527)
Epoch: [56][40/391]	Time 0.046 (0.063)	Loss 0.1889 (0.1775)	Prec@1 92.969 (93.845)
Epoch: [56][60/391]	Time 0.046 (0.057)	Loss 0.2072 (0.1787)	Prec@1 92.969 (93.852)
Epoch: [56][80/391]	Time 0.045 (0.055)	Loss 0.2332 (0.1792)	Prec@1 92.969 (93.808)
Epoch: [56][100/391]	Time 0.045 (0.053)	Loss 0.1752 (0.1781)	Prec@1 94.531 (93.951)
Epoch: [56][120/391]	Time 0.046 (0.052)	Loss 0.2131 (0.1818)	Prec@1 93.750 (93.879)
Epoch: [56][140/391]	Time 0.046 (0.051)	Loss 0.1664 (0.1852)	Prec@1 93.750 (93.794)
Epoch: [56][160/391]	Time 0.047 (0.050)	Loss 0.0872 (0.1835)	Prec@1 96.875 (93.886)
Epoch: [56][180/391]	Time 0.187 (0.051)	Loss 0.3494 (0.1820)	Prec@1 87.500 (93.923)
Epoch: [56][200/391]	Time 0.042 (0.050)	Loss 0.1204 (0.1830)	Prec@1 96.094 (93.855)
Epoch: [56][220/391]	Time 0.045 (0.050)	Loss 0.2009 (0.1837)	Prec@1 92.188 (93.810)
Epoch: [56][240/391]	Time 0.046 (0.049)	Loss 0.1893 (0.1839)	Prec@1 93.750 (93.818)
Epoch: [56][260/391]	Time 0.046 (0.049)	Loss 0.2374 (0.1854)	Prec@1 93.750 (93.816)
Epoch: [56][280/391]	Time 0.044 (0.049)	Loss 0.1851 (0.1841)	Prec@1 92.969 (93.831)
Epoch: [56][300/391]	Time 0.045 (0.049)	Loss 0.1395 (0.1845)	Prec@1 94.531 (93.781)
Epoch: [56][320/391]	Time 0.046 (0.049)	Loss 0.1671 (0.1859)	Prec@1 92.969 (93.731)
Epoch: [56][340/391]	Time 0.045 (0.048)	Loss 0.2242 (0.1862)	Prec@1 92.188 (93.700)
Epoch: [56][360/391]	Time 0.044 (0.048)	Loss 0.2918 (0.1865)	Prec@1 89.844 (93.707)
Epoch: [56][380/391]	Time 0.048 (0.048)	Loss 0.1171 (0.1861)	Prec@1 95.312 (93.699)
training time:  18.996726274490356
Test: [0/79]	Time 0.784 (0.784)	Loss 0.2453 (0.2453)	Prec@1 92.188 (92.188)
Test: [20/79]	Time 0.030 (0.066)	Loss 0.2662 (0.3662)	Prec@1 89.062 (87.984)
Test: [40/79]	Time 0.029 (0.048)	Loss 0.5135 (0.3867)	Prec@1 84.375 (87.557)
Test: [60/79]	Time 0.031 (0.043)	Loss 0.4310 (0.3765)	Prec@1 88.281 (88.025)
 * Prec@1 88.000
Epoch: [57][0/391]	Time 0.815 (0.815)	Loss 0.1926 (0.1926)	Prec@1 96.094 (96.094)
Epoch: [57][20/391]	Time 0.047 (0.083)	Loss 0.0988 (0.1614)	Prec@1 97.656 (94.754)
Epoch: [57][40/391]	Time 0.047 (0.065)	Loss 0.1949 (0.1573)	Prec@1 93.750 (94.798)
Epoch: [57][60/391]	Time 0.044 (0.059)	Loss 0.1817 (0.1624)	Prec@1 92.188 (94.493)
Epoch: [57][80/391]	Time 0.046 (0.055)	Loss 0.1185 (0.1656)	Prec@1 96.094 (94.329)
Epoch: [57][100/391]	Time 0.044 (0.053)	Loss 0.1590 (0.1708)	Prec@1 92.969 (94.168)
Epoch: [57][120/391]	Time 0.044 (0.052)	Loss 0.1374 (0.1729)	Prec@1 94.531 (94.079)
Epoch: [57][140/391]	Time 0.045 (0.051)	Loss 0.1320 (0.1712)	Prec@1 97.656 (94.160)
Epoch: [57][160/391]	Time 0.047 (0.051)	Loss 0.1493 (0.1682)	Prec@1 92.969 (94.284)
Epoch: [57][180/391]	Time 0.050 (0.050)	Loss 0.1108 (0.1706)	Prec@1 95.312 (94.182)
Epoch: [57][200/391]	Time 0.047 (0.050)	Loss 0.1971 (0.1739)	Prec@1 92.969 (94.018)
Epoch: [57][220/391]	Time 0.047 (0.049)	Loss 0.0945 (0.1727)	Prec@1 98.438 (94.065)
Epoch: [57][240/391]	Time 0.049 (0.049)	Loss 0.1685 (0.1746)	Prec@1 95.312 (94.016)
Epoch: [57][260/391]	Time 0.047 (0.049)	Loss 0.1058 (0.1756)	Prec@1 96.875 (93.974)
Epoch: [57][280/391]	Time 0.046 (0.049)	Loss 0.2072 (0.1769)	Prec@1 92.188 (93.945)
Epoch: [57][300/391]	Time 0.048 (0.049)	Loss 0.1808 (0.1785)	Prec@1 95.312 (93.877)
Epoch: [57][320/391]	Time 0.046 (0.049)	Loss 0.1277 (0.1786)	Prec@1 96.875 (93.874)
Epoch: [57][340/391]	Time 0.050 (0.048)	Loss 0.1998 (0.1790)	Prec@1 92.188 (93.865)
Epoch: [57][360/391]	Time 0.043 (0.048)	Loss 0.1478 (0.1800)	Prec@1 92.969 (93.826)
Epoch: [57][380/391]	Time 0.042 (0.048)	Loss 0.2137 (0.1800)	Prec@1 93.750 (93.809)
training time:  18.940195083618164
Test: [0/79]	Time 0.792 (0.792)	Loss 0.2581 (0.2581)	Prec@1 89.062 (89.062)
Test: [20/79]	Time 0.030 (0.067)	Loss 0.3478 (0.3003)	Prec@1 84.375 (90.104)
Test: [40/79]	Time 0.029 (0.049)	Loss 0.3367 (0.2912)	Prec@1 88.281 (90.377)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.2209 (0.2863)	Prec@1 92.969 (90.625)
 * Prec@1 90.500
=> Saving checkpoint for epoch 57, with Prec@1 90.500000.
Epoch: [58][0/391]	Time 0.824 (0.824)	Loss 0.1900 (0.1900)	Prec@1 92.969 (92.969)
Epoch: [58][20/391]	Time 0.047 (0.083)	Loss 0.1867 (0.1611)	Prec@1 92.969 (94.568)
Epoch: [58][40/391]	Time 0.045 (0.065)	Loss 0.2027 (0.1550)	Prec@1 93.750 (94.855)
Epoch: [58][60/391]	Time 0.046 (0.059)	Loss 0.2234 (0.1578)	Prec@1 92.188 (94.749)
Epoch: [58][80/391]	Time 0.045 (0.056)	Loss 0.1074 (0.1630)	Prec@1 96.875 (94.512)
Epoch: [58][100/391]	Time 0.043 (0.054)	Loss 0.1645 (0.1661)	Prec@1 93.750 (94.307)
Epoch: [58][120/391]	Time 0.047 (0.053)	Loss 0.1850 (0.1658)	Prec@1 93.750 (94.196)
Epoch: [58][140/391]	Time 0.041 (0.052)	Loss 0.1720 (0.1674)	Prec@1 94.531 (94.099)
Epoch: [58][160/391]	Time 0.044 (0.051)	Loss 0.1607 (0.1684)	Prec@1 95.312 (94.143)
Epoch: [58][180/391]	Time 0.046 (0.050)	Loss 0.1398 (0.1692)	Prec@1 95.312 (94.104)
Epoch: [58][200/391]	Time 0.046 (0.050)	Loss 0.1121 (0.1697)	Prec@1 96.875 (94.084)
Epoch: [58][220/391]	Time 0.047 (0.050)	Loss 0.0953 (0.1713)	Prec@1 96.875 (94.089)
Epoch: [58][240/391]	Time 0.047 (0.050)	Loss 0.1284 (0.1711)	Prec@1 95.312 (94.107)
Epoch: [58][260/391]	Time 0.046 (0.049)	Loss 0.1266 (0.1718)	Prec@1 94.531 (94.058)
Epoch: [58][280/391]	Time 0.046 (0.049)	Loss 0.2252 (0.1716)	Prec@1 92.969 (94.047)
Epoch: [58][300/391]	Time 0.046 (0.049)	Loss 0.1153 (0.1712)	Prec@1 96.875 (94.074)
Epoch: [58][320/391]	Time 0.048 (0.049)	Loss 0.0920 (0.1702)	Prec@1 97.656 (94.093)
Epoch: [58][340/391]	Time 0.045 (0.049)	Loss 0.1931 (0.1711)	Prec@1 92.969 (94.052)
Epoch: [58][360/391]	Time 0.046 (0.049)	Loss 0.1718 (0.1696)	Prec@1 95.312 (94.129)
Epoch: [58][380/391]	Time 0.044 (0.048)	Loss 0.2086 (0.1698)	Prec@1 93.750 (94.117)
training time:  19.08817172050476
Test: [0/79]	Time 0.748 (0.748)	Loss 0.3986 (0.3986)	Prec@1 88.281 (88.281)
Test: [20/79]	Time 0.031 (0.066)	Loss 0.3302 (0.3581)	Prec@1 89.062 (88.951)
Test: [40/79]	Time 0.030 (0.050)	Loss 0.3339 (0.3464)	Prec@1 86.719 (89.253)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.3718 (0.3257)	Prec@1 91.406 (89.908)
 * Prec@1 89.740
Epoch: [59][0/391]	Time 0.785 (0.785)	Loss 0.0903 (0.0903)	Prec@1 97.656 (97.656)
Epoch: [59][20/391]	Time 0.046 (0.081)	Loss 0.0813 (0.1489)	Prec@1 97.656 (95.201)
Epoch: [59][40/391]	Time 0.047 (0.064)	Loss 0.0666 (0.1439)	Prec@1 99.219 (95.351)
Epoch: [59][60/391]	Time 0.046 (0.058)	Loss 0.1625 (0.1449)	Prec@1 95.312 (95.197)
Epoch: [59][80/391]	Time 0.045 (0.055)	Loss 0.1588 (0.1410)	Prec@1 95.312 (95.303)
Epoch: [59][100/391]	Time 0.046 (0.053)	Loss 0.1333 (0.1412)	Prec@1 96.875 (95.312)
Epoch: [59][120/391]	Time 0.046 (0.052)	Loss 0.2344 (0.1462)	Prec@1 92.188 (95.087)
Epoch: [59][140/391]	Time 0.045 (0.051)	Loss 0.1250 (0.1501)	Prec@1 96.094 (94.925)
Epoch: [59][160/391]	Time 0.046 (0.051)	Loss 0.0871 (0.1546)	Prec@1 96.875 (94.754)
Epoch: [59][180/391]	Time 0.045 (0.050)	Loss 0.1337 (0.1527)	Prec@1 95.312 (94.777)
Epoch: [59][200/391]	Time 0.046 (0.049)	Loss 0.1863 (0.1555)	Prec@1 92.188 (94.675)
Epoch: [59][220/391]	Time 0.042 (0.049)	Loss 0.1182 (0.1556)	Prec@1 96.875 (94.687)
Epoch: [59][240/391]	Time 0.042 (0.049)	Loss 0.1692 (0.1567)	Prec@1 95.312 (94.629)
Epoch: [59][260/391]	Time 0.046 (0.048)	Loss 0.1669 (0.1589)	Prec@1 96.094 (94.549)
Epoch: [59][280/391]	Time 0.046 (0.048)	Loss 0.1522 (0.1601)	Prec@1 95.312 (94.523)
Epoch: [59][300/391]	Time 0.045 (0.048)	Loss 0.1548 (0.1612)	Prec@1 93.750 (94.472)
Epoch: [59][320/391]	Time 0.047 (0.048)	Loss 0.1633 (0.1632)	Prec@1 95.312 (94.419)
Epoch: [59][340/391]	Time 0.047 (0.048)	Loss 0.3143 (0.1642)	Prec@1 92.188 (94.394)
Epoch: [59][360/391]	Time 0.046 (0.048)	Loss 0.1690 (0.1655)	Prec@1 93.750 (94.362)
Epoch: [59][380/391]	Time 0.045 (0.048)	Loss 0.2145 (0.1657)	Prec@1 94.531 (94.347)
training time:  18.796019554138184
Test: [0/79]	Time 0.748 (0.748)	Loss 0.2197 (0.2197)	Prec@1 92.969 (92.969)
Test: [20/79]	Time 0.032 (0.066)	Loss 0.2350 (0.2886)	Prec@1 94.531 (90.848)
Test: [40/79]	Time 0.033 (0.049)	Loss 0.4413 (0.2915)	Prec@1 86.719 (90.835)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.1935 (0.2919)	Prec@1 92.188 (90.830)
 * Prec@1 90.970
=> Saving checkpoint for epoch 59, with Prec@1 90.970000.
Epoch: [60][0/391]	Time 0.779 (0.779)	Loss 0.1003 (0.1003)	Prec@1 98.438 (98.438)
Epoch: [60][20/391]	Time 0.048 (0.082)	Loss 0.2125 (0.1457)	Prec@1 92.188 (95.015)
Epoch: [60][40/391]	Time 0.045 (0.065)	Loss 0.0684 (0.1418)	Prec@1 97.656 (95.198)
Epoch: [60][60/391]	Time 0.046 (0.059)	Loss 0.2302 (0.1468)	Prec@1 91.406 (95.120)
Epoch: [60][80/391]	Time 0.048 (0.056)	Loss 0.1346 (0.1524)	Prec@1 93.750 (94.956)
Epoch: [60][100/391]	Time 0.048 (0.054)	Loss 0.1624 (0.1536)	Prec@1 93.750 (94.864)
Epoch: [60][120/391]	Time 0.047 (0.053)	Loss 0.1086 (0.1539)	Prec@1 96.094 (94.835)
Epoch: [60][140/391]	Time 0.043 (0.051)	Loss 0.1896 (0.1547)	Prec@1 89.844 (94.742)
Epoch: [60][160/391]	Time 0.044 (0.051)	Loss 0.2053 (0.1528)	Prec@1 94.531 (94.793)
Epoch: [60][180/391]	Time 0.043 (0.050)	Loss 0.1571 (0.1538)	Prec@1 93.750 (94.769)
Epoch: [60][200/391]	Time 0.046 (0.050)	Loss 0.2478 (0.1543)	Prec@1 92.969 (94.733)
Epoch: [60][220/391]	Time 0.047 (0.050)	Loss 0.1267 (0.1549)	Prec@1 95.312 (94.736)
Epoch: [60][240/391]	Time 0.046 (0.050)	Loss 0.1246 (0.1554)	Prec@1 96.094 (94.755)
Epoch: [60][260/391]	Time 0.047 (0.049)	Loss 0.2328 (0.1570)	Prec@1 89.062 (94.675)
Epoch: [60][280/391]	Time 0.045 (0.049)	Loss 0.1364 (0.1584)	Prec@1 92.969 (94.637)
Epoch: [60][300/391]	Time 0.044 (0.049)	Loss 0.1352 (0.1588)	Prec@1 94.531 (94.627)
Epoch: [60][320/391]	Time 0.047 (0.049)	Loss 0.1118 (0.1589)	Prec@1 96.094 (94.658)
Epoch: [60][340/391]	Time 0.047 (0.049)	Loss 0.1380 (0.1595)	Prec@1 94.531 (94.630)
Epoch: [60][360/391]	Time 0.046 (0.049)	Loss 0.1335 (0.1598)	Prec@1 94.531 (94.637)
Epoch: [60][380/391]	Time 0.046 (0.048)	Loss 0.1837 (0.1599)	Prec@1 96.094 (94.648)
training time:  19.088281869888306
Test: [0/79]	Time 0.747 (0.747)	Loss 0.4189 (0.4189)	Prec@1 90.625 (90.625)
Test: [20/79]	Time 0.032 (0.064)	Loss 0.4136 (0.3504)	Prec@1 87.500 (89.174)
Test: [40/79]	Time 0.028 (0.047)	Loss 0.5400 (0.3351)	Prec@1 82.812 (89.482)
Test: [60/79]	Time 0.032 (0.042)	Loss 0.2611 (0.3229)	Prec@1 92.969 (89.805)
 * Prec@1 89.800
Epoch: [61][0/391]	Time 0.776 (0.776)	Loss 0.1651 (0.1651)	Prec@1 93.750 (93.750)
Epoch: [61][20/391]	Time 0.047 (0.081)	Loss 0.1611 (0.1425)	Prec@1 96.875 (94.606)
Epoch: [61][40/391]	Time 0.046 (0.064)	Loss 0.1193 (0.1453)	Prec@1 96.094 (94.970)
Epoch: [61][60/391]	Time 0.047 (0.058)	Loss 0.1489 (0.1434)	Prec@1 95.312 (95.018)
Epoch: [61][80/391]	Time 0.046 (0.055)	Loss 0.1729 (0.1442)	Prec@1 94.531 (94.994)
Epoch: [61][100/391]	Time 0.046 (0.054)	Loss 0.1459 (0.1456)	Prec@1 96.094 (94.895)
Epoch: [61][120/391]	Time 0.043 (0.052)	Loss 0.1890 (0.1434)	Prec@1 92.969 (94.964)
Epoch: [61][140/391]	Time 0.044 (0.051)	Loss 0.1112 (0.1466)	Prec@1 97.656 (94.819)
Epoch: [61][160/391]	Time 0.045 (0.051)	Loss 0.1679 (0.1471)	Prec@1 94.531 (94.779)
Epoch: [61][180/391]	Time 0.044 (0.050)	Loss 0.1671 (0.1464)	Prec@1 95.312 (94.877)
Epoch: [61][200/391]	Time 0.046 (0.050)	Loss 0.2128 (0.1453)	Prec@1 93.750 (94.935)
Epoch: [61][220/391]	Time 0.047 (0.049)	Loss 0.1115 (0.1456)	Prec@1 96.875 (94.941)
Epoch: [61][240/391]	Time 0.047 (0.049)	Loss 0.1929 (0.1474)	Prec@1 92.188 (94.859)
Epoch: [61][260/391]	Time 0.047 (0.049)	Loss 0.1644 (0.1482)	Prec@1 95.312 (94.861)
Epoch: [61][280/391]	Time 0.045 (0.048)	Loss 0.1561 (0.1493)	Prec@1 96.094 (94.829)
Epoch: [61][300/391]	Time 0.046 (0.048)	Loss 0.1985 (0.1511)	Prec@1 92.969 (94.767)
Epoch: [61][320/391]	Time 0.048 (0.048)	Loss 0.1402 (0.1527)	Prec@1 95.312 (94.711)
Epoch: [61][340/391]	Time 0.044 (0.048)	Loss 0.2719 (0.1545)	Prec@1 91.406 (94.666)
Epoch: [61][360/391]	Time 0.046 (0.048)	Loss 0.1370 (0.1543)	Prec@1 96.094 (94.691)
Epoch: [61][380/391]	Time 0.044 (0.048)	Loss 0.1941 (0.1546)	Prec@1 92.969 (94.691)
training time:  18.83166003227234
Test: [0/79]	Time 0.795 (0.795)	Loss 0.2420 (0.2420)	Prec@1 92.969 (92.969)
Test: [20/79]	Time 0.032 (0.068)	Loss 0.2497 (0.2927)	Prec@1 89.844 (90.402)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.4015 (0.2824)	Prec@1 87.500 (90.473)
Test: [60/79]	Time 0.028 (0.044)	Loss 0.1931 (0.2704)	Prec@1 91.406 (91.009)
 * Prec@1 91.100
=> Saving checkpoint for epoch 61, with Prec@1 91.100000.
Epoch: [62][0/391]	Time 0.783 (0.783)	Loss 0.1310 (0.1310)	Prec@1 93.750 (93.750)
Epoch: [62][20/391]	Time 0.044 (0.081)	Loss 0.1014 (0.1375)	Prec@1 97.656 (95.350)
Epoch: [62][40/391]	Time 0.042 (0.063)	Loss 0.0962 (0.1362)	Prec@1 96.875 (95.465)
Epoch: [62][60/391]	Time 0.043 (0.056)	Loss 0.1771 (0.1406)	Prec@1 93.750 (95.261)
Epoch: [62][80/391]	Time 0.042 (0.053)	Loss 0.1210 (0.1377)	Prec@1 94.531 (95.332)
Epoch: [62][100/391]	Time 0.043 (0.051)	Loss 0.1244 (0.1407)	Prec@1 96.094 (95.235)
Epoch: [62][120/391]	Time 0.045 (0.051)	Loss 0.1913 (0.1412)	Prec@1 92.188 (95.216)
Epoch: [62][140/391]	Time 0.047 (0.050)	Loss 0.1089 (0.1411)	Prec@1 96.094 (95.157)
Epoch: [62][160/391]	Time 0.043 (0.049)	Loss 0.1963 (0.1411)	Prec@1 90.625 (95.128)
Epoch: [62][180/391]	Time 0.042 (0.048)	Loss 0.1949 (0.1418)	Prec@1 93.750 (95.118)
Epoch: [62][200/391]	Time 0.043 (0.049)	Loss 0.1671 (0.1422)	Prec@1 95.312 (95.106)
Epoch: [62][220/391]	Time 0.043 (0.048)	Loss 0.0759 (0.1419)	Prec@1 99.219 (95.139)
Epoch: [62][240/391]	Time 0.046 (0.048)	Loss 0.1265 (0.1415)	Prec@1 96.094 (95.137)
Epoch: [62][260/391]	Time 0.046 (0.048)	Loss 0.1939 (0.1439)	Prec@1 95.312 (95.073)
Epoch: [62][280/391]	Time 0.046 (0.048)	Loss 0.1805 (0.1451)	Prec@1 95.312 (95.032)
Epoch: [62][300/391]	Time 0.045 (0.048)	Loss 0.1829 (0.1446)	Prec@1 95.312 (95.050)
Epoch: [62][320/391]	Time 0.045 (0.048)	Loss 0.1677 (0.1439)	Prec@1 94.531 (95.074)
Epoch: [62][340/391]	Time 0.047 (0.048)	Loss 0.1731 (0.1434)	Prec@1 93.750 (95.077)
Epoch: [62][360/391]	Time 0.046 (0.047)	Loss 0.0934 (0.1426)	Prec@1 97.656 (95.107)
Epoch: [62][380/391]	Time 0.046 (0.047)	Loss 0.1457 (0.1428)	Prec@1 96.094 (95.122)
training time:  18.641212224960327
Test: [0/79]	Time 0.733 (0.733)	Loss 0.3880 (0.3880)	Prec@1 89.844 (89.844)
Test: [20/79]	Time 0.032 (0.065)	Loss 0.2004 (0.2973)	Prec@1 91.406 (90.737)
Test: [40/79]	Time 0.032 (0.049)	Loss 0.3005 (0.2885)	Prec@1 88.281 (90.587)
Test: [60/79]	Time 0.031 (0.043)	Loss 0.2598 (0.2795)	Prec@1 90.625 (90.971)
 * Prec@1 91.070
Epoch: [63][0/391]	Time 0.790 (0.790)	Loss 0.1257 (0.1257)	Prec@1 96.094 (96.094)
Epoch: [63][20/391]	Time 0.048 (0.081)	Loss 0.1533 (0.1233)	Prec@1 94.531 (95.647)
Epoch: [63][40/391]	Time 0.042 (0.063)	Loss 0.0804 (0.1235)	Prec@1 97.656 (95.770)
Epoch: [63][60/391]	Time 0.047 (0.058)	Loss 0.1594 (0.1274)	Prec@1 95.312 (95.620)
Epoch: [63][80/391]	Time 0.046 (0.055)	Loss 0.1423 (0.1282)	Prec@1 94.531 (95.640)
Epoch: [63][100/391]	Time 0.047 (0.053)	Loss 0.1690 (0.1329)	Prec@1 92.188 (95.483)
Epoch: [63][120/391]	Time 0.046 (0.052)	Loss 0.1717 (0.1329)	Prec@1 94.531 (95.526)
Epoch: [63][140/391]	Time 0.047 (0.051)	Loss 0.0630 (0.1343)	Prec@1 99.219 (95.457)
Epoch: [63][160/391]	Time 0.046 (0.050)	Loss 0.1918 (0.1348)	Prec@1 94.531 (95.414)
Epoch: [63][180/391]	Time 0.046 (0.050)	Loss 0.1863 (0.1360)	Prec@1 92.969 (95.407)
Epoch: [63][200/391]	Time 0.047 (0.050)	Loss 0.0682 (0.1357)	Prec@1 97.656 (95.398)
Epoch: [63][220/391]	Time 0.046 (0.049)	Loss 0.1162 (0.1369)	Prec@1 96.875 (95.351)
Epoch: [63][240/391]	Time 0.046 (0.049)	Loss 0.1403 (0.1368)	Prec@1 95.312 (95.351)
Epoch: [63][260/391]	Time 0.045 (0.049)	Loss 0.2845 (0.1379)	Prec@1 90.625 (95.330)
Epoch: [63][280/391]	Time 0.046 (0.049)	Loss 0.1216 (0.1377)	Prec@1 95.312 (95.351)
Epoch: [63][300/391]	Time 0.047 (0.048)	Loss 0.2312 (0.1401)	Prec@1 92.188 (95.253)
Epoch: [63][320/391]	Time 0.048 (0.048)	Loss 0.1501 (0.1418)	Prec@1 96.094 (95.188)
Epoch: [63][340/391]	Time 0.047 (0.048)	Loss 0.1272 (0.1419)	Prec@1 95.312 (95.180)
Epoch: [63][360/391]	Time 0.048 (0.048)	Loss 0.0593 (0.1419)	Prec@1 99.219 (95.187)
Epoch: [63][380/391]	Time 0.046 (0.048)	Loss 0.0968 (0.1429)	Prec@1 96.875 (95.130)
training time:  18.925541639328003
Test: [0/79]	Time 0.740 (0.740)	Loss 0.3475 (0.3475)	Prec@1 92.969 (92.969)
Test: [20/79]	Time 0.033 (0.065)	Loss 0.3742 (0.3009)	Prec@1 91.406 (90.774)
Test: [40/79]	Time 0.033 (0.049)	Loss 0.4599 (0.2981)	Prec@1 84.375 (90.796)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.2132 (0.2858)	Prec@1 94.531 (91.214)
 * Prec@1 91.190
=> Saving checkpoint for epoch 63, with Prec@1 91.190000.
Epoch: [64][0/391]	Time 0.824 (0.824)	Loss 0.1512 (0.1512)	Prec@1 95.312 (95.312)
Epoch: [64][20/391]	Time 0.046 (0.083)	Loss 0.0932 (0.1262)	Prec@1 95.312 (95.424)
Epoch: [64][40/391]	Time 0.048 (0.065)	Loss 0.1315 (0.1283)	Prec@1 95.312 (95.408)
Epoch: [64][60/391]	Time 0.046 (0.059)	Loss 0.1239 (0.1275)	Prec@1 94.531 (95.479)
Epoch: [64][80/391]	Time 0.043 (0.055)	Loss 0.1532 (0.1306)	Prec@1 94.531 (95.322)
Epoch: [64][100/391]	Time 0.046 (0.053)	Loss 0.1427 (0.1281)	Prec@1 94.531 (95.436)
Epoch: [64][120/391]	Time 0.042 (0.052)	Loss 0.1613 (0.1288)	Prec@1 95.312 (95.461)
Epoch: [64][140/391]	Time 0.044 (0.050)	Loss 0.1522 (0.1313)	Prec@1 94.531 (95.407)
Epoch: [64][160/391]	Time 0.047 (0.050)	Loss 0.1086 (0.1314)	Prec@1 96.094 (95.448)
Epoch: [64][180/391]	Time 0.046 (0.049)	Loss 0.1187 (0.1319)	Prec@1 95.312 (95.464)
Epoch: [64][200/391]	Time 0.045 (0.050)	Loss 0.0618 (0.1310)	Prec@1 98.438 (95.538)
Epoch: [64][220/391]	Time 0.048 (0.049)	Loss 0.1068 (0.1308)	Prec@1 95.312 (95.556)
Epoch: [64][240/391]	Time 0.048 (0.049)	Loss 0.0824 (0.1287)	Prec@1 97.656 (95.630)
Epoch: [64][260/391]	Time 0.046 (0.049)	Loss 0.0736 (0.1284)	Prec@1 99.219 (95.627)
Epoch: [64][280/391]	Time 0.049 (0.049)	Loss 0.0686 (0.1289)	Prec@1 97.656 (95.593)
Epoch: [64][300/391]	Time 0.046 (0.049)	Loss 0.1399 (0.1287)	Prec@1 94.531 (95.590)
Epoch: [64][320/391]	Time 0.047 (0.048)	Loss 0.1783 (0.1294)	Prec@1 92.188 (95.583)
Epoch: [64][340/391]	Time 0.047 (0.048)	Loss 0.1799 (0.1311)	Prec@1 91.406 (95.512)
Epoch: [64][360/391]	Time 0.046 (0.048)	Loss 0.1783 (0.1334)	Prec@1 93.750 (95.423)
Epoch: [64][380/391]	Time 0.044 (0.048)	Loss 0.2172 (0.1350)	Prec@1 92.969 (95.333)
training time:  18.9231173992157
Test: [0/79]	Time 0.781 (0.781)	Loss 0.2590 (0.2590)	Prec@1 89.844 (89.844)
Test: [20/79]	Time 0.032 (0.067)	Loss 0.2565 (0.2741)	Prec@1 90.625 (90.811)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.3070 (0.2763)	Prec@1 87.500 (91.120)
Test: [60/79]	Time 0.030 (0.044)	Loss 0.2536 (0.2713)	Prec@1 92.188 (91.189)
 * Prec@1 91.180
Epoch: [65][0/391]	Time 0.841 (0.841)	Loss 0.1278 (0.1278)	Prec@1 93.750 (93.750)
Epoch: [65][20/391]	Time 0.045 (0.084)	Loss 0.1220 (0.1268)	Prec@1 94.531 (95.536)
Epoch: [65][40/391]	Time 0.046 (0.066)	Loss 0.0538 (0.1250)	Prec@1 98.438 (95.655)
Epoch: [65][60/391]	Time 0.046 (0.059)	Loss 0.0695 (0.1231)	Prec@1 97.656 (95.953)
Epoch: [65][80/391]	Time 0.047 (0.056)	Loss 0.1235 (0.1183)	Prec@1 96.094 (96.026)
Epoch: [65][100/391]	Time 0.046 (0.054)	Loss 0.1030 (0.1187)	Prec@1 96.875 (96.040)
Epoch: [65][120/391]	Time 0.047 (0.053)	Loss 0.2403 (0.1228)	Prec@1 92.969 (95.868)
Epoch: [65][140/391]	Time 0.046 (0.052)	Loss 0.0863 (0.1218)	Prec@1 96.875 (95.900)
Epoch: [65][160/391]	Time 0.046 (0.051)	Loss 0.1105 (0.1246)	Prec@1 96.094 (95.788)
Epoch: [65][180/391]	Time 0.046 (0.051)	Loss 0.2116 (0.1228)	Prec@1 91.406 (95.865)
Epoch: [65][200/391]	Time 0.042 (0.050)	Loss 0.0751 (0.1229)	Prec@1 96.875 (95.857)
Epoch: [65][220/391]	Time 0.046 (0.050)	Loss 0.0980 (0.1230)	Prec@1 95.312 (95.846)
Epoch: [65][240/391]	Time 0.049 (0.049)	Loss 0.0922 (0.1239)	Prec@1 96.094 (95.841)
Epoch: [65][260/391]	Time 0.048 (0.049)	Loss 0.0762 (0.1243)	Prec@1 96.875 (95.815)
Epoch: [65][280/391]	Time 0.049 (0.049)	Loss 0.2204 (0.1248)	Prec@1 93.750 (95.799)
Epoch: [65][300/391]	Time 0.044 (0.048)	Loss 0.1074 (0.1252)	Prec@1 95.312 (95.782)
Epoch: [65][320/391]	Time 0.046 (0.048)	Loss 0.0780 (0.1254)	Prec@1 96.875 (95.775)
Epoch: [65][340/391]	Time 0.046 (0.048)	Loss 0.0933 (0.1261)	Prec@1 96.875 (95.759)
Epoch: [65][360/391]	Time 0.046 (0.048)	Loss 0.1025 (0.1266)	Prec@1 96.875 (95.732)
Epoch: [65][380/391]	Time 0.045 (0.048)	Loss 0.0744 (0.1270)	Prec@1 98.438 (95.710)
training time:  18.763771295547485
Test: [0/79]	Time 0.779 (0.779)	Loss 0.3419 (0.3419)	Prec@1 89.844 (89.844)
Test: [20/79]	Time 0.034 (0.066)	Loss 0.3529 (0.2966)	Prec@1 89.062 (90.737)
Test: [40/79]	Time 0.032 (0.049)	Loss 0.2513 (0.2904)	Prec@1 89.844 (90.777)
Test: [60/79]	Time 0.030 (0.044)	Loss 0.2491 (0.2789)	Prec@1 89.844 (91.240)
 * Prec@1 91.350
=> Saving checkpoint for epoch 65, with Prec@1 91.350000.
Epoch: [66][0/391]	Time 0.827 (0.827)	Loss 0.1075 (0.1075)	Prec@1 96.094 (96.094)
Epoch: [66][20/391]	Time 0.046 (0.081)	Loss 0.0739 (0.1098)	Prec@1 96.875 (96.094)
Epoch: [66][40/391]	Time 0.047 (0.064)	Loss 0.1990 (0.1215)	Prec@1 94.531 (95.789)
Epoch: [66][60/391]	Time 0.047 (0.058)	Loss 0.1313 (0.1255)	Prec@1 94.531 (95.517)
Epoch: [66][80/391]	Time 0.044 (0.055)	Loss 0.1717 (0.1177)	Prec@1 92.969 (95.872)
Epoch: [66][100/391]	Time 0.044 (0.053)	Loss 0.0825 (0.1143)	Prec@1 98.438 (96.078)
Epoch: [66][120/391]	Time 0.044 (0.051)	Loss 0.1590 (0.1130)	Prec@1 93.750 (96.113)
Epoch: [66][140/391]	Time 0.043 (0.050)	Loss 0.1196 (0.1120)	Prec@1 96.875 (96.177)
Epoch: [66][160/391]	Time 0.046 (0.050)	Loss 0.1733 (0.1106)	Prec@1 93.750 (96.201)
Epoch: [66][180/391]	Time 0.046 (0.049)	Loss 0.1378 (0.1117)	Prec@1 96.094 (96.215)
Epoch: [66][200/391]	Time 0.043 (0.049)	Loss 0.0754 (0.1128)	Prec@1 97.656 (96.199)
Epoch: [66][220/391]	Time 0.047 (0.049)	Loss 0.1968 (0.1139)	Prec@1 90.625 (96.129)
Epoch: [66][240/391]	Time 0.047 (0.049)	Loss 0.0660 (0.1134)	Prec@1 97.656 (96.136)
Epoch: [66][260/391]	Time 0.047 (0.048)	Loss 0.1074 (0.1140)	Prec@1 94.531 (96.088)
Epoch: [66][280/391]	Time 0.048 (0.048)	Loss 0.1621 (0.1151)	Prec@1 94.531 (96.072)
Epoch: [66][300/391]	Time 0.044 (0.048)	Loss 0.1110 (0.1155)	Prec@1 95.312 (96.060)
Epoch: [66][320/391]	Time 0.044 (0.048)	Loss 0.0614 (0.1160)	Prec@1 98.438 (96.057)
Epoch: [66][340/391]	Time 0.043 (0.048)	Loss 0.1388 (0.1162)	Prec@1 94.531 (96.036)
Epoch: [66][360/391]	Time 0.046 (0.047)	Loss 0.1157 (0.1171)	Prec@1 96.875 (96.014)
Epoch: [66][380/391]	Time 0.045 (0.047)	Loss 0.1271 (0.1184)	Prec@1 94.531 (95.960)
training time:  18.66247868537903
Test: [0/79]	Time 0.788 (0.788)	Loss 0.3252 (0.3252)	Prec@1 91.406 (91.406)
Test: [20/79]	Time 0.032 (0.066)	Loss 0.3335 (0.2978)	Prec@1 90.625 (90.476)
Test: [40/79]	Time 0.029 (0.049)	Loss 0.2927 (0.2903)	Prec@1 91.406 (90.911)
Test: [60/79]	Time 0.030 (0.043)	Loss 0.1739 (0.2813)	Prec@1 93.750 (91.253)
 * Prec@1 91.290
Epoch: [67][0/391]	Time 0.820 (0.820)	Loss 0.1591 (0.1591)	Prec@1 93.750 (93.750)
Epoch: [67][20/391]	Time 0.045 (0.083)	Loss 0.1544 (0.1052)	Prec@1 96.875 (96.615)
Epoch: [67][40/391]	Time 0.045 (0.065)	Loss 0.1383 (0.1034)	Prec@1 96.094 (96.608)
Epoch: [67][60/391]	Time 0.047 (0.059)	Loss 0.1517 (0.1028)	Prec@1 92.969 (96.440)
Epoch: [67][80/391]	Time 0.046 (0.056)	Loss 0.1519 (0.1000)	Prec@1 95.312 (96.624)
Epoch: [67][100/391]	Time 0.047 (0.054)	Loss 0.1307 (0.0984)	Prec@1 92.969 (96.604)
Epoch: [67][120/391]	Time 0.046 (0.053)	Loss 0.0914 (0.0997)	Prec@1 96.875 (96.565)
Epoch: [67][140/391]	Time 0.045 (0.052)	Loss 0.1004 (0.1034)	Prec@1 96.094 (96.443)
Epoch: [67][160/391]	Time 0.046 (0.051)	Loss 0.0860 (0.1069)	Prec@1 98.438 (96.327)
Epoch: [67][180/391]	Time 0.046 (0.051)	Loss 0.1905 (0.1081)	Prec@1 93.750 (96.266)
Epoch: [67][200/391]	Time 0.046 (0.050)	Loss 0.1573 (0.1085)	Prec@1 93.750 (96.249)
Epoch: [67][220/391]	Time 0.046 (0.050)	Loss 0.1220 (0.1082)	Prec@1 97.656 (96.278)
Epoch: [67][240/391]	Time 0.046 (0.050)	Loss 0.1287 (0.1095)	Prec@1 94.531 (96.233)
Epoch: [67][260/391]	Time 0.047 (0.049)	Loss 0.1452 (0.1095)	Prec@1 93.750 (96.234)
Epoch: [67][280/391]	Time 0.045 (0.049)	Loss 0.1847 (0.1113)	Prec@1 93.750 (96.172)
Epoch: [67][300/391]	Time 0.045 (0.049)	Loss 0.1327 (0.1122)	Prec@1 96.094 (96.130)
Epoch: [67][320/391]	Time 0.047 (0.049)	Loss 0.1471 (0.1121)	Prec@1 94.531 (96.116)
Epoch: [67][340/391]	Time 0.046 (0.049)	Loss 0.1008 (0.1122)	Prec@1 95.312 (96.107)
Epoch: [67][360/391]	Time 0.045 (0.048)	Loss 0.0705 (0.1114)	Prec@1 98.438 (96.139)
Epoch: [67][380/391]	Time 0.045 (0.048)	Loss 0.1303 (0.1122)	Prec@1 95.312 (96.125)
training time:  19.018587827682495
Test: [0/79]	Time 0.788 (0.788)	Loss 0.1986 (0.1986)	Prec@1 95.312 (95.312)
Test: [20/79]	Time 0.032 (0.067)	Loss 0.2642 (0.2687)	Prec@1 92.188 (91.778)
Test: [40/79]	Time 0.030 (0.049)	Loss 0.2591 (0.2792)	Prec@1 90.625 (91.292)
Test: [60/79]	Time 0.032 (0.044)	Loss 0.2147 (0.2755)	Prec@1 92.969 (91.163)
 * Prec@1 91.280
Epoch: [68][0/391]	Time 0.780 (0.780)	Loss 0.0848 (0.0848)	Prec@1 97.656 (97.656)
Epoch: [68][20/391]	Time 0.044 (0.081)	Loss 0.0731 (0.0955)	Prec@1 98.438 (96.763)
Epoch: [68][40/391]	Time 0.047 (0.064)	Loss 0.0900 (0.0913)	Prec@1 96.094 (96.951)
Epoch: [68][60/391]	Time 0.044 (0.058)	Loss 0.1617 (0.0968)	Prec@1 92.969 (96.670)
Epoch: [68][80/391]	Time 0.047 (0.055)	Loss 0.1412 (0.1016)	Prec@1 96.875 (96.566)
Epoch: [68][100/391]	Time 0.043 (0.054)	Loss 0.1074 (0.1021)	Prec@1 97.656 (96.558)
Epoch: [68][120/391]	Time 0.045 (0.052)	Loss 0.0359 (0.1039)	Prec@1 99.219 (96.513)
Epoch: [68][140/391]	Time 0.045 (0.051)	Loss 0.0797 (0.1014)	Prec@1 98.438 (96.626)
Epoch: [68][160/391]	Time 0.048 (0.051)	Loss 0.1273 (0.1027)	Prec@1 95.312 (96.579)
Epoch: [68][180/391]	Time 0.049 (0.050)	Loss 0.0737 (0.1030)	Prec@1 97.656 (96.590)
Epoch: [68][200/391]	Time 0.051 (0.051)	Loss 0.1080 (0.1048)	Prec@1 96.094 (96.517)
Epoch: [68][220/391]	Time 0.048 (0.050)	Loss 0.0805 (0.1064)	Prec@1 96.094 (96.454)
Epoch: [68][240/391]	Time 0.048 (0.050)	Loss 0.1102 (0.1057)	Prec@1 96.875 (96.470)
Epoch: [68][260/391]	Time 0.045 (0.050)	Loss 0.1055 (0.1052)	Prec@1 96.875 (96.477)
Epoch: [68][280/391]	Time 0.043 (0.049)	Loss 0.1262 (0.1051)	Prec@1 96.875 (96.505)
Epoch: [68][300/391]	Time 0.046 (0.049)	Loss 0.0361 (0.1041)	Prec@1 99.219 (96.530)
Epoch: [68][320/391]	Time 0.046 (0.049)	Loss 0.0771 (0.1031)	Prec@1 98.438 (96.571)
Epoch: [68][340/391]	Time 0.050 (0.049)	Loss 0.1489 (0.1037)	Prec@1 95.312 (96.545)
Epoch: [68][360/391]	Time 0.048 (0.049)	Loss 0.0472 (0.1045)	Prec@1 97.656 (96.520)
Epoch: [68][380/391]	Time 0.046 (0.049)	Loss 0.1529 (0.1055)	Prec@1 93.750 (96.455)
training time:  19.08556294441223
Test: [0/79]	Time 0.739 (0.739)	Loss 0.2321 (0.2321)	Prec@1 91.406 (91.406)
Test: [20/79]	Time 0.031 (0.066)	Loss 0.3956 (0.3256)	Prec@1 89.844 (89.844)
Test: [40/79]	Time 0.032 (0.049)	Loss 0.3543 (0.3169)	Prec@1 90.625 (90.111)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.2603 (0.3126)	Prec@1 89.844 (90.394)
 * Prec@1 90.380
Epoch: [69][0/391]	Time 0.800 (0.800)	Loss 0.1015 (0.1015)	Prec@1 96.875 (96.875)
Epoch: [69][20/391]	Time 0.075 (0.083)	Loss 0.1033 (0.0956)	Prec@1 94.531 (96.987)
Epoch: [69][40/391]	Time 0.046 (0.065)	Loss 0.0936 (0.0930)	Prec@1 96.875 (97.027)
Epoch: [69][60/391]	Time 0.046 (0.059)	Loss 0.0466 (0.0905)	Prec@1 98.438 (97.182)
Epoch: [69][80/391]	Time 0.050 (0.056)	Loss 0.0344 (0.0902)	Prec@1 100.000 (97.020)
Epoch: [69][100/391]	Time 0.045 (0.054)	Loss 0.1020 (0.0878)	Prec@1 96.094 (97.107)
Epoch: [69][120/391]	Time 0.049 (0.053)	Loss 0.1177 (0.0880)	Prec@1 93.750 (97.036)
Epoch: [69][140/391]	Time 0.046 (0.052)	Loss 0.0330 (0.0878)	Prec@1 99.219 (97.058)
Epoch: [69][160/391]	Time 0.044 (0.051)	Loss 0.0496 (0.0874)	Prec@1 99.219 (97.059)
Epoch: [69][180/391]	Time 0.047 (0.050)	Loss 0.1792 (0.0882)	Prec@1 92.188 (97.039)
Epoch: [69][200/391]	Time 0.044 (0.050)	Loss 0.1824 (0.0907)	Prec@1 94.531 (96.972)
Epoch: [69][220/391]	Time 0.044 (0.050)	Loss 0.1071 (0.0911)	Prec@1 95.312 (96.974)
Epoch: [69][240/391]	Time 0.046 (0.049)	Loss 0.0775 (0.0932)	Prec@1 98.438 (96.872)
Epoch: [69][260/391]	Time 0.045 (0.049)	Loss 0.0683 (0.0947)	Prec@1 98.438 (96.839)
Epoch: [69][280/391]	Time 0.046 (0.049)	Loss 0.1072 (0.0968)	Prec@1 95.312 (96.755)
Epoch: [69][300/391]	Time 0.047 (0.049)	Loss 0.0542 (0.0978)	Prec@1 97.656 (96.696)
Epoch: [69][320/391]	Time 0.046 (0.049)	Loss 0.0765 (0.0982)	Prec@1 96.094 (96.675)
Epoch: [69][340/391]	Time 0.045 (0.048)	Loss 0.0882 (0.0978)	Prec@1 95.312 (96.687)
Epoch: [69][360/391]	Time 0.043 (0.048)	Loss 0.0572 (0.0981)	Prec@1 98.438 (96.687)
Epoch: [69][380/391]	Time 0.044 (0.048)	Loss 0.0785 (0.0991)	Prec@1 96.094 (96.645)
training time:  18.93574333190918
Test: [0/79]	Time 0.763 (0.763)	Loss 0.2587 (0.2587)	Prec@1 89.062 (89.062)
Test: [20/79]	Time 0.033 (0.066)	Loss 0.3596 (0.3085)	Prec@1 91.406 (91.146)
Test: [40/79]	Time 0.033 (0.050)	Loss 0.4745 (0.2960)	Prec@1 86.719 (91.082)
Test: [60/79]	Time 0.032 (0.044)	Loss 0.2377 (0.2951)	Prec@1 92.969 (91.086)
 * Prec@1 91.250
Epoch: [70][0/391]	Time 0.814 (0.814)	Loss 0.0709 (0.0709)	Prec@1 97.656 (97.656)
Epoch: [70][20/391]	Time 0.047 (0.083)	Loss 0.0756 (0.0789)	Prec@1 98.438 (97.433)
Epoch: [70][40/391]	Time 0.048 (0.065)	Loss 0.0466 (0.0830)	Prec@1 98.438 (97.332)
Epoch: [70][60/391]	Time 0.044 (0.059)	Loss 0.0971 (0.0828)	Prec@1 95.312 (97.246)
Epoch: [70][80/391]	Time 0.046 (0.056)	Loss 0.0646 (0.0822)	Prec@1 96.875 (97.174)
Epoch: [70][100/391]	Time 0.046 (0.054)	Loss 0.1167 (0.0863)	Prec@1 96.094 (96.921)
Epoch: [70][120/391]	Time 0.045 (0.053)	Loss 0.1163 (0.0892)	Prec@1 96.875 (96.843)
Epoch: [70][140/391]	Time 0.044 (0.052)	Loss 0.0567 (0.0893)	Prec@1 97.656 (96.864)
Epoch: [70][160/391]	Time 0.046 (0.051)	Loss 0.2000 (0.0919)	Prec@1 92.188 (96.739)
Epoch: [70][180/391]	Time 0.043 (0.050)	Loss 0.1220 (0.0930)	Prec@1 96.094 (96.711)
Epoch: [70][200/391]	Time 0.046 (0.050)	Loss 0.0951 (0.0940)	Prec@1 96.094 (96.704)
Epoch: [70][220/391]	Time 0.045 (0.050)	Loss 0.1090 (0.0951)	Prec@1 96.875 (96.698)
Epoch: [70][240/391]	Time 0.046 (0.050)	Loss 0.0504 (0.0965)	Prec@1 97.656 (96.658)
Epoch: [70][260/391]	Time 0.046 (0.050)	Loss 0.1303 (0.0965)	Prec@1 94.531 (96.659)
Epoch: [70][280/391]	Time 0.046 (0.049)	Loss 0.0848 (0.0975)	Prec@1 97.656 (96.641)
Epoch: [70][300/391]	Time 0.046 (0.049)	Loss 0.0885 (0.0972)	Prec@1 96.094 (96.657)
Epoch: [70][320/391]	Time 0.045 (0.049)	Loss 0.0957 (0.0965)	Prec@1 96.875 (96.714)
Epoch: [70][340/391]	Time 0.045 (0.049)	Loss 0.0536 (0.0954)	Prec@1 97.656 (96.751)
Epoch: [70][360/391]	Time 0.047 (0.049)	Loss 0.0965 (0.0948)	Prec@1 96.875 (96.795)
Epoch: [70][380/391]	Time 0.046 (0.049)	Loss 0.1637 (0.0949)	Prec@1 93.750 (96.789)
training time:  19.107678413391113
Test: [0/79]	Time 0.755 (0.755)	Loss 0.2253 (0.2253)	Prec@1 91.406 (91.406)
Test: [20/79]	Time 0.029 (0.064)	Loss 0.2016 (0.2834)	Prec@1 91.406 (91.481)
Test: [40/79]	Time 0.031 (0.048)	Loss 0.3391 (0.2753)	Prec@1 89.062 (91.921)
Test: [60/79]	Time 0.032 (0.043)	Loss 0.1859 (0.2749)	Prec@1 96.094 (91.983)
 * Prec@1 92.030
=> Saving checkpoint for epoch 70, with Prec@1 92.030000.
Epoch: [71][0/391]	Time 0.775 (0.775)	Loss 0.0631 (0.0631)	Prec@1 98.438 (98.438)
Epoch: [71][20/391]	Time 0.047 (0.081)	Loss 0.1084 (0.0781)	Prec@1 94.531 (97.359)
Epoch: [71][40/391]	Time 0.045 (0.064)	Loss 0.0819 (0.0778)	Prec@1 96.875 (97.332)
Epoch: [71][60/391]	Time 0.045 (0.058)	Loss 0.0578 (0.0779)	Prec@1 99.219 (97.362)
Epoch: [71][80/391]	Time 0.043 (0.055)	Loss 0.0601 (0.0766)	Prec@1 98.438 (97.444)
Epoch: [71][100/391]	Time 0.043 (0.053)	Loss 0.1136 (0.0772)	Prec@1 96.094 (97.393)
Epoch: [71][120/391]	Time 0.047 (0.052)	Loss 0.0428 (0.0747)	Prec@1 98.438 (97.514)
Epoch: [71][140/391]	Time 0.047 (0.051)	Loss 0.1183 (0.0755)	Prec@1 96.875 (97.529)
Epoch: [71][160/391]	Time 0.045 (0.051)	Loss 0.0686 (0.0747)	Prec@1 98.438 (97.569)
Epoch: [71][180/391]	Time 0.046 (0.050)	Loss 0.1030 (0.0748)	Prec@1 96.875 (97.535)
Epoch: [71][200/391]	Time 0.048 (0.050)	Loss 0.0459 (0.0771)	Prec@1 98.438 (97.485)
Epoch: [71][220/391]	Time 0.048 (0.050)	Loss 0.0559 (0.0785)	Prec@1 99.219 (97.423)
Epoch: [71][240/391]	Time 0.044 (0.050)	Loss 0.1098 (0.0790)	Prec@1 95.312 (97.394)
Epoch: [71][260/391]	Time 0.043 (0.049)	Loss 0.1057 (0.0802)	Prec@1 95.312 (97.327)
Epoch: [71][280/391]	Time 0.043 (0.049)	Loss 0.0491 (0.0806)	Prec@1 99.219 (97.309)
Epoch: [71][300/391]	Time 0.043 (0.049)	Loss 0.0998 (0.0816)	Prec@1 98.438 (97.295)
Epoch: [71][320/391]	Time 0.046 (0.048)	Loss 0.1550 (0.0819)	Prec@1 95.312 (97.274)
Epoch: [71][340/391]	Time 0.047 (0.048)	Loss 0.0998 (0.0825)	Prec@1 96.875 (97.251)
Epoch: [71][360/391]	Time 0.046 (0.048)	Loss 0.1111 (0.0831)	Prec@1 96.094 (97.221)
Epoch: [71][380/391]	Time 0.047 (0.048)	Loss 0.1217 (0.0829)	Prec@1 95.312 (97.215)
training time:  18.919707536697388
Test: [0/79]	Time 0.750 (0.750)	Loss 0.2919 (0.2919)	Prec@1 92.188 (92.188)
Test: [20/79]	Time 0.029 (0.064)	Loss 0.3229 (0.2687)	Prec@1 92.188 (91.853)
Test: [40/79]	Time 0.028 (0.047)	Loss 0.2338 (0.2677)	Prec@1 90.625 (91.921)
Test: [60/79]	Time 0.031 (0.042)	Loss 0.1774 (0.2563)	Prec@1 94.531 (92.367)
 * Prec@1 92.430
=> Saving checkpoint for epoch 71, with Prec@1 92.430000.
Epoch: [72][0/391]	Time 0.783 (0.783)	Loss 0.0844 (0.0844)	Prec@1 96.875 (96.875)
Epoch: [72][20/391]	Time 0.046 (0.081)	Loss 0.0381 (0.0826)	Prec@1 99.219 (97.284)
Epoch: [72][40/391]	Time 0.046 (0.064)	Loss 0.0696 (0.0749)	Prec@1 96.875 (97.523)
Epoch: [72][60/391]	Time 0.048 (0.058)	Loss 0.0505 (0.0731)	Prec@1 99.219 (97.554)
Epoch: [72][80/391]	Time 0.046 (0.055)	Loss 0.1190 (0.0709)	Prec@1 96.875 (97.666)
Epoch: [72][100/391]	Time 0.046 (0.053)	Loss 0.0376 (0.0718)	Prec@1 98.438 (97.633)
Epoch: [72][120/391]	Time 0.047 (0.052)	Loss 0.1250 (0.0726)	Prec@1 94.531 (97.566)
Epoch: [72][140/391]	Time 0.046 (0.051)	Loss 0.0795 (0.0744)	Prec@1 97.656 (97.484)
Epoch: [72][160/391]	Time 0.046 (0.051)	Loss 0.0603 (0.0747)	Prec@1 98.438 (97.457)
Epoch: [72][180/391]	Time 0.046 (0.050)	Loss 0.0608 (0.0743)	Prec@1 98.438 (97.445)
Epoch: [72][200/391]	Time 0.045 (0.050)	Loss 0.0611 (0.0761)	Prec@1 98.438 (97.396)
Epoch: [72][220/391]	Time 0.046 (0.050)	Loss 0.0989 (0.0767)	Prec@1 96.875 (97.352)
Epoch: [72][240/391]	Time 0.046 (0.050)	Loss 0.0597 (0.0770)	Prec@1 97.656 (97.339)
Epoch: [72][260/391]	Time 0.046 (0.049)	Loss 0.0677 (0.0786)	Prec@1 97.656 (97.252)
Epoch: [72][280/391]	Time 0.047 (0.049)	Loss 0.0586 (0.0795)	Prec@1 98.438 (97.228)
Epoch: [72][300/391]	Time 0.047 (0.049)	Loss 0.0602 (0.0801)	Prec@1 98.438 (97.194)
Epoch: [72][320/391]	Time 0.046 (0.049)	Loss 0.0310 (0.0800)	Prec@1 99.219 (97.196)
Epoch: [72][340/391]	Time 0.046 (0.049)	Loss 0.0705 (0.0802)	Prec@1 98.438 (97.196)
Epoch: [72][360/391]	Time 0.047 (0.049)	Loss 0.1197 (0.0807)	Prec@1 96.875 (97.182)
Epoch: [72][380/391]	Time 0.046 (0.049)	Loss 0.1124 (0.0807)	Prec@1 96.875 (97.176)
training time:  19.099599838256836
Test: [0/79]	Time 0.738 (0.738)	Loss 0.2845 (0.2845)	Prec@1 92.969 (92.969)
Test: [20/79]	Time 0.029 (0.063)	Loss 0.2480 (0.2726)	Prec@1 92.969 (91.778)
Test: [40/79]	Time 0.032 (0.048)	Loss 0.2941 (0.2546)	Prec@1 90.625 (92.073)
Test: [60/79]	Time 0.031 (0.043)	Loss 0.1934 (0.2450)	Prec@1 94.531 (92.418)
 * Prec@1 92.530
=> Saving checkpoint for epoch 72, with Prec@1 92.530000.
Epoch: [73][0/391]	Time 0.774 (0.774)	Loss 0.0537 (0.0537)	Prec@1 98.438 (98.438)
Epoch: [73][20/391]	Time 0.045 (0.080)	Loss 0.0866 (0.0616)	Prec@1 96.875 (98.028)
Epoch: [73][40/391]	Time 0.046 (0.064)	Loss 0.0305 (0.0689)	Prec@1 99.219 (97.790)
Epoch: [73][60/391]	Time 0.046 (0.058)	Loss 0.1040 (0.0719)	Prec@1 96.875 (97.503)
Epoch: [73][80/391]	Time 0.049 (0.055)	Loss 0.0846 (0.0721)	Prec@1 97.656 (97.512)
Epoch: [73][100/391]	Time 0.044 (0.053)	Loss 0.0525 (0.0730)	Prec@1 98.438 (97.509)
Epoch: [73][120/391]	Time 0.046 (0.052)	Loss 0.0764 (0.0723)	Prec@1 96.094 (97.540)
Epoch: [73][140/391]	Time 0.046 (0.051)	Loss 0.0518 (0.0731)	Prec@1 98.438 (97.545)
Epoch: [73][160/391]	Time 0.047 (0.051)	Loss 0.0543 (0.0725)	Prec@1 98.438 (97.588)
Epoch: [73][180/391]	Time 0.046 (0.050)	Loss 0.0840 (0.0716)	Prec@1 96.875 (97.613)
Epoch: [73][200/391]	Time 0.046 (0.050)	Loss 0.0973 (0.0700)	Prec@1 97.656 (97.672)
Epoch: [73][220/391]	Time 0.046 (0.050)	Loss 0.1919 (0.0700)	Prec@1 94.531 (97.681)
Epoch: [73][240/391]	Time 0.043 (0.049)	Loss 0.0527 (0.0697)	Prec@1 97.656 (97.682)
Epoch: [73][260/391]	Time 0.045 (0.049)	Loss 0.0689 (0.0698)	Prec@1 96.875 (97.668)
Epoch: [73][280/391]	Time 0.049 (0.049)	Loss 0.1025 (0.0705)	Prec@1 95.312 (97.637)
Epoch: [73][300/391]	Time 0.047 (0.049)	Loss 0.0912 (0.0703)	Prec@1 96.875 (97.630)
Epoch: [73][320/391]	Time 0.048 (0.048)	Loss 0.1110 (0.0714)	Prec@1 96.094 (97.581)
Epoch: [73][340/391]	Time 0.047 (0.048)	Loss 0.0632 (0.0716)	Prec@1 98.438 (97.601)
Epoch: [73][360/391]	Time 0.046 (0.048)	Loss 0.0301 (0.0711)	Prec@1 100.000 (97.622)
Epoch: [73][380/391]	Time 0.045 (0.048)	Loss 0.0471 (0.0706)	Prec@1 98.438 (97.646)
training time:  18.936800003051758
Test: [0/79]	Time 0.771 (0.771)	Loss 0.1570 (0.1570)	Prec@1 94.531 (94.531)
Test: [20/79]	Time 0.032 (0.067)	Loss 0.2851 (0.2414)	Prec@1 92.969 (92.522)
Test: [40/79]	Time 0.033 (0.050)	Loss 0.2369 (0.2416)	Prec@1 92.188 (92.721)
Test: [60/79]	Time 0.032 (0.045)	Loss 0.2087 (0.2362)	Prec@1 93.750 (92.841)
 * Prec@1 92.830
=> Saving checkpoint for epoch 73, with Prec@1 92.830000.
Epoch: [74][0/391]	Time 0.821 (0.821)	Loss 0.0327 (0.0327)	Prec@1 100.000 (100.000)
Epoch: [74][20/391]	Time 0.047 (0.082)	Loss 0.0814 (0.0564)	Prec@1 96.875 (98.289)
Epoch: [74][40/391]	Time 0.043 (0.064)	Loss 0.0289 (0.0533)	Prec@1 100.000 (98.285)
Epoch: [74][60/391]	Time 0.043 (0.058)	Loss 0.0666 (0.0521)	Prec@1 96.875 (98.284)
Epoch: [74][80/391]	Time 0.047 (0.055)	Loss 0.0988 (0.0541)	Prec@1 96.094 (98.225)
Epoch: [74][100/391]	Time 0.048 (0.053)	Loss 0.0347 (0.0541)	Prec@1 98.438 (98.221)
Epoch: [74][120/391]	Time 0.042 (0.052)	Loss 0.0260 (0.0545)	Prec@1 99.219 (98.250)
Epoch: [74][140/391]	Time 0.047 (0.051)	Loss 0.1340 (0.0576)	Prec@1 96.875 (98.166)
Epoch: [74][160/391]	Time 0.046 (0.050)	Loss 0.0972 (0.0580)	Prec@1 96.875 (98.141)
Epoch: [74][180/391]	Time 0.046 (0.050)	Loss 0.0820 (0.0578)	Prec@1 97.656 (98.109)
Epoch: [74][200/391]	Time 0.046 (0.049)	Loss 0.1118 (0.0578)	Prec@1 95.312 (98.080)
Epoch: [74][220/391]	Time 0.046 (0.050)	Loss 0.0332 (0.0583)	Prec@1 98.438 (98.042)
Epoch: [74][240/391]	Time 0.046 (0.049)	Loss 0.0325 (0.0591)	Prec@1 98.438 (98.010)
Epoch: [74][260/391]	Time 0.046 (0.049)	Loss 0.0928 (0.0600)	Prec@1 96.875 (97.974)
Epoch: [74][280/391]	Time 0.047 (0.049)	Loss 0.0735 (0.0609)	Prec@1 97.656 (97.957)
Epoch: [74][300/391]	Time 0.047 (0.049)	Loss 0.0777 (0.0623)	Prec@1 96.875 (97.916)
Epoch: [74][320/391]	Time 0.045 (0.049)	Loss 0.0775 (0.0622)	Prec@1 95.312 (97.931)
Epoch: [74][340/391]	Time 0.047 (0.048)	Loss 0.0550 (0.0625)	Prec@1 97.656 (97.908)
Epoch: [74][360/391]	Time 0.046 (0.048)	Loss 0.0209 (0.0622)	Prec@1 100.000 (97.940)
Epoch: [74][380/391]	Time 0.046 (0.048)	Loss 0.0865 (0.0629)	Prec@1 96.094 (97.913)
training time:  18.98977518081665
Test: [0/79]	Time 0.783 (0.783)	Loss 0.3321 (0.3321)	Prec@1 90.625 (90.625)
Test: [20/79]	Time 0.033 (0.068)	Loss 0.2532 (0.2508)	Prec@1 93.750 (92.671)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.2644 (0.2477)	Prec@1 92.969 (92.683)
Test: [60/79]	Time 0.032 (0.044)	Loss 0.2217 (0.2433)	Prec@1 93.750 (92.674)
 * Prec@1 92.820
Epoch: [75][0/391]	Time 0.824 (0.824)	Loss 0.0707 (0.0707)	Prec@1 97.656 (97.656)
Epoch: [75][20/391]	Time 0.045 (0.083)	Loss 0.0457 (0.0614)	Prec@1 97.656 (97.991)
Epoch: [75][40/391]	Time 0.045 (0.065)	Loss 0.0446 (0.0564)	Prec@1 99.219 (98.285)
Epoch: [75][60/391]	Time 0.047 (0.058)	Loss 0.0459 (0.0545)	Prec@1 98.438 (98.297)
Epoch: [75][80/391]	Time 0.047 (0.055)	Loss 0.0590 (0.0553)	Prec@1 98.438 (98.274)
Epoch: [75][100/391]	Time 0.046 (0.053)	Loss 0.0837 (0.0561)	Prec@1 97.656 (98.198)
Epoch: [75][120/391]	Time 0.047 (0.052)	Loss 0.0926 (0.0566)	Prec@1 97.656 (98.147)
Epoch: [75][140/391]	Time 0.046 (0.051)	Loss 0.0185 (0.0568)	Prec@1 100.000 (98.155)
Epoch: [75][160/391]	Time 0.048 (0.051)	Loss 0.0564 (0.0565)	Prec@1 97.656 (98.146)
Epoch: [75][180/391]	Time 0.049 (0.050)	Loss 0.0973 (0.0570)	Prec@1 96.094 (98.109)
Epoch: [75][200/391]	Time 0.047 (0.050)	Loss 0.0812 (0.0583)	Prec@1 96.094 (98.033)
Epoch: [75][220/391]	Time 0.046 (0.049)	Loss 0.0513 (0.0588)	Prec@1 99.219 (98.020)
Epoch: [75][240/391]	Time 0.046 (0.049)	Loss 0.0923 (0.0594)	Prec@1 98.438 (98.003)
Epoch: [75][260/391]	Time 0.046 (0.049)	Loss 0.0593 (0.0594)	Prec@1 98.438 (98.000)
Epoch: [75][280/391]	Time 0.046 (0.049)	Loss 0.0172 (0.0601)	Prec@1 100.000 (97.990)
Epoch: [75][300/391]	Time 0.045 (0.048)	Loss 0.1430 (0.0606)	Prec@1 96.094 (97.973)
Epoch: [75][320/391]	Time 0.047 (0.048)	Loss 0.0358 (0.0605)	Prec@1 99.219 (97.980)
Epoch: [75][340/391]	Time 0.045 (0.048)	Loss 0.0592 (0.0603)	Prec@1 98.438 (97.984)
Epoch: [75][360/391]	Time 0.046 (0.048)	Loss 0.0389 (0.0608)	Prec@1 97.656 (97.959)
Epoch: [75][380/391]	Time 0.045 (0.048)	Loss 0.0496 (0.0609)	Prec@1 98.438 (97.952)
training time:  18.884124279022217
Test: [0/79]	Time 0.790 (0.790)	Loss 0.1891 (0.1891)	Prec@1 93.750 (93.750)
Test: [20/79]	Time 0.028 (0.067)	Loss 0.2643 (0.2602)	Prec@1 92.969 (92.894)
Test: [40/79]	Time 0.029 (0.050)	Loss 0.2688 (0.2463)	Prec@1 92.188 (92.873)
Test: [60/79]	Time 0.032 (0.044)	Loss 0.1955 (0.2381)	Prec@1 92.969 (93.020)
 * Prec@1 93.140
=> Saving checkpoint for epoch 75, with Prec@1 93.140000.
Epoch: [76][0/391]	Time 0.781 (0.781)	Loss 0.0363 (0.0363)	Prec@1 99.219 (99.219)
Epoch: [76][20/391]	Time 0.044 (0.080)	Loss 0.0367 (0.0480)	Prec@1 98.438 (98.363)
Epoch: [76][40/391]	Time 0.046 (0.064)	Loss 0.0139 (0.0457)	Prec@1 100.000 (98.609)
Epoch: [76][60/391]	Time 0.045 (0.058)	Loss 0.0361 (0.0468)	Prec@1 98.438 (98.553)
Epoch: [76][80/391]	Time 0.047 (0.055)	Loss 0.0913 (0.0465)	Prec@1 96.094 (98.438)
Epoch: [76][100/391]	Time 0.047 (0.053)	Loss 0.0880 (0.0464)	Prec@1 97.656 (98.453)
Epoch: [76][120/391]	Time 0.047 (0.052)	Loss 0.1315 (0.0485)	Prec@1 96.094 (98.412)
Epoch: [76][140/391]	Time 0.047 (0.051)	Loss 0.0734 (0.0491)	Prec@1 96.875 (98.382)
Epoch: [76][160/391]	Time 0.046 (0.051)	Loss 0.0550 (0.0502)	Prec@1 97.656 (98.350)
Epoch: [76][180/391]	Time 0.048 (0.050)	Loss 0.0677 (0.0510)	Prec@1 97.656 (98.338)
Epoch: [76][200/391]	Time 0.046 (0.050)	Loss 0.1133 (0.0508)	Prec@1 96.875 (98.336)
Epoch: [76][220/391]	Time 0.047 (0.050)	Loss 0.0573 (0.0506)	Prec@1 98.438 (98.349)
Epoch: [76][240/391]	Time 0.048 (0.050)	Loss 0.0709 (0.0512)	Prec@1 99.219 (98.350)
Epoch: [76][260/391]	Time 0.047 (0.050)	Loss 0.0285 (0.0508)	Prec@1 98.438 (98.363)
Epoch: [76][280/391]	Time 0.046 (0.049)	Loss 0.0186 (0.0501)	Prec@1 99.219 (98.368)
Epoch: [76][300/391]	Time 0.048 (0.049)	Loss 0.0608 (0.0509)	Prec@1 97.656 (98.323)
Epoch: [76][320/391]	Time 0.048 (0.049)	Loss 0.0797 (0.0519)	Prec@1 96.875 (98.291)
Epoch: [76][340/391]	Time 0.049 (0.049)	Loss 0.0714 (0.0520)	Prec@1 96.875 (98.277)
Epoch: [76][360/391]	Time 0.047 (0.049)	Loss 0.0489 (0.0515)	Prec@1 97.656 (98.297)
Epoch: [76][380/391]	Time 0.045 (0.049)	Loss 0.0295 (0.0513)	Prec@1 99.219 (98.306)
training time:  19.250259160995483
Test: [0/79]	Time 0.777 (0.777)	Loss 0.2624 (0.2624)	Prec@1 92.969 (92.969)
Test: [20/79]	Time 0.033 (0.067)	Loss 0.2854 (0.2667)	Prec@1 91.406 (92.560)
Test: [40/79]	Time 0.033 (0.050)	Loss 0.3183 (0.2445)	Prec@1 90.625 (93.045)
Test: [60/79]	Time 0.032 (0.044)	Loss 0.1724 (0.2361)	Prec@1 94.531 (93.327)
 * Prec@1 93.380
=> Saving checkpoint for epoch 76, with Prec@1 93.380000.
Epoch: [77][0/391]	Time 0.829 (0.829)	Loss 0.0149 (0.0149)	Prec@1 100.000 (100.000)
Epoch: [77][20/391]	Time 0.044 (0.084)	Loss 0.0563 (0.0401)	Prec@1 98.438 (98.698)
Epoch: [77][40/391]	Time 0.047 (0.065)	Loss 0.0309 (0.0417)	Prec@1 99.219 (98.647)
Epoch: [77][60/391]	Time 0.046 (0.059)	Loss 0.0351 (0.0418)	Prec@1 98.438 (98.681)
Epoch: [77][80/391]	Time 0.046 (0.056)	Loss 0.0288 (0.0438)	Prec@1 99.219 (98.553)
Epoch: [77][100/391]	Time 0.047 (0.054)	Loss 0.0210 (0.0446)	Prec@1 100.000 (98.554)
Epoch: [77][120/391]	Time 0.048 (0.053)	Loss 0.1161 (0.0439)	Prec@1 96.094 (98.567)
Epoch: [77][140/391]	Time 0.044 (0.052)	Loss 0.1063 (0.0442)	Prec@1 95.312 (98.537)
Epoch: [77][160/391]	Time 0.046 (0.051)	Loss 0.1249 (0.0452)	Prec@1 95.312 (98.525)
Epoch: [77][180/391]	Time 0.045 (0.051)	Loss 0.0570 (0.0460)	Prec@1 98.438 (98.489)
Epoch: [77][200/391]	Time 0.045 (0.050)	Loss 0.0571 (0.0456)	Prec@1 98.438 (98.523)
Epoch: [77][220/391]	Time 0.045 (0.050)	Loss 0.0090 (0.0445)	Prec@1 100.000 (98.558)
Epoch: [77][240/391]	Time 0.047 (0.050)	Loss 0.0247 (0.0441)	Prec@1 99.219 (98.570)
Epoch: [77][260/391]	Time 0.044 (0.049)	Loss 0.0367 (0.0434)	Prec@1 99.219 (98.590)
Epoch: [77][280/391]	Time 0.044 (0.049)	Loss 0.0230 (0.0432)	Prec@1 100.000 (98.599)
Epoch: [77][300/391]	Time 0.046 (0.049)	Loss 0.0313 (0.0434)	Prec@1 98.438 (98.596)
Epoch: [77][320/391]	Time 0.046 (0.049)	Loss 0.0250 (0.0430)	Prec@1 100.000 (98.601)
Epoch: [77][340/391]	Time 0.045 (0.049)	Loss 0.0182 (0.0431)	Prec@1 100.000 (98.609)
Epoch: [77][360/391]	Time 0.046 (0.048)	Loss 0.0162 (0.0427)	Prec@1 100.000 (98.628)
Epoch: [77][380/391]	Time 0.047 (0.048)	Loss 0.0305 (0.0426)	Prec@1 99.219 (98.620)
training time:  19.03436851501465
Test: [0/79]	Time 0.774 (0.774)	Loss 0.2569 (0.2569)	Prec@1 93.750 (93.750)
Test: [20/79]	Time 0.032 (0.067)	Loss 0.3087 (0.2740)	Prec@1 90.625 (92.225)
Test: [40/79]	Time 0.031 (0.050)	Loss 0.3464 (0.2593)	Prec@1 89.062 (92.492)
Test: [60/79]	Time 0.032 (0.044)	Loss 0.2009 (0.2523)	Prec@1 94.531 (92.572)
 * Prec@1 92.850
Epoch: [78][0/391]	Time 0.832 (0.832)	Loss 0.0394 (0.0394)	Prec@1 98.438 (98.438)
Epoch: [78][20/391]	Time 0.047 (0.084)	Loss 0.0170 (0.0348)	Prec@1 100.000 (98.772)
Epoch: [78][40/391]	Time 0.049 (0.066)	Loss 0.0130 (0.0369)	Prec@1 100.000 (98.780)
Epoch: [78][60/391]	Time 0.043 (0.059)	Loss 0.0370 (0.0364)	Prec@1 98.438 (98.783)
Epoch: [78][80/391]	Time 0.046 (0.056)	Loss 0.0196 (0.0369)	Prec@1 99.219 (98.775)
Epoch: [78][100/391]	Time 0.042 (0.054)	Loss 0.0189 (0.0373)	Prec@1 100.000 (98.747)
Epoch: [78][120/391]	Time 0.046 (0.053)	Loss 0.1031 (0.0370)	Prec@1 96.094 (98.773)
Epoch: [78][140/391]	Time 0.045 (0.052)	Loss 0.0154 (0.0372)	Prec@1 99.219 (98.737)
Epoch: [78][160/391]	Time 0.046 (0.051)	Loss 0.0140 (0.0364)	Prec@1 100.000 (98.753)
Epoch: [78][180/391]	Time 0.045 (0.050)	Loss 0.0118 (0.0358)	Prec@1 100.000 (98.787)
Epoch: [78][200/391]	Time 0.043 (0.051)	Loss 0.0508 (0.0360)	Prec@1 98.438 (98.787)
Epoch: [78][220/391]	Time 0.046 (0.050)	Loss 0.0494 (0.0360)	Prec@1 97.656 (98.802)
Epoch: [78][240/391]	Time 0.049 (0.050)	Loss 0.0524 (0.0365)	Prec@1 96.875 (98.778)
Epoch: [78][260/391]	Time 0.048 (0.050)	Loss 0.0381 (0.0360)	Prec@1 99.219 (98.815)
Epoch: [78][280/391]	Time 0.047 (0.049)	Loss 0.0222 (0.0358)	Prec@1 99.219 (98.835)
Epoch: [78][300/391]	Time 0.046 (0.049)	Loss 0.0191 (0.0357)	Prec@1 100.000 (98.848)
Epoch: [78][320/391]	Time 0.048 (0.049)	Loss 0.0264 (0.0360)	Prec@1 99.219 (98.834)
Epoch: [78][340/391]	Time 0.046 (0.049)	Loss 0.0680 (0.0362)	Prec@1 96.094 (98.811)
Epoch: [78][360/391]	Time 0.045 (0.049)	Loss 0.0214 (0.0367)	Prec@1 100.000 (98.803)
Epoch: [78][380/391]	Time 0.044 (0.049)	Loss 0.0765 (0.0370)	Prec@1 97.656 (98.800)
training time:  19.161442518234253
Test: [0/79]	Time 0.792 (0.792)	Loss 0.3377 (0.3377)	Prec@1 90.625 (90.625)
Test: [20/79]	Time 0.032 (0.068)	Loss 0.2211 (0.2545)	Prec@1 93.750 (93.043)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.2978 (0.2498)	Prec@1 91.406 (93.007)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.1617 (0.2469)	Prec@1 95.312 (93.046)
 * Prec@1 93.240
Epoch: [79][0/391]	Time 0.837 (0.837)	Loss 0.0041 (0.0041)	Prec@1 100.000 (100.000)
Epoch: [79][20/391]	Time 0.041 (0.082)	Loss 0.0129 (0.0315)	Prec@1 100.000 (99.107)
Epoch: [79][40/391]	Time 0.044 (0.064)	Loss 0.0615 (0.0343)	Prec@1 98.438 (99.047)
Epoch: [79][60/391]	Time 0.042 (0.058)	Loss 0.0447 (0.0369)	Prec@1 98.438 (98.899)
Epoch: [79][80/391]	Time 0.044 (0.055)	Loss 0.0292 (0.0354)	Prec@1 99.219 (98.929)
Epoch: [79][100/391]	Time 0.042 (0.053)	Loss 0.0657 (0.0350)	Prec@1 99.219 (98.948)
Epoch: [79][120/391]	Time 0.044 (0.052)	Loss 0.0351 (0.0339)	Prec@1 98.438 (98.986)
Epoch: [79][140/391]	Time 0.045 (0.051)	Loss 0.0413 (0.0345)	Prec@1 98.438 (98.958)
Epoch: [79][160/391]	Time 0.044 (0.051)	Loss 0.0549 (0.0343)	Prec@1 97.656 (98.966)
Epoch: [79][180/391]	Time 0.046 (0.050)	Loss 0.0282 (0.0346)	Prec@1 99.219 (98.925)
Epoch: [79][200/391]	Time 0.046 (0.050)	Loss 0.0489 (0.0343)	Prec@1 99.219 (98.939)
Epoch: [79][220/391]	Time 0.048 (0.050)	Loss 0.0409 (0.0350)	Prec@1 98.438 (98.908)
Epoch: [79][240/391]	Time 0.047 (0.049)	Loss 0.0697 (0.0354)	Prec@1 96.875 (98.882)
Epoch: [79][260/391]	Time 0.045 (0.049)	Loss 0.0081 (0.0352)	Prec@1 100.000 (98.884)
Epoch: [79][280/391]	Time 0.045 (0.049)	Loss 0.0071 (0.0356)	Prec@1 100.000 (98.871)
Epoch: [79][300/391]	Time 0.045 (0.049)	Loss 0.0255 (0.0362)	Prec@1 99.219 (98.845)
Epoch: [79][320/391]	Time 0.048 (0.049)	Loss 0.0246 (0.0363)	Prec@1 99.219 (98.842)
Epoch: [79][340/391]	Time 0.045 (0.049)	Loss 0.0581 (0.0363)	Prec@1 96.875 (98.834)
Epoch: [79][360/391]	Time 0.047 (0.048)	Loss 0.0252 (0.0362)	Prec@1 99.219 (98.834)
Epoch: [79][380/391]	Time 0.046 (0.048)	Loss 0.0156 (0.0357)	Prec@1 100.000 (98.862)
training time:  19.01052761077881
Test: [0/79]	Time 0.778 (0.778)	Loss 0.2808 (0.2808)	Prec@1 95.312 (95.312)
Test: [20/79]	Time 0.032 (0.067)	Loss 0.2590 (0.2673)	Prec@1 92.969 (92.746)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.2080 (0.2478)	Prec@1 92.969 (93.159)
Test: [60/79]	Time 0.033 (0.044)	Loss 0.2058 (0.2421)	Prec@1 95.312 (93.251)
 * Prec@1 93.350
Epoch: [80][0/391]	Time 0.831 (0.831)	Loss 0.0039 (0.0039)	Prec@1 100.000 (100.000)
Epoch: [80][20/391]	Time 0.047 (0.084)	Loss 0.0448 (0.0240)	Prec@1 98.438 (99.479)
Epoch: [80][40/391]	Time 0.044 (0.065)	Loss 0.0344 (0.0259)	Prec@1 99.219 (99.314)
Epoch: [80][60/391]	Time 0.045 (0.059)	Loss 0.0256 (0.0269)	Prec@1 98.438 (99.206)
Epoch: [80][80/391]	Time 0.048 (0.056)	Loss 0.0100 (0.0261)	Prec@1 100.000 (99.257)
Epoch: [80][100/391]	Time 0.048 (0.054)	Loss 0.0311 (0.0262)	Prec@1 99.219 (99.250)
Epoch: [80][120/391]	Time 0.046 (0.053)	Loss 0.0187 (0.0262)	Prec@1 99.219 (99.245)
Epoch: [80][140/391]	Time 0.047 (0.052)	Loss 0.0525 (0.0265)	Prec@1 98.438 (99.235)
Epoch: [80][160/391]	Time 0.049 (0.051)	Loss 0.0893 (0.0268)	Prec@1 96.875 (99.238)
Epoch: [80][180/391]	Time 0.046 (0.051)	Loss 0.0197 (0.0273)	Prec@1 100.000 (99.201)
Epoch: [80][200/391]	Time 0.048 (0.050)	Loss 0.0358 (0.0272)	Prec@1 99.219 (99.195)
Epoch: [80][220/391]	Time 0.047 (0.050)	Loss 0.0489 (0.0279)	Prec@1 98.438 (99.183)
Epoch: [80][240/391]	Time 0.046 (0.050)	Loss 0.0079 (0.0272)	Prec@1 100.000 (99.206)
Epoch: [80][260/391]	Time 0.047 (0.050)	Loss 0.0286 (0.0275)	Prec@1 99.219 (99.195)
Epoch: [80][280/391]	Time 0.046 (0.049)	Loss 0.0222 (0.0279)	Prec@1 99.219 (99.180)
Epoch: [80][300/391]	Time 0.045 (0.049)	Loss 0.0505 (0.0277)	Prec@1 98.438 (99.175)
Epoch: [80][320/391]	Time 0.042 (0.049)	Loss 0.0670 (0.0278)	Prec@1 96.875 (99.185)
Epoch: [80][340/391]	Time 0.045 (0.048)	Loss 0.0477 (0.0280)	Prec@1 96.875 (99.150)
Epoch: [80][360/391]	Time 0.041 (0.048)	Loss 0.0187 (0.0276)	Prec@1 100.000 (99.149)
Epoch: [80][380/391]	Time 0.045 (0.048)	Loss 0.0281 (0.0275)	Prec@1 99.219 (99.155)
training time:  18.84381365776062
Test: [0/79]	Time 0.783 (0.783)	Loss 0.2703 (0.2703)	Prec@1 93.750 (93.750)
Test: [20/79]	Time 0.029 (0.067)	Loss 0.3232 (0.2394)	Prec@1 91.406 (93.304)
Test: [40/79]	Time 0.029 (0.049)	Loss 0.4586 (0.2371)	Prec@1 91.406 (93.331)
Test: [60/79]	Time 0.031 (0.043)	Loss 0.1848 (0.2278)	Prec@1 95.312 (93.571)
 * Prec@1 93.810
=> Saving checkpoint for epoch 80, with Prec@1 93.810000.
Epoch: [81][0/391]	Time 0.835 (0.835)	Loss 0.0424 (0.0424)	Prec@1 98.438 (98.438)
Epoch: [81][20/391]	Time 0.044 (0.084)	Loss 0.0110 (0.0261)	Prec@1 100.000 (99.256)
Epoch: [81][40/391]	Time 0.045 (0.065)	Loss 0.0212 (0.0304)	Prec@1 100.000 (99.104)
Epoch: [81][60/391]	Time 0.045 (0.059)	Loss 0.0203 (0.0300)	Prec@1 99.219 (99.116)
Epoch: [81][80/391]	Time 0.046 (0.056)	Loss 0.0202 (0.0290)	Prec@1 99.219 (99.113)
Epoch: [81][100/391]	Time 0.049 (0.054)	Loss 0.0200 (0.0273)	Prec@1 99.219 (99.157)
Epoch: [81][120/391]	Time 0.046 (0.053)	Loss 0.0401 (0.0280)	Prec@1 98.438 (99.135)
Epoch: [81][140/391]	Time 0.045 (0.052)	Loss 0.0065 (0.0292)	Prec@1 100.000 (99.136)
Epoch: [81][160/391]	Time 0.045 (0.051)	Loss 0.0283 (0.0288)	Prec@1 99.219 (99.136)
Epoch: [81][180/391]	Time 0.045 (0.050)	Loss 0.0128 (0.0290)	Prec@1 100.000 (99.128)
Epoch: [81][200/391]	Time 0.043 (0.050)	Loss 0.0060 (0.0287)	Prec@1 100.000 (99.137)
Epoch: [81][220/391]	Time 0.048 (0.049)	Loss 0.0212 (0.0282)	Prec@1 99.219 (99.152)
Epoch: [81][240/391]	Time 0.046 (0.049)	Loss 0.0065 (0.0280)	Prec@1 100.000 (99.151)
Epoch: [81][260/391]	Time 0.045 (0.048)	Loss 0.0101 (0.0279)	Prec@1 100.000 (99.153)
Epoch: [81][280/391]	Time 0.047 (0.048)	Loss 0.0181 (0.0275)	Prec@1 100.000 (99.169)
Epoch: [81][300/391]	Time 0.047 (0.048)	Loss 0.0044 (0.0271)	Prec@1 100.000 (99.180)
Epoch: [81][320/391]	Time 0.047 (0.048)	Loss 0.0237 (0.0268)	Prec@1 100.000 (99.187)
Epoch: [81][340/391]	Time 0.046 (0.048)	Loss 0.0064 (0.0265)	Prec@1 100.000 (99.203)
Epoch: [81][360/391]	Time 0.046 (0.048)	Loss 0.0094 (0.0264)	Prec@1 100.000 (99.212)
Epoch: [81][380/391]	Time 0.043 (0.048)	Loss 0.0225 (0.0262)	Prec@1 98.438 (99.213)
training time:  18.89653968811035
Test: [0/79]	Time 0.774 (0.774)	Loss 0.2619 (0.2619)	Prec@1 93.750 (93.750)
Test: [20/79]	Time 0.032 (0.067)	Loss 0.1481 (0.2281)	Prec@1 95.312 (93.601)
Test: [40/79]	Time 0.029 (0.049)	Loss 0.2366 (0.2150)	Prec@1 92.969 (94.036)
Test: [60/79]	Time 0.031 (0.043)	Loss 0.1522 (0.2095)	Prec@1 96.875 (94.198)
 * Prec@1 94.290
=> Saving checkpoint for epoch 81, with Prec@1 94.290000.
Epoch: [82][0/391]	Time 0.819 (0.819)	Loss 0.0267 (0.0267)	Prec@1 99.219 (99.219)
Epoch: [82][20/391]	Time 0.047 (0.083)	Loss 0.0038 (0.0220)	Prec@1 100.000 (99.256)
Epoch: [82][40/391]	Time 0.046 (0.064)	Loss 0.0115 (0.0220)	Prec@1 100.000 (99.371)
Epoch: [82][60/391]	Time 0.049 (0.058)	Loss 0.0064 (0.0216)	Prec@1 100.000 (99.334)
Epoch: [82][80/391]	Time 0.047 (0.055)	Loss 0.0060 (0.0225)	Prec@1 100.000 (99.315)
Epoch: [82][100/391]	Time 0.046 (0.053)	Loss 0.0107 (0.0217)	Prec@1 100.000 (99.350)
Epoch: [82][120/391]	Time 0.046 (0.052)	Loss 0.0169 (0.0220)	Prec@1 100.000 (99.348)
Epoch: [82][140/391]	Time 0.049 (0.051)	Loss 0.0221 (0.0211)	Prec@1 98.438 (99.385)
Epoch: [82][160/391]	Time 0.050 (0.051)	Loss 0.0100 (0.0211)	Prec@1 100.000 (99.398)
Epoch: [82][180/391]	Time 0.043 (0.050)	Loss 0.0071 (0.0205)	Prec@1 100.000 (99.426)
Epoch: [82][200/391]	Time 0.046 (0.050)	Loss 0.0266 (0.0203)	Prec@1 98.438 (99.440)
Epoch: [82][220/391]	Time 0.049 (0.050)	Loss 0.0720 (0.0205)	Prec@1 98.438 (99.441)
Epoch: [82][240/391]	Time 0.049 (0.050)	Loss 0.0690 (0.0208)	Prec@1 98.438 (99.433)
Epoch: [82][260/391]	Time 0.048 (0.049)	Loss 0.0134 (0.0204)	Prec@1 100.000 (99.437)
Epoch: [82][280/391]	Time 0.048 (0.049)	Loss 0.0085 (0.0204)	Prec@1 100.000 (99.430)
Epoch: [82][300/391]	Time 0.047 (0.049)	Loss 0.0031 (0.0207)	Prec@1 100.000 (99.419)
Epoch: [82][320/391]	Time 0.048 (0.049)	Loss 0.0155 (0.0206)	Prec@1 100.000 (99.421)
Epoch: [82][340/391]	Time 0.047 (0.049)	Loss 0.0314 (0.0205)	Prec@1 99.219 (99.423)
Epoch: [82][360/391]	Time 0.046 (0.049)	Loss 0.0266 (0.0204)	Prec@1 99.219 (99.433)
Epoch: [82][380/391]	Time 0.045 (0.048)	Loss 0.0045 (0.0202)	Prec@1 100.000 (99.438)
training time:  19.048181533813477
Test: [0/79]	Time 0.783 (0.783)	Loss 0.2830 (0.2830)	Prec@1 93.750 (93.750)
Test: [20/79]	Time 0.031 (0.068)	Loss 0.1660 (0.2494)	Prec@1 95.312 (93.415)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.2043 (0.2242)	Prec@1 93.750 (93.902)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.1957 (0.2147)	Prec@1 95.312 (94.096)
 * Prec@1 94.290
Epoch: [83][0/391]	Time 0.822 (0.822)	Loss 0.0126 (0.0126)	Prec@1 99.219 (99.219)
Epoch: [83][20/391]	Time 0.043 (0.080)	Loss 0.0084 (0.0184)	Prec@1 100.000 (99.516)
Epoch: [83][40/391]	Time 0.043 (0.062)	Loss 0.0082 (0.0171)	Prec@1 100.000 (99.581)
Epoch: [83][60/391]	Time 0.046 (0.056)	Loss 0.0479 (0.0168)	Prec@1 97.656 (99.539)
Epoch: [83][80/391]	Time 0.047 (0.053)	Loss 0.0160 (0.0162)	Prec@1 100.000 (99.556)
Epoch: [83][100/391]	Time 0.045 (0.052)	Loss 0.0296 (0.0165)	Prec@1 99.219 (99.544)
Epoch: [83][120/391]	Time 0.044 (0.050)	Loss 0.0354 (0.0172)	Prec@1 99.219 (99.535)
Epoch: [83][140/391]	Time 0.046 (0.050)	Loss 0.0114 (0.0177)	Prec@1 99.219 (99.518)
Epoch: [83][160/391]	Time 0.047 (0.049)	Loss 0.0069 (0.0176)	Prec@1 100.000 (99.539)
Epoch: [83][180/391]	Time 0.046 (0.048)	Loss 0.0107 (0.0172)	Prec@1 100.000 (99.547)
Epoch: [83][200/391]	Time 0.046 (0.048)	Loss 0.0118 (0.0170)	Prec@1 100.000 (99.557)
Epoch: [83][220/391]	Time 0.043 (0.048)	Loss 0.0201 (0.0171)	Prec@1 99.219 (99.558)
Epoch: [83][240/391]	Time 0.045 (0.048)	Loss 0.0149 (0.0169)	Prec@1 100.000 (99.572)
Epoch: [83][260/391]	Time 0.045 (0.048)	Loss 0.0170 (0.0163)	Prec@1 99.219 (99.593)
Epoch: [83][280/391]	Time 0.047 (0.047)	Loss 0.0250 (0.0162)	Prec@1 99.219 (99.597)
Epoch: [83][300/391]	Time 0.046 (0.047)	Loss 0.0048 (0.0162)	Prec@1 100.000 (99.593)
Epoch: [83][320/391]	Time 0.046 (0.047)	Loss 0.0173 (0.0159)	Prec@1 99.219 (99.589)
Epoch: [83][340/391]	Time 0.046 (0.047)	Loss 0.0053 (0.0159)	Prec@1 100.000 (99.594)
Epoch: [83][360/391]	Time 0.046 (0.047)	Loss 0.0440 (0.0161)	Prec@1 97.656 (99.580)
Epoch: [83][380/391]	Time 0.045 (0.047)	Loss 0.0033 (0.0159)	Prec@1 100.000 (99.580)
training time:  18.579669713974
Test: [0/79]	Time 0.787 (0.787)	Loss 0.2896 (0.2896)	Prec@1 93.750 (93.750)
Test: [20/79]	Time 0.032 (0.068)	Loss 0.2758 (0.2462)	Prec@1 92.188 (93.155)
Test: [40/79]	Time 0.032 (0.051)	Loss 0.2529 (0.2284)	Prec@1 92.969 (93.655)
Test: [60/79]	Time 0.032 (0.045)	Loss 0.1722 (0.2191)	Prec@1 95.312 (93.788)
 * Prec@1 93.960
Epoch: [84][0/391]	Time 0.816 (0.816)	Loss 0.0382 (0.0382)	Prec@1 98.438 (98.438)
Epoch: [84][20/391]	Time 0.046 (0.083)	Loss 0.0117 (0.0120)	Prec@1 100.000 (99.702)
Epoch: [84][40/391]	Time 0.046 (0.065)	Loss 0.0074 (0.0118)	Prec@1 100.000 (99.714)
Epoch: [84][60/391]	Time 0.046 (0.059)	Loss 0.0026 (0.0114)	Prec@1 100.000 (99.731)
Epoch: [84][80/391]	Time 0.049 (0.056)	Loss 0.0116 (0.0117)	Prec@1 100.000 (99.682)
Epoch: [84][100/391]	Time 0.044 (0.054)	Loss 0.0288 (0.0123)	Prec@1 99.219 (99.675)
Epoch: [84][120/391]	Time 0.046 (0.053)	Loss 0.0022 (0.0118)	Prec@1 100.000 (99.690)
Epoch: [84][140/391]	Time 0.046 (0.052)	Loss 0.0055 (0.0117)	Prec@1 100.000 (99.701)
Epoch: [84][160/391]	Time 0.048 (0.051)	Loss 0.0067 (0.0116)	Prec@1 100.000 (99.704)
Epoch: [84][180/391]	Time 0.047 (0.051)	Loss 0.0140 (0.0115)	Prec@1 99.219 (99.698)
Epoch: [84][200/391]	Time 0.046 (0.050)	Loss 0.0082 (0.0114)	Prec@1 100.000 (99.705)
Epoch: [84][220/391]	Time 0.046 (0.051)	Loss 0.0255 (0.0116)	Prec@1 99.219 (99.703)
Epoch: [84][240/391]	Time 0.047 (0.050)	Loss 0.0072 (0.0120)	Prec@1 100.000 (99.689)
Epoch: [84][260/391]	Time 0.045 (0.050)	Loss 0.0151 (0.0122)	Prec@1 99.219 (99.680)
Epoch: [84][280/391]	Time 0.046 (0.050)	Loss 0.0150 (0.0124)	Prec@1 100.000 (99.680)
Epoch: [84][300/391]	Time 0.046 (0.049)	Loss 0.0055 (0.0123)	Prec@1 100.000 (99.676)
Epoch: [84][320/391]	Time 0.046 (0.049)	Loss 0.0268 (0.0123)	Prec@1 98.438 (99.676)
Epoch: [84][340/391]	Time 0.047 (0.049)	Loss 0.0043 (0.0123)	Prec@1 100.000 (99.675)
Epoch: [84][360/391]	Time 0.046 (0.049)	Loss 0.0071 (0.0124)	Prec@1 100.000 (99.669)
Epoch: [84][380/391]	Time 0.045 (0.049)	Loss 0.0262 (0.0124)	Prec@1 99.219 (99.672)
training time:  19.194144010543823
Test: [0/79]	Time 0.778 (0.778)	Loss 0.1973 (0.1973)	Prec@1 93.750 (93.750)
Test: [20/79]	Time 0.028 (0.067)	Loss 0.2354 (0.2222)	Prec@1 94.531 (93.564)
Test: [40/79]	Time 0.029 (0.050)	Loss 0.2015 (0.2103)	Prec@1 94.531 (94.169)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.1940 (0.2016)	Prec@1 96.094 (94.339)
 * Prec@1 94.430
=> Saving checkpoint for epoch 84, with Prec@1 94.430000.
Epoch: [85][0/391]	Time 0.778 (0.778)	Loss 0.0121 (0.0121)	Prec@1 100.000 (100.000)
Epoch: [85][20/391]	Time 0.048 (0.081)	Loss 0.0082 (0.0112)	Prec@1 100.000 (99.740)
Epoch: [85][40/391]	Time 0.047 (0.064)	Loss 0.0209 (0.0118)	Prec@1 99.219 (99.714)
Epoch: [85][60/391]	Time 0.047 (0.058)	Loss 0.0055 (0.0113)	Prec@1 100.000 (99.731)
Epoch: [85][80/391]	Time 0.047 (0.055)	Loss 0.0087 (0.0111)	Prec@1 100.000 (99.730)
Epoch: [85][100/391]	Time 0.046 (0.054)	Loss 0.0159 (0.0111)	Prec@1 99.219 (99.729)
Epoch: [85][120/391]	Time 0.047 (0.052)	Loss 0.0061 (0.0112)	Prec@1 100.000 (99.722)
Epoch: [85][140/391]	Time 0.047 (0.052)	Loss 0.0497 (0.0115)	Prec@1 98.438 (99.706)
Epoch: [85][160/391]	Time 0.048 (0.051)	Loss 0.0102 (0.0109)	Prec@1 100.000 (99.728)
Epoch: [85][180/391]	Time 0.047 (0.050)	Loss 0.0063 (0.0102)	Prec@1 100.000 (99.754)
Epoch: [85][200/391]	Time 0.047 (0.050)	Loss 0.0067 (0.0100)	Prec@1 100.000 (99.751)
Epoch: [85][220/391]	Time 0.046 (0.050)	Loss 0.0041 (0.0098)	Prec@1 100.000 (99.760)
Epoch: [85][240/391]	Time 0.046 (0.049)	Loss 0.0032 (0.0099)	Prec@1 100.000 (99.754)
Epoch: [85][260/391]	Time 0.047 (0.049)	Loss 0.0029 (0.0100)	Prec@1 100.000 (99.755)
Epoch: [85][280/391]	Time 0.046 (0.049)	Loss 0.0034 (0.0101)	Prec@1 100.000 (99.750)
Epoch: [85][300/391]	Time 0.047 (0.049)	Loss 0.0046 (0.0103)	Prec@1 100.000 (99.738)
Epoch: [85][320/391]	Time 0.046 (0.049)	Loss 0.0028 (0.0101)	Prec@1 100.000 (99.742)
Epoch: [85][340/391]	Time 0.045 (0.049)	Loss 0.0033 (0.0102)	Prec@1 100.000 (99.743)
Epoch: [85][360/391]	Time 0.048 (0.048)	Loss 0.0142 (0.0102)	Prec@1 99.219 (99.738)
Epoch: [85][380/391]	Time 0.046 (0.048)	Loss 0.0057 (0.0102)	Prec@1 100.000 (99.742)
training time:  19.00543999671936
Test: [0/79]	Time 0.763 (0.763)	Loss 0.2263 (0.2263)	Prec@1 94.531 (94.531)
Test: [20/79]	Time 0.032 (0.067)	Loss 0.2245 (0.2387)	Prec@1 94.531 (93.415)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.2347 (0.2201)	Prec@1 92.188 (93.941)
Test: [60/79]	Time 0.033 (0.044)	Loss 0.1867 (0.2094)	Prec@1 96.875 (94.198)
 * Prec@1 94.370
Epoch: [86][0/391]	Time 0.825 (0.825)	Loss 0.0163 (0.0163)	Prec@1 99.219 (99.219)
Epoch: [86][20/391]	Time 0.045 (0.083)	Loss 0.0065 (0.0068)	Prec@1 100.000 (99.814)
Epoch: [86][40/391]	Time 0.045 (0.064)	Loss 0.0067 (0.0086)	Prec@1 100.000 (99.752)
Epoch: [86][60/391]	Time 0.044 (0.058)	Loss 0.0028 (0.0076)	Prec@1 100.000 (99.821)
Epoch: [86][80/391]	Time 0.045 (0.054)	Loss 0.0030 (0.0081)	Prec@1 100.000 (99.817)
Epoch: [86][100/391]	Time 0.046 (0.052)	Loss 0.0029 (0.0073)	Prec@1 100.000 (99.845)
Epoch: [86][120/391]	Time 0.047 (0.051)	Loss 0.0125 (0.0073)	Prec@1 100.000 (99.832)
Epoch: [86][140/391]	Time 0.047 (0.050)	Loss 0.0090 (0.0072)	Prec@1 100.000 (99.845)
Epoch: [86][160/391]	Time 0.049 (0.050)	Loss 0.0019 (0.0070)	Prec@1 100.000 (99.850)
Epoch: [86][180/391]	Time 0.047 (0.050)	Loss 0.0053 (0.0069)	Prec@1 100.000 (99.853)
Epoch: [86][200/391]	Time 0.046 (0.049)	Loss 0.0090 (0.0070)	Prec@1 100.000 (99.852)
Epoch: [86][220/391]	Time 0.046 (0.050)	Loss 0.0023 (0.0071)	Prec@1 100.000 (99.852)
Epoch: [86][240/391]	Time 0.047 (0.049)	Loss 0.0024 (0.0075)	Prec@1 100.000 (99.841)
Epoch: [86][260/391]	Time 0.046 (0.049)	Loss 0.0348 (0.0077)	Prec@1 99.219 (99.832)
Epoch: [86][280/391]	Time 0.047 (0.049)	Loss 0.0099 (0.0078)	Prec@1 100.000 (99.833)
Epoch: [86][300/391]	Time 0.047 (0.049)	Loss 0.0147 (0.0082)	Prec@1 99.219 (99.818)
Epoch: [86][320/391]	Time 0.047 (0.049)	Loss 0.0026 (0.0081)	Prec@1 100.000 (99.820)
Epoch: [86][340/391]	Time 0.047 (0.048)	Loss 0.0069 (0.0080)	Prec@1 100.000 (99.824)
Epoch: [86][360/391]	Time 0.048 (0.048)	Loss 0.0020 (0.0080)	Prec@1 100.000 (99.825)
Epoch: [86][380/391]	Time 0.046 (0.048)	Loss 0.0028 (0.0080)	Prec@1 100.000 (99.830)
training time:  19.068397998809814
Test: [0/79]	Time 0.752 (0.752)	Loss 0.2007 (0.2007)	Prec@1 94.531 (94.531)
Test: [20/79]	Time 0.032 (0.066)	Loss 0.2300 (0.2267)	Prec@1 94.531 (94.085)
Test: [40/79]	Time 0.032 (0.049)	Loss 0.1746 (0.2098)	Prec@1 95.312 (94.398)
Test: [60/79]	Time 0.031 (0.043)	Loss 0.1762 (0.2021)	Prec@1 96.875 (94.595)
 * Prec@1 94.680
=> Saving checkpoint for epoch 86, with Prec@1 94.680000.
Epoch: [87][0/391]	Time 0.791 (0.791)	Loss 0.0051 (0.0051)	Prec@1 100.000 (100.000)
Epoch: [87][20/391]	Time 0.046 (0.081)	Loss 0.0030 (0.0099)	Prec@1 100.000 (99.740)
Epoch: [87][40/391]	Time 0.046 (0.064)	Loss 0.0038 (0.0088)	Prec@1 100.000 (99.809)
Epoch: [87][60/391]	Time 0.046 (0.058)	Loss 0.0028 (0.0090)	Prec@1 100.000 (99.769)
Epoch: [87][80/391]	Time 0.047 (0.055)	Loss 0.0076 (0.0084)	Prec@1 100.000 (99.817)
Epoch: [87][100/391]	Time 0.046 (0.053)	Loss 0.0034 (0.0082)	Prec@1 100.000 (99.814)
Epoch: [87][120/391]	Time 0.046 (0.052)	Loss 0.0034 (0.0078)	Prec@1 100.000 (99.845)
Epoch: [87][140/391]	Time 0.046 (0.051)	Loss 0.0027 (0.0078)	Prec@1 100.000 (99.850)
Epoch: [87][160/391]	Time 0.046 (0.051)	Loss 0.0131 (0.0075)	Prec@1 99.219 (99.859)
Epoch: [87][180/391]	Time 0.047 (0.050)	Loss 0.0081 (0.0078)	Prec@1 100.000 (99.849)
Epoch: [87][200/391]	Time 0.047 (0.050)	Loss 0.0124 (0.0078)	Prec@1 100.000 (99.848)
Epoch: [87][220/391]	Time 0.046 (0.049)	Loss 0.0019 (0.0076)	Prec@1 100.000 (99.848)
Epoch: [87][240/391]	Time 0.048 (0.049)	Loss 0.0149 (0.0078)	Prec@1 99.219 (99.841)
Epoch: [87][260/391]	Time 0.046 (0.049)	Loss 0.0373 (0.0079)	Prec@1 99.219 (99.835)
Epoch: [87][280/391]	Time 0.047 (0.049)	Loss 0.0041 (0.0081)	Prec@1 100.000 (99.825)
Epoch: [87][300/391]	Time 0.046 (0.048)	Loss 0.0053 (0.0080)	Prec@1 100.000 (99.824)
Epoch: [87][320/391]	Time 0.046 (0.048)	Loss 0.0028 (0.0080)	Prec@1 100.000 (99.817)
Epoch: [87][340/391]	Time 0.048 (0.048)	Loss 0.0098 (0.0080)	Prec@1 100.000 (99.824)
Epoch: [87][360/391]	Time 0.049 (0.048)	Loss 0.0048 (0.0081)	Prec@1 100.000 (99.805)
Epoch: [87][380/391]	Time 0.047 (0.048)	Loss 0.0026 (0.0081)	Prec@1 100.000 (99.805)
training time:  18.905936241149902
Test: [0/79]	Time 0.748 (0.748)	Loss 0.2482 (0.2482)	Prec@1 94.531 (94.531)
Test: [20/79]	Time 0.032 (0.066)	Loss 0.2452 (0.2147)	Prec@1 94.531 (94.234)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.2175 (0.2056)	Prec@1 92.188 (94.512)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.1785 (0.1971)	Prec@1 96.875 (94.723)
 * Prec@1 94.840
=> Saving checkpoint for epoch 87, with Prec@1 94.840000.
Epoch: [88][0/391]	Time 0.789 (0.789)	Loss 0.0052 (0.0052)	Prec@1 100.000 (100.000)
Epoch: [88][20/391]	Time 0.045 (0.081)	Loss 0.0088 (0.0061)	Prec@1 100.000 (99.888)
Epoch: [88][40/391]	Time 0.042 (0.064)	Loss 0.0157 (0.0063)	Prec@1 99.219 (99.848)
Epoch: [88][60/391]	Time 0.048 (0.058)	Loss 0.0055 (0.0059)	Prec@1 100.000 (99.885)
Epoch: [88][80/391]	Time 0.040 (0.055)	Loss 0.0092 (0.0060)	Prec@1 100.000 (99.865)
Epoch: [88][100/391]	Time 0.047 (0.053)	Loss 0.0361 (0.0066)	Prec@1 99.219 (99.861)
Epoch: [88][120/391]	Time 0.045 (0.051)	Loss 0.0067 (0.0066)	Prec@1 100.000 (99.884)
Epoch: [88][140/391]	Time 0.046 (0.051)	Loss 0.0015 (0.0068)	Prec@1 100.000 (99.878)
Epoch: [88][160/391]	Time 0.046 (0.050)	Loss 0.0027 (0.0065)	Prec@1 100.000 (99.884)
Epoch: [88][180/391]	Time 0.044 (0.050)	Loss 0.0020 (0.0065)	Prec@1 100.000 (99.888)
Epoch: [88][200/391]	Time 0.045 (0.049)	Loss 0.0022 (0.0064)	Prec@1 100.000 (99.899)
Epoch: [88][220/391]	Time 0.047 (0.050)	Loss 0.0058 (0.0063)	Prec@1 100.000 (99.901)
Epoch: [88][240/391]	Time 0.046 (0.049)	Loss 0.0057 (0.0063)	Prec@1 100.000 (99.903)
Epoch: [88][260/391]	Time 0.046 (0.049)	Loss 0.0026 (0.0064)	Prec@1 100.000 (99.898)
Epoch: [88][280/391]	Time 0.045 (0.049)	Loss 0.0021 (0.0063)	Prec@1 100.000 (99.900)
Epoch: [88][300/391]	Time 0.046 (0.049)	Loss 0.0032 (0.0062)	Prec@1 100.000 (99.896)
Epoch: [88][320/391]	Time 0.045 (0.049)	Loss 0.0023 (0.0062)	Prec@1 100.000 (99.895)
Epoch: [88][340/391]	Time 0.045 (0.048)	Loss 0.0066 (0.0062)	Prec@1 100.000 (99.897)
Epoch: [88][360/391]	Time 0.046 (0.048)	Loss 0.0024 (0.0061)	Prec@1 100.000 (99.903)
Epoch: [88][380/391]	Time 0.044 (0.048)	Loss 0.0051 (0.0061)	Prec@1 100.000 (99.904)
training time:  18.934736013412476
Test: [0/79]	Time 0.739 (0.739)	Loss 0.2206 (0.2206)	Prec@1 95.312 (95.312)
Test: [20/79]	Time 0.031 (0.065)	Loss 0.2489 (0.2071)	Prec@1 94.531 (94.531)
Test: [40/79]	Time 0.032 (0.049)	Loss 0.1769 (0.2030)	Prec@1 93.750 (94.684)
Test: [60/79]	Time 0.033 (0.043)	Loss 0.1822 (0.1953)	Prec@1 95.312 (94.723)
 * Prec@1 94.910
=> Saving checkpoint for epoch 88, with Prec@1 94.910000.
Epoch: [89][0/391]	Time 0.781 (0.781)	Loss 0.0037 (0.0037)	Prec@1 100.000 (100.000)
Epoch: [89][20/391]	Time 0.048 (0.082)	Loss 0.0040 (0.0035)	Prec@1 100.000 (99.963)
Epoch: [89][40/391]	Time 0.046 (0.064)	Loss 0.0114 (0.0042)	Prec@1 99.219 (99.943)
Epoch: [89][60/391]	Time 0.047 (0.058)	Loss 0.0058 (0.0046)	Prec@1 100.000 (99.949)
Epoch: [89][80/391]	Time 0.046 (0.055)	Loss 0.0088 (0.0050)	Prec@1 99.219 (99.942)
Epoch: [89][100/391]	Time 0.046 (0.054)	Loss 0.0070 (0.0048)	Prec@1 100.000 (99.946)
Epoch: [89][120/391]	Time 0.046 (0.052)	Loss 0.0024 (0.0047)	Prec@1 100.000 (99.948)
Epoch: [89][140/391]	Time 0.048 (0.052)	Loss 0.0024 (0.0048)	Prec@1 100.000 (99.928)
Epoch: [89][160/391]	Time 0.046 (0.051)	Loss 0.0022 (0.0048)	Prec@1 100.000 (99.922)
Epoch: [89][180/391]	Time 0.047 (0.050)	Loss 0.0036 (0.0046)	Prec@1 100.000 (99.931)
Epoch: [89][200/391]	Time 0.092 (0.050)	Loss 0.0079 (0.0046)	Prec@1 99.219 (99.930)
Epoch: [89][220/391]	Time 0.043 (0.050)	Loss 0.0071 (0.0046)	Prec@1 100.000 (99.929)
Epoch: [89][240/391]	Time 0.046 (0.050)	Loss 0.0251 (0.0046)	Prec@1 99.219 (99.929)
Epoch: [89][260/391]	Time 0.046 (0.049)	Loss 0.0119 (0.0046)	Prec@1 100.000 (99.934)
Epoch: [89][280/391]	Time 0.047 (0.049)	Loss 0.0050 (0.0045)	Prec@1 100.000 (99.939)
Epoch: [89][300/391]	Time 0.046 (0.049)	Loss 0.0027 (0.0044)	Prec@1 100.000 (99.943)
Epoch: [89][320/391]	Time 0.046 (0.049)	Loss 0.0018 (0.0044)	Prec@1 100.000 (99.944)
Epoch: [89][340/391]	Time 0.046 (0.049)	Loss 0.0092 (0.0045)	Prec@1 100.000 (99.940)
Epoch: [89][360/391]	Time 0.046 (0.048)	Loss 0.0029 (0.0046)	Prec@1 100.000 (99.933)
Epoch: [89][380/391]	Time 0.044 (0.048)	Loss 0.0015 (0.0047)	Prec@1 100.000 (99.928)
training time:  19.025023698806763
Test: [0/79]	Time 0.743 (0.743)	Loss 0.2362 (0.2362)	Prec@1 95.312 (95.312)
Test: [20/79]	Time 0.032 (0.064)	Loss 0.2527 (0.2106)	Prec@1 93.750 (94.606)
Test: [40/79]	Time 0.031 (0.049)	Loss 0.2169 (0.2002)	Prec@1 92.969 (94.741)
Test: [60/79]	Time 0.031 (0.043)	Loss 0.1577 (0.1913)	Prec@1 96.875 (94.941)
 * Prec@1 95.080
=> Saving checkpoint for epoch 89, with Prec@1 95.080000.
Epoch: [90][0/391]	Time 0.778 (0.778)	Loss 0.0074 (0.0074)	Prec@1 100.000 (100.000)
Epoch: [90][20/391]	Time 0.044 (0.080)	Loss 0.0041 (0.0045)	Prec@1 100.000 (100.000)
Epoch: [90][40/391]	Time 0.042 (0.062)	Loss 0.0046 (0.0047)	Prec@1 100.000 (99.962)
Epoch: [90][60/391]	Time 0.042 (0.056)	Loss 0.0046 (0.0049)	Prec@1 100.000 (99.936)
Epoch: [90][80/391]	Time 0.044 (0.053)	Loss 0.0060 (0.0054)	Prec@1 100.000 (99.923)
Epoch: [90][100/391]	Time 0.042 (0.052)	Loss 0.0045 (0.0051)	Prec@1 100.000 (99.938)
Epoch: [90][120/391]	Time 0.043 (0.050)	Loss 0.0025 (0.0050)	Prec@1 100.000 (99.942)
Epoch: [90][140/391]	Time 0.046 (0.049)	Loss 0.0045 (0.0049)	Prec@1 100.000 (99.939)
Epoch: [90][160/391]	Time 0.044 (0.049)	Loss 0.0010 (0.0050)	Prec@1 100.000 (99.927)
Epoch: [90][180/391]	Time 0.045 (0.048)	Loss 0.0049 (0.0050)	Prec@1 100.000 (99.927)
Epoch: [90][200/391]	Time 0.044 (0.048)	Loss 0.0013 (0.0051)	Prec@1 100.000 (99.922)
Epoch: [90][220/391]	Time 0.047 (0.048)	Loss 0.0023 (0.0050)	Prec@1 100.000 (99.919)
Epoch: [90][240/391]	Time 0.046 (0.048)	Loss 0.0030 (0.0049)	Prec@1 100.000 (99.919)
Epoch: [90][260/391]	Time 0.048 (0.048)	Loss 0.0009 (0.0050)	Prec@1 100.000 (99.913)
Epoch: [90][280/391]	Time 0.046 (0.048)	Loss 0.0142 (0.0051)	Prec@1 99.219 (99.905)
Epoch: [90][300/391]	Time 0.049 (0.048)	Loss 0.0065 (0.0051)	Prec@1 100.000 (99.909)
Epoch: [90][320/391]	Time 0.048 (0.048)	Loss 0.0024 (0.0050)	Prec@1 100.000 (99.912)
Epoch: [90][340/391]	Time 0.047 (0.048)	Loss 0.0017 (0.0049)	Prec@1 100.000 (99.911)
Epoch: [90][360/391]	Time 0.047 (0.048)	Loss 0.0021 (0.0048)	Prec@1 100.000 (99.916)
Epoch: [90][380/391]	Time 0.044 (0.048)	Loss 0.0090 (0.0048)	Prec@1 99.219 (99.918)
training time:  18.743077039718628
Test: [0/79]	Time 0.744 (0.744)	Loss 0.2350 (0.2350)	Prec@1 95.312 (95.312)
Test: [20/79]	Time 0.032 (0.066)	Loss 0.2354 (0.2183)	Prec@1 94.531 (94.382)
Test: [40/79]	Time 0.032 (0.049)	Loss 0.1750 (0.2068)	Prec@1 92.969 (94.379)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.1756 (0.1955)	Prec@1 95.312 (94.621)
 * Prec@1 94.880
Epoch: [91][0/391]	Time 0.785 (0.785)	Loss 0.0066 (0.0066)	Prec@1 100.000 (100.000)
Epoch: [91][20/391]	Time 0.046 (0.081)	Loss 0.0026 (0.0053)	Prec@1 100.000 (99.926)
Epoch: [91][40/391]	Time 0.046 (0.064)	Loss 0.0032 (0.0049)	Prec@1 100.000 (99.924)
Epoch: [91][60/391]	Time 0.046 (0.058)	Loss 0.0053 (0.0045)	Prec@1 100.000 (99.949)
Epoch: [91][80/391]	Time 0.046 (0.055)	Loss 0.0234 (0.0045)	Prec@1 99.219 (99.952)
Epoch: [91][100/391]	Time 0.046 (0.053)	Loss 0.0043 (0.0044)	Prec@1 100.000 (99.954)
Epoch: [91][120/391]	Time 0.046 (0.052)	Loss 0.0073 (0.0048)	Prec@1 100.000 (99.942)
Epoch: [91][140/391]	Time 0.045 (0.051)	Loss 0.0059 (0.0047)	Prec@1 100.000 (99.939)
Epoch: [91][160/391]	Time 0.045 (0.050)	Loss 0.0033 (0.0047)	Prec@1 100.000 (99.937)
Epoch: [91][180/391]	Time 0.047 (0.050)	Loss 0.0019 (0.0046)	Prec@1 100.000 (99.940)
Epoch: [91][200/391]	Time 0.045 (0.049)	Loss 0.0032 (0.0043)	Prec@1 100.000 (99.946)
Epoch: [91][220/391]	Time 0.047 (0.049)	Loss 0.0016 (0.0044)	Prec@1 100.000 (99.943)
Epoch: [91][240/391]	Time 0.047 (0.049)	Loss 0.0028 (0.0043)	Prec@1 100.000 (99.945)
Epoch: [91][260/391]	Time 0.046 (0.049)	Loss 0.0168 (0.0045)	Prec@1 99.219 (99.937)
Epoch: [91][280/391]	Time 0.047 (0.048)	Loss 0.0017 (0.0044)	Prec@1 100.000 (99.936)
Epoch: [91][300/391]	Time 0.046 (0.048)	Loss 0.0060 (0.0044)	Prec@1 100.000 (99.938)
Epoch: [91][320/391]	Time 0.046 (0.048)	Loss 0.0035 (0.0044)	Prec@1 100.000 (99.934)
Epoch: [91][340/391]	Time 0.046 (0.048)	Loss 0.0017 (0.0043)	Prec@1 100.000 (99.938)
Epoch: [91][360/391]	Time 0.047 (0.048)	Loss 0.0021 (0.0043)	Prec@1 100.000 (99.939)
Epoch: [91][380/391]	Time 0.046 (0.048)	Loss 0.0102 (0.0043)	Prec@1 99.219 (99.936)
training time:  18.855586051940918
Test: [0/79]	Time 0.739 (0.739)	Loss 0.2168 (0.2168)	Prec@1 95.312 (95.312)
Test: [20/79]	Time 0.031 (0.065)	Loss 0.2439 (0.2075)	Prec@1 93.750 (94.903)
Test: [40/79]	Time 0.032 (0.049)	Loss 0.2074 (0.1986)	Prec@1 92.188 (94.855)
Test: [60/79]	Time 0.032 (0.044)	Loss 0.1620 (0.1875)	Prec@1 96.875 (95.108)
 * Prec@1 95.200
=> Saving checkpoint for epoch 91, with Prec@1 95.200000.
Epoch: [92][0/391]	Time 0.778 (0.778)	Loss 0.0040 (0.0040)	Prec@1 100.000 (100.000)
Epoch: [92][20/391]	Time 0.046 (0.081)	Loss 0.0027 (0.0032)	Prec@1 100.000 (99.963)
Epoch: [92][40/391]	Time 0.047 (0.065)	Loss 0.0022 (0.0035)	Prec@1 100.000 (99.962)
Epoch: [92][60/391]	Time 0.046 (0.058)	Loss 0.0014 (0.0038)	Prec@1 100.000 (99.936)
Epoch: [92][80/391]	Time 0.045 (0.055)	Loss 0.0021 (0.0040)	Prec@1 100.000 (99.942)
Epoch: [92][100/391]	Time 0.046 (0.054)	Loss 0.0032 (0.0041)	Prec@1 100.000 (99.946)
Epoch: [92][120/391]	Time 0.047 (0.052)	Loss 0.0020 (0.0041)	Prec@1 100.000 (99.942)
Epoch: [92][140/391]	Time 0.044 (0.052)	Loss 0.0024 (0.0040)	Prec@1 100.000 (99.939)
Epoch: [92][160/391]	Time 0.045 (0.051)	Loss 0.0024 (0.0041)	Prec@1 100.000 (99.942)
Epoch: [92][180/391]	Time 0.045 (0.050)	Loss 0.0024 (0.0041)	Prec@1 100.000 (99.940)
Epoch: [92][200/391]	Time 0.046 (0.051)	Loss 0.0073 (0.0040)	Prec@1 100.000 (99.946)
Epoch: [92][220/391]	Time 0.046 (0.050)	Loss 0.0057 (0.0039)	Prec@1 100.000 (99.947)
Epoch: [92][240/391]	Time 0.047 (0.050)	Loss 0.0028 (0.0039)	Prec@1 100.000 (99.951)
Epoch: [92][260/391]	Time 0.046 (0.050)	Loss 0.0031 (0.0039)	Prec@1 100.000 (99.952)
Epoch: [92][280/391]	Time 0.046 (0.049)	Loss 0.0038 (0.0038)	Prec@1 100.000 (99.953)
Epoch: [92][300/391]	Time 0.045 (0.049)	Loss 0.0014 (0.0038)	Prec@1 100.000 (99.956)
Epoch: [92][320/391]	Time 0.046 (0.049)	Loss 0.0128 (0.0039)	Prec@1 99.219 (99.951)
Epoch: [92][340/391]	Time 0.046 (0.049)	Loss 0.0023 (0.0040)	Prec@1 100.000 (99.950)
Epoch: [92][360/391]	Time 0.047 (0.049)	Loss 0.0018 (0.0040)	Prec@1 100.000 (99.948)
Epoch: [92][380/391]	Time 0.046 (0.049)	Loss 0.0018 (0.0040)	Prec@1 100.000 (99.951)
training time:  19.120787858963013
Test: [0/79]	Time 0.749 (0.749)	Loss 0.2081 (0.2081)	Prec@1 95.312 (95.312)
Test: [20/79]	Time 0.029 (0.065)	Loss 0.2222 (0.2074)	Prec@1 94.531 (94.457)
Test: [40/79]	Time 0.028 (0.048)	Loss 0.1775 (0.1989)	Prec@1 93.750 (94.550)
Test: [60/79]	Time 0.032 (0.043)	Loss 0.1505 (0.1886)	Prec@1 96.094 (94.736)
 * Prec@1 94.930
Epoch: [93][0/391]	Time 0.777 (0.777)	Loss 0.0020 (0.0020)	Prec@1 100.000 (100.000)
Epoch: [93][20/391]	Time 0.047 (0.081)	Loss 0.0024 (0.0041)	Prec@1 100.000 (99.926)
Epoch: [93][40/391]	Time 0.048 (0.064)	Loss 0.0026 (0.0042)	Prec@1 100.000 (99.924)
Epoch: [93][60/391]	Time 0.046 (0.058)	Loss 0.0019 (0.0039)	Prec@1 100.000 (99.949)
Epoch: [93][80/391]	Time 0.049 (0.055)	Loss 0.0033 (0.0036)	Prec@1 100.000 (99.961)
Epoch: [93][100/391]	Time 0.047 (0.053)	Loss 0.0089 (0.0039)	Prec@1 99.219 (99.954)
Epoch: [93][120/391]	Time 0.047 (0.052)	Loss 0.0017 (0.0038)	Prec@1 100.000 (99.955)
Epoch: [93][140/391]	Time 0.047 (0.051)	Loss 0.0021 (0.0039)	Prec@1 100.000 (99.950)
Epoch: [93][160/391]	Time 0.047 (0.051)	Loss 0.0021 (0.0037)	Prec@1 100.000 (99.956)
Epoch: [93][180/391]	Time 0.046 (0.050)	Loss 0.0040 (0.0037)	Prec@1 100.000 (99.957)
Epoch: [93][200/391]	Time 0.047 (0.050)	Loss 0.0030 (0.0037)	Prec@1 100.000 (99.953)
Epoch: [93][220/391]	Time 0.047 (0.050)	Loss 0.0070 (0.0037)	Prec@1 100.000 (99.958)
Epoch: [93][240/391]	Time 0.046 (0.049)	Loss 0.0024 (0.0036)	Prec@1 100.000 (99.961)
Epoch: [93][260/391]	Time 0.048 (0.049)	Loss 0.0018 (0.0036)	Prec@1 100.000 (99.958)
Epoch: [93][280/391]	Time 0.046 (0.049)	Loss 0.0026 (0.0035)	Prec@1 100.000 (99.961)
Epoch: [93][300/391]	Time 0.046 (0.049)	Loss 0.0062 (0.0035)	Prec@1 100.000 (99.964)
Epoch: [93][320/391]	Time 0.047 (0.049)	Loss 0.0020 (0.0034)	Prec@1 100.000 (99.966)
Epoch: [93][340/391]	Time 0.047 (0.048)	Loss 0.0070 (0.0035)	Prec@1 100.000 (99.968)
Epoch: [93][360/391]	Time 0.046 (0.048)	Loss 0.0053 (0.0035)	Prec@1 100.000 (99.970)
Epoch: [93][380/391]	Time 0.046 (0.048)	Loss 0.0024 (0.0035)	Prec@1 100.000 (99.967)
training time:  18.984532117843628
Test: [0/79]	Time 0.756 (0.756)	Loss 0.2046 (0.2046)	Prec@1 95.312 (95.312)
Test: [20/79]	Time 0.031 (0.066)	Loss 0.2114 (0.2063)	Prec@1 94.531 (94.568)
Test: [40/79]	Time 0.030 (0.050)	Loss 0.1982 (0.1982)	Prec@1 92.969 (94.646)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.1523 (0.1872)	Prec@1 96.875 (94.877)
 * Prec@1 95.070
Epoch: [94][0/391]	Time 0.798 (0.798)	Loss 0.0051 (0.0051)	Prec@1 100.000 (100.000)
Epoch: [94][20/391]	Time 0.044 (0.081)	Loss 0.0019 (0.0028)	Prec@1 100.000 (100.000)
Epoch: [94][40/391]	Time 0.048 (0.065)	Loss 0.0121 (0.0031)	Prec@1 99.219 (99.962)
Epoch: [94][60/391]	Time 0.047 (0.059)	Loss 0.0017 (0.0029)	Prec@1 100.000 (99.974)
Epoch: [94][80/391]	Time 0.048 (0.056)	Loss 0.0029 (0.0035)	Prec@1 100.000 (99.952)
Epoch: [94][100/391]	Time 0.047 (0.054)	Loss 0.0055 (0.0034)	Prec@1 100.000 (99.961)
Epoch: [94][120/391]	Time 0.047 (0.053)	Loss 0.0068 (0.0037)	Prec@1 100.000 (99.948)
Epoch: [94][140/391]	Time 0.048 (0.052)	Loss 0.0028 (0.0036)	Prec@1 100.000 (99.945)
Epoch: [94][160/391]	Time 0.046 (0.051)	Loss 0.0027 (0.0036)	Prec@1 100.000 (99.951)
Epoch: [94][180/391]	Time 0.044 (0.051)	Loss 0.0021 (0.0037)	Prec@1 100.000 (99.953)
Epoch: [94][200/391]	Time 0.050 (0.051)	Loss 0.0011 (0.0037)	Prec@1 100.000 (99.949)
Epoch: [94][220/391]	Time 0.045 (0.051)	Loss 0.0014 (0.0036)	Prec@1 100.000 (99.951)
Epoch: [94][240/391]	Time 0.050 (0.050)	Loss 0.0031 (0.0036)	Prec@1 100.000 (99.951)
Epoch: [94][260/391]	Time 0.046 (0.050)	Loss 0.0025 (0.0035)	Prec@1 100.000 (99.955)
Epoch: [94][280/391]	Time 0.050 (0.050)	Loss 0.0038 (0.0034)	Prec@1 100.000 (99.958)
Epoch: [94][300/391]	Time 0.046 (0.050)	Loss 0.0011 (0.0034)	Prec@1 100.000 (99.958)
Epoch: [94][320/391]	Time 0.047 (0.049)	Loss 0.0038 (0.0034)	Prec@1 100.000 (99.956)
Epoch: [94][340/391]	Time 0.047 (0.049)	Loss 0.0125 (0.0034)	Prec@1 99.219 (99.956)
Epoch: [94][360/391]	Time 0.048 (0.049)	Loss 0.0031 (0.0034)	Prec@1 100.000 (99.955)
Epoch: [94][380/391]	Time 0.045 (0.049)	Loss 0.0021 (0.0034)	Prec@1 100.000 (99.953)
training time:  19.2659113407135
Test: [0/79]	Time 0.748 (0.748)	Loss 0.2105 (0.2105)	Prec@1 95.312 (95.312)
Test: [20/79]	Time 0.032 (0.066)	Loss 0.2161 (0.2078)	Prec@1 93.750 (94.457)
Test: [40/79]	Time 0.032 (0.049)	Loss 0.2021 (0.1991)	Prec@1 93.750 (94.703)
Test: [60/79]	Time 0.030 (0.044)	Loss 0.1640 (0.1888)	Prec@1 96.875 (94.915)
 * Prec@1 95.080
Epoch: [95][0/391]	Time 0.802 (0.802)	Loss 0.0026 (0.0026)	Prec@1 100.000 (100.000)
Epoch: [95][20/391]	Time 0.040 (0.080)	Loss 0.0097 (0.0033)	Prec@1 100.000 (99.963)
Epoch: [95][40/391]	Time 0.044 (0.063)	Loss 0.0027 (0.0038)	Prec@1 100.000 (99.943)
Epoch: [95][60/391]	Time 0.047 (0.058)	Loss 0.0039 (0.0034)	Prec@1 100.000 (99.949)
Epoch: [95][80/391]	Time 0.044 (0.055)	Loss 0.0030 (0.0033)	Prec@1 100.000 (99.952)
Epoch: [95][100/391]	Time 0.047 (0.053)	Loss 0.0015 (0.0036)	Prec@1 100.000 (99.938)
Epoch: [95][120/391]	Time 0.047 (0.051)	Loss 0.0039 (0.0037)	Prec@1 100.000 (99.935)
Epoch: [95][140/391]	Time 0.048 (0.051)	Loss 0.0012 (0.0037)	Prec@1 100.000 (99.939)
Epoch: [95][160/391]	Time 0.046 (0.050)	Loss 0.0041 (0.0036)	Prec@1 100.000 (99.947)
Epoch: [95][180/391]	Time 0.046 (0.050)	Loss 0.0016 (0.0037)	Prec@1 100.000 (99.948)
Epoch: [95][200/391]	Time 0.047 (0.049)	Loss 0.0037 (0.0037)	Prec@1 100.000 (99.946)
Epoch: [95][220/391]	Time 0.047 (0.049)	Loss 0.0077 (0.0037)	Prec@1 100.000 (99.951)
Epoch: [95][240/391]	Time 0.047 (0.049)	Loss 0.0021 (0.0037)	Prec@1 100.000 (99.955)
Epoch: [95][260/391]	Time 0.046 (0.049)	Loss 0.0021 (0.0036)	Prec@1 100.000 (99.958)
Epoch: [95][280/391]	Time 0.047 (0.049)	Loss 0.0027 (0.0036)	Prec@1 100.000 (99.961)
Epoch: [95][300/391]	Time 0.050 (0.048)	Loss 0.0014 (0.0036)	Prec@1 100.000 (99.958)
Epoch: [95][320/391]	Time 0.048 (0.048)	Loss 0.0009 (0.0036)	Prec@1 100.000 (99.954)
Epoch: [95][340/391]	Time 0.047 (0.048)	Loss 0.0014 (0.0036)	Prec@1 100.000 (99.954)
Epoch: [95][360/391]	Time 0.045 (0.048)	Loss 0.0021 (0.0036)	Prec@1 100.000 (99.955)
Epoch: [95][380/391]	Time 0.045 (0.048)	Loss 0.0039 (0.0037)	Prec@1 100.000 (99.955)
training time:  18.977342128753662
Test: [0/79]	Time 0.786 (0.786)	Loss 0.2146 (0.2146)	Prec@1 95.312 (95.312)
Test: [20/79]	Time 0.032 (0.068)	Loss 0.2142 (0.2055)	Prec@1 93.750 (94.568)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.2058 (0.1973)	Prec@1 92.969 (94.646)
Test: [60/79]	Time 0.031 (0.044)	Loss 0.1592 (0.1867)	Prec@1 97.656 (94.980)
 * Prec@1 95.150
Epoch: [96][0/391]	Time 0.789 (0.789)	Loss 0.0074 (0.0074)	Prec@1 100.000 (100.000)
Epoch: [96][20/391]	Time 0.044 (0.082)	Loss 0.0019 (0.0041)	Prec@1 100.000 (99.926)
Epoch: [96][40/391]	Time 0.046 (0.065)	Loss 0.0017 (0.0039)	Prec@1 100.000 (99.943)
Epoch: [96][60/391]	Time 0.046 (0.058)	Loss 0.0010 (0.0034)	Prec@1 100.000 (99.962)
Epoch: [96][80/391]	Time 0.046 (0.055)	Loss 0.0013 (0.0035)	Prec@1 100.000 (99.961)
Epoch: [96][100/391]	Time 0.045 (0.054)	Loss 0.0059 (0.0032)	Prec@1 100.000 (99.969)
Epoch: [96][120/391]	Time 0.046 (0.052)	Loss 0.0025 (0.0031)	Prec@1 100.000 (99.974)
Epoch: [96][140/391]	Time 0.046 (0.052)	Loss 0.0021 (0.0031)	Prec@1 100.000 (99.978)
Epoch: [96][160/391]	Time 0.046 (0.051)	Loss 0.0017 (0.0031)	Prec@1 100.000 (99.976)
Epoch: [96][180/391]	Time 0.046 (0.050)	Loss 0.0009 (0.0030)	Prec@1 100.000 (99.974)
Epoch: [96][200/391]	Time 0.047 (0.051)	Loss 0.0010 (0.0030)	Prec@1 100.000 (99.977)
Epoch: [96][220/391]	Time 0.046 (0.050)	Loss 0.0031 (0.0031)	Prec@1 100.000 (99.972)
Epoch: [96][240/391]	Time 0.046 (0.050)	Loss 0.0025 (0.0031)	Prec@1 100.000 (99.974)
Epoch: [96][260/391]	Time 0.046 (0.050)	Loss 0.0012 (0.0031)	Prec@1 100.000 (99.973)
Epoch: [96][280/391]	Time 0.049 (0.049)	Loss 0.0008 (0.0031)	Prec@1 100.000 (99.975)
Epoch: [96][300/391]	Time 0.047 (0.049)	Loss 0.0014 (0.0030)	Prec@1 100.000 (99.977)
Epoch: [96][320/391]	Time 0.046 (0.049)	Loss 0.0040 (0.0031)	Prec@1 100.000 (99.976)
Epoch: [96][340/391]	Time 0.050 (0.049)	Loss 0.0015 (0.0031)	Prec@1 100.000 (99.973)
Epoch: [96][360/391]	Time 0.047 (0.049)	Loss 0.0132 (0.0031)	Prec@1 99.219 (99.970)
Epoch: [96][380/391]	Time 0.044 (0.049)	Loss 0.0015 (0.0032)	Prec@1 100.000 (99.969)
training time:  19.15688395500183
Test: [0/79]	Time 0.748 (0.748)	Loss 0.2215 (0.2215)	Prec@1 95.312 (95.312)
Test: [20/79]	Time 0.031 (0.066)	Loss 0.2365 (0.2077)	Prec@1 93.750 (94.420)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.2075 (0.2000)	Prec@1 94.531 (94.741)
Test: [60/79]	Time 0.032 (0.044)	Loss 0.1694 (0.1880)	Prec@1 97.656 (94.928)
 * Prec@1 95.110
Epoch: [97][0/391]	Time 0.840 (0.840)	Loss 0.0020 (0.0020)	Prec@1 100.000 (100.000)
Epoch: [97][20/391]	Time 0.044 (0.083)	Loss 0.0021 (0.0033)	Prec@1 100.000 (99.963)
Epoch: [97][40/391]	Time 0.047 (0.064)	Loss 0.0013 (0.0032)	Prec@1 100.000 (99.981)
Epoch: [97][60/391]	Time 0.043 (0.058)	Loss 0.0027 (0.0031)	Prec@1 100.000 (99.974)
Epoch: [97][80/391]	Time 0.046 (0.055)	Loss 0.0022 (0.0030)	Prec@1 100.000 (99.981)
Epoch: [97][100/391]	Time 0.048 (0.053)	Loss 0.0086 (0.0032)	Prec@1 99.219 (99.969)
Epoch: [97][120/391]	Time 0.046 (0.052)	Loss 0.0035 (0.0036)	Prec@1 100.000 (99.948)
Epoch: [97][140/391]	Time 0.049 (0.051)	Loss 0.0015 (0.0035)	Prec@1 100.000 (99.950)
Epoch: [97][160/391]	Time 0.048 (0.051)	Loss 0.0031 (0.0035)	Prec@1 100.000 (99.951)
Epoch: [97][180/391]	Time 0.047 (0.050)	Loss 0.0047 (0.0033)	Prec@1 100.000 (99.957)
Epoch: [97][200/391]	Time 0.048 (0.050)	Loss 0.0010 (0.0033)	Prec@1 100.000 (99.957)
Epoch: [97][220/391]	Time 0.046 (0.049)	Loss 0.0025 (0.0032)	Prec@1 100.000 (99.961)
Epoch: [97][240/391]	Time 0.048 (0.049)	Loss 0.0015 (0.0032)	Prec@1 100.000 (99.961)
Epoch: [97][260/391]	Time 0.048 (0.049)	Loss 0.0029 (0.0031)	Prec@1 100.000 (99.961)
Epoch: [97][280/391]	Time 0.047 (0.049)	Loss 0.0017 (0.0032)	Prec@1 100.000 (99.961)
Epoch: [97][300/391]	Time 0.049 (0.049)	Loss 0.0031 (0.0032)	Prec@1 100.000 (99.961)
Epoch: [97][320/391]	Time 0.047 (0.048)	Loss 0.0020 (0.0032)	Prec@1 100.000 (99.961)
Epoch: [97][340/391]	Time 0.047 (0.048)	Loss 0.0014 (0.0032)	Prec@1 100.000 (99.963)
Epoch: [97][360/391]	Time 0.047 (0.048)	Loss 0.0012 (0.0031)	Prec@1 100.000 (99.965)
Epoch: [97][380/391]	Time 0.046 (0.048)	Loss 0.0012 (0.0032)	Prec@1 100.000 (99.965)
training time:  18.952767610549927
Test: [0/79]	Time 0.786 (0.786)	Loss 0.2078 (0.2078)	Prec@1 96.094 (96.094)
Test: [20/79]	Time 0.033 (0.067)	Loss 0.2216 (0.2092)	Prec@1 93.750 (94.643)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.2111 (0.1997)	Prec@1 92.969 (94.855)
Test: [60/79]	Time 0.030 (0.044)	Loss 0.1575 (0.1882)	Prec@1 96.875 (95.108)
 * Prec@1 95.200
Epoch: [98][0/391]	Time 0.815 (0.815)	Loss 0.0026 (0.0026)	Prec@1 100.000 (100.000)
Epoch: [98][20/391]	Time 0.048 (0.083)	Loss 0.0017 (0.0030)	Prec@1 100.000 (100.000)
Epoch: [98][40/391]	Time 0.047 (0.065)	Loss 0.0019 (0.0028)	Prec@1 100.000 (100.000)
Epoch: [98][60/391]	Time 0.049 (0.059)	Loss 0.0031 (0.0031)	Prec@1 100.000 (99.974)
Epoch: [98][80/391]	Time 0.047 (0.056)	Loss 0.0016 (0.0029)	Prec@1 100.000 (99.981)
Epoch: [98][100/391]	Time 0.046 (0.054)	Loss 0.0019 (0.0028)	Prec@1 100.000 (99.985)
Epoch: [98][120/391]	Time 0.046 (0.052)	Loss 0.0030 (0.0028)	Prec@1 100.000 (99.981)
Epoch: [98][140/391]	Time 0.047 (0.051)	Loss 0.0019 (0.0029)	Prec@1 100.000 (99.967)
Epoch: [98][160/391]	Time 0.046 (0.051)	Loss 0.0032 (0.0030)	Prec@1 100.000 (99.971)
Epoch: [98][180/391]	Time 0.046 (0.050)	Loss 0.0018 (0.0030)	Prec@1 100.000 (99.961)
Epoch: [98][200/391]	Time 0.042 (0.051)	Loss 0.0033 (0.0031)	Prec@1 100.000 (99.961)
Epoch: [98][220/391]	Time 0.046 (0.050)	Loss 0.0021 (0.0031)	Prec@1 100.000 (99.961)
Epoch: [98][240/391]	Time 0.047 (0.050)	Loss 0.0019 (0.0031)	Prec@1 100.000 (99.964)
Epoch: [98][260/391]	Time 0.046 (0.050)	Loss 0.0069 (0.0031)	Prec@1 100.000 (99.964)
Epoch: [98][280/391]	Time 0.044 (0.049)	Loss 0.0049 (0.0031)	Prec@1 100.000 (99.967)
Epoch: [98][300/391]	Time 0.046 (0.049)	Loss 0.0022 (0.0033)	Prec@1 100.000 (99.958)
Epoch: [98][320/391]	Time 0.046 (0.049)	Loss 0.0019 (0.0032)	Prec@1 100.000 (99.961)
Epoch: [98][340/391]	Time 0.046 (0.049)	Loss 0.0028 (0.0032)	Prec@1 100.000 (99.961)
Epoch: [98][360/391]	Time 0.046 (0.049)	Loss 0.0082 (0.0032)	Prec@1 99.219 (99.959)
Epoch: [98][380/391]	Time 0.045 (0.049)	Loss 0.0036 (0.0032)	Prec@1 100.000 (99.959)
training time:  19.092275381088257
Test: [0/79]	Time 0.784 (0.784)	Loss 0.2162 (0.2162)	Prec@1 95.312 (95.312)
Test: [20/79]	Time 0.029 (0.067)	Loss 0.2264 (0.2086)	Prec@1 94.531 (94.680)
Test: [40/79]	Time 0.032 (0.050)	Loss 0.1954 (0.1988)	Prec@1 92.969 (94.741)
Test: [60/79]	Time 0.032 (0.044)	Loss 0.1566 (0.1882)	Prec@1 96.094 (95.005)
 * Prec@1 95.110
Epoch: [99][0/391]	Time 0.837 (0.837)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)
Epoch: [99][20/391]	Time 0.044 (0.082)	Loss 0.0025 (0.0032)	Prec@1 100.000 (100.000)
Epoch: [99][40/391]	Time 0.042 (0.064)	Loss 0.0029 (0.0033)	Prec@1 100.000 (99.981)
Epoch: [99][60/391]	Time 0.046 (0.058)	Loss 0.0044 (0.0036)	Prec@1 100.000 (99.974)
Epoch: [99][80/391]	Time 0.046 (0.055)	Loss 0.0016 (0.0035)	Prec@1 100.000 (99.971)
Epoch: [99][100/391]	Time 0.048 (0.053)	Loss 0.0028 (0.0034)	Prec@1 100.000 (99.961)
Epoch: [99][120/391]	Time 0.047 (0.052)	Loss 0.0009 (0.0035)	Prec@1 100.000 (99.955)
Epoch: [99][140/391]	Time 0.047 (0.051)	Loss 0.0053 (0.0036)	Prec@1 100.000 (99.950)
Epoch: [99][160/391]	Time 0.046 (0.050)	Loss 0.0018 (0.0035)	Prec@1 100.000 (99.947)
Epoch: [99][180/391]	Time 0.049 (0.050)	Loss 0.0077 (0.0036)	Prec@1 99.219 (99.948)
Epoch: [99][200/391]	Time 0.048 (0.050)	Loss 0.0011 (0.0035)	Prec@1 100.000 (99.946)
Epoch: [99][220/391]	Time 0.047 (0.049)	Loss 0.0014 (0.0034)	Prec@1 100.000 (99.951)
Epoch: [99][240/391]	Time 0.046 (0.049)	Loss 0.0029 (0.0034)	Prec@1 100.000 (99.951)
Epoch: [99][260/391]	Time 0.046 (0.049)	Loss 0.0019 (0.0033)	Prec@1 100.000 (99.955)
Epoch: [99][280/391]	Time 0.046 (0.049)	Loss 0.0026 (0.0034)	Prec@1 100.000 (99.953)
Epoch: [99][300/391]	Time 0.046 (0.049)	Loss 0.0014 (0.0033)	Prec@1 100.000 (99.953)
Epoch: [99][320/391]	Time 0.047 (0.049)	Loss 0.0013 (0.0033)	Prec@1 100.000 (99.954)
Epoch: [99][340/391]	Time 0.046 (0.048)	Loss 0.0018 (0.0032)	Prec@1 100.000 (99.956)
Epoch: [99][360/391]	Time 0.046 (0.048)	Loss 0.0011 (0.0032)	Prec@1 100.000 (99.959)
Epoch: [99][380/391]	Time 0.044 (0.048)	Loss 0.0022 (0.0032)	Prec@1 100.000 (99.961)
training time:  18.983022689819336
Test: [0/79]	Time 0.782 (0.782)	Loss 0.2071 (0.2071)	Prec@1 95.312 (95.312)
Test: [20/79]	Time 0.031 (0.067)	Loss 0.2162 (0.2049)	Prec@1 93.750 (94.680)
Test: [40/79]	Time 0.030 (0.049)	Loss 0.1927 (0.1958)	Prec@1 92.969 (94.874)
Test: [60/79]	Time 0.031 (0.043)	Loss 0.1560 (0.1866)	Prec@1 96.094 (95.018)
 * Prec@1 95.130
training time:  2248.24382686615
| Best accuracy:  95.2