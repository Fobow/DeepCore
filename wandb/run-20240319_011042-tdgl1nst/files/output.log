================== Exp 0 ==================
dataset: CIFAR10, model: ResNet18, selection: GraNd, num_ex: 1, epochs: 100, fraction: 0.2, seed: 41352, lr: 0.1, save_path: ./result, resume: , device: cuda, checkpoint_name: CIFAR10_ResNet18_GraNd_exp0_epoch100_2024-03-19 01:10:43.169539_0.2_
Files already downloaded and verified
Files already downloaded and verified
=> training samples: 40000, validation samples: 10000
called grand, with 1 ensemble and 10 epochs
=> Early Training Epoch #0
| Epoch [  0/ 10] Iter[  1/391]		Loss: 2.6894
| Epoch [  0/ 10] Iter[ 21/391]		Loss: 2.2838
| Epoch [  0/ 10] Iter[ 41/391]		Loss: 2.0238
| Epoch [  0/ 10] Iter[ 61/391]		Loss: 1.9849
| Epoch [  0/ 10] Iter[ 81/391]		Loss: 2.0515
| Epoch [  0/ 10] Iter[101/391]		Loss: 1.9750
| Epoch [  0/ 10] Iter[121/391]		Loss: 1.8866
| Epoch [  0/ 10] Iter[141/391]		Loss: 1.5648
| Epoch [  0/ 10] Iter[161/391]		Loss: 1.7407
| Epoch [  0/ 10] Iter[181/391]		Loss: 1.7714
| Epoch [  0/ 10] Iter[201/391]		Loss: 1.6908
| Epoch [  0/ 10] Iter[221/391]		Loss: 1.5324
| Epoch [  0/ 10] Iter[241/391]		Loss: 1.4573
| Epoch [  0/ 10] Iter[261/391]		Loss: 1.6684
| Epoch [  0/ 10] Iter[281/391]		Loss: 1.7624
| Epoch [  0/ 10] Iter[301/391]		Loss: 1.4774
| Epoch [  0/ 10] Iter[321/391]		Loss: 1.5135
| Epoch [  0/ 10] Iter[341/391]		Loss: 1.5009
| Epoch [  0/ 10] Iter[361/391]		Loss: 1.5225
| Epoch [  0/ 10] Iter[381/391]		Loss: 1.4614
=> Early Training Epoch #1
| Epoch [  1/ 10] Iter[  1/391]		Loss: 1.4497
| Epoch [  1/ 10] Iter[ 21/391]		Loss: 1.6128
| Epoch [  1/ 10] Iter[ 41/391]		Loss: 1.5008
| Epoch [  1/ 10] Iter[ 61/391]		Loss: 1.4323
| Epoch [  1/ 10] Iter[ 81/391]		Loss: 1.5729
| Epoch [  1/ 10] Iter[101/391]		Loss: 1.3271
| Epoch [  1/ 10] Iter[121/391]		Loss: 1.3709
| Epoch [  1/ 10] Iter[141/391]		Loss: 1.4537
| Epoch [  1/ 10] Iter[161/391]		Loss: 1.4271
| Epoch [  1/ 10] Iter[181/391]		Loss: 1.3751
| Epoch [  1/ 10] Iter[201/391]		Loss: 1.2904
| Epoch [  1/ 10] Iter[221/391]		Loss: 1.2656
| Epoch [  1/ 10] Iter[241/391]		Loss: 1.1484
| Epoch [  1/ 10] Iter[261/391]		Loss: 1.3825
| Epoch [  1/ 10] Iter[281/391]		Loss: 1.2075
| Epoch [  1/ 10] Iter[301/391]		Loss: 1.1213
| Epoch [  1/ 10] Iter[321/391]		Loss: 1.1886
| Epoch [  1/ 10] Iter[341/391]		Loss: 1.1933
| Epoch [  1/ 10] Iter[361/391]		Loss: 1.2441
| Epoch [  1/ 10] Iter[381/391]		Loss: 1.1752
=> Early Training Epoch #2
| Epoch [  2/ 10] Iter[  1/391]		Loss: 1.0572
| Epoch [  2/ 10] Iter[ 21/391]		Loss: 1.1012
| Epoch [  2/ 10] Iter[ 41/391]		Loss: 0.9516
| Epoch [  2/ 10] Iter[ 61/391]		Loss: 0.9707
| Epoch [  2/ 10] Iter[ 81/391]		Loss: 0.9720
| Epoch [  2/ 10] Iter[101/391]		Loss: 1.0630
| Epoch [  2/ 10] Iter[121/391]		Loss: 0.8737
| Epoch [  2/ 10] Iter[141/391]		Loss: 1.0074
| Epoch [  2/ 10] Iter[161/391]		Loss: 0.8916
| Epoch [  2/ 10] Iter[181/391]		Loss: 1.1230
| Epoch [  2/ 10] Iter[201/391]		Loss: 0.9403
| Epoch [  2/ 10] Iter[221/391]		Loss: 0.9707
| Epoch [  2/ 10] Iter[241/391]		Loss: 0.8801
| Epoch [  2/ 10] Iter[261/391]		Loss: 1.0725
| Epoch [  2/ 10] Iter[281/391]		Loss: 0.9724
| Epoch [  2/ 10] Iter[301/391]		Loss: 0.9135
| Epoch [  2/ 10] Iter[321/391]		Loss: 0.7020
| Epoch [  2/ 10] Iter[341/391]		Loss: 1.0536
| Epoch [  2/ 10] Iter[361/391]		Loss: 1.2735
| Epoch [  2/ 10] Iter[381/391]		Loss: 0.9627
=> Early Training Epoch #3
| Epoch [  3/ 10] Iter[  1/391]		Loss: 0.8461
| Epoch [  3/ 10] Iter[ 21/391]		Loss: 0.8189
| Epoch [  3/ 10] Iter[ 41/391]		Loss: 0.7643
| Epoch [  3/ 10] Iter[ 61/391]		Loss: 0.9363
| Epoch [  3/ 10] Iter[ 81/391]		Loss: 0.6855
| Epoch [  3/ 10] Iter[101/391]		Loss: 0.8203
| Epoch [  3/ 10] Iter[121/391]		Loss: 0.7832
| Epoch [  3/ 10] Iter[141/391]		Loss: 0.7835
| Epoch [  3/ 10] Iter[161/391]		Loss: 0.7899
| Epoch [  3/ 10] Iter[181/391]		Loss: 0.7808
| Epoch [  3/ 10] Iter[201/391]		Loss: 0.8132
| Epoch [  3/ 10] Iter[221/391]		Loss: 0.7108
| Epoch [  3/ 10] Iter[241/391]		Loss: 0.8221
| Epoch [  3/ 10] Iter[261/391]		Loss: 0.6574
| Epoch [  3/ 10] Iter[281/391]		Loss: 0.7712
| Epoch [  3/ 10] Iter[301/391]		Loss: 0.6979
| Epoch [  3/ 10] Iter[321/391]		Loss: 0.8121
| Epoch [  3/ 10] Iter[341/391]		Loss: 0.6085
| Epoch [  3/ 10] Iter[361/391]		Loss: 0.8354
| Epoch [  3/ 10] Iter[381/391]		Loss: 0.7874
=> Early Training Epoch #4
| Epoch [  4/ 10] Iter[  1/391]		Loss: 0.6518
| Epoch [  4/ 10] Iter[ 21/391]		Loss: 0.7170
| Epoch [  4/ 10] Iter[ 41/391]		Loss: 0.6896
| Epoch [  4/ 10] Iter[ 61/391]		Loss: 0.6802
| Epoch [  4/ 10] Iter[ 81/391]		Loss: 0.6052
| Epoch [  4/ 10] Iter[101/391]		Loss: 0.8147
| Epoch [  4/ 10] Iter[121/391]		Loss: 0.7746
| Epoch [  4/ 10] Iter[141/391]		Loss: 0.6999
| Epoch [  4/ 10] Iter[161/391]		Loss: 0.5842
| Epoch [  4/ 10] Iter[181/391]		Loss: 0.6328
| Epoch [  4/ 10] Iter[201/391]		Loss: 0.7523
| Epoch [  4/ 10] Iter[221/391]		Loss: 0.9216
| Epoch [  4/ 10] Iter[241/391]		Loss: 0.7130
| Epoch [  4/ 10] Iter[261/391]		Loss: 0.6557
| Epoch [  4/ 10] Iter[281/391]		Loss: 0.6651
| Epoch [  4/ 10] Iter[301/391]		Loss: 0.7505
| Epoch [  4/ 10] Iter[321/391]		Loss: 0.7275
| Epoch [  4/ 10] Iter[341/391]		Loss: 0.6487
| Epoch [  4/ 10] Iter[361/391]		Loss: 0.9251
| Epoch [  4/ 10] Iter[381/391]		Loss: 0.7683
=> Early Training Epoch #5
| Epoch [  5/ 10] Iter[  1/391]		Loss: 0.6712
| Epoch [  5/ 10] Iter[ 21/391]		Loss: 0.4775
| Epoch [  5/ 10] Iter[ 41/391]		Loss: 0.5650
| Epoch [  5/ 10] Iter[ 61/391]		Loss: 0.6096
| Epoch [  5/ 10] Iter[ 81/391]		Loss: 0.5966
| Epoch [  5/ 10] Iter[101/391]		Loss: 0.5373
| Epoch [  5/ 10] Iter[121/391]		Loss: 0.5493
| Epoch [  5/ 10] Iter[141/391]		Loss: 0.5188
| Epoch [  5/ 10] Iter[161/391]		Loss: 0.5259
| Epoch [  5/ 10] Iter[181/391]		Loss: 0.5421
| Epoch [  5/ 10] Iter[201/391]		Loss: 0.5439
| Epoch [  5/ 10] Iter[221/391]		Loss: 0.5040
| Epoch [  5/ 10] Iter[241/391]		Loss: 0.5875
| Epoch [  5/ 10] Iter[261/391]		Loss: 0.5192
| Epoch [  5/ 10] Iter[281/391]		Loss: 0.6268
| Epoch [  5/ 10] Iter[301/391]		Loss: 0.5515
| Epoch [  5/ 10] Iter[321/391]		Loss: 0.7146
| Epoch [  5/ 10] Iter[341/391]		Loss: 0.6198
| Epoch [  5/ 10] Iter[361/391]		Loss: 0.5588
| Epoch [  5/ 10] Iter[381/391]		Loss: 0.5925
=> Early Training Epoch #6
| Epoch [  6/ 10] Iter[  1/391]		Loss: 0.4860
| Epoch [  6/ 10] Iter[ 21/391]		Loss: 0.5049
| Epoch [  6/ 10] Iter[ 41/391]		Loss: 0.4158
| Epoch [  6/ 10] Iter[ 61/391]		Loss: 0.3819
| Epoch [  6/ 10] Iter[ 81/391]		Loss: 0.4688
| Epoch [  6/ 10] Iter[101/391]		Loss: 0.6452
| Epoch [  6/ 10] Iter[121/391]		Loss: 0.4350
| Epoch [  6/ 10] Iter[141/391]		Loss: 0.5751
| Epoch [  6/ 10] Iter[161/391]		Loss: 0.4555
| Epoch [  6/ 10] Iter[181/391]		Loss: 0.5159
| Epoch [  6/ 10] Iter[201/391]		Loss: 0.5202
| Epoch [  6/ 10] Iter[221/391]		Loss: 0.5045
| Epoch [  6/ 10] Iter[241/391]		Loss: 0.6043
| Epoch [  6/ 10] Iter[261/391]		Loss: 0.5521
| Epoch [  6/ 10] Iter[281/391]		Loss: 0.4194
| Epoch [  6/ 10] Iter[301/391]		Loss: 0.6172
| Epoch [  6/ 10] Iter[321/391]		Loss: 0.6260
| Epoch [  6/ 10] Iter[341/391]		Loss: 0.4593
| Epoch [  6/ 10] Iter[361/391]		Loss: 0.4006
| Epoch [  6/ 10] Iter[381/391]		Loss: 0.5043
=> Early Training Epoch #7
| Epoch [  7/ 10] Iter[  1/391]		Loss: 0.4547
| Epoch [  7/ 10] Iter[ 21/391]		Loss: 0.3758
| Epoch [  7/ 10] Iter[ 41/391]		Loss: 0.3826
| Epoch [  7/ 10] Iter[ 61/391]		Loss: 0.3597
| Epoch [  7/ 10] Iter[ 81/391]		Loss: 0.6499
| Epoch [  7/ 10] Iter[101/391]		Loss: 0.5020
| Epoch [  7/ 10] Iter[121/391]		Loss: 0.4923
| Epoch [  7/ 10] Iter[141/391]		Loss: 0.5612
| Epoch [  7/ 10] Iter[161/391]		Loss: 0.4130
| Epoch [  7/ 10] Iter[181/391]		Loss: 0.4666
| Epoch [  7/ 10] Iter[201/391]		Loss: 0.5975
| Epoch [  7/ 10] Iter[221/391]		Loss: 0.5013
| Epoch [  7/ 10] Iter[241/391]		Loss: 0.3536
| Epoch [  7/ 10] Iter[261/391]		Loss: 0.4338
| Epoch [  7/ 10] Iter[281/391]		Loss: 0.4497
| Epoch [  7/ 10] Iter[301/391]		Loss: 0.5153
| Epoch [  7/ 10] Iter[321/391]		Loss: 0.5107
| Epoch [  7/ 10] Iter[341/391]		Loss: 0.4483
| Epoch [  7/ 10] Iter[361/391]		Loss: 0.3953
| Epoch [  7/ 10] Iter[381/391]		Loss: 0.4939
=> Early Training Epoch #8
| Epoch [  8/ 10] Iter[  1/391]		Loss: 0.2575
| Epoch [  8/ 10] Iter[ 21/391]		Loss: 0.2796
| Epoch [  8/ 10] Iter[ 41/391]		Loss: 0.3126
| Epoch [  8/ 10] Iter[ 61/391]		Loss: 0.3034
| Epoch [  8/ 10] Iter[ 81/391]		Loss: 0.2742
| Epoch [  8/ 10] Iter[101/391]		Loss: 0.3863
| Epoch [  8/ 10] Iter[121/391]		Loss: 0.2772
| Epoch [  8/ 10] Iter[141/391]		Loss: 0.3565
| Epoch [  8/ 10] Iter[161/391]		Loss: 0.3583
| Epoch [  8/ 10] Iter[181/391]		Loss: 0.4072
| Epoch [  8/ 10] Iter[201/391]		Loss: 0.3676
| Epoch [  8/ 10] Iter[221/391]		Loss: 0.1765
| Epoch [  8/ 10] Iter[241/391]		Loss: 0.4551
| Epoch [  8/ 10] Iter[261/391]		Loss: 0.4434
| Epoch [  8/ 10] Iter[281/391]		Loss: 0.2989
| Epoch [  8/ 10] Iter[301/391]		Loss: 0.3633
| Epoch [  8/ 10] Iter[321/391]		Loss: 0.4585
| Epoch [  8/ 10] Iter[341/391]		Loss: 0.5487
| Epoch [  8/ 10] Iter[361/391]		Loss: 0.4081
| Epoch [  8/ 10] Iter[381/391]		Loss: 0.5469
=> Early Training Epoch #9
| Epoch [  9/ 10] Iter[  1/391]		Loss: 0.3085
| Epoch [  9/ 10] Iter[ 21/391]		Loss: 0.1927
| Epoch [  9/ 10] Iter[ 41/391]		Loss: 0.2192
| Epoch [  9/ 10] Iter[ 61/391]		Loss: 0.3399
| Epoch [  9/ 10] Iter[ 81/391]		Loss: 0.1965
| Epoch [  9/ 10] Iter[101/391]		Loss: 0.2822
| Epoch [  9/ 10] Iter[121/391]		Loss: 0.3811
| Epoch [  9/ 10] Iter[141/391]		Loss: 0.3040
| Epoch [  9/ 10] Iter[161/391]		Loss: 0.3320
| Epoch [  9/ 10] Iter[181/391]		Loss: 0.3096
| Epoch [  9/ 10] Iter[201/391]		Loss: 0.3463
| Epoch [  9/ 10] Iter[221/391]		Loss: 0.4601
| Epoch [  9/ 10] Iter[241/391]		Loss: 0.4561
| Epoch [  9/ 10] Iter[261/391]		Loss: 0.2837
| Epoch [  9/ 10] Iter[281/391]		Loss: 0.4456
| Epoch [  9/ 10] Iter[301/391]		Loss: 0.2953
| Epoch [  9/ 10] Iter[321/391]		Loss: 0.2941
| Epoch [  9/ 10] Iter[341/391]		Loss: 0.4021
| Epoch [  9/ 10] Iter[361/391]		Loss: 0.2897
| Epoch [  9/ 10] Iter[381/391]		Loss: 0.3374
=> selecting time:  122.49164724349976
=> number of seletcted samples:  10000
=> Saving checkpoint for epoch 0, with Prec@1 0.000000.
Epoch: [0][0/79]	Time 3.408 (3.408)	Loss 2.4242 (2.4242)	Prec@1 9.375 (9.375)
Epoch: [0][20/79]	Time 0.047 (0.207)	Loss 3.7000 (5.2690)	Prec@1 10.938 (10.305)
Epoch: [0][40/79]	Time 0.046 (0.128)	Loss 2.3133 (3.9248)	Prec@1 17.188 (11.890)
Epoch: [0][60/79]	Time 0.046 (0.101)	Loss 2.1946 (3.4200)	Prec@1 15.625 (13.204)
epoch training time:  7.164377927780151
Test: [0/391]	Time 0.859 (0.859)	Loss 2.2354 (2.2354)	Prec@1 22.656 (22.656)
Test: [20/391]	Time 0.033 (0.073)	Loss 2.2423 (2.1805)	Prec@1 14.844 (20.424)
Test: [40/391]	Time 0.033 (0.053)	Loss 2.2299 (2.2115)	Prec@1 14.844 (19.646)
Test: [60/391]	Time 0.033 (0.046)	Loss 2.1619 (2.2106)	Prec@1 20.312 (19.595)
Test: [80/391]	Time 0.032 (0.043)	Loss 2.3597 (2.2084)	Prec@1 17.969 (19.473)
Test: [100/391]	Time 0.032 (0.041)	Loss 2.2036 (2.2039)	Prec@1 16.406 (19.446)
Test: [120/391]	Time 0.032 (0.039)	Loss 2.3123 (2.2070)	Prec@1 18.750 (19.157)
Test: [140/391]	Time 0.032 (0.038)	Loss 2.3094 (2.2039)	Prec@1 16.406 (19.221)
Test: [160/391]	Time 0.033 (0.038)	Loss 2.1724 (2.2007)	Prec@1 16.406 (19.167)
Test: [180/391]	Time 0.031 (0.037)	Loss 2.1851 (2.2064)	Prec@1 21.094 (19.290)
Test: [200/391]	Time 0.031 (0.036)	Loss 2.1458 (2.2051)	Prec@1 16.406 (19.259)
Test: [220/391]	Time 0.033 (0.036)	Loss 2.2077 (2.2062)	Prec@1 23.438 (19.319)
Test: [240/391]	Time 0.032 (0.036)	Loss 2.2782 (2.2077)	Prec@1 18.750 (19.269)
Test: [260/391]	Time 0.032 (0.035)	Loss 2.2293 (2.2073)	Prec@1 16.406 (19.364)
Test: [280/391]	Time 0.032 (0.035)	Loss 2.2213 (2.2060)	Prec@1 16.406 (19.292)
Test: [300/391]	Time 0.033 (0.035)	Loss 2.1759 (2.2078)	Prec@1 20.312 (19.241)
Test: [320/391]	Time 0.030 (0.035)	Loss 2.2091 (2.2057)	Prec@1 17.188 (19.295)
Test: [340/391]	Time 0.029 (0.035)	Loss 2.2675 (2.2037)	Prec@1 21.094 (19.369)
Test: [360/391]	Time 0.029 (0.034)	Loss 2.1323 (2.2032)	Prec@1 23.438 (19.369)
Test: [380/391]	Time 0.032 (0.034)	Loss 2.1670 (2.2039)	Prec@1 26.562 (19.361)
 * Prec@1 19.386
Test: [0/79]	Time 0.816 (0.816)	Loss 2.1091 (2.1091)	Prec@1 22.656 (22.656)
Test: [20/79]	Time 0.029 (0.068)	Loss 2.1979 (2.1624)	Prec@1 18.750 (20.647)
Test: [40/79]	Time 0.032 (0.051)	Loss 2.0857 (2.1664)	Prec@1 18.750 (20.046)
Test: [60/79]	Time 0.031 (0.045)	Loss 2.0661 (2.1629)	Prec@1 23.438 (19.992)
 * Prec@1 20.040
=> Saving checkpoint for epoch 0, with Prec@1 20.040000.
Epoch: [1][0/79]	Time 0.869 (0.869)	Loss 2.2248 (2.2248)	Prec@1 18.750 (18.750)
Epoch: [1][20/79]	Time 0.049 (0.085)	Loss 2.0760 (2.1639)	Prec@1 19.531 (19.457)
Epoch: [1][40/79]	Time 0.045 (0.066)	Loss 2.1004 (2.1588)	Prec@1 20.312 (19.931)
Epoch: [1][60/79]	Time 0.177 (0.062)	Loss 2.1213 (2.1513)	Prec@1 21.094 (19.826)
epoch training time:  4.727615833282471
Test: [0/391]	Time 0.875 (0.875)	Loss 2.1029 (2.1029)	Prec@1 24.219 (24.219)
Test: [20/391]	Time 0.032 (0.073)	Loss 2.0543 (2.1097)	Prec@1 20.312 (23.103)
Test: [40/391]	Time 0.032 (0.053)	Loss 2.0892 (2.0958)	Prec@1 25.000 (23.190)
Test: [60/391]	Time 0.032 (0.046)	Loss 2.0123 (2.0917)	Prec@1 24.219 (22.797)
Test: [80/391]	Time 0.032 (0.043)	Loss 2.0637 (2.0944)	Prec@1 28.125 (22.676)
Test: [100/391]	Time 0.033 (0.041)	Loss 2.0097 (2.0990)	Prec@1 30.469 (22.293)
Test: [120/391]	Time 0.032 (0.039)	Loss 2.1087 (2.0963)	Prec@1 26.562 (22.463)
Test: [140/391]	Time 0.034 (0.038)	Loss 2.1395 (2.0939)	Prec@1 16.406 (22.268)
Test: [160/391]	Time 0.032 (0.038)	Loss 2.0737 (2.0930)	Prec@1 17.188 (22.127)
Test: [180/391]	Time 0.032 (0.037)	Loss 2.1681 (2.0922)	Prec@1 19.531 (22.156)
Test: [200/391]	Time 0.032 (0.037)	Loss 2.1231 (2.0926)	Prec@1 25.000 (22.248)
Test: [220/391]	Time 0.032 (0.036)	Loss 2.0095 (2.0945)	Prec@1 25.000 (22.229)
Test: [240/391]	Time 0.032 (0.036)	Loss 2.0353 (2.0941)	Prec@1 25.781 (22.196)
Test: [260/391]	Time 0.033 (0.036)	Loss 2.1280 (2.0928)	Prec@1 20.312 (22.138)
Test: [280/391]	Time 0.032 (0.036)	Loss 2.0297 (2.0932)	Prec@1 22.656 (22.045)
Test: [300/391]	Time 0.033 (0.035)	Loss 1.9848 (2.0937)	Prec@1 26.562 (22.007)
Test: [320/391]	Time 0.032 (0.035)	Loss 2.0904 (2.0933)	Prec@1 20.312 (22.004)
Test: [340/391]	Time 0.033 (0.035)	Loss 2.1955 (2.0936)	Prec@1 23.438 (22.051)
Test: [360/391]	Time 0.032 (0.035)	Loss 2.1613 (2.0947)	Prec@1 18.750 (22.050)
Test: [380/391]	Time 0.033 (0.035)	Loss 2.1492 (2.0949)	Prec@1 21.094 (22.062)
 * Prec@1 22.054
Test: [0/79]	Time 0.838 (0.838)	Loss 2.1017 (2.1017)	Prec@1 26.562 (26.562)
Test: [20/79]	Time 0.031 (0.070)	Loss 2.0822 (2.0854)	Prec@1 20.312 (24.033)
Test: [40/79]	Time 0.032 (0.052)	Loss 2.0837 (2.0800)	Prec@1 21.094 (23.304)
Test: [60/79]	Time 0.032 (0.045)	Loss 1.9964 (2.0810)	Prec@1 28.906 (23.015)
 * Prec@1 22.990
=> Saving checkpoint for epoch 1, with Prec@1 22.990000.
Epoch: [2][0/79]	Time 0.871 (0.871)	Loss 2.0989 (2.0989)	Prec@1 24.219 (24.219)
Epoch: [2][20/79]	Time 0.046 (0.085)	Loss 2.2370 (2.1079)	Prec@1 23.438 (21.094)
Epoch: [2][40/79]	Time 0.046 (0.066)	Loss 2.0169 (2.0937)	Prec@1 26.562 (21.608)
Epoch: [2][60/79]	Time 0.045 (0.060)	Loss 2.0020 (2.0890)	Prec@1 28.125 (21.452)
epoch training time:  4.6413421630859375
Test: [0/391]	Time 0.860 (0.860)	Loss 1.9451 (1.9451)	Prec@1 26.562 (26.562)
Test: [20/391]	Time 0.033 (0.071)	Loss 1.9830 (2.0274)	Prec@1 27.344 (24.516)
Test: [40/391]	Time 0.032 (0.052)	Loss 1.9343 (2.0201)	Prec@1 28.125 (24.219)
Test: [60/391]	Time 0.031 (0.046)	Loss 2.0035 (2.0213)	Prec@1 23.438 (24.078)
Test: [80/391]	Time 0.032 (0.042)	Loss 1.9402 (2.0157)	Prec@1 28.906 (24.171)
Test: [100/391]	Time 0.031 (0.040)	Loss 2.0063 (2.0162)	Prec@1 25.781 (24.288)
Test: [120/391]	Time 0.032 (0.039)	Loss 1.9847 (2.0192)	Prec@1 25.000 (24.193)
Test: [140/391]	Time 0.032 (0.038)	Loss 2.0903 (2.0217)	Prec@1 27.344 (24.363)
Test: [160/391]	Time 0.032 (0.037)	Loss 2.0092 (2.0191)	Prec@1 25.781 (24.393)
Test: [180/391]	Time 0.033 (0.037)	Loss 1.9825 (2.0194)	Prec@1 29.688 (24.409)
Test: [200/391]	Time 0.034 (0.036)	Loss 1.8971 (2.0161)	Prec@1 30.469 (24.499)
Test: [220/391]	Time 0.034 (0.036)	Loss 2.0063 (2.0158)	Prec@1 21.094 (24.438)
Test: [240/391]	Time 0.030 (0.035)	Loss 1.9541 (2.0164)	Prec@1 31.250 (24.462)
Test: [260/391]	Time 0.030 (0.035)	Loss 2.1438 (2.0163)	Prec@1 10.938 (24.321)
Test: [280/391]	Time 0.033 (0.035)	Loss 2.0182 (2.0160)	Prec@1 19.531 (24.238)
Test: [300/391]	Time 0.029 (0.035)	Loss 1.9542 (2.0160)	Prec@1 25.000 (24.195)
Test: [320/391]	Time 0.032 (0.034)	Loss 1.9796 (2.0153)	Prec@1 25.781 (24.289)
Test: [340/391]	Time 0.030 (0.034)	Loss 2.0156 (2.0161)	Prec@1 22.656 (24.310)
Test: [360/391]	Time 0.034 (0.034)	Loss 1.9719 (2.0159)	Prec@1 24.219 (24.266)
Test: [380/391]	Time 0.033 (0.034)	Loss 2.0421 (2.0162)	Prec@1 24.219 (24.231)
 * Prec@1 24.208
Test: [0/79]	Time 0.796 (0.796)	Loss 1.9926 (1.9926)	Prec@1 32.031 (32.031)
Test: [20/79]	Time 0.033 (0.069)	Loss 2.0469 (2.0058)	Prec@1 22.656 (25.260)
Test: [40/79]	Time 0.034 (0.051)	Loss 1.9953 (1.9927)	Prec@1 28.125 (25.495)
Test: [60/79]	Time 0.030 (0.045)	Loss 1.8930 (1.9952)	Prec@1 32.031 (25.461)
 * Prec@1 25.430
=> Saving checkpoint for epoch 2, with Prec@1 25.430000.
Epoch: [3][0/79]	Time 0.880 (0.880)	Loss 2.0448 (2.0448)	Prec@1 21.875 (21.875)
Epoch: [3][20/79]	Time 0.047 (0.086)	Loss 2.1094 (2.0401)	Prec@1 22.656 (23.698)
Epoch: [3][40/79]	Time 0.047 (0.067)	Loss 1.9363 (2.0319)	Prec@1 21.875 (23.876)
Epoch: [3][60/79]	Time 0.045 (0.060)	Loss 1.9903 (2.0216)	Prec@1 28.125 (24.116)
epoch training time:  4.635473251342773
Test: [0/391]	Time 0.883 (0.883)	Loss 1.9828 (1.9828)	Prec@1 25.000 (25.000)
Test: [20/391]	Time 0.032 (0.072)	Loss 2.0717 (1.9915)	Prec@1 23.438 (24.516)
Test: [40/391]	Time 0.032 (0.052)	Loss 1.9627 (1.9969)	Prec@1 29.688 (23.933)
Test: [60/391]	Time 0.032 (0.046)	Loss 2.0562 (1.9992)	Prec@1 20.312 (23.719)
Test: [80/391]	Time 0.032 (0.042)	Loss 1.9830 (1.9941)	Prec@1 23.438 (23.582)
Test: [100/391]	Time 0.032 (0.040)	Loss 1.9038 (1.9945)	Prec@1 22.656 (23.677)
Test: [120/391]	Time 0.032 (0.039)	Loss 1.9870 (1.9926)	Prec@1 26.562 (23.709)
Test: [140/391]	Time 0.032 (0.038)	Loss 1.9558 (1.9965)	Prec@1 21.875 (23.493)
Test: [160/391]	Time 0.030 (0.037)	Loss 2.0103 (1.9961)	Prec@1 22.656 (23.496)
Test: [180/391]	Time 0.032 (0.037)	Loss 1.9578 (1.9941)	Prec@1 25.781 (23.606)
Test: [200/391]	Time 0.033 (0.036)	Loss 2.0708 (1.9952)	Prec@1 14.844 (23.585)
Test: [220/391]	Time 0.032 (0.036)	Loss 1.9342 (1.9962)	Prec@1 29.688 (23.515)
Test: [240/391]	Time 0.032 (0.035)	Loss 2.0044 (1.9969)	Prec@1 22.656 (23.431)
Test: [260/391]	Time 0.033 (0.035)	Loss 2.1055 (1.9991)	Prec@1 21.094 (23.378)
Test: [280/391]	Time 0.031 (0.035)	Loss 2.0125 (1.9997)	Prec@1 24.219 (23.374)
Test: [300/391]	Time 0.032 (0.034)	Loss 1.9456 (2.0005)	Prec@1 28.906 (23.370)
Test: [320/391]	Time 0.031 (0.034)	Loss 1.9464 (1.9991)	Prec@1 28.906 (23.403)
Test: [340/391]	Time 0.033 (0.034)	Loss 2.0091 (1.9985)	Prec@1 25.000 (23.481)
Test: [360/391]	Time 0.032 (0.034)	Loss 2.0719 (1.9984)	Prec@1 26.562 (23.520)
Test: [380/391]	Time 0.031 (0.034)	Loss 2.0570 (1.9989)	Prec@1 22.656 (23.534)
 * Prec@1 23.544
Test: [0/79]	Time 0.810 (0.810)	Loss 2.0268 (2.0268)	Prec@1 22.656 (22.656)
Test: [20/79]	Time 0.033 (0.069)	Loss 2.0298 (1.9753)	Prec@1 18.750 (24.033)
Test: [40/79]	Time 0.032 (0.051)	Loss 1.9793 (1.9634)	Prec@1 24.219 (24.562)
Test: [60/79]	Time 0.031 (0.045)	Loss 1.9508 (1.9720)	Prec@1 25.781 (24.475)
 * Prec@1 24.290
Epoch: [4][0/79]	Time 0.900 (0.900)	Loss 1.9568 (1.9568)	Prec@1 25.000 (25.000)
Epoch: [4][20/79]	Time 0.048 (0.087)	Loss 2.0336 (2.0317)	Prec@1 16.406 (23.214)
Epoch: [4][40/79]	Time 0.047 (0.067)	Loss 1.9068 (2.0036)	Prec@1 25.781 (24.409)
Epoch: [4][60/79]	Time 0.046 (0.060)	Loss 1.8710 (1.9841)	Prec@1 29.688 (25.371)
epoch training time:  4.662103891372681
Test: [0/391]	Time 1.053 (1.053)	Loss 1.8530 (1.8530)	Prec@1 29.688 (29.688)
Test: [20/391]	Time 0.031 (0.081)	Loss 1.9146 (1.8995)	Prec@1 23.438 (28.943)
Test: [40/391]	Time 0.030 (0.057)	Loss 1.8328 (1.8958)	Prec@1 34.375 (28.754)
Test: [60/391]	Time 0.030 (0.048)	Loss 1.8193 (1.8864)	Prec@1 32.031 (29.892)
Test: [80/391]	Time 0.029 (0.044)	Loss 1.9515 (1.8915)	Prec@1 18.750 (29.495)
Test: [100/391]	Time 0.029 (0.041)	Loss 1.8263 (1.8865)	Prec@1 25.000 (29.633)
Test: [120/391]	Time 0.029 (0.039)	Loss 1.8326 (1.8838)	Prec@1 31.250 (29.578)
Test: [140/391]	Time 0.033 (0.038)	Loss 1.8415 (1.8823)	Prec@1 30.469 (29.588)
Test: [160/391]	Time 0.033 (0.038)	Loss 1.8278 (1.8820)	Prec@1 30.469 (29.421)
Test: [180/391]	Time 0.033 (0.037)	Loss 1.8849 (1.8829)	Prec@1 28.125 (29.411)
Test: [200/391]	Time 0.034 (0.036)	Loss 1.9037 (1.8817)	Prec@1 27.344 (29.361)
Test: [220/391]	Time 0.033 (0.036)	Loss 1.8251 (1.8800)	Prec@1 23.438 (29.369)
Test: [240/391]	Time 0.032 (0.036)	Loss 1.7895 (1.8786)	Prec@1 28.125 (29.383)
Test: [260/391]	Time 0.032 (0.035)	Loss 2.0126 (1.8804)	Prec@1 27.344 (29.197)
Test: [280/391]	Time 0.033 (0.035)	Loss 1.8074 (1.8805)	Prec@1 29.688 (29.254)
Test: [300/391]	Time 0.032 (0.035)	Loss 1.9592 (1.8790)	Prec@1 21.094 (29.296)
Test: [320/391]	Time 0.032 (0.035)	Loss 1.8919 (1.8795)	Prec@1 27.344 (29.210)
Test: [340/391]	Time 0.032 (0.035)	Loss 1.9043 (1.8792)	Prec@1 28.125 (29.195)
Test: [360/391]	Time 0.032 (0.034)	Loss 1.7620 (1.8795)	Prec@1 33.594 (29.240)
Test: [380/391]	Time 0.032 (0.034)	Loss 1.8967 (1.8805)	Prec@1 22.656 (29.251)
 * Prec@1 29.264
Test: [0/79]	Time 0.806 (0.806)	Loss 1.8453 (1.8453)	Prec@1 33.594 (33.594)
Test: [20/79]	Time 0.032 (0.069)	Loss 1.8862 (1.8527)	Prec@1 24.219 (31.548)
Test: [40/79]	Time 0.029 (0.050)	Loss 1.8470 (1.8418)	Prec@1 30.469 (31.155)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.7785 (1.8426)	Prec@1 28.125 (31.032)
 * Prec@1 30.780
=> Saving checkpoint for epoch 4, with Prec@1 30.780000.
Epoch: [5][0/79]	Time 0.845 (0.845)	Loss 1.9486 (1.9486)	Prec@1 25.000 (25.000)
Epoch: [5][20/79]	Time 0.043 (0.084)	Loss 1.9402 (1.9445)	Prec@1 27.344 (27.455)
Epoch: [5][40/79]	Time 0.042 (0.064)	Loss 1.8174 (1.9316)	Prec@1 26.562 (27.268)
Epoch: [5][60/79]	Time 0.046 (0.058)	Loss 2.0027 (1.9277)	Prec@1 24.219 (26.972)
epoch training time:  4.521563529968262
Test: [0/391]	Time 0.865 (0.865)	Loss 2.0191 (2.0191)	Prec@1 25.781 (25.781)
Test: [20/391]	Time 0.033 (0.072)	Loss 1.9762 (2.0704)	Prec@1 21.094 (23.363)
Test: [40/391]	Time 0.032 (0.052)	Loss 2.1026 (2.0773)	Prec@1 23.438 (23.457)
Test: [60/391]	Time 0.032 (0.046)	Loss 2.1300 (2.0741)	Prec@1 17.188 (23.194)
Test: [80/391]	Time 0.032 (0.042)	Loss 1.9899 (2.0672)	Prec@1 25.000 (23.225)
Test: [100/391]	Time 0.032 (0.040)	Loss 2.0502 (2.0698)	Prec@1 23.438 (23.120)
Test: [120/391]	Time 0.032 (0.039)	Loss 1.9541 (2.0694)	Prec@1 28.125 (22.908)
Test: [140/391]	Time 0.032 (0.038)	Loss 2.0848 (2.0665)	Prec@1 20.312 (22.778)
Test: [160/391]	Time 0.032 (0.037)	Loss 2.2050 (2.0689)	Prec@1 18.750 (22.807)
Test: [180/391]	Time 0.033 (0.037)	Loss 2.2101 (2.0690)	Prec@1 21.875 (22.872)
Test: [200/391]	Time 0.033 (0.037)	Loss 2.2796 (2.0737)	Prec@1 20.312 (22.785)
Test: [220/391]	Time 0.034 (0.036)	Loss 2.0875 (2.0735)	Prec@1 21.875 (22.801)
Test: [240/391]	Time 0.033 (0.036)	Loss 2.0640 (2.0728)	Prec@1 25.000 (22.799)
Test: [260/391]	Time 0.032 (0.036)	Loss 2.0454 (2.0737)	Prec@1 17.969 (22.806)
Test: [280/391]	Time 0.033 (0.035)	Loss 2.2364 (2.0751)	Prec@1 21.875 (22.823)
Test: [300/391]	Time 0.031 (0.036)	Loss 2.2403 (2.0771)	Prec@1 16.406 (22.815)
Test: [320/391]	Time 0.033 (0.035)	Loss 2.1548 (2.0790)	Prec@1 16.406 (22.744)
Test: [340/391]	Time 0.034 (0.035)	Loss 2.0993 (2.0790)	Prec@1 24.219 (22.771)
Test: [360/391]	Time 0.032 (0.035)	Loss 2.0773 (2.0789)	Prec@1 22.656 (22.827)
Test: [380/391]	Time 0.032 (0.035)	Loss 2.0982 (2.0799)	Prec@1 25.000 (22.814)
 * Prec@1 22.776
Test: [0/79]	Time 0.862 (0.862)	Loss 1.9579 (1.9579)	Prec@1 25.000 (25.000)
Test: [20/79]	Time 0.032 (0.071)	Loss 2.1812 (2.0563)	Prec@1 21.875 (23.996)
Test: [40/79]	Time 0.032 (0.052)	Loss 2.0221 (2.0398)	Prec@1 27.344 (24.162)
Test: [60/79]	Time 0.032 (0.046)	Loss 2.1131 (2.0446)	Prec@1 18.750 (23.706)
 * Prec@1 23.580
Epoch: [6][0/79]	Time 0.889 (0.889)	Loss 2.0266 (2.0266)	Prec@1 28.125 (28.125)
Epoch: [6][20/79]	Time 0.048 (0.086)	Loss 2.0249 (1.9598)	Prec@1 18.750 (27.530)
Epoch: [6][40/79]	Time 0.048 (0.067)	Loss 1.8426 (1.9220)	Prec@1 28.125 (28.582)
Epoch: [6][60/79]	Time 0.044 (0.060)	Loss 1.8595 (1.9154)	Prec@1 28.125 (28.753)
epoch training time:  4.642887592315674
Test: [0/391]	Time 0.881 (0.881)	Loss 1.8595 (1.8595)	Prec@1 30.469 (30.469)
Test: [20/391]	Time 0.033 (0.071)	Loss 1.8754 (1.8389)	Prec@1 27.344 (29.688)
Test: [40/391]	Time 0.030 (0.052)	Loss 1.9196 (1.8348)	Prec@1 27.344 (30.183)
Test: [60/391]	Time 0.032 (0.045)	Loss 1.7480 (1.8295)	Prec@1 35.938 (30.149)
Test: [80/391]	Time 0.033 (0.042)	Loss 1.7929 (1.8308)	Prec@1 32.031 (30.054)
Test: [100/391]	Time 0.032 (0.040)	Loss 1.8322 (1.8279)	Prec@1 32.031 (30.190)
Test: [120/391]	Time 0.034 (0.039)	Loss 1.8556 (1.8278)	Prec@1 28.125 (30.333)
Test: [140/391]	Time 0.033 (0.038)	Loss 1.8572 (1.8290)	Prec@1 30.469 (30.502)
Test: [160/391]	Time 0.032 (0.037)	Loss 1.8416 (1.8362)	Prec@1 28.125 (30.275)
Test: [180/391]	Time 0.034 (0.037)	Loss 1.7928 (1.8365)	Prec@1 33.594 (30.275)
Test: [200/391]	Time 0.032 (0.036)	Loss 1.7917 (1.8361)	Prec@1 35.938 (30.453)
Test: [220/391]	Time 0.033 (0.036)	Loss 1.7872 (1.8345)	Prec@1 35.156 (30.582)
Test: [240/391]	Time 0.032 (0.036)	Loss 1.8720 (1.8328)	Prec@1 29.688 (30.585)
Test: [260/391]	Time 0.032 (0.035)	Loss 1.8231 (1.8328)	Prec@1 31.250 (30.469)
Test: [280/391]	Time 0.033 (0.035)	Loss 1.7863 (1.8349)	Prec@1 28.906 (30.485)
Test: [300/391]	Time 0.032 (0.035)	Loss 1.8194 (1.8335)	Prec@1 37.500 (30.554)
Test: [320/391]	Time 0.032 (0.035)	Loss 1.8779 (1.8318)	Prec@1 28.906 (30.622)
Test: [340/391]	Time 0.033 (0.035)	Loss 1.8621 (1.8324)	Prec@1 25.781 (30.595)
Test: [360/391]	Time 0.034 (0.035)	Loss 1.8185 (1.8327)	Prec@1 31.250 (30.614)
Test: [380/391]	Time 0.033 (0.034)	Loss 1.7580 (1.8324)	Prec@1 31.250 (30.604)
 * Prec@1 30.626
Test: [0/79]	Time 0.819 (0.819)	Loss 1.8048 (1.8048)	Prec@1 28.906 (28.906)
Test: [20/79]	Time 0.032 (0.070)	Loss 1.8955 (1.7952)	Prec@1 29.688 (32.999)
Test: [40/79]	Time 0.033 (0.052)	Loss 1.8170 (1.7855)	Prec@1 28.125 (33.365)
Test: [60/79]	Time 0.033 (0.046)	Loss 1.7428 (1.7875)	Prec@1 34.375 (33.248)
 * Prec@1 32.900
=> Saving checkpoint for epoch 6, with Prec@1 32.900000.
Epoch: [7][0/79]	Time 0.848 (0.848)	Loss 1.7900 (1.7900)	Prec@1 32.812 (32.812)
Epoch: [7][20/79]	Time 0.046 (0.085)	Loss 1.9618 (1.8763)	Prec@1 25.000 (29.390)
Epoch: [7][40/79]	Time 0.046 (0.066)	Loss 1.8085 (1.8748)	Prec@1 30.469 (29.573)
Epoch: [7][60/79]	Time 0.045 (0.059)	Loss 1.7776 (1.8633)	Prec@1 33.594 (30.238)
epoch training time:  4.601906061172485
Test: [0/391]	Time 0.892 (0.892)	Loss 1.8075 (1.8075)	Prec@1 32.031 (32.031)
Test: [20/391]	Time 0.166 (0.080)	Loss 1.7891 (1.7821)	Prec@1 32.812 (31.064)
Test: [40/391]	Time 0.032 (0.056)	Loss 1.7824 (1.7891)	Prec@1 35.938 (30.526)
Test: [60/391]	Time 0.033 (0.049)	Loss 1.7974 (1.7920)	Prec@1 27.344 (30.341)
Test: [80/391]	Time 0.033 (0.045)	Loss 1.8068 (1.7960)	Prec@1 28.906 (30.314)
Test: [100/391]	Time 0.032 (0.042)	Loss 1.8004 (1.7991)	Prec@1 29.688 (30.221)
Test: [120/391]	Time 0.033 (0.040)	Loss 1.6815 (1.7989)	Prec@1 39.062 (30.391)
Test: [140/391]	Time 0.032 (0.039)	Loss 1.7854 (1.7984)	Prec@1 28.125 (30.391)
Test: [160/391]	Time 0.033 (0.038)	Loss 1.6919 (1.7948)	Prec@1 32.812 (30.585)
Test: [180/391]	Time 0.033 (0.038)	Loss 1.7714 (1.7923)	Prec@1 39.062 (30.706)
Test: [200/391]	Time 0.029 (0.037)	Loss 1.7331 (1.7944)	Prec@1 36.719 (30.741)
Test: [220/391]	Time 0.032 (0.036)	Loss 1.7357 (1.7934)	Prec@1 36.719 (30.713)
Test: [240/391]	Time 0.029 (0.036)	Loss 1.6798 (1.7927)	Prec@1 34.375 (30.819)
Test: [260/391]	Time 0.029 (0.036)	Loss 1.7653 (1.7943)	Prec@1 24.219 (30.651)
Test: [280/391]	Time 0.029 (0.035)	Loss 1.8558 (1.7967)	Prec@1 28.125 (30.624)
Test: [300/391]	Time 0.032 (0.035)	Loss 1.8138 (1.7963)	Prec@1 26.562 (30.614)
Test: [320/391]	Time 0.032 (0.035)	Loss 1.8275 (1.7979)	Prec@1 28.125 (30.530)
Test: [340/391]	Time 0.033 (0.035)	Loss 1.7524 (1.7983)	Prec@1 33.594 (30.501)
Test: [360/391]	Time 0.032 (0.035)	Loss 1.7940 (1.7992)	Prec@1 29.688 (30.499)
Test: [380/391]	Time 0.031 (0.034)	Loss 1.8691 (1.8000)	Prec@1 24.219 (30.465)
 * Prec@1 30.540
Test: [0/79]	Time 0.854 (0.854)	Loss 1.7844 (1.7844)	Prec@1 33.594 (33.594)
Test: [20/79]	Time 0.031 (0.071)	Loss 1.8783 (1.7574)	Prec@1 25.781 (33.110)
Test: [40/79]	Time 0.032 (0.052)	Loss 1.8015 (1.7493)	Prec@1 28.906 (32.870)
Test: [60/79]	Time 0.029 (0.046)	Loss 1.7871 (1.7565)	Prec@1 31.250 (32.492)
 * Prec@1 32.250
Epoch: [8][0/79]	Time 0.897 (0.897)	Loss 2.0055 (2.0055)	Prec@1 21.094 (21.094)
Epoch: [8][20/79]	Time 0.043 (0.086)	Loss 1.8914 (1.8357)	Prec@1 28.125 (30.655)
Epoch: [8][40/79]	Time 0.048 (0.067)	Loss 1.8652 (1.8473)	Prec@1 25.000 (30.145)
Epoch: [8][60/79]	Time 0.048 (0.060)	Loss 1.8037 (1.8381)	Prec@1 33.594 (31.135)
epoch training time:  4.641638278961182
Test: [0/391]	Time 0.893 (0.893)	Loss 1.8822 (1.8822)	Prec@1 25.781 (25.781)
Test: [20/391]	Time 0.032 (0.073)	Loss 1.8381 (1.8803)	Prec@1 31.250 (28.757)
Test: [40/391]	Time 0.032 (0.053)	Loss 1.9667 (1.8846)	Prec@1 27.344 (29.459)
Test: [60/391]	Time 0.032 (0.046)	Loss 1.9184 (1.8812)	Prec@1 28.125 (29.572)
Test: [80/391]	Time 0.032 (0.042)	Loss 1.9108 (1.8796)	Prec@1 28.125 (29.504)
Test: [100/391]	Time 0.033 (0.040)	Loss 1.9317 (1.8836)	Prec@1 26.562 (29.339)
Test: [120/391]	Time 0.032 (0.039)	Loss 1.8110 (1.8845)	Prec@1 28.125 (29.416)
Test: [140/391]	Time 0.032 (0.038)	Loss 1.8920 (1.8813)	Prec@1 24.219 (29.599)
Test: [160/391]	Time 0.032 (0.037)	Loss 1.8243 (1.8782)	Prec@1 35.156 (29.741)
Test: [180/391]	Time 0.033 (0.036)	Loss 1.9086 (1.8773)	Prec@1 28.125 (29.683)
Test: [200/391]	Time 0.032 (0.036)	Loss 1.8930 (1.8795)	Prec@1 28.125 (29.583)
Test: [220/391]	Time 0.033 (0.036)	Loss 1.7930 (1.8788)	Prec@1 28.906 (29.504)
Test: [240/391]	Time 0.033 (0.035)	Loss 1.8155 (1.8777)	Prec@1 31.250 (29.600)
Test: [260/391]	Time 0.032 (0.035)	Loss 1.8730 (1.8792)	Prec@1 30.469 (29.577)
Test: [280/391]	Time 0.032 (0.035)	Loss 1.8078 (1.8779)	Prec@1 29.688 (29.585)
Test: [300/391]	Time 0.032 (0.035)	Loss 1.9278 (1.8769)	Prec@1 25.000 (29.521)
Test: [320/391]	Time 0.033 (0.035)	Loss 1.8541 (1.8764)	Prec@1 31.250 (29.568)
Test: [340/391]	Time 0.033 (0.035)	Loss 1.8005 (1.8765)	Prec@1 29.688 (29.548)
Test: [360/391]	Time 0.033 (0.035)	Loss 1.8037 (1.8756)	Prec@1 32.031 (29.543)
Test: [380/391]	Time 0.031 (0.035)	Loss 1.9331 (1.8759)	Prec@1 35.156 (29.499)
 * Prec@1 29.456
Test: [0/79]	Time 0.848 (0.848)	Loss 1.7956 (1.7956)	Prec@1 30.469 (30.469)
Test: [20/79]	Time 0.032 (0.071)	Loss 1.9170 (1.8328)	Prec@1 25.781 (30.878)
Test: [40/79]	Time 0.034 (0.052)	Loss 1.8908 (1.8257)	Prec@1 34.375 (31.174)
Test: [60/79]	Time 0.031 (0.046)	Loss 1.7699 (1.8303)	Prec@1 33.594 (30.994)
 * Prec@1 30.970
Epoch: [9][0/79]	Time 0.837 (0.837)	Loss 1.9767 (1.9767)	Prec@1 25.000 (25.000)
Epoch: [9][20/79]	Time 0.046 (0.084)	Loss 1.8242 (1.8681)	Prec@1 28.125 (29.501)
Epoch: [9][40/79]	Time 0.048 (0.066)	Loss 1.7812 (1.8393)	Prec@1 30.469 (30.297)
Epoch: [9][60/79]	Time 0.046 (0.060)	Loss 1.7463 (1.8272)	Prec@1 35.156 (30.891)
epoch training time:  4.603777885437012
Test: [0/391]	Time 0.895 (0.895)	Loss 1.7354 (1.7354)	Prec@1 34.375 (34.375)
Test: [20/391]	Time 0.033 (0.073)	Loss 1.7618 (1.8131)	Prec@1 32.031 (32.068)
Test: [40/391]	Time 0.032 (0.053)	Loss 1.9119 (1.8212)	Prec@1 28.125 (31.288)
Test: [60/391]	Time 0.032 (0.047)	Loss 1.7103 (1.8189)	Prec@1 32.031 (31.352)
Test: [80/391]	Time 0.032 (0.043)	Loss 1.7450 (1.8241)	Prec@1 31.250 (31.269)
Test: [100/391]	Time 0.032 (0.041)	Loss 1.8701 (1.8288)	Prec@1 29.688 (31.327)
Test: [120/391]	Time 0.032 (0.040)	Loss 1.7974 (1.8261)	Prec@1 39.062 (31.657)
Test: [140/391]	Time 0.031 (0.039)	Loss 1.7104 (1.8238)	Prec@1 35.938 (31.804)
Test: [160/391]	Time 0.033 (0.038)	Loss 1.8159 (1.8214)	Prec@1 34.375 (32.002)
Test: [180/391]	Time 0.033 (0.037)	Loss 1.7921 (1.8226)	Prec@1 31.250 (31.897)
Test: [200/391]	Time 0.032 (0.037)	Loss 1.8069 (1.8222)	Prec@1 31.250 (31.884)
Test: [220/391]	Time 0.033 (0.036)	Loss 1.9108 (1.8219)	Prec@1 30.469 (31.890)
Test: [240/391]	Time 0.032 (0.036)	Loss 1.7916 (1.8209)	Prec@1 38.281 (31.840)
Test: [260/391]	Time 0.031 (0.036)	Loss 1.8276 (1.8207)	Prec@1 31.250 (31.855)
Test: [280/391]	Time 0.033 (0.036)	Loss 1.7416 (1.8207)	Prec@1 33.594 (31.867)
Test: [300/391]	Time 0.032 (0.035)	Loss 1.8948 (1.8190)	Prec@1 28.125 (31.891)
Test: [320/391]	Time 0.031 (0.035)	Loss 1.7876 (1.8198)	Prec@1 35.156 (31.961)
Test: [340/391]	Time 0.031 (0.035)	Loss 1.9857 (1.8192)	Prec@1 33.594 (32.001)
Test: [360/391]	Time 0.033 (0.035)	Loss 1.7954 (1.8196)	Prec@1 35.156 (31.986)
Test: [380/391]	Time 0.031 (0.035)	Loss 1.7788 (1.8182)	Prec@1 35.938 (32.046)
 * Prec@1 32.012
Test: [0/79]	Time 0.857 (0.857)	Loss 1.6660 (1.6660)	Prec@1 38.281 (38.281)
Test: [20/79]	Time 0.032 (0.071)	Loss 1.9890 (1.7625)	Prec@1 26.562 (34.449)
Test: [40/79]	Time 0.032 (0.052)	Loss 1.8350 (1.7587)	Prec@1 27.344 (34.146)
Test: [60/79]	Time 0.030 (0.046)	Loss 1.8132 (1.7681)	Prec@1 26.562 (33.414)
 * Prec@1 33.320
=> Saving checkpoint for epoch 9, with Prec@1 33.320000.
Epoch: [10][0/79]	Time 0.898 (0.898)	Loss 1.9667 (1.9667)	Prec@1 26.562 (26.562)
Epoch: [10][20/79]	Time 0.046 (0.086)	Loss 1.8068 (1.8375)	Prec@1 31.250 (30.506)
Epoch: [10][40/79]	Time 0.046 (0.067)	Loss 1.8063 (1.8169)	Prec@1 35.156 (32.470)
Epoch: [10][60/79]	Time 0.045 (0.060)	Loss 1.6436 (1.8135)	Prec@1 39.844 (32.480)
epoch training time:  4.633800268173218
Test: [0/391]	Time 0.900 (0.900)	Loss 1.7584 (1.7584)	Prec@1 35.156 (35.156)
Test: [20/391]	Time 0.033 (0.074)	Loss 1.7626 (1.7296)	Prec@1 39.844 (34.412)
Test: [40/391]	Time 0.033 (0.054)	Loss 1.7796 (1.7369)	Prec@1 31.250 (33.384)
Test: [60/391]	Time 0.033 (0.048)	Loss 1.7246 (1.7340)	Prec@1 32.812 (33.389)
Test: [80/391]	Time 0.033 (0.044)	Loss 1.7451 (1.7369)	Prec@1 33.594 (33.468)
Test: [100/391]	Time 0.032 (0.042)	Loss 1.6410 (1.7399)	Prec@1 42.969 (33.493)
Test: [120/391]	Time 0.032 (0.040)	Loss 1.8034 (1.7417)	Prec@1 29.688 (33.587)
Test: [140/391]	Time 0.032 (0.039)	Loss 1.7134 (1.7393)	Prec@1 32.031 (33.743)
Test: [160/391]	Time 0.032 (0.038)	Loss 1.7935 (1.7397)	Prec@1 32.812 (33.861)
Test: [180/391]	Time 0.032 (0.038)	Loss 1.8165 (1.7395)	Prec@1 34.375 (34.090)
Test: [200/391]	Time 0.032 (0.037)	Loss 1.7656 (1.7377)	Prec@1 30.469 (34.165)
Test: [220/391]	Time 0.032 (0.037)	Loss 1.7085 (1.7374)	Prec@1 32.812 (34.050)
Test: [240/391]	Time 0.032 (0.036)	Loss 1.5978 (1.7377)	Prec@1 36.719 (34.116)
Test: [260/391]	Time 0.032 (0.036)	Loss 1.7834 (1.7392)	Prec@1 29.688 (34.088)
Test: [280/391]	Time 0.032 (0.036)	Loss 1.6703 (1.7398)	Prec@1 36.719 (33.991)
Test: [300/391]	Time 0.032 (0.036)	Loss 1.7630 (1.7422)	Prec@1 35.156 (33.871)
Test: [320/391]	Time 0.032 (0.035)	Loss 1.6773 (1.7429)	Prec@1 37.500 (33.818)
Test: [340/391]	Time 0.033 (0.035)	Loss 1.6711 (1.7437)	Prec@1 35.938 (33.775)
Test: [360/391]	Time 0.032 (0.035)	Loss 1.6568 (1.7454)	Prec@1 35.938 (33.711)
Test: [380/391]	Time 0.031 (0.035)	Loss 1.7045 (1.7450)	Prec@1 30.469 (33.709)
 * Prec@1 33.760
Test: [0/79]	Time 0.869 (0.869)	Loss 1.6062 (1.6062)	Prec@1 39.844 (39.844)
Test: [20/79]	Time 0.033 (0.070)	Loss 1.8578 (1.6890)	Prec@1 28.125 (35.082)
Test: [40/79]	Time 0.032 (0.051)	Loss 1.7156 (1.6800)	Prec@1 32.031 (35.518)
Test: [60/79]	Time 0.031 (0.045)	Loss 1.6810 (1.6919)	Prec@1 41.406 (34.964)
 * Prec@1 34.950
=> Saving checkpoint for epoch 10, with Prec@1 34.950000.
Epoch: [11][0/79]	Time 0.886 (0.886)	Loss 1.7500 (1.7500)	Prec@1 37.500 (37.500)
Epoch: [11][20/79]	Time 0.048 (0.086)	Loss 1.8433 (1.7924)	Prec@1 32.031 (33.668)
Epoch: [11][40/79]	Time 0.045 (0.066)	Loss 1.9249 (1.7855)	Prec@1 28.906 (33.784)
Epoch: [11][60/79]	Time 0.045 (0.059)	Loss 1.8330 (1.7902)	Prec@1 31.250 (33.363)
epoch training time:  4.573061227798462
Test: [0/391]	Time 0.888 (0.888)	Loss 1.7265 (1.7265)	Prec@1 33.594 (33.594)
Test: [20/391]	Time 0.032 (0.073)	Loss 1.9645 (1.8542)	Prec@1 22.656 (29.836)
Test: [40/391]	Time 0.032 (0.053)	Loss 1.9195 (1.8589)	Prec@1 28.125 (29.954)
Test: [60/391]	Time 0.032 (0.046)	Loss 1.8170 (1.8494)	Prec@1 27.344 (30.277)
Test: [80/391]	Time 0.033 (0.043)	Loss 1.9348 (1.8442)	Prec@1 24.219 (30.363)
Test: [100/391]	Time 0.033 (0.041)	Loss 1.8181 (1.8444)	Prec@1 28.906 (30.739)
Test: [120/391]	Time 0.031 (0.039)	Loss 1.8453 (1.8420)	Prec@1 34.375 (30.798)
Test: [140/391]	Time 0.033 (0.038)	Loss 1.8006 (1.8407)	Prec@1 30.469 (30.707)
Test: [160/391]	Time 0.032 (0.038)	Loss 1.7998 (1.8387)	Prec@1 28.906 (30.755)
Test: [180/391]	Time 0.032 (0.037)	Loss 1.9368 (1.8379)	Prec@1 32.812 (30.775)
Test: [200/391]	Time 0.032 (0.037)	Loss 1.9243 (1.8372)	Prec@1 27.344 (30.951)
Test: [220/391]	Time 0.032 (0.036)	Loss 1.7769 (1.8346)	Prec@1 30.469 (31.084)
Test: [240/391]	Time 0.033 (0.036)	Loss 1.7834 (1.8367)	Prec@1 36.719 (30.997)
Test: [260/391]	Time 0.032 (0.036)	Loss 1.8421 (1.8389)	Prec@1 32.031 (31.002)
Test: [280/391]	Time 0.030 (0.035)	Loss 1.8209 (1.8403)	Prec@1 34.375 (31.022)
Test: [300/391]	Time 0.031 (0.035)	Loss 1.8435 (1.8410)	Prec@1 34.375 (31.074)
Test: [320/391]	Time 0.032 (0.035)	Loss 1.7278 (1.8425)	Prec@1 39.062 (31.029)
Test: [340/391]	Time 0.032 (0.035)	Loss 1.9446 (1.8405)	Prec@1 25.781 (31.161)
Test: [360/391]	Time 0.033 (0.035)	Loss 1.6860 (1.8392)	Prec@1 35.938 (31.192)
Test: [380/391]	Time 0.031 (0.035)	Loss 1.9504 (1.8396)	Prec@1 25.000 (31.188)
 * Prec@1 31.196
Test: [0/79]	Time 0.862 (0.862)	Loss 1.7060 (1.7060)	Prec@1 30.469 (30.469)
Test: [20/79]	Time 0.032 (0.071)	Loss 1.9339 (1.7833)	Prec@1 23.438 (32.589)
Test: [40/79]	Time 0.029 (0.052)	Loss 1.8086 (1.7715)	Prec@1 32.812 (33.060)
Test: [60/79]	Time 0.030 (0.045)	Loss 1.7989 (1.7841)	Prec@1 30.469 (32.659)
 * Prec@1 32.450
Epoch: [12][0/79]	Time 0.901 (0.901)	Loss 1.7898 (1.7898)	Prec@1 32.031 (32.031)
Epoch: [12][20/79]	Time 0.047 (0.087)	Loss 1.6525 (1.7715)	Prec@1 35.156 (33.408)
Epoch: [12][40/79]	Time 0.043 (0.066)	Loss 1.7563 (1.7620)	Prec@1 38.281 (34.394)
Epoch: [12][60/79]	Time 0.046 (0.063)	Loss 1.7374 (1.7678)	Prec@1 32.812 (34.247)
epoch training time:  4.839944362640381
Test: [0/391]	Time 0.916 (0.916)	Loss 1.6943 (1.6943)	Prec@1 35.156 (35.156)
Test: [20/391]	Time 0.031 (0.074)	Loss 1.7099 (1.6964)	Prec@1 36.719 (37.091)
Test: [40/391]	Time 0.033 (0.053)	Loss 1.7924 (1.7195)	Prec@1 32.812 (36.433)
Test: [60/391]	Time 0.031 (0.046)	Loss 1.8816 (1.7262)	Prec@1 28.906 (35.976)
Test: [80/391]	Time 0.032 (0.043)	Loss 1.5917 (1.7182)	Prec@1 40.625 (36.343)
Test: [100/391]	Time 0.034 (0.041)	Loss 1.7633 (1.7160)	Prec@1 35.156 (36.409)
Test: [120/391]	Time 0.032 (0.039)	Loss 1.7067 (1.7130)	Prec@1 35.938 (36.260)
Test: [140/391]	Time 0.032 (0.038)	Loss 1.7486 (1.7101)	Prec@1 33.594 (36.270)
Test: [160/391]	Time 0.032 (0.038)	Loss 1.6847 (1.7093)	Prec@1 37.500 (36.107)
Test: [180/391]	Time 0.032 (0.037)	Loss 1.7569 (1.7095)	Prec@1 34.375 (36.045)
Test: [200/391]	Time 0.032 (0.036)	Loss 1.7773 (1.7114)	Prec@1 30.469 (35.918)
Test: [220/391]	Time 0.032 (0.037)	Loss 1.7987 (1.7124)	Prec@1 28.125 (35.835)
Test: [240/391]	Time 0.033 (0.036)	Loss 1.7580 (1.7139)	Prec@1 30.469 (35.837)
Test: [260/391]	Time 0.032 (0.036)	Loss 1.7679 (1.7167)	Prec@1 32.812 (35.692)
Test: [280/391]	Time 0.032 (0.036)	Loss 1.6762 (1.7164)	Prec@1 35.156 (35.704)
Test: [300/391]	Time 0.031 (0.035)	Loss 1.7245 (1.7143)	Prec@1 32.812 (35.841)
Test: [320/391]	Time 0.032 (0.035)	Loss 1.6288 (1.7150)	Prec@1 41.406 (35.869)
Test: [340/391]	Time 0.031 (0.035)	Loss 1.7901 (1.7172)	Prec@1 34.375 (35.802)
Test: [360/391]	Time 0.033 (0.035)	Loss 1.6719 (1.7167)	Prec@1 35.156 (35.818)
Test: [380/391]	Time 0.032 (0.035)	Loss 1.8337 (1.7155)	Prec@1 29.688 (35.870)
 * Prec@1 35.984
Test: [0/79]	Time 0.819 (0.819)	Loss 1.5964 (1.5964)	Prec@1 39.844 (39.844)
Test: [20/79]	Time 0.033 (0.069)	Loss 1.8487 (1.6592)	Prec@1 29.688 (38.728)
Test: [40/79]	Time 0.032 (0.051)	Loss 1.7248 (1.6552)	Prec@1 32.812 (38.205)
Test: [60/79]	Time 0.030 (0.045)	Loss 1.6255 (1.6656)	Prec@1 42.969 (37.487)
 * Prec@1 37.180
=> Saving checkpoint for epoch 12, with Prec@1 37.180000.
Epoch: [13][0/79]	Time 0.869 (0.869)	Loss 1.8064 (1.8064)	Prec@1 36.719 (36.719)
Epoch: [13][20/79]	Time 0.047 (0.086)	Loss 1.7831 (1.7484)	Prec@1 36.719 (34.003)
Epoch: [13][40/79]	Time 0.044 (0.066)	Loss 1.6892 (1.7421)	Prec@1 42.188 (34.966)
Epoch: [13][60/79]	Time 0.046 (0.060)	Loss 1.8525 (1.7478)	Prec@1 32.031 (34.529)
epoch training time:  4.637060642242432
Test: [0/391]	Time 0.911 (0.911)	Loss 1.6867 (1.6867)	Prec@1 34.375 (34.375)
Test: [20/391]	Time 0.033 (0.074)	Loss 1.8776 (1.7856)	Prec@1 32.031 (32.403)
Test: [40/391]	Time 0.033 (0.054)	Loss 1.8312 (1.7767)	Prec@1 37.500 (33.289)
Test: [60/391]	Time 0.033 (0.047)	Loss 1.7105 (1.7666)	Prec@1 36.719 (33.799)
Test: [80/391]	Time 0.032 (0.043)	Loss 1.7999 (1.7724)	Prec@1 39.844 (33.507)
Test: [100/391]	Time 0.032 (0.041)	Loss 1.6968 (1.7682)	Prec@1 35.156 (33.586)
Test: [120/391]	Time 0.033 (0.040)	Loss 1.6631 (1.7655)	Prec@1 39.062 (33.587)
Test: [140/391]	Time 0.032 (0.039)	Loss 1.7153 (1.7663)	Prec@1 39.062 (33.477)
Test: [160/391]	Time 0.033 (0.038)	Loss 1.6826 (1.7635)	Prec@1 35.938 (33.628)
Test: [180/391]	Time 0.033 (0.037)	Loss 1.8622 (1.7574)	Prec@1 25.000 (33.866)
Test: [200/391]	Time 0.031 (0.037)	Loss 1.7292 (1.7580)	Prec@1 30.469 (33.905)
Test: [220/391]	Time 0.032 (0.036)	Loss 1.8150 (1.7580)	Prec@1 31.250 (33.880)
Test: [240/391]	Time 0.034 (0.036)	Loss 1.7354 (1.7592)	Prec@1 39.062 (33.924)
Test: [260/391]	Time 0.032 (0.036)	Loss 1.7477 (1.7602)	Prec@1 32.031 (33.836)
Test: [280/391]	Time 0.033 (0.035)	Loss 1.6848 (1.7600)	Prec@1 36.719 (33.813)
Test: [300/391]	Time 0.033 (0.035)	Loss 1.7817 (1.7598)	Prec@1 36.719 (33.882)
Test: [320/391]	Time 0.032 (0.035)	Loss 1.7552 (1.7571)	Prec@1 39.062 (33.959)
Test: [340/391]	Time 0.032 (0.035)	Loss 1.7040 (1.7575)	Prec@1 33.594 (33.912)
Test: [360/391]	Time 0.032 (0.035)	Loss 1.7474 (1.7593)	Prec@1 35.938 (33.806)
Test: [380/391]	Time 0.032 (0.035)	Loss 1.6644 (1.7590)	Prec@1 36.719 (33.821)
 * Prec@1 33.770
Test: [0/79]	Time 0.867 (0.867)	Loss 1.6605 (1.6605)	Prec@1 38.281 (38.281)
Test: [20/79]	Time 0.032 (0.072)	Loss 1.8280 (1.7010)	Prec@1 38.281 (36.570)
Test: [40/79]	Time 0.032 (0.052)	Loss 1.7553 (1.6946)	Prec@1 32.031 (35.938)
Test: [60/79]	Time 0.031 (0.046)	Loss 1.7466 (1.7091)	Prec@1 34.375 (35.617)
 * Prec@1 35.310
Epoch: [14][0/79]	Time 0.869 (0.869)	Loss 1.5399 (1.5399)	Prec@1 42.188 (42.188)
Epoch: [14][20/79]	Time 0.049 (0.085)	Loss 1.7474 (1.7269)	Prec@1 32.031 (36.049)
Epoch: [14][40/79]	Time 0.046 (0.066)	Loss 1.6298 (1.7250)	Prec@1 39.844 (36.014)
Epoch: [14][60/79]	Time 0.047 (0.060)	Loss 1.6759 (1.7251)	Prec@1 35.938 (35.950)
epoch training time:  4.618032217025757
Test: [0/391]	Time 0.863 (0.863)	Loss 1.5041 (1.5041)	Prec@1 46.875 (46.875)
Test: [20/391]	Time 0.033 (0.072)	Loss 1.8046 (1.7947)	Prec@1 35.938 (33.594)
Test: [40/391]	Time 0.032 (0.053)	Loss 1.8554 (1.8000)	Prec@1 26.562 (33.422)
Test: [60/391]	Time 0.032 (0.048)	Loss 1.8415 (1.7957)	Prec@1 28.125 (33.376)
Test: [80/391]	Time 0.034 (0.044)	Loss 1.7053 (1.7922)	Prec@1 39.062 (33.468)
Test: [100/391]	Time 0.033 (0.042)	Loss 1.7785 (1.7965)	Prec@1 33.594 (33.184)
Test: [120/391]	Time 0.033 (0.040)	Loss 1.6639 (1.7983)	Prec@1 38.281 (33.245)
Test: [140/391]	Time 0.034 (0.039)	Loss 1.9258 (1.7971)	Prec@1 32.812 (33.128)
Test: [160/391]	Time 0.032 (0.038)	Loss 1.7292 (1.7955)	Prec@1 32.812 (33.176)
Test: [180/391]	Time 0.033 (0.038)	Loss 1.7907 (1.7954)	Prec@1 38.281 (33.253)
Test: [200/391]	Time 0.032 (0.037)	Loss 1.7468 (1.7935)	Prec@1 35.938 (33.259)
Test: [220/391]	Time 0.033 (0.037)	Loss 1.8588 (1.7918)	Prec@1 34.375 (33.438)
Test: [240/391]	Time 0.032 (0.036)	Loss 1.7735 (1.7883)	Prec@1 35.156 (33.496)
Test: [260/391]	Time 0.033 (0.036)	Loss 1.8665 (1.7905)	Prec@1 28.906 (33.492)
Test: [280/391]	Time 0.032 (0.036)	Loss 1.8082 (1.7903)	Prec@1 32.812 (33.510)
Test: [300/391]	Time 0.033 (0.036)	Loss 1.5971 (1.7909)	Prec@1 36.719 (33.511)
Test: [320/391]	Time 0.033 (0.035)	Loss 1.7319 (1.7916)	Prec@1 34.375 (33.511)
Test: [340/391]	Time 0.032 (0.035)	Loss 1.8316 (1.7921)	Prec@1 24.219 (33.518)
Test: [360/391]	Time 0.033 (0.035)	Loss 1.7302 (1.7902)	Prec@1 39.844 (33.652)
Test: [380/391]	Time 0.031 (0.035)	Loss 1.7834 (1.7894)	Prec@1 28.125 (33.676)
 * Prec@1 33.686
Test: [0/79]	Time 0.822 (0.822)	Loss 1.6650 (1.6650)	Prec@1 36.719 (36.719)
Test: [20/79]	Time 0.034 (0.070)	Loss 1.8117 (1.7412)	Prec@1 39.844 (36.235)
Test: [40/79]	Time 0.031 (0.052)	Loss 1.8138 (1.7369)	Prec@1 33.594 (35.880)
Test: [60/79]	Time 0.031 (0.046)	Loss 1.7789 (1.7546)	Prec@1 32.812 (34.785)
 * Prec@1 34.690
Epoch: [15][0/79]	Time 0.901 (0.901)	Loss 1.7789 (1.7789)	Prec@1 32.812 (32.812)
Epoch: [15][20/79]	Time 0.047 (0.088)	Loss 1.6072 (1.7403)	Prec@1 34.375 (34.970)
Epoch: [15][40/79]	Time 0.047 (0.068)	Loss 1.6807 (1.7320)	Prec@1 45.312 (35.118)
Epoch: [15][60/79]	Time 0.046 (0.061)	Loss 1.5541 (1.7271)	Prec@1 39.062 (35.656)
epoch training time:  4.683191299438477
Test: [0/391]	Time 0.882 (0.882)	Loss 1.6566 (1.6566)	Prec@1 40.625 (40.625)
Test: [20/391]	Time 0.029 (0.072)	Loss 1.6509 (1.6796)	Prec@1 30.469 (36.533)
Test: [40/391]	Time 0.032 (0.052)	Loss 1.6866 (1.6773)	Prec@1 35.156 (36.643)
Test: [60/391]	Time 0.032 (0.045)	Loss 1.6742 (1.6816)	Prec@1 32.031 (36.552)
Test: [80/391]	Time 0.033 (0.042)	Loss 1.6684 (1.6810)	Prec@1 40.625 (36.941)
Test: [100/391]	Time 0.032 (0.040)	Loss 1.7113 (1.6804)	Prec@1 34.375 (36.881)
Test: [120/391]	Time 0.032 (0.039)	Loss 1.6854 (1.6820)	Prec@1 33.594 (36.609)
Test: [140/391]	Time 0.032 (0.038)	Loss 1.6953 (1.6835)	Prec@1 35.156 (36.564)
Test: [160/391]	Time 0.032 (0.037)	Loss 1.6923 (1.6822)	Prec@1 39.062 (36.534)
Test: [180/391]	Time 0.033 (0.037)	Loss 1.6528 (1.6808)	Prec@1 31.250 (36.378)
Test: [200/391]	Time 0.032 (0.036)	Loss 1.6025 (1.6805)	Prec@1 38.281 (36.416)
Test: [220/391]	Time 0.032 (0.036)	Loss 1.6649 (1.6810)	Prec@1 39.062 (36.326)
Test: [240/391]	Time 0.032 (0.036)	Loss 1.6382 (1.6812)	Prec@1 35.156 (36.385)
Test: [260/391]	Time 0.032 (0.035)	Loss 1.5439 (1.6792)	Prec@1 42.969 (36.503)
Test: [280/391]	Time 0.029 (0.035)	Loss 1.6641 (1.6779)	Prec@1 36.719 (36.605)
Test: [300/391]	Time 0.029 (0.035)	Loss 1.5818 (1.6763)	Prec@1 39.062 (36.706)
Test: [320/391]	Time 0.029 (0.034)	Loss 1.5920 (1.6749)	Prec@1 44.531 (36.763)
Test: [340/391]	Time 0.029 (0.034)	Loss 1.7901 (1.6751)	Prec@1 34.375 (36.787)
Test: [360/391]	Time 0.029 (0.034)	Loss 1.6638 (1.6738)	Prec@1 36.719 (36.831)
Test: [380/391]	Time 0.031 (0.034)	Loss 1.6399 (1.6717)	Prec@1 35.938 (36.918)
 * Prec@1 36.952
Test: [0/79]	Time 0.872 (0.872)	Loss 1.5838 (1.5838)	Prec@1 39.844 (39.844)
Test: [20/79]	Time 0.033 (0.071)	Loss 1.7591 (1.6198)	Prec@1 33.594 (39.397)
Test: [40/79]	Time 0.032 (0.051)	Loss 1.6861 (1.6125)	Prec@1 36.719 (39.329)
Test: [60/79]	Time 0.031 (0.045)	Loss 1.5613 (1.6221)	Prec@1 41.406 (38.678)
 * Prec@1 38.230
=> Saving checkpoint for epoch 15, with Prec@1 38.230000.
Epoch: [16][0/79]	Time 0.928 (0.928)	Loss 1.7900 (1.7900)	Prec@1 35.938 (35.938)
Epoch: [16][20/79]	Time 0.046 (0.088)	Loss 1.7177 (1.7094)	Prec@1 39.062 (35.751)
Epoch: [16][40/79]	Time 0.046 (0.067)	Loss 1.7366 (1.6993)	Prec@1 40.625 (36.604)
Epoch: [16][60/79]	Time 0.045 (0.060)	Loss 1.7628 (1.6963)	Prec@1 32.031 (37.039)
epoch training time:  4.682076930999756
Test: [0/391]	Time 0.895 (0.895)	Loss 1.6405 (1.6405)	Prec@1 34.375 (34.375)
Test: [20/391]	Time 0.032 (0.074)	Loss 1.7999 (1.6965)	Prec@1 27.344 (34.338)
Test: [40/391]	Time 0.031 (0.053)	Loss 1.8863 (1.7112)	Prec@1 32.031 (34.299)
Test: [60/391]	Time 0.030 (0.046)	Loss 1.7929 (1.7150)	Prec@1 28.125 (34.029)
Test: [80/391]	Time 0.029 (0.042)	Loss 1.6446 (1.7145)	Prec@1 35.938 (34.182)
Test: [100/391]	Time 0.028 (0.040)	Loss 1.7019 (1.7102)	Prec@1 39.062 (34.429)
Test: [120/391]	Time 0.030 (0.039)	Loss 1.8763 (1.7108)	Prec@1 32.812 (34.427)
Test: [140/391]	Time 0.029 (0.038)	Loss 1.6403 (1.7061)	Prec@1 39.062 (34.630)
Test: [160/391]	Time 0.031 (0.037)	Loss 1.6459 (1.7069)	Prec@1 34.375 (34.424)
Test: [180/391]	Time 0.032 (0.037)	Loss 1.6805 (1.7088)	Prec@1 31.250 (34.483)
Test: [200/391]	Time 0.031 (0.036)	Loss 1.6471 (1.7085)	Prec@1 36.719 (34.492)
Test: [220/391]	Time 0.032 (0.036)	Loss 1.7228 (1.7108)	Prec@1 36.719 (34.531)
Test: [240/391]	Time 0.032 (0.035)	Loss 1.5222 (1.7090)	Prec@1 45.312 (34.790)
Test: [260/391]	Time 0.032 (0.035)	Loss 1.8176 (1.7076)	Prec@1 25.781 (34.821)
Test: [280/391]	Time 0.032 (0.035)	Loss 1.7156 (1.7092)	Prec@1 39.062 (34.753)
Test: [300/391]	Time 0.029 (0.035)	Loss 1.6345 (1.7086)	Prec@1 32.031 (34.718)
Test: [320/391]	Time 0.032 (0.035)	Loss 1.7896 (1.7087)	Prec@1 32.031 (34.762)
Test: [340/391]	Time 0.032 (0.034)	Loss 1.5610 (1.7100)	Prec@1 35.938 (34.684)
Test: [360/391]	Time 0.032 (0.034)	Loss 1.6519 (1.7123)	Prec@1 34.375 (34.646)
Test: [380/391]	Time 0.031 (0.034)	Loss 1.7647 (1.7109)	Prec@1 33.594 (34.773)
 * Prec@1 34.756
Test: [0/79]	Time 0.879 (0.879)	Loss 1.7073 (1.7073)	Prec@1 32.812 (32.812)
Test: [20/79]	Time 0.032 (0.072)	Loss 1.8654 (1.6901)	Prec@1 32.031 (36.161)
Test: [40/79]	Time 0.032 (0.053)	Loss 1.8100 (1.6745)	Prec@1 30.469 (37.062)
Test: [60/79]	Time 0.032 (0.046)	Loss 1.6089 (1.6798)	Prec@1 35.156 (36.245)
 * Prec@1 35.800
Epoch: [17][0/79]	Time 0.864 (0.864)	Loss 1.5588 (1.5588)	Prec@1 36.719 (36.719)
Epoch: [17][20/79]	Time 0.044 (0.085)	Loss 1.6407 (1.6813)	Prec@1 36.719 (37.426)
Epoch: [17][40/79]	Time 0.046 (0.066)	Loss 1.6079 (1.6698)	Prec@1 32.812 (38.034)
Epoch: [17][60/79]	Time 0.046 (0.060)	Loss 1.7318 (1.6646)	Prec@1 34.375 (38.653)
epoch training time:  4.642249822616577
Test: [0/391]	Time 0.884 (0.884)	Loss 1.6492 (1.6492)	Prec@1 36.719 (36.719)
Test: [20/391]	Time 0.030 (0.071)	Loss 1.6714 (1.6291)	Prec@1 30.469 (36.272)
Test: [40/391]	Time 0.029 (0.052)	Loss 1.6664 (1.6356)	Prec@1 36.719 (36.490)
Test: [60/391]	Time 0.028 (0.045)	Loss 1.6276 (1.6276)	Prec@1 35.156 (36.949)
Test: [80/391]	Time 0.029 (0.042)	Loss 1.6155 (1.6341)	Prec@1 34.375 (36.613)
Test: [100/391]	Time 0.029 (0.040)	Loss 1.6291 (1.6295)	Prec@1 39.844 (36.812)
Test: [120/391]	Time 0.033 (0.038)	Loss 1.6471 (1.6316)	Prec@1 35.938 (37.061)
Test: [140/391]	Time 0.032 (0.038)	Loss 1.6011 (1.6293)	Prec@1 38.281 (37.206)
Test: [160/391]	Time 0.032 (0.037)	Loss 1.5639 (1.6293)	Prec@1 39.844 (37.223)
Test: [180/391]	Time 0.032 (0.036)	Loss 1.5455 (1.6301)	Prec@1 39.844 (37.263)
Test: [200/391]	Time 0.032 (0.036)	Loss 1.6697 (1.6300)	Prec@1 33.594 (37.177)
Test: [220/391]	Time 0.029 (0.036)	Loss 1.7506 (1.6310)	Prec@1 34.375 (37.139)
Test: [240/391]	Time 0.032 (0.035)	Loss 1.6619 (1.6302)	Prec@1 30.469 (37.121)
Test: [260/391]	Time 0.032 (0.035)	Loss 1.5757 (1.6297)	Prec@1 37.500 (37.177)
Test: [280/391]	Time 0.029 (0.035)	Loss 1.7357 (1.6286)	Prec@1 35.938 (37.241)
Test: [300/391]	Time 0.032 (0.035)	Loss 1.7004 (1.6280)	Prec@1 33.594 (37.334)
Test: [320/391]	Time 0.032 (0.035)	Loss 1.5465 (1.6290)	Prec@1 37.500 (37.271)
Test: [340/391]	Time 0.028 (0.034)	Loss 1.5957 (1.6284)	Prec@1 35.156 (37.353)
Test: [360/391]	Time 0.029 (0.034)	Loss 1.8467 (1.6274)	Prec@1 22.656 (37.455)
Test: [380/391]	Time 0.031 (0.034)	Loss 1.5548 (1.6273)	Prec@1 35.156 (37.457)
 * Prec@1 37.464
Test: [0/79]	Time 0.849 (0.849)	Loss 1.5941 (1.5941)	Prec@1 34.375 (34.375)
Test: [20/79]	Time 0.029 (0.071)	Loss 1.6529 (1.5781)	Prec@1 40.625 (38.690)
Test: [40/79]	Time 0.029 (0.051)	Loss 1.5151 (1.5767)	Prec@1 39.062 (39.463)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.4748 (1.5779)	Prec@1 49.219 (39.728)
 * Prec@1 39.360
=> Saving checkpoint for epoch 17, with Prec@1 39.360000.
Epoch: [18][0/79]	Time 0.867 (0.867)	Loss 1.4969 (1.4969)	Prec@1 40.625 (40.625)
Epoch: [18][20/79]	Time 0.046 (0.085)	Loss 1.7191 (1.6448)	Prec@1 34.375 (39.807)
Epoch: [18][40/79]	Time 0.047 (0.066)	Loss 1.6707 (1.6396)	Prec@1 36.719 (39.672)
Epoch: [18][60/79]	Time 0.047 (0.060)	Loss 1.5174 (1.6371)	Prec@1 46.875 (39.626)
epoch training time:  4.614849805831909
Test: [0/391]	Time 0.852 (0.852)	Loss 1.5140 (1.5140)	Prec@1 40.625 (40.625)
Test: [20/391]	Time 0.033 (0.071)	Loss 1.6280 (1.5728)	Prec@1 36.719 (40.997)
Test: [40/391]	Time 0.032 (0.052)	Loss 1.5213 (1.5469)	Prec@1 37.500 (42.168)
Test: [60/391]	Time 0.033 (0.046)	Loss 1.4631 (1.5505)	Prec@1 45.312 (41.150)
Test: [80/391]	Time 0.032 (0.042)	Loss 1.5777 (1.5530)	Prec@1 35.938 (40.905)
Test: [100/391]	Time 0.033 (0.040)	Loss 1.6080 (1.5494)	Prec@1 39.844 (41.136)
Test: [120/391]	Time 0.032 (0.039)	Loss 1.5324 (1.5530)	Prec@1 43.750 (41.051)
Test: [140/391]	Time 0.032 (0.038)	Loss 1.4988 (1.5554)	Prec@1 40.625 (40.725)
Test: [160/391]	Time 0.032 (0.037)	Loss 1.5539 (1.5554)	Prec@1 36.719 (40.839)
Test: [180/391]	Time 0.032 (0.037)	Loss 1.6149 (1.5584)	Prec@1 39.844 (40.780)
Test: [200/391]	Time 0.033 (0.036)	Loss 1.6020 (1.5603)	Prec@1 42.969 (40.722)
Test: [220/391]	Time 0.033 (0.036)	Loss 1.6078 (1.5606)	Prec@1 35.156 (40.639)
Test: [240/391]	Time 0.032 (0.036)	Loss 1.6159 (1.5619)	Prec@1 39.844 (40.508)
Test: [260/391]	Time 0.033 (0.035)	Loss 1.7046 (1.5625)	Prec@1 36.719 (40.538)
Test: [280/391]	Time 0.033 (0.035)	Loss 1.4144 (1.5630)	Prec@1 41.406 (40.508)
Test: [300/391]	Time 0.033 (0.035)	Loss 1.5852 (1.5635)	Prec@1 35.156 (40.493)
Test: [320/391]	Time 0.034 (0.035)	Loss 1.5649 (1.5636)	Prec@1 39.844 (40.564)
Test: [340/391]	Time 0.031 (0.035)	Loss 1.5448 (1.5638)	Prec@1 47.656 (40.565)
Test: [360/391]	Time 0.032 (0.034)	Loss 1.6074 (1.5645)	Prec@1 42.188 (40.497)
Test: [380/391]	Time 0.032 (0.034)	Loss 1.4100 (1.5635)	Prec@1 49.219 (40.561)
 * Prec@1 40.566
Test: [0/79]	Time 0.871 (0.871)	Loss 1.5196 (1.5196)	Prec@1 39.844 (39.844)
Test: [20/79]	Time 0.033 (0.072)	Loss 1.6301 (1.5176)	Prec@1 35.156 (41.183)
Test: [40/79]	Time 0.033 (0.053)	Loss 1.5312 (1.5156)	Prec@1 44.531 (41.749)
Test: [60/79]	Time 0.030 (0.046)	Loss 1.4796 (1.5168)	Prec@1 42.188 (41.419)
 * Prec@1 41.350
=> Saving checkpoint for epoch 18, with Prec@1 41.350000.
Epoch: [19][0/79]	Time 0.902 (0.902)	Loss 1.7696 (1.7696)	Prec@1 28.906 (28.906)
Epoch: [19][20/79]	Time 0.042 (0.085)	Loss 1.6748 (1.6528)	Prec@1 39.062 (37.835)
Epoch: [19][40/79]	Time 0.041 (0.066)	Loss 1.6381 (1.6112)	Prec@1 40.625 (40.225)
Epoch: [19][60/79]	Time 0.043 (0.059)	Loss 1.5892 (1.6164)	Prec@1 35.156 (40.100)
epoch training time:  4.553072452545166
Test: [0/391]	Time 0.916 (0.916)	Loss 1.4911 (1.4911)	Prec@1 41.406 (41.406)
Test: [20/391]	Time 0.029 (0.074)	Loss 1.4248 (1.5486)	Prec@1 46.094 (41.667)
Test: [40/391]	Time 0.032 (0.053)	Loss 1.6640 (1.5542)	Prec@1 35.156 (41.749)
Test: [60/391]	Time 0.031 (0.046)	Loss 1.5389 (1.5630)	Prec@1 42.969 (41.253)
Test: [80/391]	Time 0.032 (0.043)	Loss 1.6401 (1.5731)	Prec@1 34.375 (40.480)
Test: [100/391]	Time 0.031 (0.040)	Loss 1.4684 (1.5690)	Prec@1 46.875 (40.695)
Test: [120/391]	Time 0.032 (0.040)	Loss 1.4692 (1.5682)	Prec@1 48.438 (40.754)
Test: [140/391]	Time 0.032 (0.039)	Loss 1.5091 (1.5694)	Prec@1 49.219 (40.614)
Test: [160/391]	Time 0.029 (0.038)	Loss 1.3759 (1.5654)	Prec@1 46.094 (40.853)
Test: [180/391]	Time 0.031 (0.037)	Loss 1.6303 (1.5644)	Prec@1 39.844 (40.750)
Test: [200/391]	Time 0.032 (0.037)	Loss 1.5509 (1.5647)	Prec@1 42.188 (40.695)
Test: [220/391]	Time 0.032 (0.036)	Loss 1.6212 (1.5658)	Prec@1 31.250 (40.565)
Test: [240/391]	Time 0.032 (0.036)	Loss 1.5824 (1.5658)	Prec@1 41.406 (40.670)
Test: [260/391]	Time 0.031 (0.036)	Loss 1.4293 (1.5650)	Prec@1 44.531 (40.754)
Test: [280/391]	Time 0.031 (0.035)	Loss 1.6059 (1.5658)	Prec@1 42.969 (40.822)
Test: [300/391]	Time 0.032 (0.035)	Loss 1.4855 (1.5669)	Prec@1 46.094 (40.833)
Test: [320/391]	Time 0.031 (0.035)	Loss 1.6161 (1.5668)	Prec@1 39.844 (40.868)
Test: [340/391]	Time 0.032 (0.035)	Loss 1.6096 (1.5660)	Prec@1 36.719 (40.957)
Test: [360/391]	Time 0.032 (0.035)	Loss 1.5455 (1.5658)	Prec@1 39.062 (40.947)
Test: [380/391]	Time 0.031 (0.034)	Loss 1.5241 (1.5673)	Prec@1 42.188 (40.842)
 * Prec@1 40.864
Test: [0/79]	Time 0.824 (0.824)	Loss 1.5133 (1.5133)	Prec@1 42.188 (42.188)
Test: [20/79]	Time 0.032 (0.067)	Loss 1.6487 (1.5218)	Prec@1 38.281 (42.560)
Test: [40/79]	Time 0.032 (0.050)	Loss 1.5361 (1.5245)	Prec@1 40.625 (42.454)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.5558 (1.5375)	Prec@1 39.844 (41.931)
 * Prec@1 41.790
=> Saving checkpoint for epoch 19, with Prec@1 41.790000.
Epoch: [20][0/79]	Time 0.883 (0.883)	Loss 1.6403 (1.6403)	Prec@1 32.812 (32.812)
Epoch: [20][20/79]	Time 0.046 (0.085)	Loss 1.5633 (1.6310)	Prec@1 42.969 (39.286)
Epoch: [20][40/79]	Time 0.046 (0.066)	Loss 1.6447 (1.6180)	Prec@1 35.938 (39.577)
Epoch: [20][60/79]	Time 0.048 (0.059)	Loss 1.5757 (1.6126)	Prec@1 42.188 (39.895)
epoch training time:  4.605730295181274
Test: [0/391]	Time 0.860 (0.860)	Loss 1.5569 (1.5569)	Prec@1 37.500 (37.500)
Test: [20/391]	Time 0.033 (0.072)	Loss 1.5826 (1.5200)	Prec@1 42.969 (42.188)
Test: [40/391]	Time 0.032 (0.053)	Loss 1.6062 (1.5185)	Prec@1 39.062 (42.626)
Test: [60/391]	Time 0.033 (0.046)	Loss 1.6266 (1.5162)	Prec@1 34.375 (42.495)
Test: [80/391]	Time 0.034 (0.042)	Loss 1.5304 (1.5158)	Prec@1 37.500 (42.159)
Test: [100/391]	Time 0.033 (0.040)	Loss 1.5154 (1.5150)	Prec@1 42.969 (42.342)
Test: [120/391]	Time 0.032 (0.038)	Loss 1.5157 (1.5172)	Prec@1 41.406 (42.342)
Test: [140/391]	Time 0.032 (0.037)	Loss 1.5271 (1.5184)	Prec@1 43.750 (42.409)
Test: [160/391]	Time 0.034 (0.037)	Loss 1.4941 (1.5194)	Prec@1 42.188 (42.280)
Test: [180/391]	Time 0.032 (0.036)	Loss 1.6010 (1.5209)	Prec@1 41.406 (42.304)
Test: [200/391]	Time 0.033 (0.035)	Loss 1.5130 (1.5230)	Prec@1 39.844 (42.137)
Test: [220/391]	Time 0.032 (0.035)	Loss 1.5698 (1.5249)	Prec@1 44.531 (42.251)
Test: [240/391]	Time 0.030 (0.035)	Loss 1.5338 (1.5254)	Prec@1 43.750 (42.340)
Test: [260/391]	Time 0.033 (0.034)	Loss 1.5233 (1.5245)	Prec@1 40.625 (42.325)
Test: [280/391]	Time 0.032 (0.034)	Loss 1.5091 (1.5253)	Prec@1 42.969 (42.254)
Test: [300/391]	Time 0.031 (0.034)	Loss 1.4928 (1.5241)	Prec@1 44.531 (42.424)
Test: [320/391]	Time 0.032 (0.034)	Loss 1.5534 (1.5234)	Prec@1 39.062 (42.407)
Test: [340/391]	Time 0.032 (0.034)	Loss 1.6052 (1.5235)	Prec@1 42.188 (42.366)
Test: [360/391]	Time 0.032 (0.034)	Loss 1.5192 (1.5244)	Prec@1 44.531 (42.337)
Test: [380/391]	Time 0.031 (0.034)	Loss 1.6432 (1.5246)	Prec@1 40.625 (42.323)
 * Prec@1 42.350
Test: [0/79]	Time 0.837 (0.837)	Loss 1.5455 (1.5455)	Prec@1 41.406 (41.406)
Test: [20/79]	Time 0.047 (0.069)	Loss 1.6461 (1.5002)	Prec@1 41.406 (43.750)
Test: [40/79]	Time 0.029 (0.050)	Loss 1.5809 (1.4922)	Prec@1 33.594 (43.178)
Test: [60/79]	Time 0.031 (0.044)	Loss 1.5371 (1.5025)	Prec@1 42.969 (42.994)
 * Prec@1 42.620
=> Saving checkpoint for epoch 20, with Prec@1 42.620000.
Epoch: [21][0/79]	Time 0.867 (0.867)	Loss 1.5372 (1.5372)	Prec@1 44.531 (44.531)
Epoch: [21][20/79]	Time 0.042 (0.083)	Loss 1.7513 (1.6123)	Prec@1 37.500 (40.402)
Epoch: [21][40/79]	Time 0.044 (0.064)	Loss 1.5908 (1.5827)	Prec@1 39.844 (41.616)
Epoch: [21][60/79]	Time 0.047 (0.059)	Loss 1.5677 (1.5841)	Prec@1 40.625 (41.573)
epoch training time:  4.6090614795684814
Test: [0/391]	Time 0.852 (0.852)	Loss 1.8711 (1.8711)	Prec@1 32.031 (32.031)
Test: [20/391]	Time 0.030 (0.071)	Loss 1.6919 (1.7733)	Prec@1 39.844 (36.607)
Test: [40/391]	Time 0.030 (0.052)	Loss 1.8739 (1.7955)	Prec@1 35.156 (36.547)
Test: [60/391]	Time 0.029 (0.045)	Loss 1.8863 (1.7824)	Prec@1 34.375 (36.629)
Test: [80/391]	Time 0.030 (0.042)	Loss 1.7903 (1.7753)	Prec@1 37.500 (36.921)
Test: [100/391]	Time 0.030 (0.040)	Loss 1.8577 (1.7819)	Prec@1 35.156 (36.850)
Test: [120/391]	Time 0.028 (0.038)	Loss 1.7448 (1.7844)	Prec@1 37.500 (37.093)
Test: [140/391]	Time 0.031 (0.037)	Loss 1.9386 (1.7811)	Prec@1 36.719 (37.251)
Test: [160/391]	Time 0.032 (0.037)	Loss 1.9722 (1.7810)	Prec@1 39.844 (37.272)
Test: [180/391]	Time 0.032 (0.036)	Loss 1.6645 (1.7812)	Prec@1 43.750 (37.427)
Test: [200/391]	Time 0.030 (0.035)	Loss 1.8783 (1.7839)	Prec@1 36.719 (37.271)
Test: [220/391]	Time 0.033 (0.035)	Loss 1.6633 (1.7854)	Prec@1 39.062 (37.189)
Test: [240/391]	Time 0.031 (0.035)	Loss 1.7667 (1.7869)	Prec@1 37.500 (37.130)
Test: [260/391]	Time 0.032 (0.035)	Loss 1.8243 (1.7867)	Prec@1 41.406 (37.168)
Test: [280/391]	Time 0.033 (0.034)	Loss 1.6641 (1.7868)	Prec@1 43.750 (37.169)
Test: [300/391]	Time 0.033 (0.034)	Loss 1.8946 (1.7886)	Prec@1 39.062 (37.147)
Test: [320/391]	Time 0.030 (0.034)	Loss 1.8251 (1.7880)	Prec@1 34.375 (37.179)
Test: [340/391]	Time 0.032 (0.034)	Loss 1.9286 (1.7866)	Prec@1 34.375 (37.175)
Test: [360/391]	Time 0.032 (0.034)	Loss 1.8434 (1.7885)	Prec@1 39.062 (37.145)
Test: [380/391]	Time 0.032 (0.034)	Loss 1.6297 (1.7884)	Prec@1 38.281 (37.174)
 * Prec@1 37.208
Test: [0/79]	Time 0.867 (0.867)	Loss 1.8850 (1.8850)	Prec@1 32.031 (32.031)
Test: [20/79]	Time 0.031 (0.072)	Loss 1.7407 (1.7169)	Prec@1 39.844 (38.728)
Test: [40/79]	Time 0.032 (0.052)	Loss 1.8224 (1.7258)	Prec@1 34.375 (38.262)
Test: [60/79]	Time 0.033 (0.046)	Loss 1.7492 (1.7467)	Prec@1 35.938 (37.897)
 * Prec@1 37.600
Epoch: [22][0/79]	Time 0.907 (0.907)	Loss 1.5682 (1.5682)	Prec@1 40.625 (40.625)
Epoch: [22][20/79]	Time 0.046 (0.087)	Loss 1.4712 (1.5477)	Prec@1 46.094 (42.374)
Epoch: [22][40/79]	Time 0.046 (0.067)	Loss 1.4074 (1.5602)	Prec@1 51.562 (41.845)
Epoch: [22][60/79]	Time 0.045 (0.060)	Loss 1.4008 (1.5495)	Prec@1 44.531 (42.200)
epoch training time:  4.656219482421875
Test: [0/391]	Time 0.885 (0.885)	Loss 1.4273 (1.4273)	Prec@1 46.094 (46.094)
Test: [20/391]	Time 0.032 (0.073)	Loss 1.5042 (1.5117)	Prec@1 44.531 (44.382)
Test: [40/391]	Time 0.032 (0.053)	Loss 1.5388 (1.5199)	Prec@1 44.531 (43.712)
Test: [60/391]	Time 0.032 (0.046)	Loss 1.5059 (1.5067)	Prec@1 44.531 (44.096)
Test: [80/391]	Time 0.033 (0.043)	Loss 1.5586 (1.5096)	Prec@1 43.750 (44.242)
Test: [100/391]	Time 0.033 (0.041)	Loss 1.6080 (1.5027)	Prec@1 45.312 (44.578)
Test: [120/391]	Time 0.032 (0.039)	Loss 1.5884 (1.5013)	Prec@1 37.500 (44.473)
Test: [140/391]	Time 0.032 (0.038)	Loss 1.5273 (1.5047)	Prec@1 48.438 (44.359)
Test: [160/391]	Time 0.033 (0.037)	Loss 1.4566 (1.5037)	Prec@1 42.969 (44.255)
Test: [180/391]	Time 0.032 (0.037)	Loss 1.4725 (1.5027)	Prec@1 45.312 (44.246)
Test: [200/391]	Time 0.032 (0.036)	Loss 1.4496 (1.5067)	Prec@1 44.531 (44.018)
Test: [220/391]	Time 0.032 (0.036)	Loss 1.5111 (1.5061)	Prec@1 41.406 (44.029)
Test: [240/391]	Time 0.032 (0.036)	Loss 1.5702 (1.5057)	Prec@1 41.406 (43.925)
Test: [260/391]	Time 0.032 (0.035)	Loss 1.3395 (1.5060)	Prec@1 55.469 (43.909)
Test: [280/391]	Time 0.034 (0.035)	Loss 1.5156 (1.5045)	Prec@1 43.750 (43.953)
Test: [300/391]	Time 0.033 (0.035)	Loss 1.5591 (1.5033)	Prec@1 41.406 (43.973)
Test: [320/391]	Time 0.032 (0.035)	Loss 1.4262 (1.5018)	Prec@1 43.750 (43.969)
Test: [340/391]	Time 0.033 (0.035)	Loss 1.6215 (1.5034)	Prec@1 38.281 (43.855)
Test: [360/391]	Time 0.032 (0.035)	Loss 1.5007 (1.5038)	Prec@1 45.312 (43.828)
Test: [380/391]	Time 0.031 (0.035)	Loss 1.4178 (1.5040)	Prec@1 48.438 (43.824)
 * Prec@1 43.836
Test: [0/79]	Time 0.830 (0.830)	Loss 1.4399 (1.4399)	Prec@1 45.312 (45.312)
Test: [20/79]	Time 0.032 (0.070)	Loss 1.4780 (1.4811)	Prec@1 48.438 (45.052)
Test: [40/79]	Time 0.033 (0.052)	Loss 1.5404 (1.4801)	Prec@1 41.406 (45.046)
Test: [60/79]	Time 0.031 (0.046)	Loss 1.4959 (1.4831)	Prec@1 42.969 (44.365)
 * Prec@1 44.290
=> Saving checkpoint for epoch 22, with Prec@1 44.290000.
Epoch: [23][0/79]	Time 0.854 (0.854)	Loss 1.6187 (1.6187)	Prec@1 38.281 (38.281)
Epoch: [23][20/79]	Time 0.046 (0.085)	Loss 1.5873 (1.5645)	Prec@1 38.281 (42.076)
Epoch: [23][40/79]	Time 0.046 (0.066)	Loss 1.5870 (1.5560)	Prec@1 37.500 (42.435)
Epoch: [23][60/79]	Time 0.046 (0.060)	Loss 1.3513 (1.5424)	Prec@1 54.688 (43.417)
epoch training time:  4.608552932739258
Test: [0/391]	Time 0.916 (0.916)	Loss 1.5787 (1.5787)	Prec@1 44.531 (44.531)
Test: [20/391]	Time 0.032 (0.074)	Loss 1.5774 (1.5379)	Prec@1 39.062 (43.006)
Test: [40/391]	Time 0.032 (0.054)	Loss 1.5700 (1.5497)	Prec@1 38.281 (43.007)
Test: [60/391]	Time 0.032 (0.047)	Loss 1.6613 (1.5450)	Prec@1 43.750 (43.263)
Test: [80/391]	Time 0.032 (0.043)	Loss 1.4341 (1.5418)	Prec@1 50.781 (43.355)
Test: [100/391]	Time 0.033 (0.041)	Loss 1.5646 (1.5393)	Prec@1 46.094 (43.588)
Test: [120/391]	Time 0.032 (0.039)	Loss 1.5683 (1.5415)	Prec@1 42.188 (43.350)
Test: [140/391]	Time 0.032 (0.038)	Loss 1.5792 (1.5396)	Prec@1 46.094 (43.528)
Test: [160/391]	Time 0.032 (0.038)	Loss 1.5920 (1.5421)	Prec@1 39.062 (43.483)
Test: [180/391]	Time 0.032 (0.037)	Loss 1.6818 (1.5372)	Prec@1 41.406 (43.625)
Test: [200/391]	Time 0.034 (0.036)	Loss 1.5679 (1.5339)	Prec@1 38.281 (43.676)
Test: [220/391]	Time 0.033 (0.036)	Loss 1.5744 (1.5333)	Prec@1 44.531 (43.736)
Test: [240/391]	Time 0.032 (0.036)	Loss 1.5404 (1.5341)	Prec@1 42.188 (43.692)
Test: [260/391]	Time 0.033 (0.035)	Loss 1.3994 (1.5321)	Prec@1 43.750 (43.747)
Test: [280/391]	Time 0.033 (0.035)	Loss 1.6643 (1.5329)	Prec@1 39.062 (43.806)
Test: [300/391]	Time 0.033 (0.035)	Loss 1.6191 (1.5328)	Prec@1 40.625 (43.849)
Test: [320/391]	Time 0.032 (0.035)	Loss 1.4966 (1.5293)	Prec@1 47.656 (43.996)
Test: [340/391]	Time 0.033 (0.035)	Loss 1.5449 (1.5303)	Prec@1 42.969 (43.949)
Test: [360/391]	Time 0.032 (0.035)	Loss 1.4986 (1.5295)	Prec@1 46.094 (43.997)
Test: [380/391]	Time 0.031 (0.034)	Loss 1.4626 (1.5291)	Prec@1 43.750 (44.064)
 * Prec@1 44.012
Test: [0/79]	Time 0.822 (0.822)	Loss 1.6230 (1.6230)	Prec@1 39.844 (39.844)
Test: [20/79]	Time 0.032 (0.069)	Loss 1.6129 (1.4937)	Prec@1 40.625 (45.982)
Test: [40/79]	Time 0.032 (0.051)	Loss 1.5624 (1.4882)	Prec@1 44.531 (46.341)
Test: [60/79]	Time 0.031 (0.045)	Loss 1.4997 (1.4948)	Prec@1 42.188 (45.722)
 * Prec@1 45.240
=> Saving checkpoint for epoch 23, with Prec@1 45.240000.
Epoch: [24][0/79]	Time 0.907 (0.907)	Loss 1.5647 (1.5647)	Prec@1 41.406 (41.406)
Epoch: [24][20/79]	Time 0.043 (0.087)	Loss 1.5406 (1.5316)	Prec@1 41.406 (44.420)
Epoch: [24][40/79]	Time 0.046 (0.067)	Loss 1.5479 (1.5068)	Prec@1 45.312 (45.332)
Epoch: [24][60/79]	Time 0.047 (0.060)	Loss 1.4047 (1.5054)	Prec@1 45.312 (45.287)
epoch training time:  4.648821592330933
Test: [0/391]	Time 0.893 (0.893)	Loss 1.6497 (1.6497)	Prec@1 36.719 (36.719)
Test: [20/391]	Time 0.032 (0.073)	Loss 1.5370 (1.5313)	Prec@1 37.500 (42.299)
Test: [40/391]	Time 0.033 (0.053)	Loss 1.5206 (1.5292)	Prec@1 36.719 (41.997)
Test: [60/391]	Time 0.032 (0.046)	Loss 1.6013 (1.5303)	Prec@1 37.500 (41.983)
Test: [80/391]	Time 0.032 (0.043)	Loss 1.5519 (1.5383)	Prec@1 41.406 (41.860)
Test: [100/391]	Time 0.033 (0.041)	Loss 1.4656 (1.5366)	Prec@1 44.531 (42.064)
Test: [120/391]	Time 0.033 (0.039)	Loss 1.4411 (1.5363)	Prec@1 46.094 (42.142)
Test: [140/391]	Time 0.032 (0.038)	Loss 1.4991 (1.5317)	Prec@1 43.750 (42.154)
Test: [160/391]	Time 0.032 (0.038)	Loss 1.6141 (1.5363)	Prec@1 42.969 (41.930)
Test: [180/391]	Time 0.032 (0.037)	Loss 1.5164 (1.5381)	Prec@1 40.625 (41.864)
Test: [200/391]	Time 0.033 (0.037)	Loss 1.3854 (1.5382)	Prec@1 53.906 (41.830)
Test: [220/391]	Time 0.033 (0.037)	Loss 1.6391 (1.5372)	Prec@1 37.500 (41.816)
Test: [240/391]	Time 0.032 (0.036)	Loss 1.3860 (1.5351)	Prec@1 46.094 (41.837)
Test: [260/391]	Time 0.032 (0.036)	Loss 1.4739 (1.5339)	Prec@1 40.625 (41.864)
Test: [280/391]	Time 0.031 (0.036)	Loss 1.5027 (1.5341)	Prec@1 40.625 (41.732)
Test: [300/391]	Time 0.032 (0.036)	Loss 1.4509 (1.5358)	Prec@1 43.750 (41.580)
Test: [320/391]	Time 0.032 (0.035)	Loss 1.4762 (1.5350)	Prec@1 43.750 (41.552)
Test: [340/391]	Time 0.032 (0.035)	Loss 1.5153 (1.5330)	Prec@1 39.844 (41.525)
Test: [360/391]	Time 0.032 (0.035)	Loss 1.4425 (1.5341)	Prec@1 44.531 (41.508)
Test: [380/391]	Time 0.031 (0.035)	Loss 1.5676 (1.5346)	Prec@1 39.844 (41.464)
 * Prec@1 41.456
Test: [0/79]	Time 0.822 (0.822)	Loss 1.5429 (1.5429)	Prec@1 39.844 (39.844)
Test: [20/79]	Time 0.031 (0.069)	Loss 1.5623 (1.5284)	Prec@1 41.406 (42.262)
Test: [40/79]	Time 0.032 (0.051)	Loss 1.5933 (1.5194)	Prec@1 43.750 (41.997)
Test: [60/79]	Time 0.032 (0.045)	Loss 1.4605 (1.5226)	Prec@1 47.656 (41.893)
 * Prec@1 41.770
Epoch: [25][0/79]	Time 0.872 (0.872)	Loss 1.5166 (1.5166)	Prec@1 43.750 (43.750)
Epoch: [25][20/79]	Time 0.045 (0.084)	Loss 1.5766 (1.5034)	Prec@1 42.969 (44.754)
Epoch: [25][40/79]	Time 0.046 (0.066)	Loss 1.3972 (1.4654)	Prec@1 47.656 (45.446)
Epoch: [25][60/79]	Time 0.043 (0.059)	Loss 1.4397 (1.4609)	Prec@1 51.562 (45.991)
epoch training time:  4.58479642868042
Test: [0/391]	Time 0.859 (0.859)	Loss 1.3646 (1.3646)	Prec@1 48.438 (48.438)
Test: [20/391]	Time 0.032 (0.071)	Loss 1.5042 (1.3716)	Prec@1 46.094 (48.177)
Test: [40/391]	Time 0.032 (0.052)	Loss 1.3948 (1.3544)	Prec@1 44.531 (49.085)
Test: [60/391]	Time 0.033 (0.046)	Loss 1.3286 (1.3578)	Prec@1 50.781 (48.694)
Test: [80/391]	Time 0.031 (0.042)	Loss 1.4227 (1.3559)	Prec@1 46.094 (48.920)
Test: [100/391]	Time 0.033 (0.040)	Loss 1.4845 (1.3611)	Prec@1 42.188 (48.623)
Test: [120/391]	Time 0.032 (0.039)	Loss 1.3427 (1.3603)	Prec@1 42.969 (48.586)
Test: [140/391]	Time 0.033 (0.038)	Loss 1.4240 (1.3615)	Prec@1 46.875 (48.438)
Test: [160/391]	Time 0.034 (0.037)	Loss 1.3752 (1.3630)	Prec@1 44.531 (48.433)
Test: [180/391]	Time 0.034 (0.037)	Loss 1.5751 (1.3649)	Prec@1 39.844 (48.399)
Test: [200/391]	Time 0.033 (0.036)	Loss 1.4070 (1.3668)	Prec@1 48.438 (48.360)
Test: [220/391]	Time 0.032 (0.036)	Loss 1.1775 (1.3682)	Prec@1 52.344 (48.254)
Test: [240/391]	Time 0.032 (0.036)	Loss 1.4800 (1.3704)	Prec@1 44.531 (48.155)
Test: [260/391]	Time 0.032 (0.035)	Loss 1.3807 (1.3684)	Prec@1 46.094 (48.354)
Test: [280/391]	Time 0.033 (0.035)	Loss 1.4413 (1.3671)	Prec@1 42.969 (48.401)
Test: [300/391]	Time 0.033 (0.035)	Loss 1.3157 (1.3636)	Prec@1 49.219 (48.557)
Test: [320/391]	Time 0.032 (0.035)	Loss 1.2673 (1.3644)	Prec@1 52.344 (48.537)
Test: [340/391]	Time 0.032 (0.035)	Loss 1.3562 (1.3637)	Prec@1 46.094 (48.605)
Test: [360/391]	Time 0.031 (0.035)	Loss 1.2950 (1.3634)	Prec@1 52.344 (48.600)
Test: [380/391]	Time 0.031 (0.034)	Loss 1.2068 (1.3625)	Prec@1 51.562 (48.610)
 * Prec@1 48.568
Test: [0/79]	Time 0.824 (0.824)	Loss 1.2796 (1.2796)	Prec@1 49.219 (49.219)
Test: [20/79]	Time 0.032 (0.070)	Loss 1.3320 (1.3397)	Prec@1 51.562 (49.405)
Test: [40/79]	Time 0.033 (0.052)	Loss 1.3521 (1.3349)	Prec@1 53.125 (49.524)
Test: [60/79]	Time 0.031 (0.045)	Loss 1.3243 (1.3429)	Prec@1 48.438 (48.911)
 * Prec@1 49.090
=> Saving checkpoint for epoch 25, with Prec@1 49.090000.
Epoch: [26][0/79]	Time 0.912 (0.912)	Loss 1.4342 (1.4342)	Prec@1 52.344 (52.344)
Epoch: [26][20/79]	Time 0.046 (0.087)	Loss 1.4383 (1.4489)	Prec@1 49.219 (48.289)
Epoch: [26][40/79]	Time 0.046 (0.067)	Loss 1.5424 (1.4478)	Prec@1 42.969 (47.237)
Epoch: [26][60/79]	Time 0.046 (0.060)	Loss 1.6037 (1.4445)	Prec@1 41.406 (47.490)
epoch training time:  4.6941773891448975
Test: [0/391]	Time 0.891 (0.891)	Loss 1.5674 (1.5674)	Prec@1 42.969 (42.969)
Test: [20/391]	Time 0.030 (0.073)	Loss 1.6597 (1.5799)	Prec@1 41.406 (44.010)
Test: [40/391]	Time 0.034 (0.056)	Loss 1.4154 (1.5743)	Prec@1 43.750 (43.693)
Test: [60/391]	Time 0.032 (0.048)	Loss 1.5009 (1.5687)	Prec@1 46.875 (44.032)
Test: [80/391]	Time 0.032 (0.044)	Loss 1.5614 (1.5637)	Prec@1 42.188 (43.981)
Test: [100/391]	Time 0.033 (0.042)	Loss 1.4761 (1.5663)	Prec@1 45.312 (43.727)
Test: [120/391]	Time 0.033 (0.040)	Loss 1.5324 (1.5667)	Prec@1 48.438 (43.660)
Test: [140/391]	Time 0.032 (0.039)	Loss 1.7034 (1.5707)	Prec@1 42.188 (43.578)
Test: [160/391]	Time 0.033 (0.038)	Loss 1.5374 (1.5711)	Prec@1 46.094 (43.566)
Test: [180/391]	Time 0.034 (0.038)	Loss 1.3762 (1.5694)	Prec@1 48.438 (43.750)
Test: [200/391]	Time 0.032 (0.037)	Loss 1.5773 (1.5674)	Prec@1 39.844 (43.661)
Test: [220/391]	Time 0.033 (0.037)	Loss 1.6338 (1.5649)	Prec@1 34.375 (43.732)
Test: [240/391]	Time 0.032 (0.036)	Loss 1.4729 (1.5663)	Prec@1 45.312 (43.643)
Test: [260/391]	Time 0.032 (0.036)	Loss 1.6136 (1.5614)	Prec@1 39.844 (43.741)
Test: [280/391]	Time 0.033 (0.036)	Loss 1.5541 (1.5620)	Prec@1 48.438 (43.753)
Test: [300/391]	Time 0.031 (0.035)	Loss 1.4434 (1.5622)	Prec@1 48.438 (43.771)
Test: [320/391]	Time 0.032 (0.035)	Loss 1.3701 (1.5629)	Prec@1 47.656 (43.769)
Test: [340/391]	Time 0.033 (0.035)	Loss 1.5445 (1.5636)	Prec@1 47.656 (43.796)
Test: [360/391]	Time 0.033 (0.035)	Loss 1.6632 (1.5629)	Prec@1 42.188 (43.793)
Test: [380/391]	Time 0.032 (0.035)	Loss 1.5273 (1.5617)	Prec@1 44.531 (43.822)
 * Prec@1 43.868
Test: [0/79]	Time 0.833 (0.833)	Loss 1.4502 (1.4502)	Prec@1 44.531 (44.531)
Test: [20/79]	Time 0.031 (0.070)	Loss 1.5881 (1.5110)	Prec@1 48.438 (45.275)
Test: [40/79]	Time 0.031 (0.051)	Loss 1.5304 (1.4866)	Prec@1 42.188 (46.151)
Test: [60/79]	Time 0.031 (0.045)	Loss 1.4748 (1.4922)	Prec@1 44.531 (46.235)
 * Prec@1 46.050
Epoch: [27][0/79]	Time 0.855 (0.855)	Loss 1.6393 (1.6393)	Prec@1 38.281 (38.281)
Epoch: [27][20/79]	Time 0.047 (0.083)	Loss 1.4561 (1.4250)	Prec@1 45.312 (48.438)
Epoch: [27][40/79]	Time 0.047 (0.065)	Loss 1.3830 (1.3941)	Prec@1 46.875 (48.838)
Epoch: [27][60/79]	Time 0.044 (0.059)	Loss 1.3686 (1.3923)	Prec@1 52.344 (48.796)
epoch training time:  4.5694944858551025
Test: [0/391]	Time 0.863 (0.863)	Loss 1.3161 (1.3161)	Prec@1 52.344 (52.344)
Test: [20/391]	Time 0.033 (0.071)	Loss 1.4197 (1.3235)	Prec@1 53.906 (53.088)
Test: [40/391]	Time 0.029 (0.051)	Loss 1.2090 (1.3089)	Prec@1 52.344 (53.201)
Test: [60/391]	Time 0.029 (0.045)	Loss 1.2379 (1.3016)	Prec@1 52.344 (53.279)
Test: [80/391]	Time 0.032 (0.042)	Loss 1.2595 (1.3050)	Prec@1 55.469 (53.038)
Test: [100/391]	Time 0.031 (0.040)	Loss 1.1994 (1.3043)	Prec@1 53.125 (52.885)
Test: [120/391]	Time 0.031 (0.038)	Loss 1.2604 (1.3037)	Prec@1 52.344 (52.776)
Test: [140/391]	Time 0.033 (0.038)	Loss 1.3328 (1.3016)	Prec@1 46.875 (52.693)
Test: [160/391]	Time 0.030 (0.037)	Loss 1.3846 (1.3058)	Prec@1 48.438 (52.378)
Test: [180/391]	Time 0.032 (0.036)	Loss 1.1620 (1.3083)	Prec@1 57.031 (52.201)
Test: [200/391]	Time 0.032 (0.036)	Loss 1.3436 (1.3094)	Prec@1 47.656 (52.072)
Test: [220/391]	Time 0.033 (0.036)	Loss 1.4586 (1.3104)	Prec@1 43.750 (51.994)
Test: [240/391]	Time 0.032 (0.035)	Loss 1.4541 (1.3132)	Prec@1 42.188 (51.903)
Test: [260/391]	Time 0.032 (0.035)	Loss 1.2950 (1.3129)	Prec@1 50.000 (52.011)
Test: [280/391]	Time 0.032 (0.035)	Loss 1.2833 (1.3161)	Prec@1 50.781 (51.846)
Test: [300/391]	Time 0.033 (0.035)	Loss 1.2762 (1.3154)	Prec@1 54.688 (51.848)
Test: [320/391]	Time 0.032 (0.034)	Loss 1.1466 (1.3137)	Prec@1 59.375 (51.891)
Test: [340/391]	Time 0.030 (0.034)	Loss 1.3202 (1.3135)	Prec@1 51.562 (51.938)
Test: [360/391]	Time 0.031 (0.034)	Loss 1.2631 (1.3119)	Prec@1 57.031 (51.950)
Test: [380/391]	Time 0.031 (0.034)	Loss 1.2905 (1.3104)	Prec@1 53.906 (51.964)
 * Prec@1 51.998
Test: [0/79]	Time 0.862 (0.862)	Loss 1.3161 (1.3161)	Prec@1 51.562 (51.562)
Test: [20/79]	Time 0.032 (0.071)	Loss 1.3120 (1.3021)	Prec@1 46.875 (52.195)
Test: [40/79]	Time 0.032 (0.052)	Loss 1.3942 (1.2876)	Prec@1 44.531 (52.553)
Test: [60/79]	Time 0.175 (0.048)	Loss 1.2837 (1.2934)	Prec@1 48.438 (51.998)
 * Prec@1 51.400
=> Saving checkpoint for epoch 27, with Prec@1 51.400000.
Epoch: [28][0/79]	Time 0.901 (0.901)	Loss 1.5682 (1.5682)	Prec@1 39.844 (39.844)
Epoch: [28][20/79]	Time 0.044 (0.087)	Loss 1.3793 (1.3962)	Prec@1 44.531 (49.033)
Epoch: [28][40/79]	Time 0.046 (0.067)	Loss 1.2830 (1.3669)	Prec@1 57.031 (50.076)
Epoch: [28][60/79]	Time 0.045 (0.060)	Loss 1.5605 (1.3660)	Prec@1 40.625 (49.731)
epoch training time:  4.662813186645508
Test: [0/391]	Time 0.874 (0.874)	Loss 1.4992 (1.4992)	Prec@1 46.094 (46.094)
Test: [20/391]	Time 0.032 (0.072)	Loss 1.2588 (1.3926)	Prec@1 50.000 (46.949)
Test: [40/391]	Time 0.032 (0.053)	Loss 1.3096 (1.3760)	Prec@1 44.531 (47.618)
Test: [60/391]	Time 0.032 (0.046)	Loss 1.2694 (1.3772)	Prec@1 52.344 (47.439)
Test: [80/391]	Time 0.031 (0.043)	Loss 1.3530 (1.3748)	Prec@1 44.531 (47.550)
Test: [100/391]	Time 0.031 (0.040)	Loss 1.2689 (1.3748)	Prec@1 52.344 (47.463)
Test: [120/391]	Time 0.030 (0.039)	Loss 1.5400 (1.3797)	Prec@1 46.094 (47.534)
Test: [140/391]	Time 0.032 (0.038)	Loss 1.3433 (1.3749)	Prec@1 50.000 (47.667)
Test: [160/391]	Time 0.032 (0.037)	Loss 1.4958 (1.3717)	Prec@1 48.438 (47.812)
Test: [180/391]	Time 0.031 (0.037)	Loss 1.3481 (1.3710)	Prec@1 53.125 (47.820)
Test: [200/391]	Time 0.031 (0.036)	Loss 1.3610 (1.3747)	Prec@1 48.438 (47.683)
Test: [220/391]	Time 0.032 (0.036)	Loss 1.3211 (1.3749)	Prec@1 50.000 (47.780)
Test: [240/391]	Time 0.033 (0.036)	Loss 1.4361 (1.3723)	Prec@1 43.750 (47.867)
Test: [260/391]	Time 0.033 (0.035)	Loss 1.3797 (1.3714)	Prec@1 44.531 (47.839)
Test: [280/391]	Time 0.029 (0.035)	Loss 1.3048 (1.3718)	Prec@1 53.125 (47.856)
Test: [300/391]	Time 0.033 (0.035)	Loss 1.5039 (1.3721)	Prec@1 40.625 (47.737)
Test: [320/391]	Time 0.031 (0.035)	Loss 1.2706 (1.3711)	Prec@1 54.688 (47.793)
Test: [340/391]	Time 0.032 (0.034)	Loss 1.3011 (1.3705)	Prec@1 50.000 (47.807)
Test: [360/391]	Time 0.032 (0.034)	Loss 1.4082 (1.3710)	Prec@1 45.312 (47.814)
Test: [380/391]	Time 0.031 (0.034)	Loss 1.4115 (1.3717)	Prec@1 45.312 (47.773)
 * Prec@1 47.784
Test: [0/79]	Time 0.867 (0.867)	Loss 1.3611 (1.3611)	Prec@1 51.562 (51.562)
Test: [20/79]	Time 0.032 (0.072)	Loss 1.2993 (1.3336)	Prec@1 51.562 (49.405)
Test: [40/79]	Time 0.032 (0.052)	Loss 1.3549 (1.3220)	Prec@1 49.219 (50.191)
Test: [60/79]	Time 0.031 (0.046)	Loss 1.2988 (1.3293)	Prec@1 50.781 (49.923)
 * Prec@1 49.700
Epoch: [29][0/79]	Time 0.907 (0.907)	Loss 1.2637 (1.2637)	Prec@1 54.688 (54.688)
Epoch: [29][20/79]	Time 0.046 (0.088)	Loss 1.2361 (1.3786)	Prec@1 57.812 (49.368)
Epoch: [29][40/79]	Time 0.046 (0.067)	Loss 1.2707 (1.3562)	Prec@1 53.125 (50.514)
Epoch: [29][60/79]	Time 0.046 (0.061)	Loss 1.2562 (1.3471)	Prec@1 53.906 (50.461)
epoch training time:  4.68963360786438
Test: [0/391]	Time 0.895 (0.895)	Loss 1.4733 (1.4733)	Prec@1 47.656 (47.656)
Test: [20/391]	Time 0.032 (0.072)	Loss 1.2719 (1.4230)	Prec@1 51.562 (47.433)
Test: [40/391]	Time 0.033 (0.052)	Loss 1.5775 (1.4267)	Prec@1 45.312 (47.256)
Test: [60/391]	Time 0.032 (0.046)	Loss 1.3747 (1.4169)	Prec@1 50.781 (47.349)
Test: [80/391]	Time 0.032 (0.042)	Loss 1.3780 (1.4182)	Prec@1 43.750 (47.386)
Test: [100/391]	Time 0.034 (0.041)	Loss 1.3514 (1.4158)	Prec@1 52.344 (47.633)
Test: [120/391]	Time 0.032 (0.039)	Loss 1.4529 (1.4158)	Prec@1 47.656 (47.456)
Test: [140/391]	Time 0.032 (0.038)	Loss 1.4520 (1.4173)	Prec@1 46.094 (47.412)
Test: [160/391]	Time 0.031 (0.037)	Loss 1.5174 (1.4190)	Prec@1 39.844 (47.253)
Test: [180/391]	Time 0.030 (0.037)	Loss 1.4200 (1.4223)	Prec@1 46.094 (47.160)
Test: [200/391]	Time 0.031 (0.036)	Loss 1.3654 (1.4188)	Prec@1 54.688 (47.248)
Test: [220/391]	Time 0.031 (0.036)	Loss 1.2757 (1.4169)	Prec@1 56.250 (47.274)
Test: [240/391]	Time 0.033 (0.036)	Loss 1.2827 (1.4205)	Prec@1 50.781 (47.160)
Test: [260/391]	Time 0.031 (0.035)	Loss 1.3575 (1.4212)	Prec@1 52.344 (47.138)
Test: [280/391]	Time 0.032 (0.035)	Loss 1.3055 (1.4198)	Prec@1 51.562 (47.250)
Test: [300/391]	Time 0.031 (0.035)	Loss 1.3993 (1.4198)	Prec@1 46.875 (47.264)
Test: [320/391]	Time 0.030 (0.035)	Loss 1.3491 (1.4201)	Prec@1 46.875 (47.289)
Test: [340/391]	Time 0.032 (0.035)	Loss 1.6380 (1.4209)	Prec@1 36.719 (47.303)
Test: [360/391]	Time 0.031 (0.035)	Loss 1.4133 (1.4207)	Prec@1 41.406 (47.291)
Test: [380/391]	Time 0.031 (0.035)	Loss 1.3537 (1.4205)	Prec@1 45.312 (47.228)
 * Prec@1 47.272
Test: [0/79]	Time 0.861 (0.861)	Loss 1.3096 (1.3096)	Prec@1 51.562 (51.562)
Test: [20/79]	Time 0.032 (0.071)	Loss 1.2585 (1.3858)	Prec@1 54.688 (48.847)
Test: [40/79]	Time 0.034 (0.052)	Loss 1.4496 (1.3747)	Prec@1 46.875 (49.466)
Test: [60/79]	Time 0.032 (0.045)	Loss 1.3628 (1.3733)	Prec@1 50.000 (49.385)
 * Prec@1 49.020
Epoch: [30][0/79]	Time 0.865 (0.865)	Loss 1.2725 (1.2725)	Prec@1 54.688 (54.688)
Epoch: [30][20/79]	Time 0.047 (0.086)	Loss 1.4347 (1.3408)	Prec@1 41.406 (50.335)
Epoch: [30][40/79]	Time 0.047 (0.067)	Loss 1.3057 (1.3158)	Prec@1 53.906 (51.429)
Epoch: [30][60/79]	Time 0.046 (0.060)	Loss 1.3249 (1.3117)	Prec@1 51.562 (51.703)
epoch training time:  4.650027275085449
Test: [0/391]	Time 0.860 (0.860)	Loss 1.3741 (1.3741)	Prec@1 50.000 (50.000)
Test: [20/391]	Time 0.032 (0.071)	Loss 1.4103 (1.3638)	Prec@1 43.750 (49.219)
Test: [40/391]	Time 0.029 (0.052)	Loss 1.3525 (1.3507)	Prec@1 46.094 (48.800)
Test: [60/391]	Time 0.029 (0.045)	Loss 1.3769 (1.3405)	Prec@1 49.219 (49.308)
Test: [80/391]	Time 0.028 (0.041)	Loss 1.4646 (1.3359)	Prec@1 44.531 (49.489)
Test: [100/391]	Time 0.032 (0.039)	Loss 1.2426 (1.3345)	Prec@1 57.031 (49.559)
Test: [120/391]	Time 0.031 (0.038)	Loss 1.3507 (1.3340)	Prec@1 51.562 (49.851)
Test: [140/391]	Time 0.033 (0.037)	Loss 1.3112 (1.3344)	Prec@1 50.000 (49.972)
Test: [160/391]	Time 0.031 (0.037)	Loss 1.3327 (1.3322)	Prec@1 45.312 (50.233)
Test: [180/391]	Time 0.031 (0.036)	Loss 1.2221 (1.3311)	Prec@1 57.031 (50.224)
Test: [200/391]	Time 0.032 (0.036)	Loss 1.3758 (1.3313)	Prec@1 46.875 (50.288)
Test: [220/391]	Time 0.033 (0.035)	Loss 1.4831 (1.3304)	Prec@1 49.219 (50.300)
Test: [240/391]	Time 0.032 (0.035)	Loss 1.3233 (1.3284)	Prec@1 52.344 (50.289)
Test: [260/391]	Time 0.032 (0.035)	Loss 1.2112 (1.3256)	Prec@1 57.812 (50.428)
Test: [280/391]	Time 0.032 (0.035)	Loss 1.4370 (1.3242)	Prec@1 50.000 (50.445)
Test: [300/391]	Time 0.032 (0.034)	Loss 1.3405 (1.3242)	Prec@1 52.344 (50.478)
Test: [320/391]	Time 0.032 (0.034)	Loss 1.3671 (1.3259)	Prec@1 50.781 (50.458)
Test: [340/391]	Time 0.032 (0.034)	Loss 1.3203 (1.3260)	Prec@1 50.781 (50.442)
Test: [360/391]	Time 0.032 (0.034)	Loss 1.2369 (1.3258)	Prec@1 54.688 (50.470)
Test: [380/391]	Time 0.031 (0.034)	Loss 1.5129 (1.3246)	Prec@1 42.188 (50.486)
 * Prec@1 50.482
Test: [0/79]	Time 0.828 (0.828)	Loss 1.3154 (1.3154)	Prec@1 46.875 (46.875)
Test: [20/79]	Time 0.029 (0.068)	Loss 1.3277 (1.2837)	Prec@1 53.125 (52.009)
Test: [40/79]	Time 0.030 (0.049)	Loss 1.3571 (1.2833)	Prec@1 48.438 (51.601)
Test: [60/79]	Time 0.031 (0.043)	Loss 1.3075 (1.2901)	Prec@1 49.219 (51.178)
 * Prec@1 50.770
Epoch: [31][0/79]	Time 0.904 (0.904)	Loss 1.4395 (1.4395)	Prec@1 51.562 (51.562)
Epoch: [31][20/79]	Time 0.047 (0.087)	Loss 1.1771 (1.2857)	Prec@1 51.562 (52.679)
Epoch: [31][40/79]	Time 0.047 (0.067)	Loss 1.3786 (1.2680)	Prec@1 45.312 (53.220)
Epoch: [31][60/79]	Time 0.045 (0.060)	Loss 1.3234 (1.2737)	Prec@1 53.125 (53.151)
epoch training time:  4.618629217147827
Test: [0/391]	Time 0.896 (0.896)	Loss 1.3573 (1.3573)	Prec@1 53.906 (53.906)
Test: [20/391]	Time 0.029 (0.071)	Loss 1.3152 (1.3762)	Prec@1 53.125 (49.330)
Test: [40/391]	Time 0.032 (0.052)	Loss 1.3456 (1.3532)	Prec@1 53.125 (50.476)
Test: [60/391]	Time 0.033 (0.045)	Loss 1.2396 (1.3506)	Prec@1 55.469 (50.999)
Test: [80/391]	Time 0.033 (0.042)	Loss 1.3894 (1.3447)	Prec@1 50.781 (51.119)
Test: [100/391]	Time 0.174 (0.042)	Loss 1.3701 (1.3561)	Prec@1 56.250 (51.122)
Test: [120/391]	Time 0.033 (0.040)	Loss 1.0840 (1.3533)	Prec@1 62.500 (51.304)
Test: [140/391]	Time 0.033 (0.039)	Loss 1.4345 (1.3583)	Prec@1 50.000 (51.092)
Test: [160/391]	Time 0.032 (0.038)	Loss 1.3729 (1.3605)	Prec@1 53.906 (50.864)
Test: [180/391]	Time 0.031 (0.037)	Loss 1.4552 (1.3649)	Prec@1 51.562 (50.717)
Test: [200/391]	Time 0.032 (0.037)	Loss 1.5010 (1.3667)	Prec@1 42.188 (50.785)
Test: [220/391]	Time 0.031 (0.036)	Loss 1.3383 (1.3666)	Prec@1 52.344 (50.824)
Test: [240/391]	Time 0.032 (0.036)	Loss 1.3765 (1.3681)	Prec@1 51.562 (50.862)
Test: [260/391]	Time 0.033 (0.036)	Loss 1.2671 (1.3687)	Prec@1 53.125 (50.841)
Test: [280/391]	Time 0.032 (0.036)	Loss 1.4884 (1.3689)	Prec@1 44.531 (50.745)
Test: [300/391]	Time 0.032 (0.035)	Loss 1.3769 (1.3710)	Prec@1 46.875 (50.662)
Test: [320/391]	Time 0.032 (0.035)	Loss 1.2030 (1.3697)	Prec@1 60.938 (50.713)
Test: [340/391]	Time 0.033 (0.035)	Loss 1.3972 (1.3671)	Prec@1 47.656 (50.758)
Test: [360/391]	Time 0.032 (0.035)	Loss 1.2853 (1.3686)	Prec@1 53.906 (50.654)
Test: [380/391]	Time 0.031 (0.035)	Loss 1.0742 (1.3678)	Prec@1 61.719 (50.734)
 * Prec@1 50.762
Test: [0/79]	Time 0.828 (0.828)	Loss 1.2496 (1.2496)	Prec@1 54.688 (54.688)
Test: [20/79]	Time 0.032 (0.070)	Loss 1.1455 (1.3478)	Prec@1 58.594 (52.121)
Test: [40/79]	Time 0.033 (0.052)	Loss 1.2807 (1.3491)	Prec@1 53.125 (51.353)
Test: [60/79]	Time 0.031 (0.045)	Loss 1.4159 (1.3563)	Prec@1 46.875 (51.498)
 * Prec@1 51.480
=> Saving checkpoint for epoch 31, with Prec@1 51.480000.
Epoch: [32][0/79]	Time 0.873 (0.873)	Loss 1.2491 (1.2491)	Prec@1 53.125 (53.125)
Epoch: [32][20/79]	Time 0.048 (0.086)	Loss 1.1144 (1.2655)	Prec@1 56.250 (54.055)
Epoch: [32][40/79]	Time 0.048 (0.067)	Loss 1.2433 (1.2546)	Prec@1 53.906 (54.154)
Epoch: [32][60/79]	Time 0.047 (0.060)	Loss 1.1152 (1.2517)	Prec@1 57.031 (54.316)
epoch training time:  4.6560609340667725
Test: [0/391]	Time 0.845 (0.845)	Loss 1.3288 (1.3288)	Prec@1 54.688 (54.688)
Test: [20/391]	Time 0.033 (0.070)	Loss 1.5221 (1.4867)	Prec@1 39.844 (45.759)
Test: [40/391]	Time 0.033 (0.052)	Loss 1.2852 (1.4819)	Prec@1 54.688 (45.370)
Test: [60/391]	Time 0.030 (0.045)	Loss 1.6669 (1.4834)	Prec@1 34.375 (45.312)
Test: [80/391]	Time 0.033 (0.042)	Loss 1.5185 (1.4854)	Prec@1 45.312 (45.206)
Test: [100/391]	Time 0.032 (0.040)	Loss 1.4639 (1.4823)	Prec@1 42.188 (45.452)
Test: [120/391]	Time 0.033 (0.038)	Loss 1.5919 (1.4800)	Prec@1 39.062 (45.590)
Test: [140/391]	Time 0.033 (0.038)	Loss 1.4260 (1.4789)	Prec@1 46.875 (45.457)
Test: [160/391]	Time 0.031 (0.037)	Loss 1.5235 (1.4756)	Prec@1 46.094 (45.536)
Test: [180/391]	Time 0.031 (0.036)	Loss 1.2792 (1.4766)	Prec@1 58.594 (45.468)
Test: [200/391]	Time 0.032 (0.036)	Loss 1.6693 (1.4784)	Prec@1 44.531 (45.371)
Test: [220/391]	Time 0.032 (0.036)	Loss 1.5798 (1.4752)	Prec@1 42.969 (45.429)
Test: [240/391]	Time 0.032 (0.035)	Loss 1.2770 (1.4768)	Prec@1 60.938 (45.423)
Test: [260/391]	Time 0.033 (0.035)	Loss 1.5029 (1.4761)	Prec@1 42.969 (45.456)
Test: [280/391]	Time 0.033 (0.035)	Loss 1.5418 (1.4798)	Prec@1 42.188 (45.329)
Test: [300/391]	Time 0.031 (0.035)	Loss 1.4524 (1.4817)	Prec@1 48.438 (45.305)
Test: [320/391]	Time 0.032 (0.034)	Loss 1.4916 (1.4834)	Prec@1 46.094 (45.184)
Test: [340/391]	Time 0.033 (0.034)	Loss 1.5021 (1.4820)	Prec@1 43.750 (45.262)
Test: [360/391]	Time 0.033 (0.034)	Loss 1.3649 (1.4823)	Prec@1 55.469 (45.226)
Test: [380/391]	Time 0.032 (0.034)	Loss 1.4526 (1.4811)	Prec@1 42.969 (45.271)
 * Prec@1 45.222
Test: [0/79]	Time 0.859 (0.859)	Loss 1.3515 (1.3515)	Prec@1 51.562 (51.562)
Test: [20/79]	Time 0.031 (0.071)	Loss 1.3608 (1.4610)	Prec@1 47.656 (45.573)
Test: [40/79]	Time 0.032 (0.052)	Loss 1.5060 (1.4504)	Prec@1 44.531 (46.056)
Test: [60/79]	Time 0.031 (0.046)	Loss 1.4254 (1.4516)	Prec@1 43.750 (45.978)
 * Prec@1 45.740
Epoch: [33][0/79]	Time 0.868 (0.868)	Loss 1.2941 (1.2941)	Prec@1 46.875 (46.875)
Epoch: [33][20/79]	Time 0.046 (0.091)	Loss 1.2075 (1.2508)	Prec@1 56.250 (54.018)
Epoch: [33][40/79]	Time 0.045 (0.069)	Loss 1.2100 (1.2322)	Prec@1 54.688 (54.745)
Epoch: [33][60/79]	Time 0.046 (0.062)	Loss 1.2597 (1.2219)	Prec@1 50.000 (55.277)
epoch training time:  4.721230983734131
Test: [0/391]	Time 0.850 (0.850)	Loss 1.1921 (1.1921)	Prec@1 58.594 (58.594)
Test: [20/391]	Time 0.034 (0.071)	Loss 1.3306 (1.2382)	Prec@1 51.562 (54.167)
Test: [40/391]	Time 0.034 (0.052)	Loss 1.2720 (1.2283)	Prec@1 50.000 (54.287)
Test: [60/391]	Time 0.033 (0.046)	Loss 1.1605 (1.2404)	Prec@1 58.594 (53.599)
Test: [80/391]	Time 0.033 (0.042)	Loss 1.3260 (1.2487)	Prec@1 53.906 (53.173)
Test: [100/391]	Time 0.034 (0.040)	Loss 1.1596 (1.2518)	Prec@1 57.812 (53.133)
Test: [120/391]	Time 0.032 (0.039)	Loss 1.2095 (1.2463)	Prec@1 54.688 (53.403)
Test: [140/391]	Time 0.032 (0.038)	Loss 1.3562 (1.2512)	Prec@1 48.438 (53.291)
Test: [160/391]	Time 0.033 (0.037)	Loss 1.1695 (1.2510)	Prec@1 60.156 (53.465)
Test: [180/391]	Time 0.032 (0.037)	Loss 1.2794 (1.2525)	Prec@1 49.219 (53.419)
Test: [200/391]	Time 0.032 (0.036)	Loss 1.3191 (1.2516)	Prec@1 53.125 (53.451)
Test: [220/391]	Time 0.032 (0.036)	Loss 1.2751 (1.2523)	Prec@1 52.344 (53.482)
Test: [240/391]	Time 0.032 (0.036)	Loss 1.1452 (1.2544)	Prec@1 60.156 (53.358)
Test: [260/391]	Time 0.032 (0.035)	Loss 1.1927 (1.2511)	Prec@1 51.562 (53.574)
Test: [280/391]	Time 0.032 (0.035)	Loss 1.3149 (1.2475)	Prec@1 53.906 (53.776)
Test: [300/391]	Time 0.032 (0.035)	Loss 1.2373 (1.2490)	Prec@1 49.219 (53.753)
Test: [320/391]	Time 0.033 (0.035)	Loss 1.2353 (1.2492)	Prec@1 50.000 (53.707)
Test: [340/391]	Time 0.033 (0.035)	Loss 1.2316 (1.2505)	Prec@1 50.781 (53.679)
Test: [360/391]	Time 0.031 (0.034)	Loss 1.1656 (1.2517)	Prec@1 53.906 (53.625)
Test: [380/391]	Time 0.030 (0.034)	Loss 1.3643 (1.2515)	Prec@1 46.875 (53.570)
 * Prec@1 53.616
Test: [0/79]	Time 0.878 (0.878)	Loss 1.2058 (1.2058)	Prec@1 57.812 (57.812)
Test: [20/79]	Time 0.029 (0.071)	Loss 1.1355 (1.2607)	Prec@1 56.250 (53.460)
Test: [40/79]	Time 0.029 (0.051)	Loss 1.2012 (1.2593)	Prec@1 53.906 (53.639)
Test: [60/79]	Time 0.033 (0.045)	Loss 1.3622 (1.2632)	Prec@1 49.219 (53.624)
 * Prec@1 53.560
=> Saving checkpoint for epoch 33, with Prec@1 53.560000.
Epoch: [34][0/79]	Time 0.894 (0.894)	Loss 1.2933 (1.2933)	Prec@1 50.781 (50.781)
Epoch: [34][20/79]	Time 0.045 (0.087)	Loss 1.0746 (1.2003)	Prec@1 60.156 (57.068)
Epoch: [34][40/79]	Time 0.046 (0.067)	Loss 1.1265 (1.1777)	Prec@1 60.156 (58.041)
Epoch: [34][60/79]	Time 0.045 (0.060)	Loss 1.2589 (1.1890)	Prec@1 48.438 (57.364)
epoch training time:  4.674310922622681
Test: [0/391]	Time 0.898 (0.898)	Loss 1.2190 (1.2190)	Prec@1 54.688 (54.688)
Test: [20/391]	Time 0.033 (0.074)	Loss 1.1109 (1.2105)	Prec@1 60.938 (56.585)
Test: [40/391]	Time 0.032 (0.054)	Loss 1.1283 (1.1946)	Prec@1 59.375 (57.012)
Test: [60/391]	Time 0.030 (0.047)	Loss 1.0941 (1.1803)	Prec@1 57.031 (57.070)
Test: [80/391]	Time 0.032 (0.043)	Loss 1.0844 (1.1814)	Prec@1 57.031 (57.099)
Test: [100/391]	Time 0.032 (0.041)	Loss 1.0519 (1.1738)	Prec@1 64.844 (57.062)
Test: [120/391]	Time 0.033 (0.039)	Loss 1.1387 (1.1712)	Prec@1 60.938 (57.438)
Test: [140/391]	Time 0.032 (0.038)	Loss 1.0155 (1.1734)	Prec@1 59.375 (57.353)
Test: [160/391]	Time 0.033 (0.038)	Loss 1.2776 (1.1793)	Prec@1 54.688 (57.182)
Test: [180/391]	Time 0.032 (0.037)	Loss 1.3341 (1.1835)	Prec@1 48.438 (57.044)
Test: [200/391]	Time 0.032 (0.037)	Loss 1.1112 (1.1847)	Prec@1 60.156 (57.074)
Test: [220/391]	Time 0.032 (0.036)	Loss 1.2044 (1.1850)	Prec@1 58.594 (56.992)
Test: [240/391]	Time 0.033 (0.036)	Loss 1.0708 (1.1886)	Prec@1 56.250 (56.872)
Test: [260/391]	Time 0.032 (0.036)	Loss 1.1236 (1.1891)	Prec@1 60.938 (56.795)
Test: [280/391]	Time 0.033 (0.035)	Loss 1.0350 (1.1878)	Prec@1 64.062 (56.878)
Test: [300/391]	Time 0.033 (0.035)	Loss 1.2321 (1.1885)	Prec@1 57.812 (56.839)
Test: [320/391]	Time 0.033 (0.035)	Loss 1.2689 (1.1900)	Prec@1 53.125 (56.844)
Test: [340/391]	Time 0.033 (0.035)	Loss 1.2260 (1.1910)	Prec@1 59.375 (56.768)
Test: [360/391]	Time 0.033 (0.035)	Loss 1.1675 (1.1904)	Prec@1 61.719 (56.795)
Test: [380/391]	Time 0.031 (0.035)	Loss 1.1444 (1.1918)	Prec@1 60.156 (56.746)
 * Prec@1 56.752
Test: [0/79]	Time 0.860 (0.860)	Loss 1.1137 (1.1137)	Prec@1 66.406 (66.406)
Test: [20/79]	Time 0.032 (0.071)	Loss 1.0865 (1.1612)	Prec@1 60.938 (57.701)
Test: [40/79]	Time 0.032 (0.052)	Loss 1.1737 (1.1598)	Prec@1 54.688 (58.136)
Test: [60/79]	Time 0.031 (0.046)	Loss 1.1456 (1.1624)	Prec@1 60.938 (57.684)
 * Prec@1 57.400
=> Saving checkpoint for epoch 34, with Prec@1 57.400000.
Epoch: [35][0/79]	Time 0.900 (0.900)	Loss 1.1942 (1.1942)	Prec@1 58.594 (58.594)
Epoch: [35][20/79]	Time 0.046 (0.087)	Loss 1.2315 (1.1799)	Prec@1 48.438 (57.106)
Epoch: [35][40/79]	Time 0.046 (0.067)	Loss 1.1310 (1.1488)	Prec@1 55.469 (58.651)
Epoch: [35][60/79]	Time 0.046 (0.060)	Loss 1.0447 (1.1480)	Prec@1 60.938 (58.568)
epoch training time:  4.642856597900391
Test: [0/391]	Time 0.895 (0.895)	Loss 1.2364 (1.2364)	Prec@1 58.594 (58.594)
Test: [20/391]	Time 0.032 (0.073)	Loss 1.1184 (1.1304)	Prec@1 57.812 (58.854)
Test: [40/391]	Time 0.032 (0.053)	Loss 1.1631 (1.1497)	Prec@1 52.344 (57.184)
Test: [60/391]	Time 0.032 (0.046)	Loss 1.0729 (1.1518)	Prec@1 61.719 (56.967)
Test: [80/391]	Time 0.032 (0.043)	Loss 0.9923 (1.1495)	Prec@1 63.281 (57.195)
Test: [100/391]	Time 0.032 (0.040)	Loss 1.1648 (1.1477)	Prec@1 54.688 (57.271)
Test: [120/391]	Time 0.032 (0.039)	Loss 1.1766 (1.1440)	Prec@1 57.812 (57.367)
Test: [140/391]	Time 0.032 (0.038)	Loss 1.1422 (1.1415)	Prec@1 59.375 (57.475)
Test: [160/391]	Time 0.032 (0.037)	Loss 1.2777 (1.1430)	Prec@1 51.562 (57.419)
Test: [180/391]	Time 0.032 (0.037)	Loss 1.1791 (1.1431)	Prec@1 57.812 (57.364)
Test: [200/391]	Time 0.031 (0.036)	Loss 1.0620 (1.1399)	Prec@1 57.031 (57.397)
Test: [220/391]	Time 0.032 (0.036)	Loss 1.1454 (1.1426)	Prec@1 60.938 (57.300)
Test: [240/391]	Time 0.032 (0.036)	Loss 1.1473 (1.1447)	Prec@1 62.500 (57.154)
Test: [260/391]	Time 0.033 (0.035)	Loss 1.0621 (1.1427)	Prec@1 55.469 (57.244)
Test: [280/391]	Time 0.032 (0.035)	Loss 1.0259 (1.1447)	Prec@1 58.594 (57.229)
Test: [300/391]	Time 0.031 (0.035)	Loss 1.1762 (1.1448)	Prec@1 53.906 (57.236)
Test: [320/391]	Time 0.032 (0.035)	Loss 1.0165 (1.1438)	Prec@1 57.031 (57.297)
Test: [340/391]	Time 0.032 (0.035)	Loss 1.1094 (1.1467)	Prec@1 56.250 (57.240)
Test: [360/391]	Time 0.032 (0.034)	Loss 1.0737 (1.1474)	Prec@1 63.281 (57.235)
Test: [380/391]	Time 0.032 (0.034)	Loss 1.1667 (1.1480)	Prec@1 57.031 (57.154)
 * Prec@1 57.154
