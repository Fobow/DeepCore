================== Exp 0 ==================
dataset: CIFAR10, model: ResNet18, selection: GraNd, num_ex: 1, epochs: 100, fraction: 0.2, seed: 15162, lr: 0.1, save_path: ./result, resume: , device: cuda, checkpoint_name: CIFAR10_ResNet18_GraNd_exp0_epoch100_2024-03-18 13:35:16.870164_0.2_
Files already downloaded and verified
Files already downloaded and verified
=> Training Epoch #0
| Epoch [  0/ 10] Iter[  1/391]		Loss: 2.4586
| Epoch [  0/ 10] Iter[ 21/391]		Loss: 2.4212
| Epoch [  0/ 10] Iter[ 41/391]		Loss: 2.0589
| Epoch [  0/ 10] Iter[ 61/391]		Loss: 1.8481
| Epoch [  0/ 10] Iter[ 81/391]		Loss: 1.8102
| Epoch [  0/ 10] Iter[101/391]		Loss: 1.7039
| Epoch [  0/ 10] Iter[121/391]		Loss: 1.7229
| Epoch [  0/ 10] Iter[141/391]		Loss: 1.7929
| Epoch [  0/ 10] Iter[161/391]		Loss: 1.7535
| Epoch [  0/ 10] Iter[181/391]		Loss: 1.5735
| Epoch [  0/ 10] Iter[201/391]		Loss: 1.6108
| Epoch [  0/ 10] Iter[221/391]		Loss: 1.5883
| Epoch [  0/ 10] Iter[241/391]		Loss: 1.6545
| Epoch [  0/ 10] Iter[261/391]		Loss: 1.4900
| Epoch [  0/ 10] Iter[281/391]		Loss: 1.4793
| Epoch [  0/ 10] Iter[301/391]		Loss: 1.4261
| Epoch [  0/ 10] Iter[321/391]		Loss: 1.6923
| Epoch [  0/ 10] Iter[341/391]		Loss: 1.3744
| Epoch [  0/ 10] Iter[361/391]		Loss: 1.4540
| Epoch [  0/ 10] Iter[381/391]		Loss: 1.4348
=> Training Epoch #1
| Epoch [  1/ 10] Iter[  1/391]		Loss: 1.4512
| Epoch [  1/ 10] Iter[ 21/391]		Loss: 1.3783
| Epoch [  1/ 10] Iter[ 41/391]		Loss: 1.4319
| Epoch [  1/ 10] Iter[ 61/391]		Loss: 1.2638
| Epoch [  1/ 10] Iter[ 81/391]		Loss: 1.3620
| Epoch [  1/ 10] Iter[101/391]		Loss: 1.3968
| Epoch [  1/ 10] Iter[121/391]		Loss: 1.2080
| Epoch [  1/ 10] Iter[141/391]		Loss: 1.2313
| Epoch [  1/ 10] Iter[161/391]		Loss: 1.2516
| Epoch [  1/ 10] Iter[181/391]		Loss: 1.2789
| Epoch [  1/ 10] Iter[201/391]		Loss: 1.2063
| Epoch [  1/ 10] Iter[221/391]		Loss: 1.1579
| Epoch [  1/ 10] Iter[241/391]		Loss: 1.3607
| Epoch [  1/ 10] Iter[261/391]		Loss: 1.2762
| Epoch [  1/ 10] Iter[281/391]		Loss: 1.3570
| Epoch [  1/ 10] Iter[301/391]		Loss: 1.3903
| Epoch [  1/ 10] Iter[321/391]		Loss: 1.2514
| Epoch [  1/ 10] Iter[341/391]		Loss: 1.1400
| Epoch [  1/ 10] Iter[361/391]		Loss: 1.1408
| Epoch [  1/ 10] Iter[381/391]		Loss: 1.0146
=> Training Epoch #2
| Epoch [  2/ 10] Iter[  1/391]		Loss: 1.0871
| Epoch [  2/ 10] Iter[ 21/391]		Loss: 1.0419
| Epoch [  2/ 10] Iter[ 41/391]		Loss: 0.9451
| Epoch [  2/ 10] Iter[ 61/391]		Loss: 1.0179
| Epoch [  2/ 10] Iter[ 81/391]		Loss: 1.0496
| Epoch [  2/ 10] Iter[101/391]		Loss: 1.0678
| Epoch [  2/ 10] Iter[121/391]		Loss: 1.0730
| Epoch [  2/ 10] Iter[141/391]		Loss: 0.9370
| Epoch [  2/ 10] Iter[161/391]		Loss: 0.9787
| Epoch [  2/ 10] Iter[181/391]		Loss: 1.0043
| Epoch [  2/ 10] Iter[201/391]		Loss: 0.8995
| Epoch [  2/ 10] Iter[221/391]		Loss: 1.0158
| Epoch [  2/ 10] Iter[241/391]		Loss: 0.8200
| Epoch [  2/ 10] Iter[261/391]		Loss: 0.9052
| Epoch [  2/ 10] Iter[281/391]		Loss: 1.0480
| Epoch [  2/ 10] Iter[301/391]		Loss: 0.7986
| Epoch [  2/ 10] Iter[321/391]		Loss: 0.8574
| Epoch [  2/ 10] Iter[341/391]		Loss: 0.7939
| Epoch [  2/ 10] Iter[361/391]		Loss: 1.0019
| Epoch [  2/ 10] Iter[381/391]		Loss: 0.8786
=> Training Epoch #3
| Epoch [  3/ 10] Iter[  1/391]		Loss: 0.9132
| Epoch [  3/ 10] Iter[ 21/391]		Loss: 0.9141
| Epoch [  3/ 10] Iter[ 41/391]		Loss: 0.8553
| Epoch [  3/ 10] Iter[ 61/391]		Loss: 0.8124
| Epoch [  3/ 10] Iter[ 81/391]		Loss: 0.7751
| Epoch [  3/ 10] Iter[101/391]		Loss: 0.7715
| Epoch [  3/ 10] Iter[121/391]		Loss: 0.8374
| Epoch [  3/ 10] Iter[141/391]		Loss: 0.7175
| Epoch [  3/ 10] Iter[161/391]		Loss: 0.8564
| Epoch [  3/ 10] Iter[181/391]		Loss: 0.7044
| Epoch [  3/ 10] Iter[201/391]		Loss: 0.6173
| Epoch [  3/ 10] Iter[221/391]		Loss: 0.6756
| Epoch [  3/ 10] Iter[241/391]		Loss: 0.7613
| Epoch [  3/ 10] Iter[261/391]		Loss: 0.6016
| Epoch [  3/ 10] Iter[281/391]		Loss: 0.7990
| Epoch [  3/ 10] Iter[301/391]		Loss: 0.8429
| Epoch [  3/ 10] Iter[321/391]		Loss: 0.9035
| Epoch [  3/ 10] Iter[341/391]		Loss: 0.7647
| Epoch [  3/ 10] Iter[361/391]		Loss: 0.8120
| Epoch [  3/ 10] Iter[381/391]		Loss: 0.7235
=> Training Epoch #4
| Epoch [  4/ 10] Iter[  1/391]		Loss: 0.5737
| Epoch [  4/ 10] Iter[ 21/391]		Loss: 0.5499
| Epoch [  4/ 10] Iter[ 41/391]		Loss: 0.4870
| Epoch [  4/ 10] Iter[ 61/391]		Loss: 0.5627
| Epoch [  4/ 10] Iter[ 81/391]		Loss: 0.5998
| Epoch [  4/ 10] Iter[101/391]		Loss: 0.6091
| Epoch [  4/ 10] Iter[121/391]		Loss: 0.6465
| Epoch [  4/ 10] Iter[141/391]		Loss: 0.6125
| Epoch [  4/ 10] Iter[161/391]		Loss: 0.6539
| Epoch [  4/ 10] Iter[181/391]		Loss: 0.6886
| Epoch [  4/ 10] Iter[201/391]		Loss: 0.7034
| Epoch [  4/ 10] Iter[221/391]		Loss: 0.5485
| Epoch [  4/ 10] Iter[241/391]		Loss: 0.7345
| Epoch [  4/ 10] Iter[261/391]		Loss: 0.6177
| Epoch [  4/ 10] Iter[281/391]		Loss: 0.5625
| Epoch [  4/ 10] Iter[301/391]		Loss: 0.4404
| Epoch [  4/ 10] Iter[321/391]		Loss: 0.6223
| Epoch [  4/ 10] Iter[341/391]		Loss: 0.5135
| Epoch [  4/ 10] Iter[361/391]		Loss: 0.4602
| Epoch [  4/ 10] Iter[381/391]		Loss: 0.5270
=> Training Epoch #5
| Epoch [  5/ 10] Iter[  1/391]		Loss: 0.4786
| Epoch [  5/ 10] Iter[ 21/391]		Loss: 0.4830
| Epoch [  5/ 10] Iter[ 41/391]		Loss: 0.6521
| Epoch [  5/ 10] Iter[ 61/391]		Loss: 0.5565
| Epoch [  5/ 10] Iter[ 81/391]		Loss: 0.5377
| Epoch [  5/ 10] Iter[101/391]		Loss: 0.3639
| Epoch [  5/ 10] Iter[121/391]		Loss: 0.7160
| Epoch [  5/ 10] Iter[141/391]		Loss: 0.6613
| Epoch [  5/ 10] Iter[161/391]		Loss: 0.5071
| Epoch [  5/ 10] Iter[181/391]		Loss: 0.6005
| Epoch [  5/ 10] Iter[201/391]		Loss: 0.3876
| Epoch [  5/ 10] Iter[221/391]		Loss: 0.5979
| Epoch [  5/ 10] Iter[241/391]		Loss: 0.3928
| Epoch [  5/ 10] Iter[261/391]		Loss: 0.4193
| Epoch [  5/ 10] Iter[281/391]		Loss: 0.6880
| Epoch [  5/ 10] Iter[301/391]		Loss: 0.3983
| Epoch [  5/ 10] Iter[321/391]		Loss: 0.5993
| Epoch [  5/ 10] Iter[341/391]		Loss: 0.7297
| Epoch [  5/ 10] Iter[361/391]		Loss: 0.6277
| Epoch [  5/ 10] Iter[381/391]		Loss: 0.4550
=> Training Epoch #6
| Epoch [  6/ 10] Iter[  1/391]		Loss: 0.4517
| Epoch [  6/ 10] Iter[ 21/391]		Loss: 0.2976
| Epoch [  6/ 10] Iter[ 41/391]		Loss: 0.3730
| Epoch [  6/ 10] Iter[ 61/391]		Loss: 0.3193
| Epoch [  6/ 10] Iter[ 81/391]		Loss: 0.4091
| Epoch [  6/ 10] Iter[101/391]		Loss: 0.3975
| Epoch [  6/ 10] Iter[121/391]		Loss: 0.4286
| Epoch [  6/ 10] Iter[141/391]		Loss: 0.4625
| Epoch [  6/ 10] Iter[161/391]		Loss: 0.5414
| Epoch [  6/ 10] Iter[181/391]		Loss: 0.4961
| Epoch [  6/ 10] Iter[201/391]		Loss: 0.5505
| Epoch [  6/ 10] Iter[221/391]		Loss: 0.4348
| Epoch [  6/ 10] Iter[241/391]		Loss: 0.4926
| Epoch [  6/ 10] Iter[261/391]		Loss: 0.4974
| Epoch [  6/ 10] Iter[281/391]		Loss: 0.4185
| Epoch [  6/ 10] Iter[301/391]		Loss: 0.4926
| Epoch [  6/ 10] Iter[321/391]		Loss: 0.5129
| Epoch [  6/ 10] Iter[341/391]		Loss: 0.3378
| Epoch [  6/ 10] Iter[361/391]		Loss: 0.4067
| Epoch [  6/ 10] Iter[381/391]		Loss: 0.3244
=> Training Epoch #7
| Epoch [  7/ 10] Iter[  1/391]		Loss: 0.4724
| Epoch [  7/ 10] Iter[ 21/391]		Loss: 0.3613
| Epoch [  7/ 10] Iter[ 41/391]		Loss: 0.2394
| Epoch [  7/ 10] Iter[ 61/391]		Loss: 0.3664
| Epoch [  7/ 10] Iter[ 81/391]		Loss: 0.3879
| Epoch [  7/ 10] Iter[101/391]		Loss: 0.3597
| Epoch [  7/ 10] Iter[121/391]		Loss: 0.3168
| Epoch [  7/ 10] Iter[141/391]		Loss: 0.4015
| Epoch [  7/ 10] Iter[161/391]		Loss: 0.3028
| Epoch [  7/ 10] Iter[181/391]		Loss: 0.5492
| Epoch [  7/ 10] Iter[201/391]		Loss: 0.4101
| Epoch [  7/ 10] Iter[221/391]		Loss: 0.2270
| Epoch [  7/ 10] Iter[241/391]		Loss: 0.3495
| Epoch [  7/ 10] Iter[261/391]		Loss: 0.3910
| Epoch [  7/ 10] Iter[281/391]		Loss: 0.4787
| Epoch [  7/ 10] Iter[301/391]		Loss: 0.4480
| Epoch [  7/ 10] Iter[321/391]		Loss: 0.4534
| Epoch [  7/ 10] Iter[341/391]		Loss: 0.5291
| Epoch [  7/ 10] Iter[361/391]		Loss: 0.3939
| Epoch [  7/ 10] Iter[381/391]		Loss: 0.3393
=> Training Epoch #8
| Epoch [  8/ 10] Iter[  1/391]		Loss: 0.3911
| Epoch [  8/ 10] Iter[ 21/391]		Loss: 0.2723
| Epoch [  8/ 10] Iter[ 41/391]		Loss: 0.1964
| Epoch [  8/ 10] Iter[ 61/391]		Loss: 0.2128
| Epoch [  8/ 10] Iter[ 81/391]		Loss: 0.3093
| Epoch [  8/ 10] Iter[101/391]		Loss: 0.3438
| Epoch [  8/ 10] Iter[121/391]		Loss: 0.3922
| Epoch [  8/ 10] Iter[141/391]		Loss: 0.3155
| Epoch [  8/ 10] Iter[161/391]		Loss: 0.3170
| Epoch [  8/ 10] Iter[181/391]		Loss: 0.4787
| Epoch [  8/ 10] Iter[201/391]		Loss: 0.3328
| Epoch [  8/ 10] Iter[221/391]		Loss: 0.3563
| Epoch [  8/ 10] Iter[241/391]		Loss: 0.3813
| Epoch [  8/ 10] Iter[261/391]		Loss: 0.3203
| Epoch [  8/ 10] Iter[281/391]		Loss: 0.3379
| Epoch [  8/ 10] Iter[301/391]		Loss: 0.4440
| Epoch [  8/ 10] Iter[321/391]		Loss: 0.3283
| Epoch [  8/ 10] Iter[341/391]		Loss: 0.3021
| Epoch [  8/ 10] Iter[361/391]		Loss: 0.4378
| Epoch [  8/ 10] Iter[381/391]		Loss: 0.3516
=> Training Epoch #9
| Epoch [  9/ 10] Iter[  1/391]		Loss: 0.2664
| Epoch [  9/ 10] Iter[ 21/391]		Loss: 0.3155
| Epoch [  9/ 10] Iter[ 41/391]		Loss: 0.3579
| Epoch [  9/ 10] Iter[ 61/391]		Loss: 0.1644
| Epoch [  9/ 10] Iter[ 81/391]		Loss: 0.3028
| Epoch [  9/ 10] Iter[101/391]		Loss: 0.3543
| Epoch [  9/ 10] Iter[121/391]		Loss: 0.2925
| Epoch [  9/ 10] Iter[141/391]		Loss: 0.2150
| Epoch [  9/ 10] Iter[161/391]		Loss: 0.3865
| Epoch [  9/ 10] Iter[181/391]		Loss: 0.3404
| Epoch [  9/ 10] Iter[201/391]		Loss: 0.3053
| Epoch [  9/ 10] Iter[221/391]		Loss: 0.2964
| Epoch [  9/ 10] Iter[241/391]		Loss: 0.2348
| Epoch [  9/ 10] Iter[261/391]		Loss: 0.3009
| Epoch [  9/ 10] Iter[281/391]		Loss: 0.3892
| Epoch [  9/ 10] Iter[301/391]		Loss: 0.3770
| Epoch [  9/ 10] Iter[321/391]		Loss: 0.2544
| Epoch [  9/ 10] Iter[341/391]		Loss: 0.3687
| Epoch [  9/ 10] Iter[361/391]		Loss: 0.3483
| Epoch [  9/ 10] Iter[381/391]		Loss: 0.3713
=> Training Epoch #0
| Epoch [  0/ 10] Iter[  1/391]		Loss: 2.4241
| Epoch [  0/ 10] Iter[ 21/391]		Loss: 2.2645
| Epoch [  0/ 10] Iter[ 41/391]		Loss: 2.2413
| Epoch [  0/ 10] Iter[ 61/391]		Loss: 2.0524
| Epoch [  0/ 10] Iter[ 81/391]		Loss: 2.0248
| Epoch [  0/ 10] Iter[101/391]		Loss: 1.9653
| Epoch [  0/ 10] Iter[121/391]		Loss: 1.9100
| Epoch [  0/ 10] Iter[141/391]		Loss: 1.7752
| Epoch [  0/ 10] Iter[161/391]		Loss: 1.7217
| Epoch [  0/ 10] Iter[181/391]		Loss: 1.6977
| Epoch [  0/ 10] Iter[201/391]		Loss: 1.6565
| Epoch [  0/ 10] Iter[221/391]		Loss: 1.4164
| Epoch [  0/ 10] Iter[241/391]		Loss: 1.5674
| Epoch [  0/ 10] Iter[261/391]		Loss: 1.4623
| Epoch [  0/ 10] Iter[281/391]		Loss: 1.5344
| Epoch [  0/ 10] Iter[301/391]		Loss: 1.4380
| Epoch [  0/ 10] Iter[321/391]		Loss: 1.4505
| Epoch [  0/ 10] Iter[341/391]		Loss: 1.5620
| Epoch [  0/ 10] Iter[361/391]		Loss: 1.6289
| Epoch [  0/ 10] Iter[381/391]		Loss: 1.4652
=> Training Epoch #1
| Epoch [  1/ 10] Iter[  1/391]		Loss: 1.2860
| Epoch [  1/ 10] Iter[ 21/391]		Loss: 1.4073
| Epoch [  1/ 10] Iter[ 41/391]		Loss: 1.3821
| Epoch [  1/ 10] Iter[ 61/391]		Loss: 1.4336
| Epoch [  1/ 10] Iter[ 81/391]		Loss: 1.2853
| Epoch [  1/ 10] Iter[101/391]		Loss: 1.2991
| Epoch [  1/ 10] Iter[121/391]		Loss: 1.3728
| Epoch [  1/ 10] Iter[141/391]		Loss: 1.0706
| Epoch [  1/ 10] Iter[161/391]		Loss: 1.1466
| Epoch [  1/ 10] Iter[181/391]		Loss: 1.2592
| Epoch [  1/ 10] Iter[201/391]		Loss: 1.1953
| Epoch [  1/ 10] Iter[221/391]		Loss: 1.3254
| Epoch [  1/ 10] Iter[241/391]		Loss: 1.2254
| Epoch [  1/ 10] Iter[261/391]		Loss: 1.1279
| Epoch [  1/ 10] Iter[281/391]		Loss: 1.0813
| Epoch [  1/ 10] Iter[301/391]		Loss: 1.0250
| Epoch [  1/ 10] Iter[321/391]		Loss: 1.1243
| Epoch [  1/ 10] Iter[341/391]		Loss: 0.8959
| Epoch [  1/ 10] Iter[361/391]		Loss: 1.0204
| Epoch [  1/ 10] Iter[381/391]		Loss: 1.2309
=> Training Epoch #2
| Epoch [  2/ 10] Iter[  1/391]		Loss: 0.8997
| Epoch [  2/ 10] Iter[ 21/391]		Loss: 0.9264
| Epoch [  2/ 10] Iter[ 41/391]		Loss: 0.9632
| Epoch [  2/ 10] Iter[ 61/391]		Loss: 0.9441
| Epoch [  2/ 10] Iter[ 81/391]		Loss: 1.0080
| Epoch [  2/ 10] Iter[101/391]		Loss: 0.9966
| Epoch [  2/ 10] Iter[121/391]		Loss: 0.7978
| Epoch [  2/ 10] Iter[141/391]		Loss: 0.8484
| Epoch [  2/ 10] Iter[161/391]		Loss: 1.0828
| Epoch [  2/ 10] Iter[181/391]		Loss: 1.1179
| Epoch [  2/ 10] Iter[201/391]		Loss: 0.9008
| Epoch [  2/ 10] Iter[221/391]		Loss: 0.8882
| Epoch [  2/ 10] Iter[241/391]		Loss: 0.9652
| Epoch [  2/ 10] Iter[261/391]		Loss: 0.8556
| Epoch [  2/ 10] Iter[281/391]		Loss: 0.9786
| Epoch [  2/ 10] Iter[301/391]		Loss: 0.8378
| Epoch [  2/ 10] Iter[321/391]		Loss: 0.9381
| Epoch [  2/ 10] Iter[341/391]		Loss: 0.8025
| Epoch [  2/ 10] Iter[361/391]		Loss: 0.7995
| Epoch [  2/ 10] Iter[381/391]		Loss: 0.8310
=> Training Epoch #3
| Epoch [  3/ 10] Iter[  1/391]		Loss: 0.6933
| Epoch [  3/ 10] Iter[ 21/391]		Loss: 0.7225
| Epoch [  3/ 10] Iter[ 41/391]		Loss: 0.8601
| Epoch [  3/ 10] Iter[ 61/391]		Loss: 0.8048
| Epoch [  3/ 10] Iter[ 81/391]		Loss: 0.8056
| Epoch [  3/ 10] Iter[101/391]		Loss: 0.7067
| Epoch [  3/ 10] Iter[121/391]		Loss: 0.7620
| Epoch [  3/ 10] Iter[141/391]		Loss: 0.9432
| Epoch [  3/ 10] Iter[161/391]		Loss: 0.8914
| Epoch [  3/ 10] Iter[181/391]		Loss: 0.7183
| Epoch [  3/ 10] Iter[201/391]		Loss: 0.6994
| Epoch [  3/ 10] Iter[221/391]		Loss: 0.8352
| Epoch [  3/ 10] Iter[241/391]		Loss: 0.7611
| Epoch [  3/ 10] Iter[261/391]		Loss: 0.8403
| Epoch [  3/ 10] Iter[281/391]		Loss: 0.9031
| Epoch [  3/ 10] Iter[301/391]		Loss: 0.8886
| Epoch [  3/ 10] Iter[321/391]		Loss: 0.7886
| Epoch [  3/ 10] Iter[341/391]		Loss: 0.6028
| Epoch [  3/ 10] Iter[361/391]		Loss: 0.7315
| Epoch [  3/ 10] Iter[381/391]		Loss: 0.6628
=> Training Epoch #4
| Epoch [  4/ 10] Iter[  1/391]		Loss: 0.5912
| Epoch [  4/ 10] Iter[ 21/391]		Loss: 0.6152
| Epoch [  4/ 10] Iter[ 41/391]		Loss: 0.6581
| Epoch [  4/ 10] Iter[ 61/391]		Loss: 0.5896
| Epoch [  4/ 10] Iter[ 81/391]		Loss: 0.6555
| Epoch [  4/ 10] Iter[101/391]		Loss: 0.6556
| Epoch [  4/ 10] Iter[121/391]		Loss: 0.5346
| Epoch [  4/ 10] Iter[141/391]		Loss: 0.6085
| Epoch [  4/ 10] Iter[161/391]		Loss: 0.4802
| Epoch [  4/ 10] Iter[181/391]		Loss: 0.6003
| Epoch [  4/ 10] Iter[201/391]		Loss: 0.5238
| Epoch [  4/ 10] Iter[221/391]		Loss: 0.7331
| Epoch [  4/ 10] Iter[241/391]		Loss: 0.5134
| Epoch [  4/ 10] Iter[261/391]		Loss: 0.7253
| Epoch [  4/ 10] Iter[281/391]		Loss: 0.5451
| Epoch [  4/ 10] Iter[301/391]		Loss: 0.6776
| Epoch [  4/ 10] Iter[321/391]		Loss: 0.6912
| Epoch [  4/ 10] Iter[341/391]		Loss: 0.6159
| Epoch [  4/ 10] Iter[361/391]		Loss: 0.6645
| Epoch [  4/ 10] Iter[381/391]		Loss: 0.5649
=> Training Epoch #5
| Epoch [  5/ 10] Iter[  1/391]		Loss: 0.4125
| Epoch [  5/ 10] Iter[ 21/391]		Loss: 0.4842
| Epoch [  5/ 10] Iter[ 41/391]		Loss: 0.4462
| Epoch [  5/ 10] Iter[ 61/391]		Loss: 0.5109
| Epoch [  5/ 10] Iter[ 81/391]		Loss: 0.5585
| Epoch [  5/ 10] Iter[101/391]		Loss: 0.4085
| Epoch [  5/ 10] Iter[121/391]		Loss: 0.6501
| Epoch [  5/ 10] Iter[141/391]		Loss: 0.3984
| Epoch [  5/ 10] Iter[161/391]		Loss: 0.4113
| Epoch [  5/ 10] Iter[181/391]		Loss: 0.5475
| Epoch [  5/ 10] Iter[201/391]		Loss: 0.4959
| Epoch [  5/ 10] Iter[221/391]		Loss: 0.3890
| Epoch [  5/ 10] Iter[241/391]		Loss: 0.7299
| Epoch [  5/ 10] Iter[261/391]		Loss: 0.4990
| Epoch [  5/ 10] Iter[281/391]		Loss: 0.5667
| Epoch [  5/ 10] Iter[301/391]		Loss: 0.5892
| Epoch [  5/ 10] Iter[321/391]		Loss: 0.4005
| Epoch [  5/ 10] Iter[341/391]		Loss: 0.5947
| Epoch [  5/ 10] Iter[361/391]		Loss: 0.4559
| Epoch [  5/ 10] Iter[381/391]		Loss: 0.5245
=> Training Epoch #6
| Epoch [  6/ 10] Iter[  1/391]		Loss: 0.3808
| Epoch [  6/ 10] Iter[ 21/391]		Loss: 0.2881
| Epoch [  6/ 10] Iter[ 41/391]		Loss: 0.4716
| Epoch [  6/ 10] Iter[ 61/391]		Loss: 0.3631
| Epoch [  6/ 10] Iter[ 81/391]		Loss: 0.4007
| Epoch [  6/ 10] Iter[101/391]		Loss: 0.4065
| Epoch [  6/ 10] Iter[121/391]		Loss: 0.4223
| Epoch [  6/ 10] Iter[141/391]		Loss: 0.3737
| Epoch [  6/ 10] Iter[161/391]		Loss: 0.4599
| Epoch [  6/ 10] Iter[181/391]		Loss: 0.4791
| Epoch [  6/ 10] Iter[201/391]		Loss: 0.3775
| Epoch [  6/ 10] Iter[221/391]		Loss: 0.3946
| Epoch [  6/ 10] Iter[241/391]		Loss: 0.3906
| Epoch [  6/ 10] Iter[261/391]		Loss: 0.4464
| Epoch [  6/ 10] Iter[281/391]		Loss: 0.3835
| Epoch [  6/ 10] Iter[301/391]		Loss: 0.5838
| Epoch [  6/ 10] Iter[321/391]		Loss: 0.5216
| Epoch [  6/ 10] Iter[341/391]		Loss: 0.3611
| Epoch [  6/ 10] Iter[361/391]		Loss: 0.3779
| Epoch [  6/ 10] Iter[381/391]		Loss: 0.6287
=> Training Epoch #7
| Epoch [  7/ 10] Iter[  1/391]		Loss: 0.3328
| Epoch [  7/ 10] Iter[ 21/391]		Loss: 0.3247
| Epoch [  7/ 10] Iter[ 41/391]		Loss: 0.2569
| Epoch [  7/ 10] Iter[ 61/391]		Loss: 0.3229
| Epoch [  7/ 10] Iter[ 81/391]		Loss: 0.2668
| Epoch [  7/ 10] Iter[101/391]		Loss: 0.3735
| Epoch [  7/ 10] Iter[121/391]		Loss: 0.2933
| Epoch [  7/ 10] Iter[141/391]		Loss: 0.2969
| Epoch [  7/ 10] Iter[161/391]		Loss: 0.3847
| Epoch [  7/ 10] Iter[181/391]		Loss: 0.5976
| Epoch [  7/ 10] Iter[201/391]		Loss: 0.3764
| Epoch [  7/ 10] Iter[221/391]		Loss: 0.4656
| Epoch [  7/ 10] Iter[241/391]		Loss: 0.3996
| Epoch [  7/ 10] Iter[261/391]		Loss: 0.3822
| Epoch [  7/ 10] Iter[281/391]		Loss: 0.4517
| Epoch [  7/ 10] Iter[301/391]		Loss: 0.4023
| Epoch [  7/ 10] Iter[321/391]		Loss: 0.3087
| Epoch [  7/ 10] Iter[341/391]		Loss: 0.4455
| Epoch [  7/ 10] Iter[361/391]		Loss: 0.4768
| Epoch [  7/ 10] Iter[381/391]		Loss: 0.5038
=> Training Epoch #8
| Epoch [  8/ 10] Iter[  1/391]		Loss: 0.2984
| Epoch [  8/ 10] Iter[ 21/391]		Loss: 0.2323
| Epoch [  8/ 10] Iter[ 41/391]		Loss: 0.2644
| Epoch [  8/ 10] Iter[ 61/391]		Loss: 0.2206
| Epoch [  8/ 10] Iter[ 81/391]		Loss: 0.4130
| Epoch [  8/ 10] Iter[101/391]		Loss: 0.2200
| Epoch [  8/ 10] Iter[121/391]		Loss: 0.3228
| Epoch [  8/ 10] Iter[141/391]		Loss: 0.3699
| Epoch [  8/ 10] Iter[161/391]		Loss: 0.4593
| Epoch [  8/ 10] Iter[181/391]		Loss: 0.3144
| Epoch [  8/ 10] Iter[201/391]		Loss: 0.3116
| Epoch [  8/ 10] Iter[221/391]		Loss: 0.3874
| Epoch [  8/ 10] Iter[241/391]		Loss: 0.2556
| Epoch [  8/ 10] Iter[261/391]		Loss: 0.2878
| Epoch [  8/ 10] Iter[281/391]		Loss: 0.3057
| Epoch [  8/ 10] Iter[301/391]		Loss: 0.4099
| Epoch [  8/ 10] Iter[321/391]		Loss: 0.4340
| Epoch [  8/ 10] Iter[341/391]		Loss: 0.4586
| Epoch [  8/ 10] Iter[361/391]		Loss: 0.5136
| Epoch [  8/ 10] Iter[381/391]		Loss: 0.3474
=> Training Epoch #9
| Epoch [  9/ 10] Iter[  1/391]		Loss: 0.2922
| Epoch [  9/ 10] Iter[ 21/391]		Loss: 0.2241
| Epoch [  9/ 10] Iter[ 41/391]		Loss: 0.2189
| Epoch [  9/ 10] Iter[ 61/391]		Loss: 0.2566
| Epoch [  9/ 10] Iter[ 81/391]		Loss: 0.3479
| Epoch [  9/ 10] Iter[101/391]		Loss: 0.3425
| Epoch [  9/ 10] Iter[121/391]		Loss: 0.1979
| Epoch [  9/ 10] Iter[141/391]		Loss: 0.2803
| Epoch [  9/ 10] Iter[161/391]		Loss: 0.2481
| Epoch [  9/ 10] Iter[181/391]		Loss: 0.2516
| Epoch [  9/ 10] Iter[201/391]		Loss: 0.4207
| Epoch [  9/ 10] Iter[221/391]		Loss: 0.2766
| Epoch [  9/ 10] Iter[241/391]		Loss: 0.2969
| Epoch [  9/ 10] Iter[261/391]		Loss: 0.4149
| Epoch [  9/ 10] Iter[281/391]		Loss: 0.3902
| Epoch [  9/ 10] Iter[301/391]		Loss: 0.4028
| Epoch [  9/ 10] Iter[321/391]		Loss: 0.4072
| Epoch [  9/ 10] Iter[341/391]		Loss: 0.4181
| Epoch [  9/ 10] Iter[361/391]		Loss: 0.4630
| Epoch [  9/ 10] Iter[381/391]		Loss: 0.3246
=> Training Epoch #0
| Epoch [  0/ 10] Iter[  1/391]		Loss: 2.3961
| Epoch [  0/ 10] Iter[ 21/391]		Loss: 3.7296
| Epoch [  0/ 10] Iter[ 41/391]		Loss: 2.3077
| Epoch [  0/ 10] Iter[ 61/391]		Loss: 2.2845
| Epoch [  0/ 10] Iter[ 81/391]		Loss: 2.2446
| Epoch [  0/ 10] Iter[101/391]		Loss: 2.1989
| Epoch [  0/ 10] Iter[121/391]		Loss: 2.0121
| Epoch [  0/ 10] Iter[141/391]		Loss: 2.0517
| Epoch [  0/ 10] Iter[161/391]		Loss: 1.8810
| Epoch [  0/ 10] Iter[181/391]		Loss: 1.7762
| Epoch [  0/ 10] Iter[201/391]		Loss: 1.7229
| Epoch [  0/ 10] Iter[221/391]		Loss: 1.8324
| Epoch [  0/ 10] Iter[241/391]		Loss: 1.6943
| Epoch [  0/ 10] Iter[261/391]		Loss: 1.7585
| Epoch [  0/ 10] Iter[281/391]		Loss: 1.6430
| Epoch [  0/ 10] Iter[301/391]		Loss: 1.5384
| Epoch [  0/ 10] Iter[321/391]		Loss: 1.5166
| Epoch [  0/ 10] Iter[341/391]		Loss: 1.6002
| Epoch [  0/ 10] Iter[361/391]		Loss: 1.6695
| Epoch [  0/ 10] Iter[381/391]		Loss: 1.4549
=> Training Epoch #1
| Epoch [  1/ 10] Iter[  1/391]		Loss: 1.4365
| Epoch [  1/ 10] Iter[ 21/391]		Loss: 1.4685
| Epoch [  1/ 10] Iter[ 41/391]		Loss: 1.4526
| Epoch [  1/ 10] Iter[ 61/391]		Loss: 1.3813
| Epoch [  1/ 10] Iter[ 81/391]		Loss: 1.3928
| Epoch [  1/ 10] Iter[101/391]		Loss: 1.4401
| Epoch [  1/ 10] Iter[121/391]		Loss: 1.3525
| Epoch [  1/ 10] Iter[141/391]		Loss: 1.3486
| Epoch [  1/ 10] Iter[161/391]		Loss: 1.2125
| Epoch [  1/ 10] Iter[181/391]		Loss: 1.3983
| Epoch [  1/ 10] Iter[201/391]		Loss: 1.4652
| Epoch [  1/ 10] Iter[221/391]		Loss: 1.3800
| Epoch [  1/ 10] Iter[241/391]		Loss: 1.2113
| Epoch [  1/ 10] Iter[261/391]		Loss: 1.2290
| Epoch [  1/ 10] Iter[281/391]		Loss: 1.2477
| Epoch [  1/ 10] Iter[301/391]		Loss: 1.2445
| Epoch [  1/ 10] Iter[321/391]		Loss: 1.0613
| Epoch [  1/ 10] Iter[341/391]		Loss: 1.0216
| Epoch [  1/ 10] Iter[361/391]		Loss: 1.1738
| Epoch [  1/ 10] Iter[381/391]		Loss: 1.3874
=> Training Epoch #2
| Epoch [  2/ 10] Iter[  1/391]		Loss: 1.2766
| Epoch [  2/ 10] Iter[ 21/391]		Loss: 1.0100
| Epoch [  2/ 10] Iter[ 41/391]		Loss: 1.2193
| Epoch [  2/ 10] Iter[ 61/391]		Loss: 1.1942
| Epoch [  2/ 10] Iter[ 81/391]		Loss: 1.1169
| Epoch [  2/ 10] Iter[101/391]		Loss: 1.1082
| Epoch [  2/ 10] Iter[121/391]		Loss: 1.1065
| Epoch [  2/ 10] Iter[141/391]		Loss: 0.9794
| Epoch [  2/ 10] Iter[161/391]		Loss: 1.0515
| Epoch [  2/ 10] Iter[181/391]		Loss: 1.2109
| Epoch [  2/ 10] Iter[201/391]		Loss: 0.9874
| Epoch [  2/ 10] Iter[221/391]		Loss: 1.0062
| Epoch [  2/ 10] Iter[241/391]		Loss: 1.1168
| Epoch [  2/ 10] Iter[261/391]		Loss: 1.0683
| Epoch [  2/ 10] Iter[281/391]		Loss: 1.1143
| Epoch [  2/ 10] Iter[301/391]		Loss: 0.8316
| Epoch [  2/ 10] Iter[321/391]		Loss: 0.9470
| Epoch [  2/ 10] Iter[341/391]		Loss: 1.2190
| Epoch [  2/ 10] Iter[361/391]		Loss: 1.0668
| Epoch [  2/ 10] Iter[381/391]		Loss: 1.0867
=> Training Epoch #3
| Epoch [  3/ 10] Iter[  1/391]		Loss: 0.9451
| Epoch [  3/ 10] Iter[ 21/391]		Loss: 0.7491
| Epoch [  3/ 10] Iter[ 41/391]		Loss: 0.7728
| Epoch [  3/ 10] Iter[ 61/391]		Loss: 0.9801
| Epoch [  3/ 10] Iter[ 81/391]		Loss: 0.9536
| Epoch [  3/ 10] Iter[101/391]		Loss: 0.8216
| Epoch [  3/ 10] Iter[121/391]		Loss: 0.9324
| Epoch [  3/ 10] Iter[141/391]		Loss: 0.6828
| Epoch [  3/ 10] Iter[161/391]		Loss: 0.8912
| Epoch [  3/ 10] Iter[181/391]		Loss: 0.9538
| Epoch [  3/ 10] Iter[201/391]		Loss: 0.9219
| Epoch [  3/ 10] Iter[221/391]		Loss: 1.0521
| Epoch [  3/ 10] Iter[241/391]		Loss: 0.9112
| Epoch [  3/ 10] Iter[261/391]		Loss: 0.7847
| Epoch [  3/ 10] Iter[281/391]		Loss: 1.0108
| Epoch [  3/ 10] Iter[301/391]		Loss: 0.7602
| Epoch [  3/ 10] Iter[321/391]		Loss: 0.9675
| Epoch [  3/ 10] Iter[341/391]		Loss: 0.7980
| Epoch [  3/ 10] Iter[361/391]		Loss: 0.8516
| Epoch [  3/ 10] Iter[381/391]		Loss: 0.8442
=> Training Epoch #4
| Epoch [  4/ 10] Iter[  1/391]		Loss: 0.7273
| Epoch [  4/ 10] Iter[ 21/391]		Loss: 0.7918
| Epoch [  4/ 10] Iter[ 41/391]		Loss: 0.7767
| Epoch [  4/ 10] Iter[ 61/391]		Loss: 0.8203
| Epoch [  4/ 10] Iter[ 81/391]		Loss: 0.6663
| Epoch [  4/ 10] Iter[101/391]		Loss: 0.7431
| Epoch [  4/ 10] Iter[121/391]		Loss: 0.5788
| Epoch [  4/ 10] Iter[141/391]		Loss: 0.6297
| Epoch [  4/ 10] Iter[161/391]		Loss: 0.8042
| Epoch [  4/ 10] Iter[181/391]		Loss: 0.7543
| Epoch [  4/ 10] Iter[201/391]		Loss: 0.7973
| Epoch [  4/ 10] Iter[221/391]		Loss: 0.6256
| Epoch [  4/ 10] Iter[241/391]		Loss: 0.7300
| Epoch [  4/ 10] Iter[261/391]		Loss: 0.7061
| Epoch [  4/ 10] Iter[281/391]		Loss: 0.8570
| Epoch [  4/ 10] Iter[301/391]		Loss: 0.6832
| Epoch [  4/ 10] Iter[321/391]		Loss: 0.6416
| Epoch [  4/ 10] Iter[341/391]		Loss: 0.6072
| Epoch [  4/ 10] Iter[361/391]		Loss: 0.8347
| Epoch [  4/ 10] Iter[381/391]		Loss: 0.6634
=> Training Epoch #5
| Epoch [  5/ 10] Iter[  1/391]		Loss: 0.5822
| Epoch [  5/ 10] Iter[ 21/391]		Loss: 0.5826
| Epoch [  5/ 10] Iter[ 41/391]		Loss: 0.6648
| Epoch [  5/ 10] Iter[ 61/391]		Loss: 0.5538
| Epoch [  5/ 10] Iter[ 81/391]		Loss: 0.6920
| Epoch [  5/ 10] Iter[101/391]		Loss: 0.6472
| Epoch [  5/ 10] Iter[121/391]		Loss: 0.6727
| Epoch [  5/ 10] Iter[141/391]		Loss: 0.4808
| Epoch [  5/ 10] Iter[161/391]		Loss: 0.5174
| Epoch [  5/ 10] Iter[181/391]		Loss: 0.5327
| Epoch [  5/ 10] Iter[201/391]		Loss: 0.7027
| Epoch [  5/ 10] Iter[221/391]		Loss: 0.7151
| Epoch [  5/ 10] Iter[241/391]		Loss: 0.4490
| Epoch [  5/ 10] Iter[261/391]		Loss: 0.5627
| Epoch [  5/ 10] Iter[281/391]		Loss: 0.4751
| Epoch [  5/ 10] Iter[301/391]		Loss: 0.5863
| Epoch [  5/ 10] Iter[321/391]		Loss: 0.6863
| Epoch [  5/ 10] Iter[341/391]		Loss: 0.6471
| Epoch [  5/ 10] Iter[361/391]		Loss: 0.5358
| Epoch [  5/ 10] Iter[381/391]		Loss: 0.7011
=> Training Epoch #6
| Epoch [  6/ 10] Iter[  1/391]		Loss: 0.4564
| Epoch [  6/ 10] Iter[ 21/391]		Loss: 0.4670
| Epoch [  6/ 10] Iter[ 41/391]		Loss: 0.5930
| Epoch [  6/ 10] Iter[ 61/391]		Loss: 0.4551
| Epoch [  6/ 10] Iter[ 81/391]		Loss: 0.5026
| Epoch [  6/ 10] Iter[101/391]		Loss: 0.4301
| Epoch [  6/ 10] Iter[121/391]		Loss: 0.3688
| Epoch [  6/ 10] Iter[141/391]		Loss: 0.6236
| Epoch [  6/ 10] Iter[161/391]		Loss: 0.4552
| Epoch [  6/ 10] Iter[181/391]		Loss: 0.6395
| Epoch [  6/ 10] Iter[201/391]		Loss: 0.5382
| Epoch [  6/ 10] Iter[221/391]		Loss: 0.5356
| Epoch [  6/ 10] Iter[241/391]		Loss: 0.5371
| Epoch [  6/ 10] Iter[261/391]		Loss: 0.5456
| Epoch [  6/ 10] Iter[281/391]		Loss: 0.5455
| Epoch [  6/ 10] Iter[301/391]		Loss: 0.5372
| Epoch [  6/ 10] Iter[321/391]		Loss: 0.4699
| Epoch [  6/ 10] Iter[341/391]		Loss: 0.5106
| Epoch [  6/ 10] Iter[361/391]		Loss: 0.4329
| Epoch [  6/ 10] Iter[381/391]		Loss: 0.5392
=> Training Epoch #7
| Epoch [  7/ 10] Iter[  1/391]		Loss: 0.3899
| Epoch [  7/ 10] Iter[ 21/391]		Loss: 0.3406
| Epoch [  7/ 10] Iter[ 41/391]		Loss: 0.3758
| Epoch [  7/ 10] Iter[ 61/391]		Loss: 0.4682
| Epoch [  7/ 10] Iter[ 81/391]		Loss: 0.2724
| Epoch [  7/ 10] Iter[101/391]		Loss: 0.4090
| Epoch [  7/ 10] Iter[121/391]		Loss: 0.4669
| Epoch [  7/ 10] Iter[141/391]		Loss: 0.4626
| Epoch [  7/ 10] Iter[161/391]		Loss: 0.5151
| Epoch [  7/ 10] Iter[181/391]		Loss: 0.5205
| Epoch [  7/ 10] Iter[201/391]		Loss: 0.4185
| Epoch [  7/ 10] Iter[221/391]		Loss: 0.6029
| Epoch [  7/ 10] Iter[241/391]		Loss: 0.4799
| Epoch [  7/ 10] Iter[261/391]		Loss: 0.4276
| Epoch [  7/ 10] Iter[281/391]		Loss: 0.4450
| Epoch [  7/ 10] Iter[301/391]		Loss: 0.5624
| Epoch [  7/ 10] Iter[321/391]		Loss: 0.3977
| Epoch [  7/ 10] Iter[341/391]		Loss: 0.3384
| Epoch [  7/ 10] Iter[361/391]		Loss: 0.5186
| Epoch [  7/ 10] Iter[381/391]		Loss: 0.3420
=> Training Epoch #8
| Epoch [  8/ 10] Iter[  1/391]		Loss: 0.3735
| Epoch [  8/ 10] Iter[ 21/391]		Loss: 0.3023
| Epoch [  8/ 10] Iter[ 41/391]		Loss: 0.2824
| Epoch [  8/ 10] Iter[ 61/391]		Loss: 0.2866
| Epoch [  8/ 10] Iter[ 81/391]		Loss: 0.4129
| Epoch [  8/ 10] Iter[101/391]		Loss: 0.3529
| Epoch [  8/ 10] Iter[121/391]		Loss: 0.4846
| Epoch [  8/ 10] Iter[141/391]		Loss: 0.5507
| Epoch [  8/ 10] Iter[161/391]		Loss: 0.3385
| Epoch [  8/ 10] Iter[181/391]		Loss: 0.4343
| Epoch [  8/ 10] Iter[201/391]		Loss: 0.5195
| Epoch [  8/ 10] Iter[221/391]		Loss: 0.2949
| Epoch [  8/ 10] Iter[241/391]		Loss: 0.3765
| Epoch [  8/ 10] Iter[261/391]		Loss: 0.5522
| Epoch [  8/ 10] Iter[281/391]		Loss: 0.4229
| Epoch [  8/ 10] Iter[301/391]		Loss: 0.3886
| Epoch [  8/ 10] Iter[321/391]		Loss: 0.4791
| Epoch [  8/ 10] Iter[341/391]		Loss: 0.4972
| Epoch [  8/ 10] Iter[361/391]		Loss: 0.4909
| Epoch [  8/ 10] Iter[381/391]		Loss: 0.4546
=> Training Epoch #9
| Epoch [  9/ 10] Iter[  1/391]		Loss: 0.2727
| Epoch [  9/ 10] Iter[ 21/391]		Loss: 0.2698
| Epoch [  9/ 10] Iter[ 41/391]		Loss: 0.2614
| Epoch [  9/ 10] Iter[ 61/391]		Loss: 0.3580
| Epoch [  9/ 10] Iter[ 81/391]		Loss: 0.3828
| Epoch [  9/ 10] Iter[101/391]		Loss: 0.3489
| Epoch [  9/ 10] Iter[121/391]		Loss: 0.4220
| Epoch [  9/ 10] Iter[141/391]		Loss: 0.2463
| Epoch [  9/ 10] Iter[161/391]		Loss: 0.3138
| Epoch [  9/ 10] Iter[181/391]		Loss: 0.3555
| Epoch [  9/ 10] Iter[201/391]		Loss: 0.3889
| Epoch [  9/ 10] Iter[221/391]		Loss: 0.2930
| Epoch [  9/ 10] Iter[241/391]		Loss: 0.3499
| Epoch [  9/ 10] Iter[261/391]		Loss: 0.3033
| Epoch [  9/ 10] Iter[281/391]		Loss: 0.3418
| Epoch [  9/ 10] Iter[301/391]		Loss: 0.3357
| Epoch [  9/ 10] Iter[321/391]		Loss: 0.3337
| Epoch [  9/ 10] Iter[341/391]		Loss: 0.3221
| Epoch [  9/ 10] Iter[361/391]		Loss: 0.3030
| Epoch [  9/ 10] Iter[381/391]		Loss: 0.4644
=> Training Epoch #0
| Epoch [  0/ 10] Iter[  1/391]		Loss: 2.3430
| Epoch [  0/ 10] Iter[ 21/391]		Loss: 2.6481
| Epoch [  0/ 10] Iter[ 41/391]		Loss: 2.2871
| Epoch [  0/ 10] Iter[ 61/391]		Loss: 2.0757
| Epoch [  0/ 10] Iter[ 81/391]		Loss: 2.0510
| Epoch [  0/ 10] Iter[101/391]		Loss: 2.0504
| Epoch [  0/ 10] Iter[121/391]		Loss: 1.9351
| Epoch [  0/ 10] Iter[141/391]		Loss: 1.7879
| Epoch [  0/ 10] Iter[161/391]		Loss: 1.9117
| Epoch [  0/ 10] Iter[181/391]		Loss: 1.7180
| Epoch [  0/ 10] Iter[201/391]		Loss: 1.7199
| Epoch [  0/ 10] Iter[221/391]		Loss: 1.5158
| Epoch [  0/ 10] Iter[241/391]		Loss: 1.5169
| Epoch [  0/ 10] Iter[261/391]		Loss: 1.4541
| Epoch [  0/ 10] Iter[281/391]		Loss: 1.6860
| Epoch [  0/ 10] Iter[301/391]		Loss: 1.5746
| Epoch [  0/ 10] Iter[321/391]		Loss: 1.6426
| Epoch [  0/ 10] Iter[341/391]		Loss: 1.5337
| Epoch [  0/ 10] Iter[361/391]		Loss: 1.5696
| Epoch [  0/ 10] Iter[381/391]		Loss: 1.5734
=> Training Epoch #1
| Epoch [  1/ 10] Iter[  1/391]		Loss: 1.2965
| Epoch [  1/ 10] Iter[ 21/391]		Loss: 1.4941
| Epoch [  1/ 10] Iter[ 41/391]		Loss: 1.4747
| Epoch [  1/ 10] Iter[ 61/391]		Loss: 1.2161
| Epoch [  1/ 10] Iter[ 81/391]		Loss: 1.4297
| Epoch [  1/ 10] Iter[101/391]		Loss: 1.5347
| Epoch [  1/ 10] Iter[121/391]		Loss: 1.1146
| Epoch [  1/ 10] Iter[141/391]		Loss: 1.3050
| Epoch [  1/ 10] Iter[161/391]		Loss: 1.4512
| Epoch [  1/ 10] Iter[181/391]		Loss: 1.2604
| Epoch [  1/ 10] Iter[201/391]		Loss: 1.3004
| Epoch [  1/ 10] Iter[221/391]		Loss: 1.3567
| Epoch [  1/ 10] Iter[241/391]		Loss: 1.3628
| Epoch [  1/ 10] Iter[261/391]		Loss: 1.4128
| Epoch [  1/ 10] Iter[281/391]		Loss: 1.3276
| Epoch [  1/ 10] Iter[301/391]		Loss: 1.3195
| Epoch [  1/ 10] Iter[321/391]		Loss: 1.4342
| Epoch [  1/ 10] Iter[341/391]		Loss: 1.2567
| Epoch [  1/ 10] Iter[361/391]		Loss: 1.3312
| Epoch [  1/ 10] Iter[381/391]		Loss: 1.0850
=> Training Epoch #2
| Epoch [  2/ 10] Iter[  1/391]		Loss: 1.1724
| Epoch [  2/ 10] Iter[ 21/391]		Loss: 1.1384
| Epoch [  2/ 10] Iter[ 41/391]		Loss: 1.0945
| Epoch [  2/ 10] Iter[ 61/391]		Loss: 1.1628
| Epoch [  2/ 10] Iter[ 81/391]		Loss: 1.0328
| Epoch [  2/ 10] Iter[101/391]		Loss: 1.1164
| Epoch [  2/ 10] Iter[121/391]		Loss: 1.1768
| Epoch [  2/ 10] Iter[141/391]		Loss: 1.1150
| Epoch [  2/ 10] Iter[161/391]		Loss: 1.1132
| Epoch [  2/ 10] Iter[181/391]		Loss: 0.9706
| Epoch [  2/ 10] Iter[201/391]		Loss: 1.0806
| Epoch [  2/ 10] Iter[221/391]		Loss: 1.0122
| Epoch [  2/ 10] Iter[241/391]		Loss: 0.9227
| Epoch [  2/ 10] Iter[261/391]		Loss: 1.0976
| Epoch [  2/ 10] Iter[281/391]		Loss: 0.6991
| Epoch [  2/ 10] Iter[301/391]		Loss: 1.0303
| Epoch [  2/ 10] Iter[321/391]		Loss: 0.9902
| Epoch [  2/ 10] Iter[341/391]		Loss: 0.9113
| Epoch [  2/ 10] Iter[361/391]		Loss: 1.0935
| Epoch [  2/ 10] Iter[381/391]		Loss: 0.9466
=> Training Epoch #3
| Epoch [  3/ 10] Iter[  1/391]		Loss: 1.1122
| Epoch [  3/ 10] Iter[ 21/391]		Loss: 0.9504
| Epoch [  3/ 10] Iter[ 41/391]		Loss: 0.8735
| Epoch [  3/ 10] Iter[ 61/391]		Loss: 0.8273
| Epoch [  3/ 10] Iter[ 81/391]		Loss: 0.9997
| Epoch [  3/ 10] Iter[101/391]		Loss: 0.7950
| Epoch [  3/ 10] Iter[121/391]		Loss: 0.7687
| Epoch [  3/ 10] Iter[141/391]		Loss: 1.0959
| Epoch [  3/ 10] Iter[161/391]		Loss: 0.8101
| Epoch [  3/ 10] Iter[181/391]		Loss: 0.8171
| Epoch [  3/ 10] Iter[201/391]		Loss: 0.7911
| Epoch [  3/ 10] Iter[221/391]		Loss: 1.0791
| Epoch [  3/ 10] Iter[241/391]		Loss: 0.7548
| Epoch [  3/ 10] Iter[261/391]		Loss: 0.7228
| Epoch [  3/ 10] Iter[281/391]		Loss: 0.7241
| Epoch [  3/ 10] Iter[301/391]		Loss: 0.8015
| Epoch [  3/ 10] Iter[321/391]		Loss: 0.8313
| Epoch [  3/ 10] Iter[341/391]		Loss: 0.7838
| Epoch [  3/ 10] Iter[361/391]		Loss: 0.6839
| Epoch [  3/ 10] Iter[381/391]		Loss: 0.7950
=> Training Epoch #4
| Epoch [  4/ 10] Iter[  1/391]		Loss: 0.5738
| Epoch [  4/ 10] Iter[ 21/391]		Loss: 0.7394
| Epoch [  4/ 10] Iter[ 41/391]		Loss: 0.6039
| Epoch [  4/ 10] Iter[ 61/391]		Loss: 0.7538
| Epoch [  4/ 10] Iter[ 81/391]		Loss: 0.6496
| Epoch [  4/ 10] Iter[101/391]		Loss: 0.7795
| Epoch [  4/ 10] Iter[121/391]		Loss: 0.6214
| Epoch [  4/ 10] Iter[141/391]		Loss: 0.7947
| Epoch [  4/ 10] Iter[161/391]		Loss: 0.7647
| Epoch [  4/ 10] Iter[181/391]		Loss: 0.7971
| Epoch [  4/ 10] Iter[201/391]		Loss: 0.7004
| Epoch [  4/ 10] Iter[221/391]		Loss: 0.7348
| Epoch [  4/ 10] Iter[241/391]		Loss: 0.6852
| Epoch [  4/ 10] Iter[261/391]		Loss: 0.6929
| Epoch [  4/ 10] Iter[281/391]		Loss: 0.6488
| Epoch [  4/ 10] Iter[301/391]		Loss: 0.7580
| Epoch [  4/ 10] Iter[321/391]		Loss: 0.5777
| Epoch [  4/ 10] Iter[341/391]		Loss: 0.6558
| Epoch [  4/ 10] Iter[361/391]		Loss: 0.5495
| Epoch [  4/ 10] Iter[381/391]		Loss: 0.5980
=> Training Epoch #5
| Epoch [  5/ 10] Iter[  1/391]		Loss: 0.5087
| Epoch [  5/ 10] Iter[ 21/391]		Loss: 0.5745
| Epoch [  5/ 10] Iter[ 41/391]		Loss: 0.6157
| Epoch [  5/ 10] Iter[ 61/391]		Loss: 0.3517
| Epoch [  5/ 10] Iter[ 81/391]		Loss: 0.5086
| Epoch [  5/ 10] Iter[101/391]		Loss: 0.7431
| Epoch [  5/ 10] Iter[121/391]		Loss: 0.6161
| Epoch [  5/ 10] Iter[141/391]		Loss: 0.6493
| Epoch [  5/ 10] Iter[161/391]		Loss: 0.3773
| Epoch [  5/ 10] Iter[181/391]		Loss: 0.4276
| Epoch [  5/ 10] Iter[201/391]		Loss: 0.5359
| Epoch [  5/ 10] Iter[221/391]		Loss: 0.5672
| Epoch [  5/ 10] Iter[241/391]		Loss: 0.5234
| Epoch [  5/ 10] Iter[261/391]		Loss: 0.6458
| Epoch [  5/ 10] Iter[281/391]		Loss: 0.7738
| Epoch [  5/ 10] Iter[301/391]		Loss: 0.6024
| Epoch [  5/ 10] Iter[321/391]		Loss: 0.5396
| Epoch [  5/ 10] Iter[341/391]		Loss: 0.4590
| Epoch [  5/ 10] Iter[361/391]		Loss: 0.5393
| Epoch [  5/ 10] Iter[381/391]		Loss: 0.5658
=> Training Epoch #6
| Epoch [  6/ 10] Iter[  1/391]		Loss: 0.5944
| Epoch [  6/ 10] Iter[ 21/391]		Loss: 0.3511
| Epoch [  6/ 10] Iter[ 41/391]		Loss: 0.4048
| Epoch [  6/ 10] Iter[ 61/391]		Loss: 0.4102
| Epoch [  6/ 10] Iter[ 81/391]		Loss: 0.4139
| Epoch [  6/ 10] Iter[101/391]		Loss: 0.4184
| Epoch [  6/ 10] Iter[121/391]		Loss: 0.4782
| Epoch [  6/ 10] Iter[141/391]		Loss: 0.5437
| Epoch [  6/ 10] Iter[161/391]		Loss: 0.4809
| Epoch [  6/ 10] Iter[181/391]		Loss: 0.3316
| Epoch [  6/ 10] Iter[201/391]		Loss: 0.3957
| Epoch [  6/ 10] Iter[221/391]		Loss: 0.4611
| Epoch [  6/ 10] Iter[241/391]		Loss: 0.4435
| Epoch [  6/ 10] Iter[261/391]		Loss: 0.5221
| Epoch [  6/ 10] Iter[281/391]		Loss: 0.5482
| Epoch [  6/ 10] Iter[301/391]		Loss: 0.3971
| Epoch [  6/ 10] Iter[321/391]		Loss: 0.3684
| Epoch [  6/ 10] Iter[341/391]		Loss: 0.5124
| Epoch [  6/ 10] Iter[361/391]		Loss: 0.4373
| Epoch [  6/ 10] Iter[381/391]		Loss: 0.5736
=> Training Epoch #7
| Epoch [  7/ 10] Iter[  1/391]		Loss: 0.4302
| Epoch [  7/ 10] Iter[ 21/391]		Loss: 0.4593
| Epoch [  7/ 10] Iter[ 41/391]		Loss: 0.2793
| Epoch [  7/ 10] Iter[ 61/391]		Loss: 0.3107
| Epoch [  7/ 10] Iter[ 81/391]		Loss: 0.4291
| Epoch [  7/ 10] Iter[101/391]		Loss: 0.3538
| Epoch [  7/ 10] Iter[121/391]		Loss: 0.2899
| Epoch [  7/ 10] Iter[141/391]		Loss: 0.3550
| Epoch [  7/ 10] Iter[161/391]		Loss: 0.3568
| Epoch [  7/ 10] Iter[181/391]		Loss: 0.3052
| Epoch [  7/ 10] Iter[201/391]		Loss: 0.3929
| Epoch [  7/ 10] Iter[221/391]		Loss: 0.3910
| Epoch [  7/ 10] Iter[241/391]		Loss: 0.3054
| Epoch [  7/ 10] Iter[261/391]		Loss: 0.4398
| Epoch [  7/ 10] Iter[281/391]		Loss: 0.3138
| Epoch [  7/ 10] Iter[301/391]		Loss: 0.4152
| Epoch [  7/ 10] Iter[321/391]		Loss: 0.3269
| Epoch [  7/ 10] Iter[341/391]		Loss: 0.6128
| Epoch [  7/ 10] Iter[361/391]		Loss: 0.6166
| Epoch [  7/ 10] Iter[381/391]		Loss: 0.3393
=> Training Epoch #8
| Epoch [  8/ 10] Iter[  1/391]		Loss: 0.3961
| Epoch [  8/ 10] Iter[ 21/391]		Loss: 0.3421
| Epoch [  8/ 10] Iter[ 41/391]		Loss: 0.2798
| Epoch [  8/ 10] Iter[ 61/391]		Loss: 0.2394
| Epoch [  8/ 10] Iter[ 81/391]		Loss: 0.3371
| Epoch [  8/ 10] Iter[101/391]		Loss: 0.3510
| Epoch [  8/ 10] Iter[121/391]		Loss: 0.3787
| Epoch [  8/ 10] Iter[141/391]		Loss: 0.5311
| Epoch [  8/ 10] Iter[161/391]		Loss: 0.3369
| Epoch [  8/ 10] Iter[181/391]		Loss: 0.3773
| Epoch [  8/ 10] Iter[201/391]		Loss: 0.4091
| Epoch [  8/ 10] Iter[221/391]		Loss: 0.4138
| Epoch [  8/ 10] Iter[241/391]		Loss: 0.3175
| Epoch [  8/ 10] Iter[261/391]		Loss: 0.2886
| Epoch [  8/ 10] Iter[281/391]		Loss: 0.4580
| Epoch [  8/ 10] Iter[301/391]		Loss: 0.4263
| Epoch [  8/ 10] Iter[321/391]		Loss: 0.3456
| Epoch [  8/ 10] Iter[341/391]		Loss: 0.3919
| Epoch [  8/ 10] Iter[361/391]		Loss: 0.4202
| Epoch [  8/ 10] Iter[381/391]		Loss: 0.4119
=> Training Epoch #9
| Epoch [  9/ 10] Iter[  1/391]		Loss: 0.2071
| Epoch [  9/ 10] Iter[ 21/391]		Loss: 0.2751
| Epoch [  9/ 10] Iter[ 41/391]		Loss: 0.1574
| Epoch [  9/ 10] Iter[ 61/391]		Loss: 0.1993
| Epoch [  9/ 10] Iter[ 81/391]		Loss: 0.3846
| Epoch [  9/ 10] Iter[101/391]		Loss: 0.2101
| Epoch [  9/ 10] Iter[121/391]		Loss: 0.2741
| Epoch [  9/ 10] Iter[141/391]		Loss: 0.3571
| Epoch [  9/ 10] Iter[161/391]		Loss: 0.3080
| Epoch [  9/ 10] Iter[181/391]		Loss: 0.2692
| Epoch [  9/ 10] Iter[201/391]		Loss: 0.1999
| Epoch [  9/ 10] Iter[221/391]		Loss: 0.4138
| Epoch [  9/ 10] Iter[241/391]		Loss: 0.3974
| Epoch [  9/ 10] Iter[261/391]		Loss: 0.2583
| Epoch [  9/ 10] Iter[281/391]		Loss: 0.3582
| Epoch [  9/ 10] Iter[301/391]		Loss: 0.3812
| Epoch [  9/ 10] Iter[321/391]		Loss: 0.4312
| Epoch [  9/ 10] Iter[341/391]		Loss: 0.3233
| Epoch [  9/ 10] Iter[361/391]		Loss: 0.4599
| Epoch [  9/ 10] Iter[381/391]		Loss: 0.4636
=> Training Epoch #0
| Epoch [  0/ 10] Iter[  1/391]		Loss: 2.3562
| Epoch [  0/ 10] Iter[ 21/391]		Loss: 2.4893
| Epoch [  0/ 10] Iter[ 41/391]		Loss: 2.3010
| Epoch [  0/ 10] Iter[ 61/391]		Loss: 2.2090
| Epoch [  0/ 10] Iter[ 81/391]		Loss: 2.0575
| Epoch [  0/ 10] Iter[101/391]		Loss: 1.9934
| Epoch [  0/ 10] Iter[121/391]		Loss: 2.0804
| Epoch [  0/ 10] Iter[141/391]		Loss: 1.9721
| Epoch [  0/ 10] Iter[161/391]		Loss: 2.0409
| Epoch [  0/ 10] Iter[181/391]		Loss: 2.0313
| Epoch [  0/ 10] Iter[201/391]		Loss: 1.9258
| Epoch [  0/ 10] Iter[221/391]		Loss: 1.8899
| Epoch [  0/ 10] Iter[241/391]		Loss: 1.7120
| Epoch [  0/ 10] Iter[261/391]		Loss: 1.7541
| Epoch [  0/ 10] Iter[281/391]		Loss: 1.7359
| Epoch [  0/ 10] Iter[301/391]		Loss: 1.6402
| Epoch [  0/ 10] Iter[321/391]		Loss: 1.6677
| Epoch [  0/ 10] Iter[341/391]		Loss: 1.7021
| Epoch [  0/ 10] Iter[361/391]		Loss: 1.4709
| Epoch [  0/ 10] Iter[381/391]		Loss: 1.4440
=> Training Epoch #1
| Epoch [  1/ 10] Iter[  1/391]		Loss: 1.5361
| Epoch [  1/ 10] Iter[ 21/391]		Loss: 1.3098
| Epoch [  1/ 10] Iter[ 41/391]		Loss: 1.5572
| Epoch [  1/ 10] Iter[ 61/391]		Loss: 1.5101
| Epoch [  1/ 10] Iter[ 81/391]		Loss: 1.3607
| Epoch [  1/ 10] Iter[101/391]		Loss: 1.4292
| Epoch [  1/ 10] Iter[121/391]		Loss: 1.3749
| Epoch [  1/ 10] Iter[141/391]		Loss: 1.2397
| Epoch [  1/ 10] Iter[161/391]		Loss: 1.3467
| Epoch [  1/ 10] Iter[181/391]		Loss: 1.5494
| Epoch [  1/ 10] Iter[201/391]		Loss: 1.3972
| Epoch [  1/ 10] Iter[221/391]		Loss: 1.2831
| Epoch [  1/ 10] Iter[241/391]		Loss: 1.2209
| Epoch [  1/ 10] Iter[261/391]		Loss: 1.1659
| Epoch [  1/ 10] Iter[281/391]		Loss: 1.3088
| Epoch [  1/ 10] Iter[301/391]		Loss: 1.2127
| Epoch [  1/ 10] Iter[321/391]		Loss: 1.2395
| Epoch [  1/ 10] Iter[341/391]		Loss: 1.1811
| Epoch [  1/ 10] Iter[361/391]		Loss: 1.1548
| Epoch [  1/ 10] Iter[381/391]		Loss: 1.1247
=> Training Epoch #2
| Epoch [  2/ 10] Iter[  1/391]		Loss: 1.1191
| Epoch [  2/ 10] Iter[ 21/391]		Loss: 1.1142
| Epoch [  2/ 10] Iter[ 41/391]		Loss: 0.9533
| Epoch [  2/ 10] Iter[ 61/391]		Loss: 1.1009
| Epoch [  2/ 10] Iter[ 81/391]		Loss: 0.9903
| Epoch [  2/ 10] Iter[101/391]		Loss: 1.0182
| Epoch [  2/ 10] Iter[121/391]		Loss: 1.0861
| Epoch [  2/ 10] Iter[141/391]		Loss: 1.0992
| Epoch [  2/ 10] Iter[161/391]		Loss: 0.9589
| Epoch [  2/ 10] Iter[181/391]		Loss: 1.0079
| Epoch [  2/ 10] Iter[201/391]		Loss: 1.0175
| Epoch [  2/ 10] Iter[221/391]		Loss: 0.9616
| Epoch [  2/ 10] Iter[241/391]		Loss: 0.7153
| Epoch [  2/ 10] Iter[261/391]		Loss: 0.9312
| Epoch [  2/ 10] Iter[281/391]		Loss: 1.0189
| Epoch [  2/ 10] Iter[301/391]		Loss: 1.1415
| Epoch [  2/ 10] Iter[321/391]		Loss: 0.6980
| Epoch [  2/ 10] Iter[341/391]		Loss: 0.7818
| Epoch [  2/ 10] Iter[361/391]		Loss: 0.8396
| Epoch [  2/ 10] Iter[381/391]		Loss: 0.7520
=> Training Epoch #3
| Epoch [  3/ 10] Iter[  1/391]		Loss: 0.7495
| Epoch [  3/ 10] Iter[ 21/391]		Loss: 0.8902
| Epoch [  3/ 10] Iter[ 41/391]		Loss: 0.8689
| Epoch [  3/ 10] Iter[ 61/391]		Loss: 1.0300
| Epoch [  3/ 10] Iter[ 81/391]		Loss: 0.9536
| Epoch [  3/ 10] Iter[101/391]		Loss: 0.9294
| Epoch [  3/ 10] Iter[121/391]		Loss: 0.8834
| Epoch [  3/ 10] Iter[141/391]		Loss: 0.7295
| Epoch [  3/ 10] Iter[161/391]		Loss: 0.8005
| Epoch [  3/ 10] Iter[181/391]		Loss: 0.8178
| Epoch [  3/ 10] Iter[201/391]		Loss: 0.6519
| Epoch [  3/ 10] Iter[221/391]		Loss: 0.8006
| Epoch [  3/ 10] Iter[241/391]		Loss: 0.8108
| Epoch [  3/ 10] Iter[261/391]		Loss: 0.8511
| Epoch [  3/ 10] Iter[281/391]		Loss: 0.7193
| Epoch [  3/ 10] Iter[301/391]		Loss: 0.7649
| Epoch [  3/ 10] Iter[321/391]		Loss: 0.8273
| Epoch [  3/ 10] Iter[341/391]		Loss: 0.7356
| Epoch [  3/ 10] Iter[361/391]		Loss: 0.7102
| Epoch [  3/ 10] Iter[381/391]		Loss: 0.8313
=> Training Epoch #4
| Epoch [  4/ 10] Iter[  1/391]		Loss: 0.6085
| Epoch [  4/ 10] Iter[ 21/391]		Loss: 0.7595
| Epoch [  4/ 10] Iter[ 41/391]		Loss: 0.6837
| Epoch [  4/ 10] Iter[ 61/391]		Loss: 0.5694
| Epoch [  4/ 10] Iter[ 81/391]		Loss: 0.6993
| Epoch [  4/ 10] Iter[101/391]		Loss: 0.9413
| Epoch [  4/ 10] Iter[121/391]		Loss: 0.6811
| Epoch [  4/ 10] Iter[141/391]		Loss: 0.7191
| Epoch [  4/ 10] Iter[161/391]		Loss: 0.6760
| Epoch [  4/ 10] Iter[181/391]		Loss: 0.6069
| Epoch [  4/ 10] Iter[201/391]		Loss: 0.6389
| Epoch [  4/ 10] Iter[221/391]		Loss: 0.8648
| Epoch [  4/ 10] Iter[241/391]		Loss: 0.5403
| Epoch [  4/ 10] Iter[261/391]		Loss: 0.5401
| Epoch [  4/ 10] Iter[281/391]		Loss: 0.7006
| Epoch [  4/ 10] Iter[301/391]		Loss: 0.6079
| Epoch [  4/ 10] Iter[321/391]		Loss: 0.7438
| Epoch [  4/ 10] Iter[341/391]		Loss: 0.5770
| Epoch [  4/ 10] Iter[361/391]		Loss: 0.5279
| Epoch [  4/ 10] Iter[381/391]		Loss: 0.6743
=> Training Epoch #5
| Epoch [  5/ 10] Iter[  1/391]		Loss: 0.5200
| Epoch [  5/ 10] Iter[ 21/391]		Loss: 0.5894
| Epoch [  5/ 10] Iter[ 41/391]		Loss: 0.5135
| Epoch [  5/ 10] Iter[ 61/391]		Loss: 0.5580
| Epoch [  5/ 10] Iter[ 81/391]		Loss: 0.6145
| Epoch [  5/ 10] Iter[101/391]		Loss: 0.7264
| Epoch [  5/ 10] Iter[121/391]		Loss: 0.4437
| Epoch [  5/ 10] Iter[141/391]		Loss: 0.4505
| Epoch [  5/ 10] Iter[161/391]		Loss: 0.7558
| Epoch [  5/ 10] Iter[181/391]		Loss: 0.6044
| Epoch [  5/ 10] Iter[201/391]		Loss: 0.6862
| Epoch [  5/ 10] Iter[221/391]		Loss: 0.4584
| Epoch [  5/ 10] Iter[241/391]		Loss: 0.3965
| Epoch [  5/ 10] Iter[261/391]		Loss: 0.5168
| Epoch [  5/ 10] Iter[281/391]		Loss: 0.3953
| Epoch [  5/ 10] Iter[301/391]		Loss: 0.4163
| Epoch [  5/ 10] Iter[321/391]		Loss: 0.7948
| Epoch [  5/ 10] Iter[341/391]		Loss: 0.5584
| Epoch [  5/ 10] Iter[361/391]		Loss: 0.6463
| Epoch [  5/ 10] Iter[381/391]		Loss: 0.4377
=> Training Epoch #6
| Epoch [  6/ 10] Iter[  1/391]		Loss: 0.4384
| Epoch [  6/ 10] Iter[ 21/391]		Loss: 0.4779
| Epoch [  6/ 10] Iter[ 41/391]		Loss: 0.4938
| Epoch [  6/ 10] Iter[ 61/391]		Loss: 0.4497
| Epoch [  6/ 10] Iter[ 81/391]		Loss: 0.3251
| Epoch [  6/ 10] Iter[101/391]		Loss: 0.5525
| Epoch [  6/ 10] Iter[121/391]		Loss: 0.4750
| Epoch [  6/ 10] Iter[141/391]		Loss: 0.5173
| Epoch [  6/ 10] Iter[161/391]		Loss: 0.4800
| Epoch [  6/ 10] Iter[181/391]		Loss: 0.4845
| Epoch [  6/ 10] Iter[201/391]		Loss: 0.5436
| Epoch [  6/ 10] Iter[221/391]		Loss: 0.5819
| Epoch [  6/ 10] Iter[241/391]		Loss: 0.5019
| Epoch [  6/ 10] Iter[261/391]		Loss: 0.3990
| Epoch [  6/ 10] Iter[281/391]		Loss: 0.3339
| Epoch [  6/ 10] Iter[301/391]		Loss: 0.3858
| Epoch [  6/ 10] Iter[321/391]		Loss: 0.3468
| Epoch [  6/ 10] Iter[341/391]		Loss: 0.4771
| Epoch [  6/ 10] Iter[361/391]		Loss: 0.3988
| Epoch [  6/ 10] Iter[381/391]		Loss: 0.3911
=> Training Epoch #7
| Epoch [  7/ 10] Iter[  1/391]		Loss: 0.5078
| Epoch [  7/ 10] Iter[ 21/391]		Loss: 0.3738
| Epoch [  7/ 10] Iter[ 41/391]		Loss: 0.2931
| Epoch [  7/ 10] Iter[ 61/391]		Loss: 0.3320
| Epoch [  7/ 10] Iter[ 81/391]		Loss: 0.4549
| Epoch [  7/ 10] Iter[101/391]		Loss: 0.3779
| Epoch [  7/ 10] Iter[121/391]		Loss: 0.5127
| Epoch [  7/ 10] Iter[141/391]		Loss: 0.4670
| Epoch [  7/ 10] Iter[161/391]		Loss: 0.4966
| Epoch [  7/ 10] Iter[181/391]		Loss: 0.3820
| Epoch [  7/ 10] Iter[201/391]		Loss: 0.6125
| Epoch [  7/ 10] Iter[221/391]		Loss: 0.4361
| Epoch [  7/ 10] Iter[241/391]		Loss: 0.4112
| Epoch [  7/ 10] Iter[261/391]		Loss: 0.5168
| Epoch [  7/ 10] Iter[281/391]		Loss: 0.4037
| Epoch [  7/ 10] Iter[301/391]		Loss: 0.4577
| Epoch [  7/ 10] Iter[321/391]		Loss: 0.3966
| Epoch [  7/ 10] Iter[341/391]		Loss: 0.4108
| Epoch [  7/ 10] Iter[361/391]		Loss: 0.3706
| Epoch [  7/ 10] Iter[381/391]		Loss: 0.4550
=> Training Epoch #8
| Epoch [  8/ 10] Iter[  1/391]		Loss: 0.2556
| Epoch [  8/ 10] Iter[ 21/391]		Loss: 0.3526
| Epoch [  8/ 10] Iter[ 41/391]		Loss: 0.4157
| Epoch [  8/ 10] Iter[ 61/391]		Loss: 0.2687
| Epoch [  8/ 10] Iter[ 81/391]		Loss: 0.2410
| Epoch [  8/ 10] Iter[101/391]		Loss: 0.4152
| Epoch [  8/ 10] Iter[121/391]		Loss: 0.2691
| Epoch [  8/ 10] Iter[141/391]		Loss: 0.3524
| Epoch [  8/ 10] Iter[161/391]		Loss: 0.2157
| Epoch [  8/ 10] Iter[181/391]		Loss: 0.3092
| Epoch [  8/ 10] Iter[201/391]		Loss: 0.3177
| Epoch [  8/ 10] Iter[221/391]		Loss: 0.2750
| Epoch [  8/ 10] Iter[241/391]		Loss: 0.4624
| Epoch [  8/ 10] Iter[261/391]		Loss: 0.3713
| Epoch [  8/ 10] Iter[281/391]		Loss: 0.4170
| Epoch [  8/ 10] Iter[301/391]		Loss: 0.4553
| Epoch [  8/ 10] Iter[321/391]		Loss: 0.3493
| Epoch [  8/ 10] Iter[341/391]		Loss: 0.3436
| Epoch [  8/ 10] Iter[361/391]		Loss: 0.5527
| Epoch [  8/ 10] Iter[381/391]		Loss: 0.3231
=> Training Epoch #9
| Epoch [  9/ 10] Iter[  1/391]		Loss: 0.2012
| Epoch [  9/ 10] Iter[ 21/391]		Loss: 0.1948
| Epoch [  9/ 10] Iter[ 41/391]		Loss: 0.3454
| Epoch [  9/ 10] Iter[ 61/391]		Loss: 0.3715
| Epoch [  9/ 10] Iter[ 81/391]		Loss: 0.4558
| Epoch [  9/ 10] Iter[101/391]		Loss: 0.2803
| Epoch [  9/ 10] Iter[121/391]		Loss: 0.3452
| Epoch [  9/ 10] Iter[141/391]		Loss: 0.3423
| Epoch [  9/ 10] Iter[161/391]		Loss: 0.3014
| Epoch [  9/ 10] Iter[181/391]		Loss: 0.3272
| Epoch [  9/ 10] Iter[201/391]		Loss: 0.3202
| Epoch [  9/ 10] Iter[221/391]		Loss: 0.3910
| Epoch [  9/ 10] Iter[241/391]		Loss: 0.2954
| Epoch [  9/ 10] Iter[261/391]		Loss: 0.4253
| Epoch [  9/ 10] Iter[281/391]		Loss: 0.2580
| Epoch [  9/ 10] Iter[301/391]		Loss: 0.3498
| Epoch [  9/ 10] Iter[321/391]		Loss: 0.4360
| Epoch [  9/ 10] Iter[341/391]		Loss: 0.4107
| Epoch [  9/ 10] Iter[361/391]		Loss: 0.4692
| Epoch [  9/ 10] Iter[381/391]		Loss: 0.2821
=> Training Epoch #0
| Epoch [  0/ 10] Iter[  1/391]		Loss: 2.5107
| Epoch [  0/ 10] Iter[ 21/391]		Loss: 2.3232
| Epoch [  0/ 10] Iter[ 41/391]		Loss: 2.2690
| Epoch [  0/ 10] Iter[ 61/391]		Loss: 2.1010
| Epoch [  0/ 10] Iter[ 81/391]		Loss: 1.9151
| Epoch [  0/ 10] Iter[101/391]		Loss: 1.8082
| Epoch [  0/ 10] Iter[121/391]		Loss: 1.9141
| Epoch [  0/ 10] Iter[141/391]		Loss: 1.8991
| Epoch [  0/ 10] Iter[161/391]		Loss: 1.6465
| Epoch [  0/ 10] Iter[181/391]		Loss: 1.5855
| Epoch [  0/ 10] Iter[201/391]		Loss: 1.6553
| Epoch [  0/ 10] Iter[221/391]		Loss: 1.5772
| Epoch [  0/ 10] Iter[241/391]		Loss: 1.8625
| Epoch [  0/ 10] Iter[261/391]		Loss: 1.6818
| Epoch [  0/ 10] Iter[281/391]		Loss: 1.6982
| Epoch [  0/ 10] Iter[301/391]		Loss: 1.4735
| Epoch [  0/ 10] Iter[321/391]		Loss: 1.4340
| Epoch [  0/ 10] Iter[341/391]		Loss: 1.7755
| Epoch [  0/ 10] Iter[361/391]		Loss: 1.4480
| Epoch [  0/ 10] Iter[381/391]		Loss: 1.3791
=> Training Epoch #1
| Epoch [  1/ 10] Iter[  1/391]		Loss: 1.4125
| Epoch [  1/ 10] Iter[ 21/391]		Loss: 1.5701
| Epoch [  1/ 10] Iter[ 41/391]		Loss: 1.3914
| Epoch [  1/ 10] Iter[ 61/391]		Loss: 1.1727
| Epoch [  1/ 10] Iter[ 81/391]		Loss: 1.3548
| Epoch [  1/ 10] Iter[101/391]		Loss: 1.6658
| Epoch [  1/ 10] Iter[121/391]		Loss: 1.2014
| Epoch [  1/ 10] Iter[141/391]		Loss: 1.2604
| Epoch [  1/ 10] Iter[161/391]		Loss: 1.3232
| Epoch [  1/ 10] Iter[181/391]		Loss: 1.1153
| Epoch [  1/ 10] Iter[201/391]		Loss: 1.2869
| Epoch [  1/ 10] Iter[221/391]		Loss: 1.1903
| Epoch [  1/ 10] Iter[241/391]		Loss: 1.2381
| Epoch [  1/ 10] Iter[261/391]		Loss: 1.0450
| Epoch [  1/ 10] Iter[281/391]		Loss: 1.0481
| Epoch [  1/ 10] Iter[301/391]		Loss: 1.0966
| Epoch [  1/ 10] Iter[321/391]		Loss: 1.0958
| Epoch [  1/ 10] Iter[341/391]		Loss: 1.1798
| Epoch [  1/ 10] Iter[361/391]		Loss: 1.0479
| Epoch [  1/ 10] Iter[381/391]		Loss: 0.9306
=> Training Epoch #2
| Epoch [  2/ 10] Iter[  1/391]		Loss: 1.0039
| Epoch [  2/ 10] Iter[ 21/391]		Loss: 0.9373
| Epoch [  2/ 10] Iter[ 41/391]		Loss: 1.1585
| Epoch [  2/ 10] Iter[ 61/391]		Loss: 1.0052
| Epoch [  2/ 10] Iter[ 81/391]		Loss: 0.8589
| Epoch [  2/ 10] Iter[101/391]		Loss: 0.8559
| Epoch [  2/ 10] Iter[121/391]		Loss: 0.9150
| Epoch [  2/ 10] Iter[141/391]		Loss: 0.7240
| Epoch [  2/ 10] Iter[161/391]		Loss: 0.8955
| Epoch [  2/ 10] Iter[181/391]		Loss: 0.9279
| Epoch [  2/ 10] Iter[201/391]		Loss: 1.0704
| Epoch [  2/ 10] Iter[221/391]		Loss: 0.8167
| Epoch [  2/ 10] Iter[241/391]		Loss: 0.9165
| Epoch [  2/ 10] Iter[261/391]		Loss: 0.9501
| Epoch [  2/ 10] Iter[281/391]		Loss: 1.0449
| Epoch [  2/ 10] Iter[301/391]		Loss: 0.8784
| Epoch [  2/ 10] Iter[321/391]		Loss: 0.8642
| Epoch [  2/ 10] Iter[341/391]		Loss: 0.9656
| Epoch [  2/ 10] Iter[361/391]		Loss: 0.7664
| Epoch [  2/ 10] Iter[381/391]		Loss: 0.7261
=> Training Epoch #3
| Epoch [  3/ 10] Iter[  1/391]		Loss: 0.7845
| Epoch [  3/ 10] Iter[ 21/391]		Loss: 0.8344
| Epoch [  3/ 10] Iter[ 41/391]		Loss: 0.7887
| Epoch [  3/ 10] Iter[ 61/391]		Loss: 0.7781
| Epoch [  3/ 10] Iter[ 81/391]		Loss: 0.8183
| Epoch [  3/ 10] Iter[101/391]		Loss: 0.6651
| Epoch [  3/ 10] Iter[121/391]		Loss: 0.9418
| Epoch [  3/ 10] Iter[141/391]		Loss: 0.9167
| Epoch [  3/ 10] Iter[161/391]		Loss: 0.7799
| Epoch [  3/ 10] Iter[181/391]		Loss: 0.8917
| Epoch [  3/ 10] Iter[201/391]		Loss: 0.8319
| Epoch [  3/ 10] Iter[221/391]		Loss: 0.7533
| Epoch [  3/ 10] Iter[241/391]		Loss: 0.8746
| Epoch [  3/ 10] Iter[261/391]		Loss: 0.6677
| Epoch [  3/ 10] Iter[281/391]		Loss: 0.6349
| Epoch [  3/ 10] Iter[301/391]		Loss: 0.8284
| Epoch [  3/ 10] Iter[321/391]		Loss: 0.4851
| Epoch [  3/ 10] Iter[341/391]		Loss: 0.7465
| Epoch [  3/ 10] Iter[361/391]		Loss: 0.8412
| Epoch [  3/ 10] Iter[381/391]		Loss: 0.7684
=> Training Epoch #4
| Epoch [  4/ 10] Iter[  1/391]		Loss: 0.6736
| Epoch [  4/ 10] Iter[ 21/391]		Loss: 0.8182
| Epoch [  4/ 10] Iter[ 41/391]		Loss: 0.6464
| Epoch [  4/ 10] Iter[ 61/391]		Loss: 0.5400
| Epoch [  4/ 10] Iter[ 81/391]		Loss: 0.6715
| Epoch [  4/ 10] Iter[101/391]		Loss: 0.7647
| Epoch [  4/ 10] Iter[121/391]		Loss: 0.7057
| Epoch [  4/ 10] Iter[141/391]		Loss: 0.5390
| Epoch [  4/ 10] Iter[161/391]		Loss: 0.6795
| Epoch [  4/ 10] Iter[181/391]		Loss: 0.5595
| Epoch [  4/ 10] Iter[201/391]		Loss: 0.8251
| Epoch [  4/ 10] Iter[221/391]		Loss: 0.6506
| Epoch [  4/ 10] Iter[241/391]		Loss: 0.5982
| Epoch [  4/ 10] Iter[261/391]		Loss: 0.6939
| Epoch [  4/ 10] Iter[281/391]		Loss: 0.5799
| Epoch [  4/ 10] Iter[301/391]		Loss: 0.7300
| Epoch [  4/ 10] Iter[321/391]		Loss: 0.6020
| Epoch [  4/ 10] Iter[341/391]		Loss: 0.5169
| Epoch [  4/ 10] Iter[361/391]		Loss: 0.4904
| Epoch [  4/ 10] Iter[381/391]		Loss: 0.5010
=> Training Epoch #5
| Epoch [  5/ 10] Iter[  1/391]		Loss: 0.3880
| Epoch [  5/ 10] Iter[ 21/391]		Loss: 0.4703
| Epoch [  5/ 10] Iter[ 41/391]		Loss: 0.6167
| Epoch [  5/ 10] Iter[ 61/391]		Loss: 0.3551
| Epoch [  5/ 10] Iter[ 81/391]		Loss: 0.4326
| Epoch [  5/ 10] Iter[101/391]		Loss: 0.3947
| Epoch [  5/ 10] Iter[121/391]		Loss: 0.5643
| Epoch [  5/ 10] Iter[141/391]		Loss: 0.4534
| Epoch [  5/ 10] Iter[161/391]		Loss: 0.4011
| Epoch [  5/ 10] Iter[181/391]		Loss: 0.5181
| Epoch [  5/ 10] Iter[201/391]		Loss: 0.6568
| Epoch [  5/ 10] Iter[221/391]		Loss: 0.4685
| Epoch [  5/ 10] Iter[241/391]		Loss: 0.5748
| Epoch [  5/ 10] Iter[261/391]		Loss: 0.5299
| Epoch [  5/ 10] Iter[281/391]		Loss: 0.5072
| Epoch [  5/ 10] Iter[301/391]		Loss: 0.6091
| Epoch [  5/ 10] Iter[321/391]		Loss: 0.5884
| Epoch [  5/ 10] Iter[341/391]		Loss: 0.5257
| Epoch [  5/ 10] Iter[361/391]		Loss: 0.5398
| Epoch [  5/ 10] Iter[381/391]		Loss: 0.5053
=> Training Epoch #6
| Epoch [  6/ 10] Iter[  1/391]		Loss: 0.5216
| Epoch [  6/ 10] Iter[ 21/391]		Loss: 0.4387
| Epoch [  6/ 10] Iter[ 41/391]		Loss: 0.4666
| Epoch [  6/ 10] Iter[ 61/391]		Loss: 0.4450
| Epoch [  6/ 10] Iter[ 81/391]		Loss: 0.4661
| Epoch [  6/ 10] Iter[101/391]		Loss: 0.3533
| Epoch [  6/ 10] Iter[121/391]		Loss: 0.3949
| Epoch [  6/ 10] Iter[141/391]		Loss: 0.5235
| Epoch [  6/ 10] Iter[161/391]		Loss: 0.4608
| Epoch [  6/ 10] Iter[181/391]		Loss: 0.4129
| Epoch [  6/ 10] Iter[201/391]		Loss: 0.5544
| Epoch [  6/ 10] Iter[221/391]		Loss: 0.5631
| Epoch [  6/ 10] Iter[241/391]		Loss: 0.4712
| Epoch [  6/ 10] Iter[261/391]		Loss: 0.6743
| Epoch [  6/ 10] Iter[281/391]		Loss: 0.4653
| Epoch [  6/ 10] Iter[301/391]		Loss: 0.4852
| Epoch [  6/ 10] Iter[321/391]		Loss: 0.4452
| Epoch [  6/ 10] Iter[341/391]		Loss: 0.4371
| Epoch [  6/ 10] Iter[361/391]		Loss: 0.6158
| Epoch [  6/ 10] Iter[381/391]		Loss: 0.4001
=> Training Epoch #7
| Epoch [  7/ 10] Iter[  1/391]		Loss: 0.3906
| Epoch [  7/ 10] Iter[ 21/391]		Loss: 0.4302
| Epoch [  7/ 10] Iter[ 41/391]		Loss: 0.2596
| Epoch [  7/ 10] Iter[ 61/391]		Loss: 0.3461
| Epoch [  7/ 10] Iter[ 81/391]		Loss: 0.3776
| Epoch [  7/ 10] Iter[101/391]		Loss: 0.4440
| Epoch [  7/ 10] Iter[121/391]		Loss: 0.4710
| Epoch [  7/ 10] Iter[141/391]		Loss: 0.3324
| Epoch [  7/ 10] Iter[161/391]		Loss: 0.4044
| Epoch [  7/ 10] Iter[181/391]		Loss: 0.4751
| Epoch [  7/ 10] Iter[201/391]		Loss: 0.3898
| Epoch [  7/ 10] Iter[221/391]		Loss: 0.3503
| Epoch [  7/ 10] Iter[241/391]		Loss: 0.5261
| Epoch [  7/ 10] Iter[261/391]		Loss: 0.6317
| Epoch [  7/ 10] Iter[281/391]		Loss: 0.3854
| Epoch [  7/ 10] Iter[301/391]		Loss: 0.4097
| Epoch [  7/ 10] Iter[321/391]		Loss: 0.4364
| Epoch [  7/ 10] Iter[341/391]		Loss: 0.4581
| Epoch [  7/ 10] Iter[361/391]		Loss: 0.4878
| Epoch [  7/ 10] Iter[381/391]		Loss: 0.4961
=> Training Epoch #8
| Epoch [  8/ 10] Iter[  1/391]		Loss: 0.2917
| Epoch [  8/ 10] Iter[ 21/391]		Loss: 0.4256
| Epoch [  8/ 10] Iter[ 41/391]		Loss: 0.2173
| Epoch [  8/ 10] Iter[ 61/391]		Loss: 0.3363
| Epoch [  8/ 10] Iter[ 81/391]		Loss: 0.3135
| Epoch [  8/ 10] Iter[101/391]		Loss: 0.2332
| Epoch [  8/ 10] Iter[121/391]		Loss: 0.4275
| Epoch [  8/ 10] Iter[141/391]		Loss: 0.2274
| Epoch [  8/ 10] Iter[161/391]		Loss: 0.4252
| Epoch [  8/ 10] Iter[181/391]		Loss: 0.3432
| Epoch [  8/ 10] Iter[201/391]		Loss: 0.4173
| Epoch [  8/ 10] Iter[221/391]		Loss: 0.3719
| Epoch [  8/ 10] Iter[241/391]		Loss: 0.2784
| Epoch [  8/ 10] Iter[261/391]		Loss: 0.5988
| Epoch [  8/ 10] Iter[281/391]		Loss: 0.4417
| Epoch [  8/ 10] Iter[301/391]		Loss: 0.4465
| Epoch [  8/ 10] Iter[321/391]		Loss: 0.3515
| Epoch [  8/ 10] Iter[341/391]		Loss: 0.3738
| Epoch [  8/ 10] Iter[361/391]		Loss: 0.4864
| Epoch [  8/ 10] Iter[381/391]		Loss: 0.4691
=> Training Epoch #9
| Epoch [  9/ 10] Iter[  1/391]		Loss: 0.1823
| Epoch [  9/ 10] Iter[ 21/391]		Loss: 0.2343
| Epoch [  9/ 10] Iter[ 41/391]		Loss: 0.1497
| Epoch [  9/ 10] Iter[ 61/391]		Loss: 0.2393
| Epoch [  9/ 10] Iter[ 81/391]		Loss: 0.3138
| Epoch [  9/ 10] Iter[101/391]		Loss: 0.3782
| Epoch [  9/ 10] Iter[121/391]		Loss: 0.3204
| Epoch [  9/ 10] Iter[141/391]		Loss: 0.2962
| Epoch [  9/ 10] Iter[161/391]		Loss: 0.2995
| Epoch [  9/ 10] Iter[181/391]		Loss: 0.3554
| Epoch [  9/ 10] Iter[201/391]		Loss: 0.3788
| Epoch [  9/ 10] Iter[221/391]		Loss: 0.2872
| Epoch [  9/ 10] Iter[241/391]		Loss: 0.2416
| Epoch [  9/ 10] Iter[261/391]		Loss: 0.3231
| Epoch [  9/ 10] Iter[281/391]		Loss: 0.3922
| Epoch [  9/ 10] Iter[301/391]		Loss: 0.2773
| Epoch [  9/ 10] Iter[321/391]		Loss: 0.5269
| Epoch [  9/ 10] Iter[341/391]		Loss: 0.3041
| Epoch [  9/ 10] Iter[361/391]		Loss: 0.4410
| Epoch [  9/ 10] Iter[381/391]		Loss: 0.4030
=> Training Epoch #0
| Epoch [  0/ 10] Iter[  1/391]		Loss: 2.3435
| Epoch [  0/ 10] Iter[ 21/391]		Loss: 2.5428
| Epoch [  0/ 10] Iter[ 41/391]		Loss: 2.1778
| Epoch [  0/ 10] Iter[ 61/391]		Loss: 2.0675
| Epoch [  0/ 10] Iter[ 81/391]		Loss: 2.0604
| Epoch [  0/ 10] Iter[101/391]		Loss: 1.9530
| Epoch [  0/ 10] Iter[121/391]		Loss: 1.9171
| Epoch [  0/ 10] Iter[141/391]		Loss: 1.7487
| Epoch [  0/ 10] Iter[161/391]		Loss: 1.7161
| Epoch [  0/ 10] Iter[181/391]		Loss: 1.7538
| Epoch [  0/ 10] Iter[201/391]		Loss: 1.5411
| Epoch [  0/ 10] Iter[221/391]		Loss: 1.5411
| Epoch [  0/ 10] Iter[241/391]		Loss: 1.6410
| Epoch [  0/ 10] Iter[261/391]		Loss: 1.3442
| Epoch [  0/ 10] Iter[281/391]		Loss: 1.6143
| Epoch [  0/ 10] Iter[301/391]		Loss: 1.5229
| Epoch [  0/ 10] Iter[321/391]		Loss: 1.4860
| Epoch [  0/ 10] Iter[341/391]		Loss: 1.3788
| Epoch [  0/ 10] Iter[361/391]		Loss: 1.5879
| Epoch [  0/ 10] Iter[381/391]		Loss: 1.4643
=> Training Epoch #1
| Epoch [  1/ 10] Iter[  1/391]		Loss: 1.2797
| Epoch [  1/ 10] Iter[ 21/391]		Loss: 1.2373
| Epoch [  1/ 10] Iter[ 41/391]		Loss: 1.2437
| Epoch [  1/ 10] Iter[ 61/391]		Loss: 1.1553
| Epoch [  1/ 10] Iter[ 81/391]		Loss: 1.2160
| Epoch [  1/ 10] Iter[101/391]		Loss: 1.3558
| Epoch [  1/ 10] Iter[121/391]		Loss: 1.1702
| Epoch [  1/ 10] Iter[141/391]		Loss: 1.2180
| Epoch [  1/ 10] Iter[161/391]		Loss: 1.2511
| Epoch [  1/ 10] Iter[181/391]		Loss: 1.2336
| Epoch [  1/ 10] Iter[201/391]		Loss: 1.0043
| Epoch [  1/ 10] Iter[221/391]		Loss: 1.1529
| Epoch [  1/ 10] Iter[241/391]		Loss: 1.2404
| Epoch [  1/ 10] Iter[261/391]		Loss: 0.9863
| Epoch [  1/ 10] Iter[281/391]		Loss: 1.1669
| Epoch [  1/ 10] Iter[301/391]		Loss: 1.3736
| Epoch [  1/ 10] Iter[321/391]		Loss: 1.0767
| Epoch [  1/ 10] Iter[341/391]		Loss: 0.8657
| Epoch [  1/ 10] Iter[361/391]		Loss: 1.1533
| Epoch [  1/ 10] Iter[381/391]		Loss: 1.0492
=> Training Epoch #2
| Epoch [  2/ 10] Iter[  1/391]		Loss: 1.0145
| Epoch [  2/ 10] Iter[ 21/391]		Loss: 1.0595
| Epoch [  2/ 10] Iter[ 41/391]		Loss: 0.9040
| Epoch [  2/ 10] Iter[ 61/391]		Loss: 0.8600
| Epoch [  2/ 10] Iter[ 81/391]		Loss: 0.9088
| Epoch [  2/ 10] Iter[101/391]		Loss: 0.9361
| Epoch [  2/ 10] Iter[121/391]		Loss: 1.0473
| Epoch [  2/ 10] Iter[141/391]		Loss: 0.7423
| Epoch [  2/ 10] Iter[161/391]		Loss: 1.1294
| Epoch [  2/ 10] Iter[181/391]		Loss: 1.0547
| Epoch [  2/ 10] Iter[201/391]		Loss: 0.8569
| Epoch [  2/ 10] Iter[221/391]		Loss: 0.9953
| Epoch [  2/ 10] Iter[241/391]		Loss: 0.8674
| Epoch [  2/ 10] Iter[261/391]		Loss: 1.0061
| Epoch [  2/ 10] Iter[281/391]		Loss: 0.9745
| Epoch [  2/ 10] Iter[301/391]		Loss: 1.0504
| Epoch [  2/ 10] Iter[321/391]		Loss: 0.8794
| Epoch [  2/ 10] Iter[341/391]		Loss: 0.7647
| Epoch [  2/ 10] Iter[361/391]		Loss: 0.7575
| Epoch [  2/ 10] Iter[381/391]		Loss: 0.7658
=> Training Epoch #3
| Epoch [  3/ 10] Iter[  1/391]		Loss: 0.7185
| Epoch [  3/ 10] Iter[ 21/391]		Loss: 0.8360
| Epoch [  3/ 10] Iter[ 41/391]		Loss: 0.8001
| Epoch [  3/ 10] Iter[ 61/391]		Loss: 0.9182
| Epoch [  3/ 10] Iter[ 81/391]		Loss: 0.5919
| Epoch [  3/ 10] Iter[101/391]		Loss: 0.6869
| Epoch [  3/ 10] Iter[121/391]		Loss: 0.7930
| Epoch [  3/ 10] Iter[141/391]		Loss: 0.6590
| Epoch [  3/ 10] Iter[161/391]		Loss: 0.8837
| Epoch [  3/ 10] Iter[181/391]		Loss: 0.7823
| Epoch [  3/ 10] Iter[201/391]		Loss: 0.7586
| Epoch [  3/ 10] Iter[221/391]		Loss: 0.7916
| Epoch [  3/ 10] Iter[241/391]		Loss: 0.7898
| Epoch [  3/ 10] Iter[261/391]		Loss: 0.7547
| Epoch [  3/ 10] Iter[281/391]		Loss: 0.7547
| Epoch [  3/ 10] Iter[301/391]		Loss: 0.8267
| Epoch [  3/ 10] Iter[321/391]		Loss: 0.7105
| Epoch [  3/ 10] Iter[341/391]		Loss: 0.6591
| Epoch [  3/ 10] Iter[361/391]		Loss: 0.8255
| Epoch [  3/ 10] Iter[381/391]		Loss: 0.6859
=> Training Epoch #4
| Epoch [  4/ 10] Iter[  1/391]		Loss: 0.5846
| Epoch [  4/ 10] Iter[ 21/391]		Loss: 0.5521
| Epoch [  4/ 10] Iter[ 41/391]		Loss: 0.6297
| Epoch [  4/ 10] Iter[ 61/391]		Loss: 0.5641
| Epoch [  4/ 10] Iter[ 81/391]		Loss: 0.5311
| Epoch [  4/ 10] Iter[101/391]		Loss: 0.7369
| Epoch [  4/ 10] Iter[121/391]		Loss: 0.5087
| Epoch [  4/ 10] Iter[141/391]		Loss: 0.6490
| Epoch [  4/ 10] Iter[161/391]		Loss: 0.5218
| Epoch [  4/ 10] Iter[181/391]		Loss: 0.6015
| Epoch [  4/ 10] Iter[201/391]		Loss: 0.6258
| Epoch [  4/ 10] Iter[221/391]		Loss: 0.7062
| Epoch [  4/ 10] Iter[241/391]		Loss: 0.6982
| Epoch [  4/ 10] Iter[261/391]		Loss: 0.6316
| Epoch [  4/ 10] Iter[281/391]		Loss: 0.6269
| Epoch [  4/ 10] Iter[301/391]		Loss: 0.5676
| Epoch [  4/ 10] Iter[321/391]		Loss: 0.5204
| Epoch [  4/ 10] Iter[341/391]		Loss: 0.6987
| Epoch [  4/ 10] Iter[361/391]		Loss: 0.5925
| Epoch [  4/ 10] Iter[381/391]		Loss: 0.5067
=> Training Epoch #5
| Epoch [  5/ 10] Iter[  1/391]		Loss: 0.5666
| Epoch [  5/ 10] Iter[ 21/391]		Loss: 0.4836
| Epoch [  5/ 10] Iter[ 41/391]		Loss: 0.5300
| Epoch [  5/ 10] Iter[ 61/391]		Loss: 0.4163
| Epoch [  5/ 10] Iter[ 81/391]		Loss: 0.4136
| Epoch [  5/ 10] Iter[101/391]		Loss: 0.4489
| Epoch [  5/ 10] Iter[121/391]		Loss: 0.5178
| Epoch [  5/ 10] Iter[141/391]		Loss: 0.5748
| Epoch [  5/ 10] Iter[161/391]		Loss: 0.5140
| Epoch [  5/ 10] Iter[181/391]		Loss: 0.5094
| Epoch [  5/ 10] Iter[201/391]		Loss: 0.5035
| Epoch [  5/ 10] Iter[221/391]		Loss: 0.4418
| Epoch [  5/ 10] Iter[241/391]		Loss: 0.4901
| Epoch [  5/ 10] Iter[261/391]		Loss: 0.5206
| Epoch [  5/ 10] Iter[281/391]		Loss: 0.4428
| Epoch [  5/ 10] Iter[301/391]		Loss: 0.4014
| Epoch [  5/ 10] Iter[321/391]		Loss: 0.4728
| Epoch [  5/ 10] Iter[341/391]		Loss: 0.5422
| Epoch [  5/ 10] Iter[361/391]		Loss: 0.5381
| Epoch [  5/ 10] Iter[381/391]		Loss: 0.4681
=> Training Epoch #6
| Epoch [  6/ 10] Iter[  1/391]		Loss: 0.4415
| Epoch [  6/ 10] Iter[ 21/391]		Loss: 0.4646
| Epoch [  6/ 10] Iter[ 41/391]		Loss: 0.3430
| Epoch [  6/ 10] Iter[ 61/391]		Loss: 0.4083
| Epoch [  6/ 10] Iter[ 81/391]		Loss: 0.4308
| Epoch [  6/ 10] Iter[101/391]		Loss: 0.3320
| Epoch [  6/ 10] Iter[121/391]		Loss: 0.4564
| Epoch [  6/ 10] Iter[141/391]		Loss: 0.4831
| Epoch [  6/ 10] Iter[161/391]		Loss: 0.3909
| Epoch [  6/ 10] Iter[181/391]		Loss: 0.6423
| Epoch [  6/ 10] Iter[201/391]		Loss: 0.3183
| Epoch [  6/ 10] Iter[221/391]		Loss: 0.3824
| Epoch [  6/ 10] Iter[241/391]		Loss: 0.4243
| Epoch [  6/ 10] Iter[261/391]		Loss: 0.4777
| Epoch [  6/ 10] Iter[281/391]		Loss: 0.5198
| Epoch [  6/ 10] Iter[301/391]		Loss: 0.5836
| Epoch [  6/ 10] Iter[321/391]		Loss: 0.5167
| Epoch [  6/ 10] Iter[341/391]		Loss: 0.4278
| Epoch [  6/ 10] Iter[361/391]		Loss: 0.4930
| Epoch [  6/ 10] Iter[381/391]		Loss: 0.4299
=> Training Epoch #7
| Epoch [  7/ 10] Iter[  1/391]		Loss: 0.3061
| Epoch [  7/ 10] Iter[ 21/391]		Loss: 0.3230
| Epoch [  7/ 10] Iter[ 41/391]		Loss: 0.3029
| Epoch [  7/ 10] Iter[ 61/391]		Loss: 0.3319
| Epoch [  7/ 10] Iter[ 81/391]		Loss: 0.3672
| Epoch [  7/ 10] Iter[101/391]		Loss: 0.2865
| Epoch [  7/ 10] Iter[121/391]		Loss: 0.3378
| Epoch [  7/ 10] Iter[141/391]		Loss: 0.3884
| Epoch [  7/ 10] Iter[161/391]		Loss: 0.3599
| Epoch [  7/ 10] Iter[181/391]		Loss: 0.2389
| Epoch [  7/ 10] Iter[201/391]		Loss: 0.2990
| Epoch [  7/ 10] Iter[221/391]		Loss: 0.4565
| Epoch [  7/ 10] Iter[241/391]		Loss: 0.3370
| Epoch [  7/ 10] Iter[261/391]		Loss: 0.3092
| Epoch [  7/ 10] Iter[281/391]		Loss: 0.4885
| Epoch [  7/ 10] Iter[301/391]		Loss: 0.3558
| Epoch [  7/ 10] Iter[321/391]		Loss: 0.3265
| Epoch [  7/ 10] Iter[341/391]		Loss: 0.4446
| Epoch [  7/ 10] Iter[361/391]		Loss: 0.3434
| Epoch [  7/ 10] Iter[381/391]		Loss: 0.4300
=> Training Epoch #8
| Epoch [  8/ 10] Iter[  1/391]		Loss: 0.3553
| Epoch [  8/ 10] Iter[ 21/391]		Loss: 0.4224
| Epoch [  8/ 10] Iter[ 41/391]		Loss: 0.2014
| Epoch [  8/ 10] Iter[ 61/391]		Loss: 0.2688
| Epoch [  8/ 10] Iter[ 81/391]		Loss: 0.2711
| Epoch [  8/ 10] Iter[101/391]		Loss: 0.3477
| Epoch [  8/ 10] Iter[121/391]		Loss: 0.2393
| Epoch [  8/ 10] Iter[141/391]		Loss: 0.3564
| Epoch [  8/ 10] Iter[161/391]		Loss: 0.2861
| Epoch [  8/ 10] Iter[181/391]		Loss: 0.3429
| Epoch [  8/ 10] Iter[201/391]		Loss: 0.3454
| Epoch [  8/ 10] Iter[221/391]		Loss: 0.3904
| Epoch [  8/ 10] Iter[241/391]		Loss: 0.4640
| Epoch [  8/ 10] Iter[261/391]		Loss: 0.3463
| Epoch [  8/ 10] Iter[281/391]		Loss: 0.3812
| Epoch [  8/ 10] Iter[301/391]		Loss: 0.3109
| Epoch [  8/ 10] Iter[321/391]		Loss: 0.4563
| Epoch [  8/ 10] Iter[341/391]		Loss: 0.3180
| Epoch [  8/ 10] Iter[361/391]		Loss: 0.2270
| Epoch [  8/ 10] Iter[381/391]		Loss: 0.1886
=> Training Epoch #9
| Epoch [  9/ 10] Iter[  1/391]		Loss: 0.5299
| Epoch [  9/ 10] Iter[ 21/391]		Loss: 0.2760
| Epoch [  9/ 10] Iter[ 41/391]		Loss: 0.2758
| Epoch [  9/ 10] Iter[ 61/391]		Loss: 0.3441
| Epoch [  9/ 10] Iter[ 81/391]		Loss: 0.2844
| Epoch [  9/ 10] Iter[101/391]		Loss: 0.3817
| Epoch [  9/ 10] Iter[121/391]		Loss: 0.1850
| Epoch [  9/ 10] Iter[141/391]		Loss: 0.3661
| Epoch [  9/ 10] Iter[161/391]		Loss: 0.3689
| Epoch [  9/ 10] Iter[181/391]		Loss: 0.3566
| Epoch [  9/ 10] Iter[201/391]		Loss: 0.3307
| Epoch [  9/ 10] Iter[221/391]		Loss: 0.3670
| Epoch [  9/ 10] Iter[241/391]		Loss: 0.3576
| Epoch [  9/ 10] Iter[261/391]		Loss: 0.2755
| Epoch [  9/ 10] Iter[281/391]		Loss: 0.2894
| Epoch [  9/ 10] Iter[301/391]		Loss: 0.3834
| Epoch [  9/ 10] Iter[321/391]		Loss: 0.3983
| Epoch [  9/ 10] Iter[341/391]		Loss: 0.4548
| Epoch [  9/ 10] Iter[361/391]		Loss: 0.3607
| Epoch [  9/ 10] Iter[381/391]		Loss: 0.4249
=> Training Epoch #0
| Epoch [  0/ 10] Iter[  1/391]		Loss: 2.4856
| Epoch [  0/ 10] Iter[ 21/391]		Loss: 2.5910
| Epoch [  0/ 10] Iter[ 41/391]		Loss: 2.1792
| Epoch [  0/ 10] Iter[ 61/391]		Loss: 2.0880
| Epoch [  0/ 10] Iter[ 81/391]		Loss: 1.9436
| Epoch [  0/ 10] Iter[101/391]		Loss: 1.8546
| Epoch [  0/ 10] Iter[121/391]		Loss: 1.9131
| Epoch [  0/ 10] Iter[141/391]		Loss: 1.8470
| Epoch [  0/ 10] Iter[161/391]		Loss: 1.7216
| Epoch [  0/ 10] Iter[181/391]		Loss: 1.8769
| Epoch [  0/ 10] Iter[201/391]		Loss: 1.8407
| Epoch [  0/ 10] Iter[221/391]		Loss: 1.5424
| Epoch [  0/ 10] Iter[241/391]		Loss: 1.5665
| Epoch [  0/ 10] Iter[261/391]		Loss: 1.5642
| Epoch [  0/ 10] Iter[281/391]		Loss: 1.4526
| Epoch [  0/ 10] Iter[301/391]		Loss: 1.5413
| Epoch [  0/ 10] Iter[321/391]		Loss: 1.4800
| Epoch [  0/ 10] Iter[341/391]		Loss: 1.5117
| Epoch [  0/ 10] Iter[361/391]		Loss: 1.7683
| Epoch [  0/ 10] Iter[381/391]		Loss: 1.4417
=> Training Epoch #1
| Epoch [  1/ 10] Iter[  1/391]		Loss: 1.6716
| Epoch [  1/ 10] Iter[ 21/391]		Loss: 1.5666
| Epoch [  1/ 10] Iter[ 41/391]		Loss: 1.3863
| Epoch [  1/ 10] Iter[ 61/391]		Loss: 1.5205
| Epoch [  1/ 10] Iter[ 81/391]		Loss: 1.3403
| Epoch [  1/ 10] Iter[101/391]		Loss: 1.3935
| Epoch [  1/ 10] Iter[121/391]		Loss: 1.2892
| Epoch [  1/ 10] Iter[141/391]		Loss: 1.3415
| Epoch [  1/ 10] Iter[161/391]		Loss: 1.2532
| Epoch [  1/ 10] Iter[181/391]		Loss: 1.2991
| Epoch [  1/ 10] Iter[201/391]		Loss: 1.2270
| Epoch [  1/ 10] Iter[221/391]		Loss: 1.2270
| Epoch [  1/ 10] Iter[241/391]		Loss: 1.0897
| Epoch [  1/ 10] Iter[261/391]		Loss: 1.2369
| Epoch [  1/ 10] Iter[281/391]		Loss: 1.0168
| Epoch [  1/ 10] Iter[301/391]		Loss: 1.0326
| Epoch [  1/ 10] Iter[321/391]		Loss: 1.0660
| Epoch [  1/ 10] Iter[341/391]		Loss: 1.0095
| Epoch [  1/ 10] Iter[361/391]		Loss: 1.0974
| Epoch [  1/ 10] Iter[381/391]		Loss: 1.2184
=> Training Epoch #2
| Epoch [  2/ 10] Iter[  1/391]		Loss: 1.1513
| Epoch [  2/ 10] Iter[ 21/391]		Loss: 1.2187
| Epoch [  2/ 10] Iter[ 41/391]		Loss: 0.9610
| Epoch [  2/ 10] Iter[ 61/391]		Loss: 0.9643
| Epoch [  2/ 10] Iter[ 81/391]		Loss: 1.0570
| Epoch [  2/ 10] Iter[101/391]		Loss: 1.1248
| Epoch [  2/ 10] Iter[121/391]		Loss: 1.1174
| Epoch [  2/ 10] Iter[141/391]		Loss: 0.9302
| Epoch [  2/ 10] Iter[161/391]		Loss: 0.9221
| Epoch [  2/ 10] Iter[181/391]		Loss: 1.1162
| Epoch [  2/ 10] Iter[201/391]		Loss: 0.9831
| Epoch [  2/ 10] Iter[221/391]		Loss: 0.8179
| Epoch [  2/ 10] Iter[241/391]		Loss: 1.0522
| Epoch [  2/ 10] Iter[261/391]		Loss: 0.7578
| Epoch [  2/ 10] Iter[281/391]		Loss: 0.9276
| Epoch [  2/ 10] Iter[301/391]		Loss: 0.9407
| Epoch [  2/ 10] Iter[321/391]		Loss: 0.8599
| Epoch [  2/ 10] Iter[341/391]		Loss: 0.9789
| Epoch [  2/ 10] Iter[361/391]		Loss: 1.0186
| Epoch [  2/ 10] Iter[381/391]		Loss: 0.7837
=> Training Epoch #3
| Epoch [  3/ 10] Iter[  1/391]		Loss: 0.9257
| Epoch [  3/ 10] Iter[ 21/391]		Loss: 0.7053
| Epoch [  3/ 10] Iter[ 41/391]		Loss: 0.8020
| Epoch [  3/ 10] Iter[ 61/391]		Loss: 0.7952
| Epoch [  3/ 10] Iter[ 81/391]		Loss: 0.9583
| Epoch [  3/ 10] Iter[101/391]		Loss: 0.8502
| Epoch [  3/ 10] Iter[121/391]		Loss: 0.7603
| Epoch [  3/ 10] Iter[141/391]		Loss: 0.9138
| Epoch [  3/ 10] Iter[161/391]		Loss: 0.7766
| Epoch [  3/ 10] Iter[181/391]		Loss: 0.7078
| Epoch [  3/ 10] Iter[201/391]		Loss: 0.8005
| Epoch [  3/ 10] Iter[221/391]		Loss: 0.6743
| Epoch [  3/ 10] Iter[241/391]		Loss: 0.7545
| Epoch [  3/ 10] Iter[261/391]		Loss: 0.7051
| Epoch [  3/ 10] Iter[281/391]		Loss: 0.6502
| Epoch [  3/ 10] Iter[301/391]		Loss: 0.7043
| Epoch [  3/ 10] Iter[321/391]		Loss: 0.6654
| Epoch [  3/ 10] Iter[341/391]		Loss: 0.8792
| Epoch [  3/ 10] Iter[361/391]		Loss: 0.6790
| Epoch [  3/ 10] Iter[381/391]		Loss: 0.8431
=> Training Epoch #4
| Epoch [  4/ 10] Iter[  1/391]		Loss: 0.7455
| Epoch [  4/ 10] Iter[ 21/391]		Loss: 0.5767
| Epoch [  4/ 10] Iter[ 41/391]		Loss: 0.6719
| Epoch [  4/ 10] Iter[ 61/391]		Loss: 0.6497
| Epoch [  4/ 10] Iter[ 81/391]		Loss: 0.6517
| Epoch [  4/ 10] Iter[101/391]		Loss: 0.6884
| Epoch [  4/ 10] Iter[121/391]		Loss: 0.6936
| Epoch [  4/ 10] Iter[141/391]		Loss: 0.8474
| Epoch [  4/ 10] Iter[161/391]		Loss: 0.7138
| Epoch [  4/ 10] Iter[181/391]		Loss: 0.6478
| Epoch [  4/ 10] Iter[201/391]		Loss: 0.6750
| Epoch [  4/ 10] Iter[221/391]		Loss: 0.5476
| Epoch [  4/ 10] Iter[241/391]		Loss: 0.5529
| Epoch [  4/ 10] Iter[261/391]		Loss: 0.6454
| Epoch [  4/ 10] Iter[281/391]		Loss: 0.5734
| Epoch [  4/ 10] Iter[301/391]		Loss: 0.6667
| Epoch [  4/ 10] Iter[321/391]		Loss: 0.5605
| Epoch [  4/ 10] Iter[341/391]		Loss: 0.6532
| Epoch [  4/ 10] Iter[361/391]		Loss: 0.5676
| Epoch [  4/ 10] Iter[381/391]		Loss: 0.6014
=> Training Epoch #5
| Epoch [  5/ 10] Iter[  1/391]		Loss: 0.5754
| Epoch [  5/ 10] Iter[ 21/391]		Loss: 0.4739
| Epoch [  5/ 10] Iter[ 41/391]		Loss: 0.4123
| Epoch [  5/ 10] Iter[ 61/391]		Loss: 0.5044
| Epoch [  5/ 10] Iter[ 81/391]		Loss: 0.5568
| Epoch [  5/ 10] Iter[101/391]		Loss: 0.5285
| Epoch [  5/ 10] Iter[121/391]		Loss: 0.5029
| Epoch [  5/ 10] Iter[141/391]		Loss: 0.6116
| Epoch [  5/ 10] Iter[161/391]		Loss: 0.5124
| Epoch [  5/ 10] Iter[181/391]		Loss: 0.4629
| Epoch [  5/ 10] Iter[201/391]		Loss: 0.6848
| Epoch [  5/ 10] Iter[221/391]		Loss: 0.5490
| Epoch [  5/ 10] Iter[241/391]		Loss: 0.6102
| Epoch [  5/ 10] Iter[261/391]		Loss: 0.6416
| Epoch [  5/ 10] Iter[281/391]		Loss: 0.5727
| Epoch [  5/ 10] Iter[301/391]		Loss: 0.6364
| Epoch [  5/ 10] Iter[321/391]		Loss: 0.5317
| Epoch [  5/ 10] Iter[341/391]		Loss: 0.4325
| Epoch [  5/ 10] Iter[361/391]		Loss: 0.7646
| Epoch [  5/ 10] Iter[381/391]		Loss: 0.6247
=> Training Epoch #6
| Epoch [  6/ 10] Iter[  1/391]		Loss: 0.4856
| Epoch [  6/ 10] Iter[ 21/391]		Loss: 0.5242
| Epoch [  6/ 10] Iter[ 41/391]		Loss: 0.5113
| Epoch [  6/ 10] Iter[ 61/391]		Loss: 0.3970
| Epoch [  6/ 10] Iter[ 81/391]		Loss: 0.5302
| Epoch [  6/ 10] Iter[101/391]		Loss: 0.5127
| Epoch [  6/ 10] Iter[121/391]		Loss: 0.3826
| Epoch [  6/ 10] Iter[141/391]		Loss: 0.4828
| Epoch [  6/ 10] Iter[161/391]		Loss: 0.4835
| Epoch [  6/ 10] Iter[181/391]		Loss: 0.5277
| Epoch [  6/ 10] Iter[201/391]		Loss: 0.5716
| Epoch [  6/ 10] Iter[221/391]		Loss: 0.5160
| Epoch [  6/ 10] Iter[241/391]		Loss: 0.6350
| Epoch [  6/ 10] Iter[261/391]		Loss: 0.4384
| Epoch [  6/ 10] Iter[281/391]		Loss: 0.5438
| Epoch [  6/ 10] Iter[301/391]		Loss: 0.5295
| Epoch [  6/ 10] Iter[321/391]		Loss: 0.5682
| Epoch [  6/ 10] Iter[341/391]		Loss: 0.4797
| Epoch [  6/ 10] Iter[361/391]		Loss: 0.5331
| Epoch [  6/ 10] Iter[381/391]		Loss: 0.4365
=> Training Epoch #7
| Epoch [  7/ 10] Iter[  1/391]		Loss: 0.3681
| Epoch [  7/ 10] Iter[ 21/391]		Loss: 0.3691
| Epoch [  7/ 10] Iter[ 41/391]		Loss: 0.3882
| Epoch [  7/ 10] Iter[ 61/391]		Loss: 0.4786
| Epoch [  7/ 10] Iter[ 81/391]		Loss: 0.2933
| Epoch [  7/ 10] Iter[101/391]		Loss: 0.3247
| Epoch [  7/ 10] Iter[121/391]		Loss: 0.4474
| Epoch [  7/ 10] Iter[141/391]		Loss: 0.4560
| Epoch [  7/ 10] Iter[161/391]		Loss: 0.4215
| Epoch [  7/ 10] Iter[181/391]		Loss: 0.3889
| Epoch [  7/ 10] Iter[201/391]		Loss: 0.2351
| Epoch [  7/ 10] Iter[221/391]		Loss: 0.3460
| Epoch [  7/ 10] Iter[241/391]		Loss: 0.4330
| Epoch [  7/ 10] Iter[261/391]		Loss: 0.5906
| Epoch [  7/ 10] Iter[281/391]		Loss: 0.5095
| Epoch [  7/ 10] Iter[301/391]		Loss: 0.5008
| Epoch [  7/ 10] Iter[321/391]		Loss: 0.5181
| Epoch [  7/ 10] Iter[341/391]		Loss: 0.3955
| Epoch [  7/ 10] Iter[361/391]		Loss: 0.5253
| Epoch [  7/ 10] Iter[381/391]		Loss: 0.5629
=> Training Epoch #8
| Epoch [  8/ 10] Iter[  1/391]		Loss: 0.2143
| Epoch [  8/ 10] Iter[ 21/391]		Loss: 0.2397
| Epoch [  8/ 10] Iter[ 41/391]		Loss: 0.2614
| Epoch [  8/ 10] Iter[ 61/391]		Loss: 0.1903
| Epoch [  8/ 10] Iter[ 81/391]		Loss: 0.3133
| Epoch [  8/ 10] Iter[101/391]		Loss: 0.2323
| Epoch [  8/ 10] Iter[121/391]		Loss: 0.5034
| Epoch [  8/ 10] Iter[141/391]		Loss: 0.4303
| Epoch [  8/ 10] Iter[161/391]		Loss: 0.2684
| Epoch [  8/ 10] Iter[181/391]		Loss: 0.5901
| Epoch [  8/ 10] Iter[201/391]		Loss: 0.3311
| Epoch [  8/ 10] Iter[221/391]		Loss: 0.5432
| Epoch [  8/ 10] Iter[241/391]		Loss: 0.4619
| Epoch [  8/ 10] Iter[261/391]		Loss: 0.4720
| Epoch [  8/ 10] Iter[281/391]		Loss: 0.3693
| Epoch [  8/ 10] Iter[301/391]		Loss: 0.3288
| Epoch [  8/ 10] Iter[321/391]		Loss: 0.4080
| Epoch [  8/ 10] Iter[341/391]		Loss: 0.5326
| Epoch [  8/ 10] Iter[361/391]		Loss: 0.2622
| Epoch [  8/ 10] Iter[381/391]		Loss: 0.4082
=> Training Epoch #9
| Epoch [  9/ 10] Iter[  1/391]		Loss: 0.3097
| Epoch [  9/ 10] Iter[ 21/391]		Loss: 0.2523
| Epoch [  9/ 10] Iter[ 41/391]		Loss: 0.2741
| Epoch [  9/ 10] Iter[ 61/391]		Loss: 0.3670
| Epoch [  9/ 10] Iter[ 81/391]		Loss: 0.2284
| Epoch [  9/ 10] Iter[101/391]		Loss: 0.2689
| Epoch [  9/ 10] Iter[121/391]		Loss: 0.3717
| Epoch [  9/ 10] Iter[141/391]		Loss: 0.2532
| Epoch [  9/ 10] Iter[161/391]		Loss: 0.3754
| Epoch [  9/ 10] Iter[181/391]		Loss: 0.3441
| Epoch [  9/ 10] Iter[201/391]		Loss: 0.3518
| Epoch [  9/ 10] Iter[221/391]		Loss: 0.2866
| Epoch [  9/ 10] Iter[241/391]		Loss: 0.4496
| Epoch [  9/ 10] Iter[261/391]		Loss: 0.3786
| Epoch [  9/ 10] Iter[281/391]		Loss: 0.3455
| Epoch [  9/ 10] Iter[301/391]		Loss: 0.4634
| Epoch [  9/ 10] Iter[321/391]		Loss: 0.2400
| Epoch [  9/ 10] Iter[341/391]		Loss: 0.2456
| Epoch [  9/ 10] Iter[361/391]		Loss: 0.3907
| Epoch [  9/ 10] Iter[381/391]		Loss: 0.2698
=> Training Epoch #0
| Epoch [  0/ 10] Iter[  1/391]		Loss: 2.4520
| Epoch [  0/ 10] Iter[ 21/391]		Loss: 2.5309
| Epoch [  0/ 10] Iter[ 41/391]		Loss: 2.0522
| Epoch [  0/ 10] Iter[ 61/391]		Loss: 2.1038
| Epoch [  0/ 10] Iter[ 81/391]		Loss: 1.9940
| Epoch [  0/ 10] Iter[101/391]		Loss: 1.9430
| Epoch [  0/ 10] Iter[121/391]		Loss: 1.8077
| Epoch [  0/ 10] Iter[141/391]		Loss: 1.8985
| Epoch [  0/ 10] Iter[161/391]		Loss: 1.8232
| Epoch [  0/ 10] Iter[181/391]		Loss: 1.6457
| Epoch [  0/ 10] Iter[201/391]		Loss: 1.7293
| Epoch [  0/ 10] Iter[221/391]		Loss: 1.9026
| Epoch [  0/ 10] Iter[241/391]		Loss: 1.5524
| Epoch [  0/ 10] Iter[261/391]		Loss: 1.4968
| Epoch [  0/ 10] Iter[281/391]		Loss: 1.5883
| Epoch [  0/ 10] Iter[301/391]		Loss: 1.5717
| Epoch [  0/ 10] Iter[321/391]		Loss: 1.5207
| Epoch [  0/ 10] Iter[341/391]		Loss: 1.5772
| Epoch [  0/ 10] Iter[361/391]		Loss: 1.5079
| Epoch [  0/ 10] Iter[381/391]		Loss: 1.2953
=> Training Epoch #1
| Epoch [  1/ 10] Iter[  1/391]		Loss: 1.3683
| Epoch [  1/ 10] Iter[ 21/391]		Loss: 1.3600
| Epoch [  1/ 10] Iter[ 41/391]		Loss: 1.3885
| Epoch [  1/ 10] Iter[ 61/391]		Loss: 1.3279
Traceback (most recent call last):
  File "/home/yancheng/code/DeepCore/main.py", line 345, in <module>
    main()
  File "/home/yancheng/code/DeepCore/main.py", line 172, in main
    subset = method.select()
  File "/home/yancheng/code/DeepCore/deepcore/methods/grand.py", line 62, in select
    self.run()
  File "/home/yancheng/code/DeepCore/deepcore/methods/earlytrain.py", line 140, in run
    self.train(epoch, list_of_train_idx)
  File "/home/yancheng/code/DeepCore/deepcore/methods/earlytrain.py", line 90, in train
    self.while_update(outputs, loss, targets, epoch, i, self.args.selection_batch)
  File "/home/yancheng/code/DeepCore/deepcore/methods/grand.py", line 22, in while_update
    epoch, self.epochs, batch_idx + 1, (self.n_train // batch_size) + 1, loss.item()))
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yancheng/code/DeepCore/main.py", line 345, in <module>
    main()
  File "/home/yancheng/code/DeepCore/main.py", line 172, in main
    subset = method.select()
  File "/home/yancheng/code/DeepCore/deepcore/methods/grand.py", line 62, in select
    self.run()
  File "/home/yancheng/code/DeepCore/deepcore/methods/earlytrain.py", line 140, in run
    self.train(epoch, list_of_train_idx)
  File "/home/yancheng/code/DeepCore/deepcore/methods/earlytrain.py", line 90, in train
    self.while_update(outputs, loss, targets, epoch, i, self.args.selection_batch)
  File "/home/yancheng/code/DeepCore/deepcore/methods/grand.py", line 22, in while_update
    epoch, self.epochs, batch_idx + 1, (self.n_train // batch_size) + 1, loss.item()))
KeyboardInterrupt